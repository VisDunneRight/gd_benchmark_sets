"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"D³ Data-Driven Documents","M. Bostock; V. Ogievetsky; J. Heer","Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA; Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA; Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2301","2309","Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.","1941-0506","","10.1109/TVCG.2011.185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064996","Information visualization;user interfaces;toolkits;2D graphics.","Data visualization;Cascading style sheets;Image color analysis;Debugging;Information analysis","computer animation;data visualisation;document handling;user interfaces;Web sites","data-driven documents;representation-transparent approach;Web visualization;toolkit-specific abstraction;native representation;standard document object model;document elements;dynamic transforms;representational transparency;animation;scene graph","","1628","13","41","","3 Nov 2011","","","IEEE","IEEE Journals"
"UpSet: Visualization of Intersecting Sets","A. Lex; N. Gehlenborg; H. Strobelt; R. Vuillemot; H. Pfister",Hendrik Strobelt and Hanspeter Pfister are with Harvard University.; Harvard Medical School; Hendrik Strobelt and Hanspeter Pfister are with Harvard University.; Romain Vuillemot is with Harvard University; Hendrik Strobelt and Hanspeter Pfister are with Harvard University.,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1983","1992","Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.","1941-0506","","10.1109/TVCG.2014.2346248","Austrian Science Fund (J 3437-N15) the Air Force Research Laboratory and DARPA(grant numbers:FA8750-12-C-0300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876017","Sets;set visualization;sets intersections;set attributes;set relationships;multidimensional data","Data visualization;Visualization;Power generation;Sorting;Information analysis","combinatorial mathematics;data visualisation;duality (mathematics);Internet;mathematics computing;matrix algebra;public domain software;set theory;sorting","visualization community;combinatorial explosion;set intersection visualization;UpSet;quantitative set analysis;task-driven aggregates;duality;matrix layout;associated data representation;summary statistics;subset attributes;element attributes;task-driven analysis;queries;groupings;advanced visual encodings;Web-based approach;open source approach","Computer Graphics;Databases, Factual;Informatics","826","","29","OAPA","6 Nov 2014","","","IEEE","IEEE Journals"
"Graph visualization and navigation in information visualization: A survey","I. Herman; G. Melancon; M. S. Marshall","Centre for Math. & Comput. Sci., CWI, Amsterdam, Netherlands; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2000","6","1","24","43","This is a survey on graph visualization and navigation techniques, as used in information visualization. Graphs appear in numerous applications such as Web browsing, state-transition diagrams, and data structures. The ability to visualize and to navigate in these potentially large, abstract graphs is often a crucial part of an application. Information visualization has specific requirements, which means that this survey approaches the results of traditional graph drawing from a different perspective.","1941-0506","","10.1109/2945.841119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=841119","","Navigation;Data visualization;Tree graphs;Application software;Data structures;Project management;Usability;Computer Society;Books;Taxonomy","data visualisation;graphs","graph visualization;graph navigation;information visualization;Web browsing;state-transition diagrams;data structures;abstract graphs;graph drawing","","819","33","130","","6 Aug 2002","","","IEEE","IEEE Journals"
"Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data","D. Holten",Technische Univ. Eindhoven,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","741","748","A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations.","1941-0506","","10.1109/TVCG.2006.147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015425","Network visualization;edge bundling;edge aggregation;edge concentration;curves;graph visualization;tree visualization;node-link diagrams;hierarchies;treemaps.","Data visualization;Tree graphs;Wires;Cables;Spline;Software systems;Social network services;Displays;Tree data structures","curve fitting;data visualisation;splines (mathematics);tree data structures;trees (mathematics)","hierarchical edge bundles;adjacency relation visualization;hierarchical data;compound graph;tree visualization method;B-spline curve;visual clutter","","567","18","33","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"A visibility matching tone reproduction operator for high dynamic range scenes","G. W. Larson; H. Rushmeier; C. Piatko","Silicon Graphics Comput. Syst., Mountain View, CA, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1997","3","4","291","306","We present a tone reproduction operator that preserves visibility in high dynamic range scenes. Our method introduces a new histogram adjustment technique, based on the population of local adaptation luminances in a scene. To match subjective viewing experience, the method incorporates models for human contrast sensitivity, glare, spatial acuity, and color sensitivity. We compare our results to previous work and present examples of our techniques applied to lighting simulation and electronic photography.","1941-0506","","10.1109/2945.646233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=646233","","Dynamic range;Layout;Humans;Photography;Computer displays;Image generation;Histograms;Image converters;Chemistry;Lighting control","computer graphics;user interfaces;brightness;lighting;digital simulation;photography;visibility","visibility matching;tone reproduction operator;high dynamic range scenes;histogram adjustment technique;local adaptation luminances;subjective viewing experience;human contrast sensitivity;glare;spatial acuity;color sensitivity;lighting simulation;electronic photography","","449","64","26","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Edgebreaker: connectivity compression for triangle meshes","J. Rossignac","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1999","5","1","47","61","Edgebreaker is a simple scheme for compressing the triangle/vertex incidence graphs (sometimes called connectivity or topology) of three-dimensional triangle meshes. Edgebreaker improves upon the storage required by previously reported schemes, most of which can guarantee only an O(t log(t)) storage cost for the incidence graph of a mesh of t triangles. Edgebreaker requires at most 2t bits for any mesh homeomorphic to a sphere and supports fully general meshes by using additional storage per handle and hole. For large meshes, entropy coding yields less than 1.5 bits per triangle. Edgebreaker's compression and decompression processes perform identical traversals of the mesh from one triangle to an adjacent one. At each stage, compression produces an op-code describing the topological relation between the current triangle and the boundary of the remaining part of the mesh. Decompression uses these op-codes to reconstruct the entire incidence graph. Because Edgebreaker's compression and decompression are independent of the vertex locations, they may be combined with a variety of vertex-compressing techniques that exploit topological information about the mesh to better estimate vertex locations. Edgebreaker may be used to compress the connectivity of an entire mesh bounding a 3D polyhedron or the connectivity of a triangulated surface patch whose boundary need not be encoded. The paper also offers a comparative survey of the rapidly growing field of geometric compression.","1941-0506","","10.1109/2945.764870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=764870","","Computer graphics;Solid modeling;Costs;Application software;Topology;Entropy coding;Computer architecture;Petroleum;Computational modeling;Analytical models","solid modelling;data compression;computational geometry;mesh generation;graph theory","Edgebreaker;connectivity compression;triangle meshes;triangle-vertex incidence graphs;topology;storage cost;entropy coding;geometric compression;decompression;vertex locations;vertex-compressing techniques;3D polyhedron;triangulated surface patch;3D models;solid modelling","","363","11","41","","6 Aug 2002","","","IEEE","IEEE Journals"
"NodeTrix: a Hybrid Visualization of Social Networks","N. Henry; J. Fekete; M. J. McGuffin","INRIA Futurs/University Paris-Sud, France and University of Sydney, Australia; INRIA Futurs, France; Ontario Cancer Institute and University of Toronto, Canada","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1302","1309","The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.","1941-0506","","10.1109/TVCG.2007.70582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376154","Network visualization;Matrix visualization;Hybrid visualization;Aggregation;Interaction.","Layout;Color;Animation;Matrix converters;Sparse matrices;Aggregates","data structures;data visualisation;matrix algebra;social sciences computing","NodeTrix visualization;social networks hybrid visualization;hardware capabilities;hybrid representation;adjacency matrices;interaction techniques;dragging selections;InfoVis 2004 coauthorship dataset","Algorithms;Computer Graphics;Computer Simulation;Models, Theoretical;Social Support;User-Computer Interface","306","5","35","","5 Nov 2007","","","IEEE","IEEE Journals"
"Real-time markerless tracking for augmented reality: the virtual visual servoing framework","A. I. Comport; E. Marchand; M. Pressigout; F. Chaumette","IRISA-INRIA Rennes, France; IRISA-INRIA Rennes, France; IRISA-INRIA Rennes, France; IRISA-INRIA Rennes, France","IEEE Transactions on Visualization and Computer Graphics","5 Jun 2006","2006","12","4","615","628","Tracking is a very important research subject in a real-time augmented reality context. The main requirements for trackers are high accuracy and little latency at a reasonable cost. In order to address these issues, a real-time, robust, and efficient 3D model-based tracking algorithm is proposed for a ""video see through"" monocular vision system. The tracking of objects in the scene amounts to calculating the pose between the camera and the objects. Virtual objects can then be projected into the scene using the pose. In this paper, nonlinear pose estimation is formulated by means of a virtual visual servoing approach. In this context, the derivation of point-to-curves interaction matrices are given for different 3D geometrical primitives including straight lines, circles, cylinders, and spheres. A local moving edges tracker is used in order to provide real-time tracking of points normal to the object contours. Robustness is obtained by integrating an M-estimator into the visual control law via an iteratively reweighted least squares implementation. This approach is then extended to address the 3D model-free augmented reality problem. The method presented in this paper has been validated on several complex image sequences including outdoor environments. Results show the method to be robust to occlusion, changes in illumination, and mistracking.","1941-0506","","10.1109/TVCG.2006.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634325","Augmented reality;virtual visual servoing;robust estimators;real-time;model-based tracking;model-free tracking.","Augmented reality;Visual servoing;Robustness;Layout;Delay;Costs;Real time systems;Machine vision;Cameras;Robust control","computational geometry;image motion analysis;augmented reality;tracking;object detection;image sequences;least squares approximations","real-time markerless tracking;3D model-free augmented reality;virtual visual servoing framework;3D model-based tracking algorithm;monocular vision system;virtual objects;point-to-curves interaction matrices;3D geometrical primitives;M-estimator;visual control law;image sequences","Algorithms;Computer Graphics;Computer Systems;Feedback;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Signal Processing, Computer-Assisted;User-Computer Interface","305","14","55","","5 Jun 2006","","","IEEE","IEEE Journals"
"What Makes a Visualization Memorable?","M. A. Borkin; A. A. Vo; Z. Bylinskii; P. Isola; S. Sunkavalli; A. Oliva; H. Pfister",Harvard University; Harvard University; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Harvard University; Massachusetts Institute of Technology; Harvard University,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2306","2315","An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.","1941-0506","","10.1109/TVCG.2013.234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634103","Data visualization;Taxonomy;Information technology;Encoding;memorability;Visualization taxonomy;information visualization","Data visualization;Taxonomy;Information technology;Encoding","data visualisation","visualization community;data understanding;visualization type;news media sites;government reports;scientific journals;infographic sources;data-ink ratios;visual densities;Amazon;Mechanical Turk;memorability scores","Artificial Intelligence;Cues;Humans;Image Interpretation, Computer-Assisted;Memory;Pattern Recognition, Visual;Task Performance and Analysis;User-Computer Interface","261","1","39","","16 Oct 2013","","","IEEE","IEEE Journals"
"Dynamic range reduction inspired by photoreceptor physiology","E. Reinhard; K. Devlin","Sch. of Comput. Sci., Univ. of Central Florida, Orlando, FL, USA; NA","IEEE Transactions on Visualization and Computer Graphics","17 Jan 2005","2005","11","1","13","24","A common task in computer graphics is the mapping of digital high dynamic range images to low dynamic range display devices such as monitors and printers. This task is similar to the adaptation processes which occur in the human visual system. Physiological evidence suggests that adaptation already occurs in the photoreceptors, leading to a straightforward model that can be easily adapted for tone reproduction. The result is a fast and practical algorithm for general use with intuitive user parameters that control intensity, contrast, and level of chromatic adaptation, respectively.","1941-0506","","10.1109/TVCG.2005.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359728","Index Terms- Tone reproduction;dynamic range reduction;photoreceptor physiology.","Dynamic range;Photoreceptors;Physiology;Layout;Liquid crystal displays;Computer displays;Printers;Computer graphics;Data acquisition;Computer Society","rendering (computer graphics);digital photography;image reconstruction","tone reproduction;dynamic range reduction;photoreceptor physiology;computer graphics rendering","Algorithms;Animals;Biomimetics;Color;Computer Graphics;Data Display;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Biological;Online Systems;Photoreceptors;Signal Processing, Computer-Assisted;User-Computer Interface;Vision","240","19","42","IEEE","17 Jan 2005","","","IEEE","IEEE Journals"
"Stacked Graphs – Geometry & Aesthetics","L. Byron; M. Wattenberg",The New York Times; Visual Communication Lab at IBM,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1245","1252","In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.","1941-0506","","10.1109/TVCG.2008.166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658136","Index Terms—;Streamgraph;ThemeRiver;listening history;last.fm;aesthetics;communication-minded visualization;time series","Geometry;Data visualization;Algorithm design and analysis;Graphics;History;Motion pictures;Process design;Blogs;Mathematical analysis;Optimization methods","data visualisation","stacked graphs;complex layered graph;layered graph;aesthetics;communication-minded visualization;geometry","","218","13","20","","24 Oct 2008","","","IEEE","IEEE Journals"
"Visualizing network data","R. A. Becker; S. G. Eick; A. R. Wilks","AT&T Bell Labs., Naperville, IL, USA; AT&T Bell Labs., Naperville, IL, USA; AT&T Bell Labs., Naperville, IL, USA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","1","16","28","Networks are critical to modern society, and a thorough understanding of how they behave is crucial to their efficient operation. Fortunately, data on networks is plentiful; by visualizing this data, it is possible to greatly improve our understanding. Our focus is on visualizing the data associated with a network and not on simply visualizing the structure of the network itself. We begin with three static network displays; two of these use geographical relationships, while the third is a matrix arrangement that gives equal emphasis to all network links. Static displays can be swamped with large amounts of data; hence we introduce direct manipulation techniques that permit the graphs to continue to reveal relationships in the context of much more data. In effect, the static displays are parameterized so that interesting views may easily be discovered interactively. The software to carry out this network visualization is called SeeNet.<<ETX>></ETX>","1941-0506","","10.1109/2945.468391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468391","","Data visualization;Displays;Data analysis;Personal communication networks;Statistics;Communication networks;Computer graphics;Data communication;IP networks;Computer networks","data visualisation;user interfaces;telecommunication computing;matrix algebra","network data visualization;static network displays;geographical relationships;matrix arrangement;network links;direct manipulation techniques;SeeNet;parameter focusing;network data analysis;interactive graphics","","217","8","37","","6 Aug 2002","","","IEEE","IEEE Journals"
"Towards Better Analysis of Deep Convolutional Neural Networks","M. Liu; J. Shi; Z. Li; C. Li; J. Zhu; S. Liu","School of Software and TNListTsinghua University; Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys.TNList LabCBICR Center; School of Software and TNListTsinghua University; Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys.TNList LabCBICR Center; School of Software and TNListTsinghua University; School of Software and TNListTsinghua University","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","91","100","Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.","1941-0506","","10.1109/TVCG.2016.2598831","National NSF of China(grant numbers:61672308,61322308,61332007); Microsoft Research(grant numbers:FY15-RES-OPP-112); National Basic Research Program (973 Program) of China(grant numbers:2013CB329403); Youth Top-notch Talent Support Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536654","Deep convolutional neural networks;rectangle packing;matrix reordering;edge bundling;biclustering","Neurons;Neural networks;Training;Visual analytics;Clustering algorithms;Image edge detection","convolution;data visualisation;directed graphs;edge detection;matrix algebra;neural nets","deep convolutional neural networks;pattern recognition tasks;image classification;high-quality deep models;visual analytics approach;deep CNN;directed acyclic graph;hybrid visualization;hierarchical rectangle packing algorithm;matrix reordering algorithm;neuron cluster;biclustering-based edge bundling method;visual clutter reduction","","213","","60","IEEE","9 Aug 2016","","","IEEE","IEEE Journals"
"Visual Traffic Jam Analysis Based on Trajectory Data","Z. Wang; M. Lu; X. Yuan; J. Zhang; H. Van De Wetering","Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University; Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, and Center for Computational Science and Engineering, Peking University; Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, and Center for Computational Science and Engineering, Peking University; Shanghai Key Laboratory of Intelligent Information Processing, and School of Computer Science, Fudan University; Department of Mathematics and Computer Science, Technische Universiteit Eindhoven","IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2159","2168","In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.","1941-0506","","10.1109/TVCG.2013.228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634174","Road traffic;Trajectory;Urban areas;Global Positioning System;Data visualization;Cities and towns;Data mining;Traffic control;traffic jam propagation;Traffic visualization","Road traffic;Trajectory;Urban areas;Global Positioning System;Data visualization;Cities and towns;Data mining;Traffic control","data analysis;data visualisation;Global Positioning System;interactive systems;pattern matching;traffic information systems","Beijing;taxi GPS trajectories;visual exploration;high-level traffic jam description;traffic jam propagation graphs;spatially related events;temporally related events;automatic traffic jam event detection;road segment;traffic speed;trajectory matching;road network;traffic jam information extraction;GPS trajectories;interactive system;visual urban traffic congestion analysis;trajectory data;visual traffic jam analysis","Computer Graphics;Computer Simulation;Geographic Information Systems;Models, Statistical;Motor Vehicles;Pattern Recognition, Automated;User-Computer Interface","208","4","54","","16 Oct 2013","","","IEEE","IEEE Journals"
"Stacking-Based Visualization of Trajectory Attribute Data","C. Tominski; H. Schumann; G. Andrienko; N. Andrienko",University of Rostock; University of Rostock; Fraunhofer Institute IAIS; Fraunhofer Institute IAIS,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2565","2574","Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.","1941-0506","","10.1109/TVCG.2012.265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327262","Visualization;interaction;exploratory analysis;trajectory attribute data;spatio-temporal data","Trajectory;Data visualization;Image color analysis;Navigation","cartography;data visualisation;geographic information systems;solid modelling","stacking-based visualization;trajectory attribute data;spatio-temporal context;trajectory visualization;stacked 3D trajectory band;2D-3D display;2D map;spatial context;dynamic query mechanism;2D time graph;color mapping;3D navigation;radiation surveillance;traffic analysis;maritime navigation","","195","","35","","8 Oct 2012","","","IEEE","IEEE Journals"
"Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations","C. Collins; G. Penn; S. Carpendale",University of Toronto; University of Toronto; University of Calgary,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1009","1016","While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.","1941-0506","","10.1109/TVCG.2009.122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290706","clustering;spatial layout;graph visualization;tree visualization","Data visualization;Tree graphs;Social network services;Scattering;Cognitive science;Air conditioning","data visualisation;set theory","Bubble sets;set relation;isocontours;data visualization;data sets;data relationship;primary data relation;set cluster continuity","","183","5","23","IEEE","23 Oct 2009","","","IEEE","IEEE Journals"
"A survey of visibility for walkthrough applications","D. Cohen-Or; Y. L. Chrysanthou; C. T. Silva; F. Durand","Sch. of Comput. Sci., Tel Aviv Univ., Israel; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","25 Jun 2003","2003","9","3","412","431","Visibility algorithms for walkthrough and related applications have grown into a significant area, spurred by the growth in the complexity of models and the need for highly interactive ways of navigating them. In this survey, we review the fundamental issues in visibility and conduct an overview of the visibility culling techniques developed in the last decade. The taxonomy we use distinguishes point-based methods from-region methods. Point-based methods are further subdivided into object and image-precision techniques, while from-region approaches can take advantage of the cell-and-portal structure of architectural environments or handle generic scenes.","1941-0506","","10.1109/TVCG.2003.1207447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1207447","","Layout;Geometry;Computer graphics;Rendering (computer graphics);Testing;Navigation;Taxonomy;Three dimensional displays;Image generation;Acceleration","rendering (computer graphics);visual perception;computational geometry","visibility computations;interactive rendering;occlusion culling;walkthrough systems;visibility-culling;point-based methods","","177","21","98","","25 Jun 2003","","","IEEE","IEEE Journals"
"Network Visualization by Semantic Substrates","B. Shneiderman; A. Aris","Professor with the Computer Science Department and the Human-Computer Interaction Laboratory at the University of Maryland, College Park; PhD Candidate with the Computer Science Department and the Human-Computer Interaction Laboratory at the University of Maryland, College Park","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","733","740","Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations","1941-0506","","10.1109/TVCG.2006.166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015424","Network visualization;semantic substrate;information visualization;graphical user interfaces","Data visualization;Displays;Law;Legal factors;Tunneling;Filters;Scalability;Graphical user interfaces;Terminology;Automatic control","data visualisation;graphical user interfaces","network visualization;information visualization designers;user-defined semantic substrates;NVSS 1.0;legal precedent data;legal citations;graphical user interfaces","","172","79","38","","20 Nov 2006","","","IEEE","IEEE Journals"
"Geometry-Based Edge Clustering for Graph Visualization","W. Cui; H. Zhou; H. Qu; P. C. Wong; X. Li",the Hong Kong University of Science and Technology; the Hong Kong University of Science and Technology; the Hong Kong University of Science and Technology; Pacific Northwest National Laboratory; Peking University,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1277","1284","Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difﬁcult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, ﬂexible, and efﬁcient. The experiments on some large graphs demonstrate the effectiveness of our method.","1941-0506","","10.1109/TVCG.2008.135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658140","Index Terms—;Graph visualization;visual clutter;mesh;edge clustering","Cities and towns;Road transportation;Automatic control;Data visualization;Displays;Automatic generation control;Mesh generation;Telecommunication traffic;Traffic control;Switches","computational geometry;data visualisation;graphs;pattern clustering","geometry-based edge clustering;graph visualization;edge crossings;edge-clustering process","","168","6","23","IEEE","24 Oct 2008","","","IEEE","IEEE Journals"
"Terrain simplification simplified: a general framework for view-dependent out-of-core visualization","P. Lindstrom; V. Pascucci","Lawrence Livermore Nat. Lab., CA, USA; Lawrence Livermore Nat. Lab., CA, USA","IEEE Transactions on Visualization and Computer Graphics","7 Nov 2002","2002","8","3","239","254","We describe a general framework for out-of-core rendering and management of massive terrain surfaces. The two key components of this framework are: view-dependent refinement of the terrain mesh and a simple scheme for organizing the terrain data to improve coherence and reduce the number of paging events from external storage to main memory. Similar to several previously proposed methods for view-dependent refinement, we recursively subdivide a triangle mesh defined over regularly gridded data using longest-edge bisection. As part of this single, per-frame refinement pass, we perform triangle stripping, view frustum culling, and smooth blending of geometry using geomorphing. Meanwhile, our refinement framework supports a large class of error metrics, is highly competitive in terms of rendering performance, and is surprisingly simple to implement. Independent of our refinement algorithm, we also describe several data layout techniques for providing coherent access to the terrain data. By reordering the data in a manner that is more consistent with our recursive access pattern, we show that visualization of gigabyte-size data sets can be realized even on low-end, commodity PCs without the need for complicated and explicit data paging techniques. Rather, by virtue of dramatic improvements in multilevel cache coherence, we rely on the built-in paging mechanisms of the operating system to perform this task. The end result is a straightforward, simple-to-implement, pointerless indexing scheme that dramatically improves the data locality and paging performance over conventional matrix-based layouts.","1941-0506","","10.1109/TVCG.2002.1021577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1021577","","Data visualization;Geometry;Operating systems;Large-scale systems;Organizing;Personal communication networks;Indexing;Refining;Defense industry;Toy industry","data visualisation;rendering (computer graphics);computational geometry;cache storage;paged storage;operating systems (computers);quadtrees;geography","terrain simplification;view-dependent out-of-core visualization;out-of-core rendering;quadtree;massive terrain surfaces;terrain mesh refinement;paging events;longest-edge bisection;triangle stripping;view frustum culling;smooth blending;geometry;geomorphing;error metrics;data layout techniques;commodity personal computer;multilevel cache coherence;operating system;indexing","","165","8","35","","7 Nov 2002","","","IEEE","IEEE Journals"
"Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow","K. Wongsuphasawat; D. Smilkov; J. Wexler; J. Wilson; D. Mané; D. Fritz; D. Krishnan; F. B. Viégas; M. Wattenberg",Paul G. Allen School of Computer Science & EngineeringUniversity of Washington; Google Research; Google Research; Google Research; Google Research; Google Research; Google Research; Google Research; Google Research,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","1","12","We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model's modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.","1941-0506","","10.1109/TVCG.2017.2744878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019861","Neural Network;Graph Visualization;Dataflow Graph;Clustered Graph","Visualization;Layout;Machine learning;Computational modeling;Tools;Neural networks;Standards","data flow graphs;data visualisation;graph theory;learning (artificial intelligence)","deep learning models;TensorFlow Graph Visualizer;TensorFlow machine intelligence platform;complex machine learning architectures;graph transformations;standard layout techniques;legible interactive diagram;decouple noncritical nodes;clustered graph;hierarchical structure;nested structure;stable cluster expansion;responsive cluster expansion;dataflow graphs;user feedback","","162","","57","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"ASK-GraphView: A Large Scale Graph Visualization System","J. Abello; F. van Ham; N. Krishnan","Ask.com and DIMACS, Rutgers University; IBM, but this work was performedwhile consulting for Ask.com; Ask.com","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","669","676","We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling","1941-0506","","10.1109/TVCG.2006.120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015416","Information Visualization;Graph Visualization;Graph Clustering.","Large-scale systems;Visualization;Navigation;Clustering algorithms;Filtering;Labeling;Tree graphs;Scalability;Finite element methods;Aggregates","data visualisation;graph theory;pattern clustering","ASK-GraphView;large scale graph visualization system;node-link-based graph visualization system;graph clustering;interactive navigation;weighted undirected input graph;cluster labeling","","159","7","25","","20 Nov 2006","","","IEEE","IEEE Journals"
"MatrixExplorer: a Dual-Representation System to Explore Social Networks","N. Henry; J. Fekete",IEEE Computer Society; IEEE Computer Society,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","677","684","MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process","1941-0506","","10.1109/TVCG.2006.160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015417","social networks visualization;node-link diagrams;matrix-based representations;exploratory process;matrix ordering;interactive clustering;consensus.","","data visualisation;diagrams;graph theory;matrix algebra;pattern clustering;social sciences computing","MatrixExplorer;dual-representation system;social networks;network visualization system;node-link diagrams;matrix-based representations;interactive filtering;clustering functions","Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Biological;Population Dynamics;Social Behavior;Social Support;Software;User-Computer Interface","154","2","35","","20 Nov 2006","","","IEEE","IEEE Journals"
"A Survey of Visualization Systems for Network Security","H. Shiravi; A. Shiravi; A. A. Ghorbani","University of New Brunswick, Fredericton; University of New Brunswick, Fredericton; University of New Brunswick, Fredericton","IEEE Transactions on Visualization and Computer Graphics","11 Jun 2012","2012","18","8","1313","1329","Security Visualization is a very young term. It expresses the idea that common visualization techniques have been designed for use cases that are not supportive of security-related data, demanding novel techniques fine tuned for the purpose of thorough analysis. Significant amount of work has been published in this area, but little work has been done to study this emerging visualization discipline. We offer a comprehensive review of network security visualization and provide a taxonomy in the form of five use-case classes encompassing nearly all recent works in this area. We outline the incorporated visualization techniques and data sources and provide an informative table to display our findings. From the analysis of these systems, we examine issues and concerns regarding network security visualization and provide guidelines and directions for future researchers and visual system developers.","1941-0506","","10.1109/TVCG.2011.144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007132","Information visualization;network security visualization;visualization techniques.","Data visualization;Security;Servers;Visualization;Monitoring;Feature extraction;IP networks","computer network security;data visualisation","network security visualization system;security-related data;taxonomy;use-case classes;data sources;informative table;information visualization","","152","9","90","","1 Sep 2011","","","IEEE","IEEE Journals"
"Animation, Small Multiples, and the Effect of Mental Map Preservation in Dynamic Graphs","D. Archambault; H. Purchase; B. Pinaud","UCD Casl, Dublin; University of Glasgow, Glasgow; LaBRI UMR CNRS, Talence","IEEE Transactions on Visualization and Computer Graphics","17 Feb 2011","2011","17","4","539","552","In this paper, we present the results of a human-computer interaction experiment that compared the performance of the animation of dynamic graphs to the presentation of small multiples and the effect that mental map preservation had on the two conditions. Questions used in the experiment were selected to test both local and global properties of graph evolution over time. The data sets used in this experiment were derived from standard benchmark data sets of the information visualization community. We found that small multiples gave significantly faster performance than animation overall and for each of our five graph comprehension tasks. In addition, small multiples had significantly more errors than animation for the tasks of determining sets of nodes or edges added to the graph during the same timeslice, although a positive time-error correlation coefficient suggests that, in this case, faster responses did not lead to more errors. This result suggests that, for these two tasks, animation is preferable if accuracy is more important than speed. Preserving the mental map under either the animation or the small multiples condition had little influence in terms of error rate and response time.","1941-0506","","10.1109/TVCG.2010.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473226","Dynamic graph drawing;small multiples;animation;mental map preservation;evaluation.","Animation;Heuristic algorithms;Data visualization;Human computer interaction;Benchmark testing;Error analysis;Delay;Algorithm design and analysis;Shape;Displays","computer animation;data visualisation;human computer interaction","human-computer interaction;mental map preservation effect;dynamic graphs animation;small multiples presentation;information visualization community;time-error correlation coefficient","","150","1","34","","27 May 2010","","","IEEE","IEEE Journals"
"Nanocubes for Real-Time Exploration of Spatiotemporal Datasets","L. Lins; J. T. Klosowski; C. Scheidegger",AT&T Research; AT&T Research; AT&T Research,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2456","2465","Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.","1941-0506","","10.1109/TVCG.2013.179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634137","Data visualization;Androids;Humanoid robots;Nanostructured materials;Spatiotemporal phenomena;Encoding;interactive exploration;Data cube;data structures","Data visualization;Androids;Humanoid robots;Nanostructured materials;Spatiotemporal phenomena;Encoding","data visualisation;query processing","realtime spatiotemporal datasets exploration;visual encodings;parallel coordinate plots;histograms;heatmaps;user-interaction latency;network latency;network bandwidth measurement;timing measurement;memory measurement;hierarchical structure;exact visualizations;nanocube query;aggregate query;data cube aggregation operation;relational databases;data attributes;time attribute;location attribute","Algorithms;Computer Graphics;Computer Systems;Image Enhancement;Information Storage and Retrieval;Reproducibility of Results;Sensitivity and Specificity;Spatio-Temporal Analysis;User-Computer Interface","150","6","36","","16 Oct 2013","","","IEEE","IEEE Journals"
"Two-Way Coupled SPH and Particle Level Set Fluid Simulation","F. Losasso; J. Talton; N. Kwatra; R. Fedkiw","Ind. Light & Magic, San Rafael, CA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","23 May 2008","2008","14","4","797","804","Grid-based methods have difficulty resolving features on or below the scale of the underlying grid. Although adaptive methods (e.g., RLE, octrees) can alleviate this to some degree, separate techniques are still required for simulating small-scale phenomena such as spray and foam, especially since these more diffuse materials typically behave quite differently than their denser counterparts. In this paper, we propose a two-way coupled simulation framework that uses the particle level set method to efficiently model dense liquid volumes and a smoothed particle hydrodynamics (SPH) method to simulate diffuse regions such as sprays. Our novel SPH method allows us to simulate both dense and diffuse water volumes, fully incorporates the particles that are automatically generated by the particle level set method in under-resolved regions, and allows for two-way mixing between dense SPH volumes and grid-based liquid representations.","1941-0506","","10.1109/TVCG.2008.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4459322","Animation;Physically based modeling;Animation;Physically based modeling","Level set;Spraying;Navier-Stokes equations;Hydrodynamics;Particle tracking;Finite element methods;Mesh generation;Layout;Animation","computational fluid dynamics;flow simulation;hydrodynamics;sprays","particle level set fluid simulation;grid-based methods;adaptive methods;two-way coupled simulation framework;dense liquid volumes;smoothed particle hydrodynamics method;two-way mixing","Algorithms;Computer Graphics;Computer Simulation;Models, Theoretical;Motion;Numerical Analysis, Computer-Assisted;Rheology;User-Computer Interface","149","6","52","","3 Mar 2008","","","IEEE","IEEE Journals"
"Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data","D. Guo","Department of Geography, University of South Carolina","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1041","1048","Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns.","1941-0506","","10.1109/TVCG.2009.143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290710","hierarchical clustering;graph partitioning;flow mapping;spatial interaction;contiguity constraints;multidimensional visualization;coordinated views;data mining","Data visualization;Humans;Diseases;Multidimensional systems;Data mining;Earth;Decision making;Demography;Urban planning;Transportation","cartography;data visualisation;user interfaces","multivariate visualization;large spatial interaction data;weighted location-to-location network;county-to-county migration data;integrated interactive visualization framework;spatially constrained graph partitioning method;multivariate clustering;interactive flow mapping;geographic space","","148","3","43","","23 Oct 2009","","","IEEE","IEEE Journals"
"Acquiring a radiance distribution to superimpose virtual objects onto a real scene","I. Sato; Y. Sato; K. Ikeuchi","Inst. of Ind. Sci., Tokyo Univ., Japan; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1999","5","1","1","12","This paper describes a new method for superimposing virtual objects with correct shadings onto an image of a real scene. Unlike the previously proposed methods, our method can measure a radiance distribution of a real scene automatically and use it for superimposing virtual objects appropriately onto a real scene. First, a geometric model of the scene is constructed from a pair of omnidirectional images by using an omnidirectional stereo algorithm. Then, radiance of the scene is computed from a sequence of omnidirectional images taken with different shutter speeds and mapped onto the constructed geometric model. The radiance distribution mapped onto the geometric model is used for rendering virtual objects superimposed onto the scene image. As a result, even for a complex radiance distribution, our method can superimpose virtual objects with convincing shadings and shadows cast onto the real scene. We successfully tested the proposed method by using real images to show its effectiveness.","1941-0506","","10.1109/2945.764865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=764865","","Layout;Lighting;Augmented reality;Solid modeling;Stereo vision;Computer graphics;Computer vision;Geometry;Rendering (computer graphics);Testing","augmented reality;brightness;computational geometry;stereo image processing;image sequences;rendering (computer graphics)","radiance distribution;virtual objects;real scene;geometric model;omnidirectional images;omnidirectional stereo algorithm;image sequences;shutter speeds;rendering;shadows;computer vision;augmented reality","","142","18","19","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Parallel Sets: interactive exploration and visual analysis of categorical data","R. Kosara; F. Bendix; H. Hauser","Dept. of Comput. Sci., North Carolina Univ., Charlotte, NC, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","5 Jun 2006","2006","12","4","558","568","Categorical data dimensions appear in many real-world data sets, but few visualization methods exist that properly deal with them. Parallel Sets are a new method for the visualization and interactive exploration of categorical data that shows data frequencies instead of the individual data points. The method is based on the axis layout of parallel coordinates, with boxes representing the categories and parallelograms between the axes showing the relations between categories. In addition to the visual representation, we designed a rich set of interactions. Parallel Sets allow the user to interactively remap the data to new categorizations and, thus, to consider more data dimensions during exploration and analysis than usually possible. At the same time, a metalevel, semantic representation of the data is built. Common procedures, like building the cross product of two or more dimensions, can be performed automatically, thus complementing the interactive visualization. We demonstrate Parallel Sets by analyzing a large CRM data set, as well as investigating housing data from two US states.","1941-0506","","10.1109/TVCG.2006.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634321","Information visualization;interaction;nominal data;categorical data;multivariate data.","Data analysis;Data visualization;Computer Society;Switches;Performance analysis;Frequency;Buildings;Statistics","data analysis;data visualisation;interactive systems;very large databases","Parallel Sets;categorical data interactive exploration;categorical data visualization;information visualization;large CRM data set;housing data","Computer Graphics;Computer Simulation;Data Display;Data Interpretation, Statistical;Databases, Factual;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;User-Computer Interface","142","1","27","","5 Jun 2006","","","IEEE","IEEE Journals"
"Natural motion animation through constraining and deconstraining at will","K. Yamane; Y. Nakamura","Dept. of Mechano-Informatics, Univ. of Tokyo, Japan; Dept. of Mechano-Informatics, Univ. of Tokyo, Japan","IEEE Transactions on Visualization and Computer Graphics","25 Jun 2003","2003","9","3","352","360","This paper presents a computational technique for creating whole-body motions of human and animal characters without reference motion. Our work enables animators to generate a natural motion by dragging a link to an arbitrary position with any number of links pinned in the global frame, as well as other constraints such as desired joint angles and joint motion ranges. The method leads to an intuitive pin-and-drag interface where the user can generate whole-body motions by simply switching on or off or strengthening or weakening the constraints. This work is based on a new interactive inverse kinematics technique that allows more flexible attachment of pins and various types of constraints. Editing or retargeting captured motion requires only a small modification to the original method, although it can also create natural motions from scratch. We demonstrate the usefulness and advantage of our method with a number of example motion clips.","1941-0506","","10.1109/TVCG.2003.1207443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1207443","","Animation;Humans;Kinematics;Joints;Libraries;Pins;Animals;Layout;Internet;Computer interfaces","computer animation;kinematics","natural motion animation;constraining;deconstraining;computational technique;whole-body motions;human characters;animal characters;animation;intuitive pin-and-drag interface;whole-body motion generation;interactive inverse kinematics technique;motion editing;motion retargeting;motion clips","","141","2","24","","25 Jun 2003","","","IEEE","IEEE Journals"
"Graphical Perception of Multiple Time Series","W. Javed; B. McDonnel; N. Elmqvist",Purdue University; Purdue University; Purdue University,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","927","934","Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.","1941-0506","","10.1109/TVCG.2010.162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613429","line graphs;braided graphs;horizon graphs;small multiples;stacked graphs;evaluation;design guidelines","Time series analysis;Visualization;Data visualization;Clutter;Pixel;Image color analysis;Training","data visualisation;graphs;time series","graphical perception;multiple time series;line graph;temporal data;realistic temporal analysis task;simultaneous time series;charts;shared-space technique;visual span;clutter;temporal data visualization","","140","","29","","28 Oct 2010","","","IEEE","IEEE Journals"
"Visualizing the Hidden Activity of Artificial Neural Networks","P. E. Rauber; S. G. Fadel; A. X. Falcão; A. C. Telea",University of GroningenUniversity of Campinas; University of São Paulo; University of Campinas; University of Groningen,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","101","110","In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles.","1941-0506","","10.1109/TVCG.2016.2598838","CAPES; FAPESP(grant numbers:2012/24121-9,2015/19851-6); CNPq(grant numbers:302970/2014-2,479070/2013-0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539329","Artificial neural networks;dimensionality reduction;algorithm understanding","Neurons;Visualization;Data visualization;Training;Neural networks;Computational modeling;Benchmark testing","data visualisation;learning (artificial intelligence);neural nets;pattern classification","hidden activity visualization;artificial neural networks;machine learning;pattern classification;high-dimensional vectors;dimensionality reduction","","138","","50","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization","K. Wongsuphasawat; D. Gotz",University of Maryland; IBM,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2659","2668","Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.","1941-0506","","10.1109/TVCG.2012.225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327272","Outflow;information visualization;temporal event sequences;state diagram;state transition","Data visualization;Information analysis;Sequential analysis;Layout;Image color analysis","data visualisation","temporal event sequence;event sequence data;electronic medical record;EMR;sports event;event progression pathway;outflow visualization technique;aggregate pathway;event state;cardinality;pathway state transition","Computer Graphics;Heart Failure;Humans;Image Processing, Computer-Assisted;Models, Theoretical;Soccer;Surveys and Questionnaires;Time Factors;User-Computer Interface","136","13","35","","8 Oct 2012","","","IEEE","IEEE Journals"
"Flow-Based Image Abstraction","H. Kang; S. Lee; C. K. Chui","University of Missouri, St. Louis, St. Louis; POSTECH, Pohang; University of Missouri, St. Louis, St. Louis","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2008","2009","15","1","62","76","We present a non-photorealistic rendering technique that automatically delivers a stylized abstraction of a photograph. Our approach is based on shape/color filtering guided by a vector field that describes the flow of salient features in the image. This flow-based filtering significantly improves the abstraction performance in terms of feature enhancement and stylization. Our method is simple, fast, and easy to implement. Experimental results demonstrate the effectiveness of our method in producing stylistic and feature-enhancing illustrations from photographs.","1941-0506","","10.1109/TVCG.2008.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4522547","Picture/Image Generation;Enhancement;Picture/Image Generation;Enhancement","Shape;Colored noise;Rendering (computer graphics);Filtering;Layout;Filters;Data mining;Noise shaping;Color;Displays","filtering theory;image colour analysis;image enhancement;photography;rendering (computer graphics)","flow-based image abstraction;nonphotorealistic rendering;photograph abstraction;shape/color filtering;vector field;flow-based filtering;feature enhancement;feature stylization","Algorithms;Computer Graphics;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Rheology","133","3","57","","16 May 2008","","","IEEE","IEEE Journals"
"A Visual Backchannel for Large-Scale Events","M. Dörk; D. Gruen; C. Williamson; S. Carpendale",NA; NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1129","1138","We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.","1941-0506","","10.1109/TVCG.2010.129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613451","backchannel;information visualization;events;multiple views;microblogging;information retrieval;World Wide Web","Visualization;Twitter;Data visualization;Shape;Context;Real time systems;Streaming media","data visualisation;information filtering;interactive systems;social networking (online)","visual backchannel;online conversation;large-scale event;microblogging community;Twitter;digital backchannel;political speech;sport competition;natural disaster;interactive visual overview;multifaceted visual overview;information stream visualization;visual saliency;Web-based coordinated-view system;Topic Streams;graph visualization;People Spiral;image cloud encoding;information retrieval;cross-filtering;data visualization","","132","3","43","","28 Oct 2010","","","IEEE","IEEE Journals"
"A topological hierarchy for functions on triangulated surfaces","P. -. Bremer; B. Hamann; H. Edelsbrunner; V. Pascucci","Dept. of Comput. Sci., California Univ., Davis, CA, USA; Dept. of Comput. Sci., California Univ., Davis, CA, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","18 May 2004","2004","10","4","385","396","We combine topological and geometric methods to construct a multiresolution representation for a function over a two-dimensional domain. In a preprocessing stage, we create the Morse-Smale complex of the function and progressively simplify its topology by cancelling pairs of critical points. Based on a simple notion of dependency among these cancellations, we construct a hierarchical data structure supporting traversal and reconstruction operations similarly to traditional geometry-based representations. We use this data structure to extract topologically valid approximations that satisfy error bounds provided at runtime.","1941-0506","","10.1109/TVCG.2004.3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298796","Critical point theory;Morse-Smale complex;terrain data;simplification;multiresolution data structure.","Topology;Data structures;Spatial resolution;Approximation error;Focusing;Data mining;Runtime;Data visualization;Electrostatics","data structures;graph theory;computational geometry;surface fitting;mesh generation","topological hierarchy;triangulated surfaces;multiresolution data representation;Morse-Smale complex;hierarchical data structure;critical point theory;terrain data;mesh generation","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional","129","","37","","18 May 2004","","","IEEE","IEEE Journals"
"A<sc>cti</sc>V<sc>is</sc>: Visual Exploration of Industry-Scale Deep Neural Network Models","M. Kahng; P. Y. Andrews; A. Kalro; D. H. Chau",Georgia Institute of Technology; Facebook; Facebook; Georgia Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","6 Dec 2017","2018","24","1","88","97","While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models.","1941-0506","","10.1109/TVCG.2017.2744718","NSF Graduate Research Fellowship Program(grant numbers:DGE-1650044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022871","Visual analytics;deep learning;machine learning;information visualization","Computational modeling;Tools;Machine learning;Data models;Neurons;Facebook;Data visualization","data visualisation;learning (artificial intelligence);neural nets","visual tools;large-scale datasets;participatory design sessions;interactive visualization system;large-scale deep learning models;model architecture;complex deep neural network models;visual exploration;industry-scale deep neural network models;ActiVis system;machine learning platform","","129","","38","IEEE","30 Aug 2017","","","IEEE","IEEE Journals"
"Terrain Synthesis from Digital Elevation Models","H. Zhou; J. Sun; G. Turk; J. M. Rehg","GVU Center, Georgia Institute of Technology, TSRB, 85 5th Street NW, Atlanta, GA 30308; GVU Center, Georgia Institute of Technology, TSRB, 85 5th Street NW, Atlanta, GA 30308; GVU Center, Georgia Institute of Technology, TSRB, 85 5th Street NW, Atlanta, GA 30308; GVU Center, Georgia Institute of Technology, TSRB, 85 5th Street NW, Atlanta, GA 30308","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","834","848","In this paper, we present an example-based system for terrain synthesis. In our approach, patches from a sample terrain (represented by a height field) are used to generate a new terrain. The synthesis is guided by a user-sketched feature map that specifies where terrain features occur in the resulting synthetic terrain. Our system emphasizes large-scale curvilinear features (ridges and valleys) because such features are the dominant visual elements in most terrains. Both the example height field and user's sketch map are analyzed using a technique from the field of geomorphology. The system finds patches from the example data that match the features found in the user's sketch. Patches are joined together using graph cuts and Poisson editing. The order in which patches are placed in the synthesized terrain is determined by breadth-first traversal of a feature tree and this generates improved results over standard raster-scan placement orders. Our technique supports user-controlled terrain synthesis in a wide variety of styles, based upon the visual richness of real-world terrain data.","1941-0506","","10.1109/TVCG.2007.1027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293025","Terrain synthesis;Digital Elevation Models;terrain analysis;texture synthesis.","Digital elevation models;Geology;Large-scale systems;Application software;Computational modeling;Aerospace simulation;Computer simulation;Fractals;Sun;Tree graphs","computer graphics;geomorphology;graph theory;terrain mapping;tree searching","terrain synthesis;digital elevation model;example-based system;user-sketched feature map;synthetic terrain;large-scale curvilinear features;geomorphology;graph cuts;Poisson editing;breadth-first traversal;raster-scan placement orders;texture synthesis","Algorithms;Altitude;Computer Graphics;Environment;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval","128","1","37","","20 Aug 2007","","","IEEE","IEEE Journals"
"Adaptive real-time level-of-detail based rendering for polygonal models","J. C. Xia; J. El-Sana; A. Varshney","Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1997","3","2","171","183","We present an algorithm for performing adaptive real-time level-of-detail-based rendering for triangulated polygonal models. The simplifications are dependent on viewing direction, lighting, and visibility and are performed by taking advantage of image-space, object-space, and frame-to-frame coherences. In contrast to the traditional approaches of precomputing a fixed number of level-of-detail representations for a given object, our approach involves statically generating a continuous level-of-detail representation for the object. This representation is then used at run time to guide the selection of appropriate triangles for display. The list of displayed triangles is updated incrementally from one frame to the next. Our approach is more effective than the current level-of-detail-based rendering approaches for most scientific visualization applications, where there are a limited number of highly complex objects that stay relatively close to the viewer. Our approach is applicable for scalar (such as distance from the viewer) as well as vector (such as normal direction) attributes.","1941-0506","","10.1109/2945.597799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=597799","","Iterative algorithms;Rendering (computer graphics);Electrical capacitance tomography;Visualization;Displays;Hardware;Layout;Virtual reality;Graphics;Acceleration","real-time systems;rendering (computer graphics);computational geometry;data visualisation","adaptive real-time level-of-detail rendering;triangulated polygonal models;viewing direction;lighting;visibility;image-space;object-space;frame-to-frame coherence;run time;displayed triangles;scientific visualization;scalar attributes;vector attributes;view-dependent simplifications;triangle hierarchies;multiresolution hierarchies;selective refinement","","127","8","36","","6 Aug 2002","","","IEEE","IEEE Journals"
"“Search, Show Context, Expand on Demand”: Supporting Large Graph Exploration with Degree-of-Interest","F. van Ham; A. Perer","IBM-ILOG Research in Gentilly, France; IBM Research in Haifa, Israel","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","953","960","A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas’ original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demeffectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.","1941-0506","","10.1109/TVCG.2009.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290699","Graph visualization;network visualization;degree of interest;legal citation networks;focus+context","Data visualization;Context modeling;Law;Legal factors;Information analysis;Mobile computing;Hardware;Tree graphs;Visual databases;Data analysis","citation analysis;data visualisation;graph theory;mathematics computing","large graph exploration;graph visualization;large graph database;immediate context graph;contextual subgraph;dense online database;legal citation","","127","","24","IEEE","23 Oct 2009","","","IEEE","IEEE Journals"
"Visual Analysis of Large Heterogeneous Social Networks by Semantic and Structural Abstraction","Zeqian Shen; Kwan-Liu Ma; T. Eliassi-Rad","Department of Computer Science, University of California at Davis, CA; Department of Computer Science, University of California at Davis, CA; Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1427","1439","Social network analysis is an active area of study beyond sociology. It uncovers the invisible relationships between actors in a network and provides understanding of social processes and behaviors. It has become an important technique in a variety of application areas such as the Web, organizational studies, and homeland security. This paper presents a visual analytics tool, OntoVis, for understanding large, heterogeneous social networks, in which nodes and links could represent different concepts and relations, respectively. These concepts and relations are related through an ontology (also known as a schema). OntoVis is named such because it uses information in the ontology associated with a social network to semantically prune a large, heterogeneous network. In addition to semantic abstraction, OntoVis also allows users to do structural abstraction and importance filtering to make large networks manageable and to facilitate analytic reasoning. All these unique capabilities of OntoVis are illustrated with several case studies.","1941-0506","","10.1109/TVCG.2006.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703364","Graph drawing;information visualization;ontology;semantic graphs;social networks;visual analytics.","Social networking (online);Semantics;Visualization;Ontologies;Organizations;Terrorism;Complexity theory","data visualisation;inference mechanisms;ontologies (artificial intelligence);social sciences computing","Graph drawing;information visualization;ontology;semantic graphs;social networks;visual analytics.","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Semantics;Social Support;User-Computer Interface","126","2","37","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"Directing Crowd Simulations Using Navigation Fields","S. Patil; J. van den Berg; S. Curtis; M. C. Lin; D. Manocha","University of North Carolina at Chapel Hill, Chapel Hill; University of California Berkeley, Berkeley; University of North Carolina at Chapel Hill, Chapel Hill; University of North Carolina at Chapel Hill, Chapel Hill; University of North Carolina at Chapel Hill, Chapel Hill","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2010","2011","17","2","244","254","We present a novel approach to direct and control virtual crowds using navigation fields. Our method guides one or more agents toward desired goals based on guidance fields. The system allows the user to specify these fields by either sketching paths directly in the scene via an intuitive authoring interface or by importing motion flow fields extracted from crowd video footage. We propose a novel formulation to blend input guidance fields to create singularity-free, goal-directed navigation fields. Our method can be easily combined with the most current local collision avoidance methods and we use two such methods as examples to highlight the potential of our approach. We illustrate its performance on several simulation scenarios.","1941-0506","","10.1109/TVCG.2010.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416702","Multiagent systems;animation;virtual reality.","Navigation;Computational modeling;Collision avoidance;Animation;Decision making;Computer science;Layout;Virtual reality;Artificial intelligence;Computer simulation","collision avoidance;feature extraction;navigation;virtual reality","guidance field;path sketching;crowd video footage;motion flow field extraction;goal directed navigation field;collision avoidance method","Algorithms;Computer Graphics;Computer Simulation;Crowding;Humans;Imaging, Three-Dimensional;Movement","125","4","50","","18 Feb 2010","","","IEEE","IEEE Journals"
"Balancing Systematic and Flexible Exploration of Social Networks","A. Perer; B. Shneiderman","Department of Computer Science, University of Maryland, College Park, MD 20742; Department of Computer Science, University of Maryland, College Park, MD 20742","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","693","700","Social network analysis (SNA) has emerged as a powerful method for understanding the importance of relationships in networks. However, interactive exploration of networks is currently challenging because: (1) it is difficult to find patterns and comprehend the structure of networks with many nodes and links, and (2) current systems are often a medley of statistical methods and overwhelming visual output which leaves many analysts uncertain about how to explore in an orderly manner. This results in exploration that is largely opportunistic. Our contributions are techniques to help structural analysts understand social networks more effectively. We present SocialAction, a system that uses attribute ranking and coordinated views to help users systematically examine numerous SNA measures. Users can (1) flexibly iterate through visualizations of measures to gain an overview, filter nodes, and find outliers, (2) aggregate networks using link structure, find cohesive subgroups, and focus on communities of interest, and (3) untangle networks by viewing different link types separately, or find patterns across different link types using a matrix overview. For each operation, a stable node layout is maintained in the network visualization so users can make comparisons. SocialAction offers analysts a strategy beyond opportunism, as it provides systematic, yet flexible, techniques for exploring social networks","1941-0506","","10.1109/TVCG.2006.122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015419","Social networks;interactive graph visualization;attribute ranking;coordinated views;exploratory data analysis","Social network services;Data visualization;Pattern analysis;Coordinate measuring machines;Data analysis;Statistical analysis;Gain measurement;Filters;Aggregates;Navigation","data analysis;data visualisation;graph theory;graphical user interfaces;matrix algebra;social sciences computing","social network analysis;statistical methods;SocialAction;attribute ranking;matrix overview;network visualization;data analysis","Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Biological;Population Dynamics;Social Behavior;Social Support;Software;User-Computer Interface","123","8","34","","20 Nov 2006","","","IEEE","IEEE Journals"
"VisLink: Revealing Relationships Amongst Visualizations","C. Collins; S. Carpendale",PhD Candidate with the Computer Science Department at the Univeristy of Toronto; Professor with the Computer Science Department at the University of Calgary,"IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1192","1199","We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.","1941-0506","","10.1109/TVCG.2007.70521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376140","Graph visualization;node-link diagrams;structural comparison;hierarchies;3D visualization;edge aggregation.","Data visualization;Encoding;Computer science;Filters;Information analysis;Statistics;Two dimensional displays","data visualisation;query formulation","VisLink;data visualizations;inter-representational query;information encoding;spreading activation;search filters","","119","6","22","","5 Nov 2007","","","IEEE","IEEE Journals"
"MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering","T. von Landesberger; F. Brodkorb; P. Roskosch; N. Andrienko; G. Andrienko; A. Kerren","Technical University of Darmstadt, Germany; Technical University of Darmstadt, Germany; Technical University of Darmstadt, Germany; Fraunhofer IAIS, Bonn, Germany; Fraunhofer IAIS, Bonn, Germany; Fraunhofer IAIS, Bonn, Germany","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","11","20","Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.","1941-0506","","10.1109/TVCG.2015.2468111","GRACeFUL; SoBigData; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192732","Visual analytics;movement data;networks;graphs;temporal aggregation;spatial aggregation;flows;clustering;Visual analytics;movement data;networks;graphs;temporal aggregation;spatial aggregation;flows;clustering","Data visualization;Aggregates;Visualization;Clustering algorithms;Clutter;Geology;Twitter","data visualisation;graph theory;pattern clustering;social sciences computing","MobilityGraphs;visual analysis;mass mobility dynamics;spatio-temporal graphs;people mobility;mobility data sets;people movements;people flows;mobility data analysis;spatial situations;spatio-temporal changes;flow visualizations;massive clutter;movements complex variation;time periods;visual analytics methodology;spatial simplifications;temporal simplifications;graph-based method;flow maps;visual representation;spatio-temporal variation;intersecting flows;interactive system;data exploration;interactive setting;clustering parameters;geolocated Twitter posts;Greater London city area;mobile phone call data records;Abidjan;Ivory Coast;daily movement patterns;weekly movement patterns;resident population","","117","1","56","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media","J. Zhao; N. Cao; Z. Wen; Y. Song; Y. -R. Lin; C. Collins",University of Toronto; MIT; MIT; IBM J. Watson Research Center; University of Pittsburgh; UOIT,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1773","1782","We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.","1941-0506","","10.1109/TVCG.2014.2346922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876013","Retweeting threads;anomaly detection;social media;visual analytics;machine learning;information visualization","Message systems;Media;Twitter;Feature extraction;Data visualization;Social network services;Instruction sets;Visual analytics","data analysis;data visualisation;decision making;learning (artificial intelligence);social networking (online)","#FluxFlow;anomalous information spreading;interactive visual analysis system;social media Websites;Twitter;Facebook;decision-making;social signals;crowd messages;dynamic crowd behaviors;data analyst capability;anomalous information behaviors;advanced machine learning algorithms;deeper analysis;Hurricane Sandy;quantitative measurements;back-end anomaly detection model;anomalous retweeting threads;front-end interactive visualizations","Algorithms;Computer Graphics;Humans;Informatics;Information Dissemination;Machine Learning;Social Media","114","","48","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Impossible Spaces: Maximizing Natural Walking in Virtual Environments with Self-Overlapping Architecture","E. A. Suma; Z. Lipps; S. Finkelstein; D. M. Krum; M. Bolas",University of Southern California; University of Southern California; Carnegie Mellon University; University of Southern California; University of Southern California,"IEEE Transactions on Visualization and Computer Graphics","9 Mar 2012","2012","18","4","555","564","Walking is only possible within immersive virtual environments that fit inside the boundaries of the user's physical workspace. To reduce the severity of the restrictions imposed by limited physical area, we introduce ""impossible spaces,"" a new design mechanic for virtual environments that wish to maximize the size of the virtual environment that can be explored with natural locomotion. Such environments make use of self-overlapping architectural layouts, effectively compressing comparatively large interior environments into smaller physical areas. We conducted two formal user studies to explore the perception and experience of impossible spaces. In the first experiment, we showed that reasonably small virtual rooms may overlap by as much as 56% before users begin to detect that they are in an impossible space, and that the larger virtual rooms that expanded to maximally fill our available 9.14m × 9.14m workspace may overlap by up to 31%. Our results also demonstrate that users perceive distances to objects in adjacent overlapping rooms as if the overall space was uncompressed, even at overlap levels that were overtly noticeable. In our second experiment, we combined several well-known redirection techniques to string together a chain of impossible spaces in an expansive outdoor scene. We then conducted an exploratory analysis of users' verbal feedback during exploration, which indicated that impossible spaces provide an even more powerful illusion when users are naive to the manipulation.","1941-0506","","10.1109/TVCG.2012.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165136","Virtual environments;perception;spatial illusions;redirection.","Virtual environments;Legged locomotion;Buildings;Educational institutions;Estimation;Layout;Space exploration","feedback;gait analysis;human computer interaction;virtual reality","natural walking;self-overlapping architectural layout;immersive virtual environment;user physical workspace;impossible spaces;design mechanic;natural locomotion;virtual room;adjacent overlapping room;redirection technique;expansive outdoor scene;users verbal feedback;illusion","Adult;Architecture as Topic;Computer Graphics;Distance Perception;Environment;Female;Humans;Male;Middle Aged;Motion Sickness;Space Perception;User-Computer Interface;Walking;Young Adult","114","2","31","","9 Mar 2012","","","IEEE","IEEE Journals"
"Parallel Edge Splatting for Scalable Dynamic Graph Visualization","M. Burch; C. Vehlow; F. Beck; S. Diehl; D. Weiskopf","VISUS, University of Stuttgart; VISUS, University of Stuttgart; University of Trier; University of Trier; VISUS, University of Stuttgart","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2344","2353","We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.","1941-0506","","10.1109/TVCG.2011.226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065001","Dynamic graph visualization;graph splatting;software visualization;software evolution.","Graphics;Image edge detection;Data visualization;Encoding;Image color analysis;Software engineering","data visualisation;graph theory","parallel edge splatting;scalable dynamic graph visualization;node-link diagram;nonlinear color mapping;interaction technique;data exploration;selective data zooming;call graph;JUnit open source software project;bibliography dataset","","112","1","40","","3 Nov 2011","","","IEEE","IEEE Journals"
"OpinionSeer: Interactive Visualization of Hotel Customer Feedback","Y. Wu; F. Wei; S. Liu; N. Au; W. Cui; H. Zhou; H. Qu","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China; IBM China Res. Lab., Beijing, China; IBM China Res. Lab., Beijing, China; Sch. of Hotel & Tourism Managment, Hong Kong Polytech. Univ., Kowloon, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China; Shenzhen Univ., Shenzhen, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1109","1118","The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.","1941-0506","","10.1109/TVCG.2010.183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613449","opinion visualization;radial visualization;uncertainty visualization","Data visualization;Visualization;Uncertainty;Feature extraction;Data mining;Wheels;Layout","data mining;data visualisation;feedback;hotel industry;interactive systems;Internet","OpinionSeer;interactive visualization system;hotel customer feedback;Web technology;hotel services;visual analysis;online customer opinions;visualization-centric opinion mining technique;scatterplots;radial visualization;subjective logic","","109","1","31","","28 Oct 2010","","","IEEE","IEEE Journals"
"GraphDiaries: Animated Transitions andTemporal Navigation for Dynamic Networks","B. Bach; E. Pietriga; J. -D. Fekete","INRIA, Saclay , France; INRIA, Saclay, France and INRIA Chile-CIRIC, Santiago, Chile; INRIA, Saclay , France","IEEE Transactions on Visualization and Computer Graphics","17 Mar 2014","2014","20","5","740","754","Identifying, tracking and understanding changes in dynamic networks are complex and cognitively demanding tasks. We present GraphDiaries, a visual interface designed to improve support for these tasks in any node-link based graph visualization system. GraphDiaries relies on animated transitions that highlight changes in the network between time steps, thus helping users identify and understand those changes. To better understand the tasks related to the exploration of dynamic networks, we first introduce a task taxonomy, that informs the design of GraphDiaries, presented afterwards. We then report on a user study, based on representative tasks identified through the taxonomy, and that compares GraphDiaries to existing techniques for temporal navigation in dynamic networks, showing that it outperforms them in terms of both task time and errors for several of these tasks.","1941-0506","","10.1109/TVCG.2013.254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6658746","Dynamic networks;graph visualization;temporal navigation;user experiment","Visualization;Layout;Animation;Taxonomy;Navigation;Topology;Complexity theory","computer animation;data visualisation;graph theory;graphical user interfaces;network theory (graphs)","GraphDiaries;animated transitions;dynamic networks;visual interface;node-link-based graph visualization system;time steps;task taxonomy;temporal navigation;task time;task errors","","108","1","48","IEEE","8 Nov 2013","","","IEEE","IEEE Journals"
"Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization","A. Satyanarayan; R. Russell; J. Hoffswell; J. Heer",Stanford University; University of Washington; University of Washington; University of Washington,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","659","668","We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.","1941-0506","","10.1109/TVCG.2015.2467091","SAP Stanford Graduate Fellowship, the Intel Big Data ISTC, the Moore Foundation, and DARPA XDATA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192704","Information visualization;systems;toolkits;declarative specification;optimization;interaction;streaming data;Information visualization;systems;toolkits;declarative specification;optimization;interaction;streaming data","Data visualization;Visualization;Data models;Encoding;Indexes;Runtime;Computer architecture","data flow graphs;data visualisation;formal specification;optimisation","Reactive Vega;streaming dataflow architecture;declarative interactive visualization;system architecture;declarative visual design;interaction design;data visualization;single declarative specification;dataflow graph;scene graph elements;interaction events;first-class streaming data sources;expressive interactive visualizations;time-varying scalar;relational data;hierarchical data;compile-time optimization;run-time optimization;interactive performance","","108","1","41","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"CloudLines: Compact Display of Event Episodes in Multiple Time-Series","M. Krstajic; E. Bertini; D. Keim",University of Konstanz; University of Konstanz; University of Konstanz,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2432","2439","We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.","1941-0506","","10.1109/TVCG.2011.179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065010","Incremental visualization;event based data;lens distortion.","Time series analysis;Data visualization;Lenses;Estimation;Event detection","computer displays;data analysis;data structures;data visualisation;financial management;information resources;Internet;security of data;time series","CloudLines;event episode compact display;multiple time series visualization technique;interactive distortion;time-based representation;data analysis;network security;financial service;temporal context;data visualization;decay function;magnifying lens technique;logarithmic time scale;readability enhancement;incremental data sets;online news streams","","107","3","30","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"PivotPaths: Strolling through Faceted Information Spaces","M. Dörk; N. Henry Riche; G. Ramos; S. Dumais",University of Calgary; Microsoft; Microsoft; Microsoft,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2709","2718","We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to ‘take a stroll’ through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.","1941-0506","","10.1109/TVCG.2012.252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327277","Information visualization;interactivity;node-link diagrams;animation;information seeking;exploratory search","Visualization;Motion pictures;Layout;Navigation;Context;Information services;Facial animation","information filters;information resources;information retrieval","PivotPaths;interactive visualization;faceted information resources;facet lists;filter operations;iterative design-and-evaluation process;academic publications","","107","2","24","IEEE","8 Oct 2012","","","IEEE","IEEE Journals"
"Neural Style Transfer: A Review","Y. Jing; Y. Yang; Z. Feng; J. Ye; Y. Yu; M. Song","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong; College of Computer Science and Technology, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","30 Sep 2020","2020","26","11","3365","3385","The seminal work of Gatys et al. demonstrated the power of Convolutional Neural Networks (CNNs) in creating artistic imagery by separating and recombining image content and style. This process of using CNNs to render a content image in different styles is referred to as Neural Style Transfer (NST). Since then, NST has become a trending topic both in academic literature and industrial applications. It is receiving increasing attention and a variety of approaches are proposed to either improve or extend the original NST algorithm. In this paper, we aim to provide a comprehensive overview of the current progress towards NST. We first propose a taxonomy of current algorithms in the field of NST. Then, we present several evaluation methods and compare different NST algorithms both qualitatively and quantitatively. The review concludes with a discussion of various applications of NST and open problems for future research. A list of papers discussed in this review, corresponding codes, pre-trained models and more comparison results are publicly available at: https://osf.io/f8tu4/.","1941-0506","","10.1109/TVCG.2019.2921336","National Key Research and Development Program of China(grant numbers:2016YFB1200203); National Natural Science Foundation of China(grant numbers:61572428,U1509206); Key Research and Development Program of Zhejiang Province(grant numbers:2018C01004); International Science and Technology Cooperation Programme(grant numbers:2013DFG12840); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732370","Neural style transfer (NST);convolutional neural network (CNN)","Rendering (computer graphics);Painting;Taxonomy;Visualization;Convolutional neural networks;Art;Shape","convolutional neural nets;image processing","neural style transfer;convolutional neural networks;CNN;artistic imagery;image content;NST algorithm","","106","","110","IEEE","6 Jun 2019","","","IEEE","IEEE Journals"
"OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media","Y. Wu; S. Liu; K. Yan; M. Liu; F. Wu",Microsoft Research; Microsoft Research; Harbin Institute of Technology; Tsinghua University; Tsinghua University,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1763","1772","It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.","1941-0506","","10.1109/TVCG.2014.2346920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876032","Opinion visualization;opinion diffusion;opinion flow;influence estimation;kernel density estimation;level-of-detail","Visual analytics;Social network services;Media;Data visualization;Twitter;Information analysis","data analysis;data visualisation;social networking (online);social sciences computing","OpinionFlow;social media;government;business intelligence;public opinion diffusion;visual analysis system;information diffusion model;selective exposure theory;opinion propagation patterns;Twitter;opinion diffusion model;opinion flow visualization;stacked tree","Algorithms;Communication;Computer Graphics;Humans;Informatics;Public Opinion;Social Media","106","","48","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Egocentric depth judgments in optical, see-through augmented reality","J. E. Swan; A. Jones; E. Kolstad; M. A. Livingston; H. S. Smallman","Department of Computer Science and Engineering and the Institute for Neurocognitive Science and Technology, Mississippi State University, 300 Butler Hall, PO Box 9637, Mississippi State, MS 39762.; Department of Computer Science and Engineering and the Institute for Neurocognitive Science and Technology, Mississippi State University, 300 Butler Hall, PO Box 9637, Mississippi State, MS 39762.; Department of Computer Science and Engineering and the Institute for Neurocognitive Science and Technology, Mississippi State University, 300 Butler Hall, PO Box 9637, Mississippi State, MS 39762.; 3D Virtual and Mixed Environments Laboratory, Code 5580, Naval Research Laboratory, Washington DC, 20375; Pacific Science & Engineering Group, San Diego, CA, 92121","IEEE Transactions on Visualization and Computer Graphics","22 Sep 2016","2007","13","3","429","442","A fundamental problem in optical, see-through augmented reality (AR) is characterizing how it affects the perception of spatial layout and depth. This problem is important because AR system developers need to both place graphics in arbitrary spatial relationships with real-world objects, and to know that users will perceive them in the same relationships. Furthermore, AR makes possible enhanced perceptual techniques that have no real-world equivalent, such as x-ray vision, where AR users are supposed to perceive graphics as being located behind opaque surfaces. This paper reviews and discusses protocols for measuring egocentric depth judgments in both virtual and augmented environments, and discusses the well-known problem of depth underestimation in virtual environments. It then describes two experiments that measured egocentric depth judgments in AR. Experiment I used a perceptual matching protocol to measure AR depth judgments at medium and far-field distances of 5 to 45 meters. The experiment studied the effects of upper versus lower visual field location, the x-ray vision condition, and practice on the task. The experimental findings include evidence for a switch in bias, from underestimating to overestimating the distance of AR-presented graphics, at ~ 23 meters, as well as a quantification of how much more difficult the x-ray vision condition makes the task. Experiment II used blind walking and verbal report protocols to measure AR depth judgments at distances of 3 to 7 meters. The experiment examined real-world objects, real-world objects seen through the AR display, virtual objects, and combined real and virtual objects. The results give evidence that the egocentric depth of AR objects is underestimated at these distances, but to a lesser degree than has previously been found for most virtual reality environments. The results are consistent with previous studies that have implicated a restricted field-of-view, combined with an inability for observers to scan the ground plane in a near-to-far direction, as explanations for the observed depth underestimation.","1941-0506","","10.1109/TVCG.2007.1035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573294","Artificial;augmented;and virtual realities;ergonomics;evaluation/methodology;screen design;experimentation;measurement;performance;depth perception;optical see-through augmented reality.","Observers;Legged locomotion;Augmented reality;Visualization;Optical variables measurement","","","Computer Graphics;Depth Perception;Humans;User-Computer Interface","105","","","","22 Sep 2016","","","IEEE","IEEE Journals"
"TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data","X. Huang; Y. Zhao; C. Ma; J. Yang; X. Ye; C. Zhang","Department of Computer Science, Kent State University; Department of Computer Science, Kent State University; Department of Computer Science, Kent State University; Department of Computer Science, University of North Carolina at Charlotte; Department of Geography, Kent State University; Department of Computer Science, University of North Carolina at Charlotte","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","160","169","We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis.","1941-0506","","10.1109/TVCG.2015.2467771","National Science Foundation(grant numbers:1535031,1535081,1416509); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192687","Graph based visual analytics;Centrality;Taxi trajectories;Urban network;Transportation assessment;Graph based visual analytics;Centrality;Taxi trajectories;Urban network;Transportation assessment","Urban areas;Public transportation;Roads;Trajectory;Visual analytics","data visualisation;graph theory;interactive systems;public transport;road traffic;town and country planning;traffic information systems","graph-based visual analytics approach;urban network centralities;TrajGraph;urban mobility patterns;graph modeling;visual analysis;taxi trajectory data;real traffic information;city streets;urban transportation dynamics;graph analysis algorithms;interactive multiscale visual analytics;graph partitioning algorithm;region-level graphs;street-level graph;graph centralities;Pagerank;betweenness;urban regions;node-link graph view;map view;temporal information view;city traffic patterns;Shenzhen;China;visual interface;urban transportation analysis","","104","","39","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"SparkClouds: Visualizing Trends in Tag Clouds","B. Lee; N. H. Riche; A. K. Karlson; S. Carpendale",Microsoft Research; Microsoft Research; Microsoft Research; University of Calgary,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1182","1189","Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.","1941-0506","","10.1109/TVCG.2010.194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613457","Tag clouds;trend visualization;multiple line graphs;stacked bar charts;evaluation","Tag clouds;Visualization;Data visualization;Encoding;Layout;Color;Clouds","data visualisation;Internet","SparkClouds;trend visualization;tag clouds;World Wide Web;tag frequency","","103","2","29","","28 Oct 2010","","","IEEE","IEEE Journals"
"Importance-driven feature enhancement in volume visualization","I. Viola; A. Kanitsar; M. E. Groller","Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria; Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria; Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria","IEEE Transactions on Visualization and Computer Graphics","23 May 2005","2005","11","4","408","418","This paper presents importance-driven feature enhancement as a technique for the automatic generation of cut-away and ghosted views out of volumetric data. The presented focus+context approach removes or suppresses less important parts of a scene to reveal more important underlying information. However, less important parts are fully visible in those regions, where important visual information is not lost, i.e., more relevant features are not occluded. Features within the volumetric data are first classified according to a new dimension, denoted as object importance. This property determines which structures should be readily discernible and which structures are less important. Next, for each feature, various representations (levels of sparseness) from a dense to a sparse depiction are defined. Levels of sparseness define a spectrum of optical properties or rendering styles. The resulting image is generated by ray-casting and combining the intersected features proportional to their importance (importance compositing). The paper includes an extended discussion on several possible schemes for levels of sparseness specification. Furthermore, different approaches to importance compositing are treated.","1941-0506","","10.1109/TVCG.2005.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1432686","Index Terms- View-dependent visualization;volume rendering;focus+context techniques;level-of-detail techniques;illustrative techniques.","Data visualization;Medical diagnostic imaging;Liver neoplasms;Lesions;Focusing;Biomedical optical imaging;Biomedical imaging;Rendering (computer graphics);Shape;Layout","feature extraction;data visualisation;hidden feature removal;rendering (computer graphics);ray tracing;visual databases","importance-driven feature enhancement;volume visualization;focus-context approach;ray-casting;sparseness specification","Algorithms;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Biological;Numerical Analysis, Computer-Assisted;Online Systems;Pattern Recognition, Automated;User-Computer Interface","102","8","29","","23 May 2005","","","IEEE","IEEE Journals"
"Design Study of LineSets, a Novel Set Visualization Technique","B. Alper; N. Riche; G. Ramos; M. Czerwinski","Microsoft Research, UC Santa Barbara; Microsoft Research; Microsoft Research; Microsoft Research","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2259","2267","Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.","1941-0506","","10.1109/TVCG.2011.186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064991","Set visualization;clustering;faceted data visualization;graph visualization.","Data visualization;Social network services;Shape analysis;Accuracy;Geometry","cartography;data visualisation;geometry;set theory","linesets;set visualization;convex geometry;concave geometry;set visual representation;information visualization;heuristics;search tasks;map;community analysis task;social network","","101","","22","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Online Dynamic Graph Drawing","Y. Frishman; A. Tal","Dept. of Comput. Sci., Israel Inst. of Technol., Haifa; NA","IEEE Transactions on Visualization and Computer Graphics","23 May 2008","2008","14","4","727","740","This paper presents an algorithm for drawing a sequence of graphs online. The algorithm strives to maintain the global structure of the graph and, thus, the user's mental map while allowing arbitrary modifications between consecutive layouts. The algorithm works online and uses various execution culling methods in order to reduce the layout time and handle large dynamic graphs. Techniques for representing graphs on the GPU allow a speedup by a factor of up to 17 compared to the CPU implementation. The scalability of the algorithm across GPU generations is demonstrated. Applications of the algorithm to the visualization of discussion threads in Internet sites and to the visualization of social networks are provided.","1941-0506","","10.1109/TVCG.2008.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4433990","Graph layout;GPU;Graph layout;GPU","Visualization;Sequences;Social network services;Application software;Engineering drawings;Heuristic algorithms;Internet;Scalability;IP networks","coprocessors;data visualisation;graph theory;Internet","online dynamic graph drawing;user mental map;consecutive layouts;execution culling methods;GPU;discussion threads visualization;Internet sites;social networks","Algorithms;Computer Graphics;Image Processing, Computer-Assisted;Numerical Analysis, Computer-Assisted;Online Systems;Signal Processing, Computer-Assisted;User-Computer Interface","101","","38","","2 Feb 2008","","","IEEE","IEEE Journals"
"StoryFlow: Tracking the Evolution of Stories","S. Liu; Y. Wu; E. Wei; M. Liu; Y. Liu",Microsoft Research Asia; Microsoft Research Asia; Shanghai Jiao Tong University; Tsinghua University; Microsoft Research Asia,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2436","2445","Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.","1941-0506","","10.1109/TVCG.2013.196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634164","Layout;Optimization;White spaces;Heuristic algorithms;Motion pictures;optimization;Storylines;story-telling visualization;user interactions;level-of-detail","Layout;Optimization;White spaces;Heuristic algorithms;Motion pictures","data visualisation;humanities;optimisation","StoryFlow;story evolution;storyline visualizations;dynamic relationships;storyline layout;hybrid optimization approach;discrete optimization;continuous optimization;discrete method;entities ordering;entities alignment;real-time interactions","Algorithms;Computer Graphics;Image Enhancement;Information Dissemination;Information Storage and Retrieval;Narration;Software;User-Computer Interface","100","3","47","","16 Oct 2013","","","IEEE","IEEE Journals"
"Exploiting triangulated surface extraction using tetrahedral decomposition","A. Gueziec; R. Hummel","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","4","328","342","Beginning with digitized volumetric data, we wish to rapidly and efficiently extract and represent surfaces defined as isosurfaces in the interpolated data. The Marching Cubes algorithm is a standard approach to this problem. We instead perform a decomposition of each 8-cell associated with a voxel into five tetrahedra. We guarantee the resulting surface representation to be closed and oriented, defined by a valid triangulation of the surface of the body, which in turn is presented as a collection of tetrahedra. The entire surface is ""wrapped"" by a collection of triangles, which form a graph structure, and where each triangle is contained within a single tetrahedron. The representation is similar to the homology theory that uses simplices embedded in a manifold to define a closed curve within each tetrahedron. We introduce data structures based upon a new encoding of the tetrahedra that are at least four times more compact than the standard data structures using vertices and triangles. For parallel computing and improved cache performance, the vertex information is stored local to the tetrahedra. We can distribute the vertices in such a way that no tetrahedron ever contains more than one vertex, We give methods to evaluate surface curvatures and principal directions at each vertex, whenever these quantities are defined. Finally, we outline a method for simplifying the surface, that is reducing the vertex count while preserving the geometry. We compare the characteristics of our methods with an 8-cell based method, and show results of surface extractions from CT-scans and MR-scans at full resolution.","1941-0506","","10.1109/2945.485620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485620","","Data structures;Data mining;Isosurfaces;Testing;Encoding;Parallel processing;Geometry;Surgery","computational geometry;interpolation;image representation;data structures;data visualisation","triangulated surface extraction;tetrahedral decomposition;digitized volumetric data;surface representation;isosurfaces;interpolation;Marching Cubes algorithm;tetrahedra;triangulation;graph structure;data structures;parallel computing;cache performance;surface curvatures;geometry;surface extraction;CT-scans;MR-scans;full resolution","","99","6","34","","6 Aug 2002","","","IEEE","IEEE Journals"
"Design Considerations for Optimizing Storyline Visualizations","Y. Tanahashi; K. Ma",University of California Davis; University of California Davis,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2679","2688","Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's “Movie Narrative Charts” [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.","1941-0506","","10.1109/TVCG.2012.212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327274","Layout algorithm;timeline visualization;storyline visualization;design study","Layout;Data visualization;Genomics;Design methodology;White spaces;Motion pictures","data visualisation;evolutionary computation;humanities;interactive systems;optimisation","design considerations;storyline visualization optimization;social interactions;hand-drawn illustration;XKCD;movie narrative charts;global trends;local interactions;storyline visualization automation;evolutionary computation","","98","1","36","","8 Oct 2012","","","IEEE","IEEE Journals"
"Dynamic free-form deformations for animation synthesis","P. Faloutsos; M. Van de Panne; D. Terzopoulos","Dept. of Comput. Sci., Toronto Univ., Ont., Canada; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1997","3","3","201","214","Free form deformations (FFDs) are a popular tool for modeling and keyframe animation. The paper extends the use of FFDs to a dynamic setting. Our goal is to enable normally inanimate graphics objects, such as teapots and tables, to become animated, and learn to move about in a charming, cartoon like manner. To achieve this goal, we implement a system that can transform a wide class of objects into dynamic characters. Our formulation is based on parameterized hierarchical FFDs augmented with Lagrangian dynamics, and provides an efficient way to animate and control the simulated characters. Objects are assigned mass distributions and elastic deformation properties, which allow them to translate, rotate, and deform according to internal and external forces. In addition, we implement an automated optimization process that searches for suitable control strategies. The primary contributions of the work are threefold. First, we formulate a dynamic generalization of conventional, geometric FFDs. The formulation employs deformation modes which are tailored by the user and are expressed in terms of FFDs. Second, the formulation accommodates a hierarchy of dynamic FFDs that can be used to model local as well as global deformations. Third, the deformation modes can be active, thereby producing locomotion.","1941-0506","","10.1109/2945.620488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620488","","Animation;Deformable models;Automatic control;Lattices;Electrical capacitance tomography;Lagrangian functions;Computer graphics;Solid modeling;Shape control;Layout","computer animation;computational geometry;digital simulation;elastic deformation","dynamic free form deformations;animation synthesis;keyframe animation;Lagrangian dynamics;normally inanimate graphics objects;dynamic characters;parameterized hierarchical FFDs;simulated characters;mass distributions;elastic deformation properties;automated optimization process;control strategies;dynamic generalization;deformation modes;dynamic FFDs;global deformations;locomotion","","97","6","27","","6 Aug 2002","","","IEEE","IEEE Journals"
"SoccerStories: A Kick-off for Visual Soccer Analysis","C. Perin; R. Vuillemot; J. Fekete",INRIA and Universite Paris-Sud; INRIA; INRIA,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2506","2515","This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.","1941-0506","","10.1109/TVCG.2013.192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634087","Games;Data visualization;Layout;Navigation;visual aggregation;Visual knowledge discovery;visual knowledge representation;sport analytics","Games;Data visualization;Layout;Navigation","data analysis;data visualisation;sport","SoccerStories visualization interface;visual soccer analysis;soccer data exploration;quantitative analysis;game phase overview-detail interface;connected visualizations;qualitative user studies;word-sized graphics","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Information Dissemination;Narration;Reproducibility of Results;Sensitivity and Specificity;Soccer;User-Computer Interface","97","1","26","","16 Oct 2013","","","IEEE","IEEE Journals"
"Spatially Ordered Treemaps","J. Wood; J. Dykes","giCentre, City University London; giCentre, City University London","IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1348","1355","Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.","1941-0506","","10.1109/TVCG.2008.165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658149","Index Terms—;Geovisualization;Treemaps;Cartograms;CIELab;Geographic information;Tree structures","Data visualization;Tree graphs;Spatial databases;Visual databases;Tree data structures;Informatics;Impedance;Navigation","data visualisation;tree data structures","spatially ordered treemaps;data order;visual ordering;locational consistency;tessellated cartograms;geovisualization;Flickr database","","97","","32","","24 Oct 2008","","","IEEE","IEEE Journals"
"Skeleton-Based Edge Bundling for Graph Visualization","O. Ersoy; C. Hurter; F. Paulovich; G. Cantareiro; A. Telea","University of Groningen, The Netherlands; DGAC/DSNA, Toulouse, France; University of São Paulo, São Carlos/SP, Brazil; University of São Paulo, São Carlos/SP, Brazil; University of Groningen, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2364","2373","In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.","1941-0506","","10.1109/TVCG.2011.233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065003","Graph layouts;edge bundles;image-based information visualization.","Image edge detection;Shape analysis;Transforms;Smoothing methods;Image processing","data visualisation;graph theory;pattern clustering","skeleton-based edge bundling;graph visualization;medial axes;edge clustering;distance fields;2D skeletonization;graphics hardware","","96","4","36","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Conveying the 3D shape of smoothly curving transparent surfaces via texture","V. Interrante; H. Fuchs; S. M. Pizer","Inst. for Comput. Appl. in Sci. & Eng., Hampton, VA, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1997","3","2","98","117","Transparency can be a useful device for depicting multiple overlapping surfaces in a single image. The challenge is to render the transparent surfaces in such a way that their 3D shape can be readily understood and their depth distance from underlying structures clearly perceived. This paper describes our investigations into the use of sparsely-distributed discrete, opaque texture as an artistic device for more explicitly indicating the relative depth of a transparent surface and for communicating the essential features of its 3D shape in an intuitively meaningful and minimally occluding way. The driving application for this work is the visualization of layered surfaces in radiation therapy treatment planning data, and the technique is illustrated on transparent isointensity surfaces of radiation dose. We describe the perceptual motivation and artistic inspiration for defining a stroke texture that is locally oriented in the direction of greatest normal curvature (and in which individual strokes are of a length proportional to the magnitude of the curvature in the direction they indicate), and we discuss two alternative methods for applying this texture to isointensity surfaces defined in a volume. We propose an experimental paradigm for objectively measuring observers' ability to judge the shape and depth of a layered transparent surface, in the course of a task which is relevant to the needs of radiotherapy treatment planning, and use this paradigm to evaluate the practical effectiveness of our approach through a controlled observer experiment based on images generated from actual clinical data.","1941-0506","","10.1109/2945.597794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=597794","","Surface texture;Surface treatment;Shape control;Biomedical applications of radiation;Surface reconstruction;Shape measurement;Layout;Optical refraction;Cancer;Rendering (computer graphics)","transparency;image texture;radiation therapy;medical image processing;mathematical morphology;rendering (computer graphics);data visualisation;art","3D shape;smoothly curving transparent surfaces;sparsely-distributed discrete opaque texture;multiple overlapping surfaces;rendering;depth distance;artistic device;relative depth;minimal occlusion;layered surface visualization;radiation therapy treatment planning data;transparent isointensity surfaces;radiation dose;shape perception;stroke texture;normal curvature;observers' ability;radiotherapy;clinical data;depth perception;shape representation;principal direction texture","","95","2","61","","6 Aug 2002","","","IEEE","IEEE Journals"
"Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time","N. Cao; Y. -R. Lin; X. Sun; D. Lazer; S. Liu; H. Qu",Hong Kong University of Science and Technology; Northeastern University; TongJi University; Northeastern University; Microsoft Research Asia; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2649","2658","When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, “Whisper”, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.","1941-0506","","10.1109/TVCG.2012.291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327271","Information visualization;information diffusion;contagion;Social media;microblogging;spatiotemporal patterns","Media;Monitoring;Real-time systems;Diffusion processes;Twitter;Social network services","data mining;data visualisation;social networking (online)","Whisper;spatiotemporal process;information diffusion;social media;Twitter;visualization design;temporal trend;social-spatial extent;sunflower metaphor;spatial hierarchical layout;flux line-drawing algorithm;temporal pattern;spatial pattern;focused diffusion series","Computer Graphics;Information Dissemination;Software;Spatio-Temporal Analysis;User-Computer Interface","94","1","54","","8 Oct 2012","","","IEEE","IEEE Journals"
"A Deeper Understanding of Sequence in Narrative Visualization","J. Hullman; S. Drucker; N. Henry Riche; B. Lee; D. Fisher; E. Adar",University of Michigan; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research; University of Michigan,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2406","2415","Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.","1941-0506","","10.1109/TVCG.2013.119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634182","Data visualization;Sequential analysis;Parallel processing;Encoding;Linear programming;narrative structure;Data storytelling;narrative visualization","Data visualization;Sequential analysis;Parallel processing;Encoding;Linear programming","cognition;data visualisation;graph theory;humanities;sequences","narrative sequencing;slideshow-style presentations;qualitative analysis;professional narrative visualizations;graph-driven approach;automatic effective sequence identification;visualization set;local transitions;visualization-to-visualization transitions;audience perspective;user preferences;global sequencing strategies;visualization sequence optimization;narrative systems","Algorithms;Artificial Intelligence;Comprehension;Computer Graphics;Humans;Multimodal Imaging;Narration;Pattern Recognition, Visual;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface;Visual Perception","93","","37","IEEE","16 Oct 2013","","","IEEE","IEEE Journals"
"Novel view synthesis by cascading trilinear tensors","S. Avidan; A. Shashua","Dept. of Comput. Sci., Hebrew Univ., Jerusalem, Israel; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1998","4","4","293","306","Presents a new method for synthesizing novel views of a 3D scene from two or three reference images in full correspondence. The core of this work is the use and manipulation of an algebraic entity, termed the ""trilinear tensor"", that links point correspondences across three images. For a given virtual camera position and orientation, a new trilinear tensor can be computed based on the original tensor of the reference images. The desired view can then be created using this new trilinear tensor and point correspondences across two of the reference images.","1941-0506","","10.1109/2945.765324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=765324","","Tensile stress;Cameras;Interpolation;Layout;Rendering (computer graphics);Virtual reality;Engines;Image generation;Extrapolation;Image quality","image registration;rendering (computer graphics);virtual reality;tensors;image matching","novel view synthesis;cascaded trilinear tensors;3D scene;reference images;images correspondence;algebraic entity;point correspondences;virtual camera position;virtual camera orientation;image-based rendering;virtual reality;image manipulation","","91","5","56","","6 Aug 2002","","","IEEE","IEEE Journals"
"Mapping Text with Phrase Nets","F. van Ham; M. Wattenberg; F. B. Viegas",IBM Research; IBM Research; IBM Research,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1169","1176","We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.","1941-0506","","10.1109/TVCG.2009.165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290726","Text visualization;tag cloud;natural language processing;semantic net","Displays;Books;Visualization;Pattern matching;Natural language processing;Computer network reliability;Pattern analysis;Tag clouds;Turning;Speech","data visualisation;text analysis","text mapping;phrase nets;visual overviews;user-specified relation","","90","3","21","","23 Oct 2009","","","IEEE","IEEE Journals"
"Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data","B. Bach; C. Shi; N. Heulot; T. Madhyastha; T. Grabowski; P. Dragicevic","Microsoft Research-Inria Joint Centre; IBM T.J, Watson Research Center, Yorktown Height, NY; IRT SystemX; Department of Radiology, University of Washington; Department of Radiology and Neurology, University of Washington; Inria","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","559","568","We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.","1941-0506","","10.1109/TVCG.2015.2467851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192639","Temporal data visualization;information visualization;multidimensional scaling;Temporal data visualization;information visualization;multidimensional scaling","Data visualization;Encyclopedias;Electronic publishing;Internet;Visualization;History","data visualisation;document handling;pattern recognition","informative pattern;temporal snapshot similarity metric;timeline visualization;video analysis;dynamic network analysis;collaborative document editing;data temporal evolution;pattern visualization;time folding;time curves","","90","1","49","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Untangling Euler Diagrams","N. H. Riche; T. Dwyer",Microsoft Research; Microsoft Corporation Microsoft Corporation,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1090","1099","In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.","1941-0506","","10.1109/TVCG.2010.210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613447","Information Visualization;Euler diagrams;Set Visualization;Graph Visualization.","Shape;Layout;Complexity theory;Visualization;Data visualization;Social network services;Semantics","data analysis;data visualisation;set theory","Venn style diagrams;Euler style diagrams;data analysis;data elements;nonempty intersection;nonconvex region technique;information visualization;set visualization;graph visualization","","90","1","33","","28 Oct 2010","","","IEEE","IEEE Journals"
"A Principled Way of Assessing Visualization Literacy","J. Boy; R. A. Rensink; E. Bertini; J. Fekete","Inria, Telecom ParisTech, EnsadLab; University of British Columbia; NYU Polytechnic School of Engineering; Inria","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1963","1972","We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use.","1941-0506","","10.1109/TVCG.2014.2346984","Google Research Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875906","Literacy;Visualization literacy;Rasch Model;Item Response Theory","Data visualization;Data models;Data mining;Encoding;Market research","computer aided instruction;computer science education;data visualisation;graph theory","principled way;assessing visualization literacy;VL;item response theory;line graphs;bar chart method;scatterplots","Comprehension;Computer Graphics;Humans;Literacy;Psychological Tests;Reading;Task Performance and Analysis","89","","52","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"FacetAtlas: Multifaceted Visualization for Rich Text Corpora","N. Cao; J. Sun; Y. Lin; D. Gotz; S. Liu; H. Qu","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; NA; Arts Media & Eng., Arizona State Univ., Tempe, AZ, USA; NA; IBM China Res. Lab., Beijing, China; IEEE, Member","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1172","1181","Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.","1941-0506","","10.1109/TVCG.2010.154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613456","Multifaceted visualization;Text visualization;Multi-relational Graph;Search UI","Visualization;Diseases;Data visualization;Data models;Context;Diabetes;Switches","data analysis;data visualisation;pattern clustering;search problems;text analysis","FacetAtlas;rich text corpora;multiple facets;search tools;multifaceted relations;document clusters;multifaceted visualization technique;search technology;visual analytical tools;node cliques;multifaceted edges;optimized density map;automated opacity pattern enhancement;visual patterns;patient education;health care domain;complex multifaceted data analysis","Cluster Analysis;Computer Graphics;Data Mining;Diabetes Mellitus;Diagnosis, Computer-Assisted;HIV Infections;Humans;Pattern Recognition, Automated","89","6","32","","28 Oct 2010","","","IEEE","IEEE Journals"
"Immersive Collaborative Analysis of Network Connectivity: CAVE-style or Head-Mounted Display?","M. Cordeil; T. Dwyer; K. Klein; B. Laha; K. Marriott; B. H. Thomas","Monash University; Monash University; Monash University; Stanford University, USA; Monash University; University of South Australia","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","441","450","High-quality immersive display technologies are becoming mainstream with the release of head-mounted displays (HMDs) such as the Oculus Rift. These devices potentially represent an affordable alternative to the more traditional, centralised CAVE-style immersive environments. One driver for the development of CAVE-style immersive environments has been collaborative sense-making. Despite this, there has been little research on the effectiveness of collaborative visualisation in CAVE-style facilities, especially with respect to abstract data visualisation tasks. Indeed, very few studies have focused on the use of these displays to explore and analyse abstract data such as networks and there have been no formal user studies investigating collaborative visualisation of abstract data in immersive environments. In this paper we present the results of the first such study. It explores the relative merits of HMD and CAVE-style immersive environments for collaborative analysis of network connectivity, a common and important task involving abstract data. We find significant differences between the two conditions in task completion time and the physical movements of the participants within the space: participants using the HMD were faster while the CAVE2 condition introduced an asymmetry in movement between collaborators. Otherwise, affordances for collaborative data analysis offered by the low-cost HMD condition were not found to be different for accuracy and communication with the CAVE2. These results are notable, given that the latest HMDs will soon be accessible (in terms of cost and potentially ubiquity) to a massive audience.","1941-0506","","10.1109/TVCG.2016.2599107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539620","Oculus Rift;CAVE;Immersive Analytics;Collaboration;3D Network","Collaboration;Data visualization;Three-dimensional displays;Visualization;Two dimensional displays;Virtual reality;Navigation","data analysis;data visualisation;helmet mounted displays;virtual reality","immersive collaborative analysis;head-mounted display;high-quality immersive display technologies;low-cost HMD condition;centralised CAVE-style immersive environments;collaborative visualisation;CAVE-style facilities;abstract data visualisation tasks;network connectivity collaborative analysis;task completion time;CAVE2 condition;collaborative data analysis","","89","","41","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration","S. van den Elzen; D. Holten; J. Blaas; J. J. van Wijk",Eindhoven University of Technology; SynerScope B. V.; SynerScope B. V.; Eindhoven University of Technology,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","1","10","We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.","1941-0506","","10.1109/TVCG.2015.2468078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192717","Dynamic Networks;Exploration;Dimensionality Reduction;Dynamic Networks;Exploration;Dimensionality Reduction","Principal component analysis;Visual analytics;Animation;Manganese;Data visualization;Indexes","data analysis;data visualisation;network theory (graphs);topology","visual analytics approach;dynamic network exploration;dynamic network analysis;network snapshots;network evolution;stable state detection;recurring state detection;outlier topology;discretization;vectorization;normalization;dimensionality reduction","","89","","63","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Pargnostics: Screen-Space Metrics for Parallel Coordinates","A. Dasgupta; R. Kosara",University of North Carolina at Charlotte; University of North Carolina at Charlotte,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1017","1026","Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.","1941-0506","","10.1109/TVCG.2010.184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613439","Parallel Coordinates;metrics;display optimization;visualization models.","Measurement;Data visualization;Histograms;Clutter;Optimization;Visualization;Pixel","computational complexity;data visualisation;interactive programming;matrix algebra;parallel programming;program diagnostics","pargnostics;screen-space metrics;interactive visualization;screen space;parallel coordinates diagnostics;matrix display;NP-complete problem","","88","","32","","28 Oct 2010","","","IEEE","IEEE Journals"
"Calibration requirements and procedures for a monitor-based augmented reality system","M. Tuceryan; D. S. Greer; R. T. Whitaker; D. E. Breen; C. Crampton; E. Rose; K. H. Ahlers","Eur. Comput. Ind. Res. Centre, Munich, Germany; Eur. Comput. Ind. Res. Centre, Munich, Germany; Eur. Comput. Ind. Res. Centre, Munich, Germany; Eur. Comput. Ind. Res. Centre, Munich, Germany; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","3","255","273","Augmented reality entails the use of models and their associated renderings to supplement information in a real scene. In order for this information to be relevant or meaningful, the models must be positioned and displayed in such a way that they blend into the real world in terms of alignments, perspectives, illuminations, etc. For practical reasons the information necessary to obtain this realistic blending cannot be known a priori, and cannot be hard wired into a system. Instead a number of calibration procedures are necessary so that the location and parameters of each of the system components are known. We identify the calibration steps necessary to build a computer model of the real world and then, using the monitor based augmented reality system developed at ECRC (GRASP) as an example, we describe each of the calibration processes. These processes determine the internal parameters of our imaging devices (scan converter, frame grabber, and video camera), as well as the geometric transformations that relate all of the physical objects of the system to a known world coordinate system.<<ETX>></ETX>","1941-0506","","10.1109/2945.466720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=466720","","Calibration;Augmented reality;Computerized monitoring;Layout;Solid modeling;Cameras;Computer graphics;Engines;Computational geometry;Computer Society","virtual reality;realistic images;computational geometry;calibration","calibration requirements;monitor based augmented reality system;real scene;real world;realistic blending;calibration procedures;system components;calibration steps;computer model;monitor-based augmented reality system;GRASP;internal parameters;imaging devices;geometric transformations;physical objects;known world coordinate system;virtual reality","","87","28","38","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Parameterization and reconstruction from 3D scattered points based on neural network and PDE techniques","J. Barhak; A. Fischer","Dept. of Mech. Eng., Technion-Israel Inst. of Technol., Haifa, Israel; NA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2001","7","1","1","16","Reverse engineering ordinarily uses laser scanners since they can sample 3D data quickly and accurately relative to other systems. These laser scanner systems, however, yield an enormous amount of irregular and scattered digitized point data that requires intensive reconstruction processing. Reconstruction of freeform objects consists of two main stages: parameterization and surface fitting. Selection of an appropriate parameterization is essential for topology reconstruction as well as surface fitness. Current parameterization methods have topological problems that lead to undesired surface fitting results, such as noisy self-intersecting surfaces. Such problems are particularly common with concave shapes whose parametric grid is self-intersecting, resulting in a fitted surface that considerably twists and changes its original shape. In such cases, other parameterization approaches should be used in order to guarantee non-self-intersecting behavior. The parameterization method described in this paper is based on two stages: 2D initial parameterization; and 3D adaptive parameterization. Two methods were developed for the first stage: partial differential equation (PDE) parameterization and neural network self organizing maps (SOM) parameterization. The Gradient Descent Algorithm (GDA) and Random Surface Error Correction (RSEC), both of which are iterative surface fitting methods, were developed and implemented.","1941-0506","","10.1109/2945.910817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=910817","","Scattering parameters;Surface fitting;Surface reconstruction;Shape;Reverse engineering;Topology;Noise shaping;Partial differential equations;Neural networks;Self organizing feature maps","image reconstruction;surface fitting;partial differential equations;self-organising feature maps;iterative methods;solid modelling;computational geometry","2D initial parameterization;3D scattered points;neural network;freeform object reconstruction;surface fitting;topology reconstruction;noisy self-intersecting surfaces;3D adaptive parameterization;partial differential equation parameterization;self organizing maps;Gradient Descent Algorithm;Random Surface Error Correction;iterative methods;solid modeling","","87","2","24","","7 Aug 2002","","","IEEE","IEEE Journals"
"TopoLayout: Multilevel Graph Layout by Topological Features","D. Archambault; T. Munzner; D. Auber","Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC; IEEE Computer Society; NA","IEEE Transactions on Visualization and Computer Graphics","22 Jan 2007","2007","13","2","305","317","We describe TopoLayout, a feature-based, multilevel algorithm that draws undirected graphs based on the topological features they contain. Topological features are detected recursively inside the graph, and their subgraphs are collapsed into single nodes, forming a graph hierarchy. Each feature is drawn with an algorithm tuned for its topology. As would be expected from a feature-based approach, the runtime and visual quality of TopoLayout depends on the number and types of topological features present in the graph. We show experimental results comparing speed and visual quality for TopoLayout against four other multilevel algorithms on a variety of data sets with a range of connectivities and sizes. TopoLayout frequently improves the results in terms of speed and visual quality on these data sets","1941-0506","","10.1109/TVCG.2007.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069239","Information visualization;graphs and networks;graph visualization.","Computer vision;Clustering algorithms;Topology;Runtime;Data visualization;Computer Society;Tree graphs;Detectors","graph theory","TopoLayout;multilevel graph layout;topological features;undirected graphs;graph hierarchy;visual quality;information visualization;graph visualization","Algorithms;Computer Graphics;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Software;User-Computer Interface","87","","31","","22 Jan 2007","","","IEEE","IEEE Journals"
"A Study of Layout, Rendering, and Interaction Methods for Immersive Graph Visualization","O. Kwon; C. Muelder; K. Lee; K. Ma","Department of Computer Science, University of California, Davis, Davis, CA; Department of Computer Science, University of California, Davis, Davis, CA; Department of Digital Media, Ajou University, Suwon, Korea; Department of Computer Science, University of California, Davis, Davis, CA","IEEE Transactions on Visualization and Computer Graphics","25 May 2016","2016","22","7","1802","1815","Information visualization has traditionally limited itself to 2D representations, primarily due to the prevalence of 2D displays and report formats. However, there has been a recent surge in popularity of consumer grade 3D displays and immersive head-mounted displays (HMDs). The ubiquity of such displays enables the possibility of immersive, stereoscopic visualization environments. While techniques that utilize such immersive environments have been explored extensively for spatial and scientific visualizations, contrastingly very little has been explored for information visualization. In this paper, we present our considerations of layout, rendering, and interaction methods for visualizing graphs in an immersive environment. We conducted a user study to evaluate our techniques compared to traditional 2D graph visualization. The results show that participants answered significantly faster with a fewer number of interactions using our techniques, especially for more difficult tasks. While the overall correctness rates are not significantly different, we found that participants gave significantly more correct answers using our techniques for larger graphs.","1941-0506","","10.1109/TVCG.2016.2520921","National Research Foundation of Korea; U.S. National Science Foundation; NSF(grant numbers:DRL-1323214); NSF(grant numbers:DE-FC02-12ER26072); UC Davis's RISE program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390081","Graph visualization;virtual reality;immersive environments;head-mounted display;Graph visualization;virtual reality;immersive environments;head-mounted display","Layout;Three-dimensional displays;Data visualization;Rendering (computer graphics);Stereo image processing;Image edge detection;Two dimensional displays","data visualisation;rendering (computer graphics)","layout method;rendering method;interaction method;immersive graph visualization;information visualization;consumer grade 3D displays;immersive head-mounted displays;HMD;stereoscopic visualization environment;2D graph visualization","","86","1","61","IEEE","22 Jan 2016","","","IEEE","IEEE Journals"
"Drawing and Labeling High-Quality Metro Maps by Mixed-Integer Programming","M. Nollenburg; A. Wolff","Karlsruhe Institute of Technology (KIT) , Karlsruhe; Universität Würzburg, Würzburg","IEEE Transactions on Visualization and Computer Graphics","14 Mar 2011","2011","17","5","626","641","Metro maps are schematic diagrams of public transport networks that serve as visual aids for route planning and navigation tasks. It is a challenging problem in network visualization to automatically draw appealing metro maps. There are two aspects to this problem that depend on each other: the layout problem of finding station and link coordinates and the labeling problem of placing nonoverlapping station labels. In this paper, we present a new integral approach that solves the combined layout and labeling problem (each of which, independently, is known to be NP-hard) using mixed-integer programming (MIP). We identify seven design rules used in most real-world metro maps. We split these rules into hard and soft constraints and translate them into an MIP model. Our MIP formulation finds a metro map that satisfies all hard constraints (if such a drawing exists) and minimizes a weighted sum of costs that correspond to the soft constraints. We have implemented the MIP model and present a case study and the results of an expert assessment to evaluate the performance of our approach in comparison to both manually designed official maps and results of previous layout methods.","1941-0506","","10.1109/TVCG.2010.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473229","Network visualization;graph drawing;graph labeling;metro map;octilinear layout;mixed-integer programming.","Labeling;Navigation;Visualization;Network topology;Costs;Urban areas;Geography;Space stations;Information geometry","cartography;computational complexity;data visualisation;integer programming","high quality metro maps drawing;high quality metro maps labeling;mixed integer programming;public transport networks;visual aids;route planning;navigation tasks;network visualization;NP hard","","86","1","39","IEEE","27 May 2010","","","IEEE","IEEE Journals"
"Exact and Approximate Area-Proportional Circular Venn and Euler Diagrams","L. Wilkinson","Systat Software, Inc., Chicago","IEEE Transactions on Visualization and Computer Graphics","12 Dec 2011","2012","18","2","321","331","Scientists conducting microarray and other experiments use circular Venn and Euler diagrams to analyze and illustrate their results. As one solution to this problem, this paper introduces a statistical model for fitting area-proportional Venn and Euler diagrams to observed data. The statistical model outlined in this paper includes a statistical loss function and a minimization procedure that enables formal estimation of the Venn/Euler area-proportional model for the first time. A significance test of the null hypothesis is computed for the solution. Residuals from the model are available for inspection. As a result, this algorithm can be used for both exploration and inference on real data sets. A Java program implementing this algorithm is available under the Mozilla Public License. An R function venneuler () is available as a package in CRAN and a plugin is available in Cytoscape.","1941-0506","","10.1109/TVCG.2011.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728808","Visualization;bioinformatics;statistical graphics.","Stress;Approximation methods;Computational modeling;Mathematical model;Data models;Equations;Layout","computational geometry;diagrams;statistical analysis","area-proportional circular Venn diagrams;Euler diagrams;statistical model;statistical loss function;minimization procedure;null hypothesis;Java program;R function venneuler;CRAN","Algorithms;Computational Biology;Computer Graphics;Internet;Models, Statistical;Software","85","","52","","10 Mar 2011","","","IEEE","IEEE Journals"
"GrouseFlocks: Steerable Exploration of Graph Hierarchy Space","D. Archambault; T. Munzner; D. Auber","Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC; Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC; NA","IEEE Transactions on Visualization and Computer Graphics","23 May 2008","2008","14","4","900","913","Several previous systems allow users to interactively explore a large input graph through cuts of a superimposed hierarchy. This hierarchy is often created using clustering algorithms or topological features present in the graph. However, many graphs have domain-specific attributes associated with the nodes and edges, which could be used to create many possible hierarchies providing unique views of the input graph. GrouseFlocks is a system for the exploration of this graph hierarchy space. By allowing users to see several different possible hierarchies on the same graph, the system helps users investigate graph hierarchy space instead of a single fixed hierarchy. GrouseFlocks provides a simple set of operations so that users can create and modify their graph hierarchies based on selections. These selections can be made manually or based on patterns in the attribute data provided with the graph. It provides feedback to the user within seconds, allowing interactive exploration of this space.","1941-0506","","10.1109/TVCG.2008.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4447668","General;Graph Theory;Graph Drawing System;General;Graph Theory;Graph Drawing System","Software engineering;Packaging;Topology;Space exploration;Software packages;Tree graphs;Clustering algorithms;Feedback;Engineering drawings;Large-scale systems","graph theory;graphs;pattern clustering","graph hierarchy space;superimposed hierarchy;clustering algorithms;topological features;domain-specific attributes;GrouseFlocks","Algorithms;Computer Graphics;Motion;Numerical Analysis, Computer-Assisted;User-Computer Interface","85","2","32","","8 Feb 2008","","","IEEE","IEEE Journals"
"ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided Filtering","H. Bosch; D. Thom; F. Heimerl; E. Püttmann; S. Koch; R. Krüger; M. Wörner; T. Ertl","Visualization and Interactive Systems, University of Stuttgart; Visualization and Interactive Systems, University of Stuttgart; Visualization and Interactive Systems, University of Stuttgart; Visualization and Interactive Systems, University of Stuttgart; Visualization and Interactive Systems, University of Stuttgart; Visualization and Interactive Systems, University of Stuttgart; Visualization and Interactive Systems, University of Stuttgart; Visualization and Interactive Systems, University of Stuttgart","IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2022","2031","The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.","1941-0506","","10.1109/TVCG.2013.186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634195","Blogs;Social network services;Information retrieval;Twitter;Real-time systems;Labeling;Spatiotemporal phenomena;text classification;Microblog analysis;Twitter;text analytics;social media monitoring;live monitoring;visual analytics;information visualization;filter construction;query construction","Blogs;Social network services;Information retrieval;Twitter;Real-time systems;Labeling;Spatiotemporal phenomena","decision making;emergency management;information filtering;information filters;meta data;pattern classification;query processing;social networking (online);statistical distributions","ScatterBlogs2;microblog message real-time monitoring;user-guided filtering;microblog posts;message retrieval;Twitter;situational awareness;decision making;time-critical tasks;user-defined keyword queries;metadata restrictions;task-tailored message filters;supervised classification;query creation;term statistical distribution;co-occurrence statistical distribution;microblog feeds;emergency management scenarios","Algorithms;Blogging;Computer Graphics;Computer Systems;Information Storage and Retrieval;Reproducibility of Results;Sensitivity and Specificity;Social Media;Software;User-Computer Interface","85","3","35","","16 Oct 2013","","","IEEE","IEEE Journals"
"DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks","N. Pezzotti; T. Höllt; J. Van Gemert; B. P. F. Lelieveldt; E. Eisemann; A. Vilanova","Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Department of Radiology, Division of Image Processing, Leiden University Medical Center, Leiden, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","98","108","Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.","1941-0506","","10.1109/TVCG.2017.2744358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019872","Progressive visual analytics;deep neural networks;machine learning","Neurons;Training;Visual analytics;Neural networks;Three-dimensional displays;Layout;Kernel","data visualisation;image recognition;learning (artificial intelligence);neural net architecture","DeepEyes;pattern recognition problems;complex features;network architecture parameters;superfluous filters;trained network;deep neural networks;progressive visual analytics system","","83","","50","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study","M. Burch; N. Konevtsova; J. Heinrich; M. Hoeferlin; D. Weiskopf","VISUS, University of Stuttgart; VISUS, University of Stuttgart; VISUS, University of Stuttgart; VISUS, University of Stuttgart; VISUS, University of Stuttgart","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2440","2448","Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.","1941-0506","","10.1109/TVCG.2011.193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065011","Hierarchy visualization;node-link layout;eye tracking;user study.","Data visualization;Tracking;Trajectory;Hierarchical systems;Upper bound;Analysis of variance","data visualisation;diagrams;trees (mathematics)","orthogonal diagrams;radial tree diagrams;eye tracking study;node-link diagrams;parent-child relationship;eye tracking experiment;radial node-link tree layouts;visual exploration behavior;hierarchy exploration task;static tree diagram;gaze trajectory;nonradial diagrams;diagram orientation;eye movement data;orthogonal tree layout;trajectory analysis;nonradial layout","Adult;Algorithms;Computer Graphics;Eye Movement Measurements;Female;Humans;Male;Middle Aged;User-Computer Interface;Visual Perception;Young Adult","83","","24","","3 Nov 2011","","","IEEE","IEEE Journals"
"Origin-Destination Flow Data Smoothing and Mapping","D. Guo; X. Zhu","Department of Geography, University of South Carolina; Department of Geography, University of South Carolina","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2043","2052","This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.","1941-0506","","10.1109/TVCG.2014.2346271","National Science Foundation(grant numbers:0748813); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875983","flow mapping;kernel smoothing;generalization;multi-resolution mapping;graph drawing;spatial data mining","Flow graphs;Statistics;Smoothing methods;Bandwidth allocation;Feature extraction;Data visualization","data analysis;data visualisation;pattern classification;traffic engineering computing","origin-destination flow data;flow data smooting;flow data mapping;massive geographic mobility data;visual data representation;origin-destination flow density estimation;flow map generalization;control population;high-level pattern detection;flow data analysis;taxi trips;county-to-county migration;point-based flow data;area-based flow data","","83","","45","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Flow Map Layout via Spiral Trees","K. Buchin; B. Speckmann; K. Verbeek",TU Eindhoven; TU Eindhoven; TU Eindhoven,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2536","2544","Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments.","1941-0506","","10.1109/TVCG.2011.202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065021","Flow maps;Automated Cartography;Spiral Trees.","Tree data structures;Cost function;Steiner trees;Cartography;Approximation algorithms","cartography;data visualisation;pattern clustering;trees (mathematics)","flow map layout;spiral trees;thematic maps;object movement;good flow maps;Steiner tree;logarithmic spirals;target clustering","","82","","23","","3 Nov 2011","","","IEEE","IEEE Journals"
"Interactive Exploration and Analysis of Large-Scale Simulations Using Topology-Based Data Segmentation","P. Bremer; G. Weber; J. Tierny; V. Pascucci; M. Day; J. Bell","Lawrence Livermore National Laboratory, Livermore; Lawrence Berkeley National Laboratory, Berkeley; French National Center for Scientific Research, Paris, and Telecom ParisTech, Paris; University of Utah, Salt Lake City; Lawrence Berkeley National Laboratory, Berkeley; Lawrence Berkeley National Laboratory, Berkeley","IEEE Transactions on Visualization and Computer Graphics","11 Jul 2011","2011","17","9","1307","1324","Large-scale simulations are increasingly being used to study complex scientific and engineering phenomena. As a result, advanced visualization and data analysis are also becoming an integral part of the scientific process. Often, a key step in extracting insight from these large simulations involves the definition, extraction, and evaluation of features in the space and time coordinates of the solution. However, in many applications, these features involve a range of parameters and decisions that will affect the quality and direction of the analysis. Examples include particular level sets of a specific scalar field, or local inequalities between derived quantities. A critical step in the analysis is to understand how these arbitrary parameters/decisions impact the statistical properties of the features, since such a characterization will help to evaluate the conclusions of the analysis as a whole. We present a new topological framework that in a single-pass extracts and encodes entire families of possible features definitions as well as their statistical properties. For each time step we construct a hierarchical merge tree a highly compact, yet flexible feature representation. While this data structure is more than two orders of magnitude smaller than the raw simulation data it allows us to extract a set of features for any given parameter selection in a postprocessing step. Furthermore, we augment the trees with additional attributes making it possible to gather a large number of useful global, local, as well as conditional statistic that would otherwise be extremely difficult to compile. We also use this representation to create tracking graphs that describe the temporal evolution of the features over time. Our system provides a linked-view interface to explore the time-evolution of the graph interactively alongside the segmentation, thus making it possible to perform extensive data analysis in a very efficient manner. We demonstrate our framework by extracting and analyzing burning cells from a large-scale turbulent combustion simulation. In particular, we show how the statistical analysis enabled by our techniques provides new insight into the combustion process.","1941-0506","","10.1109/TVCG.2010.253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669296","Topology;Morse theory;merge trees;segmentation;streaming algorithms;combustion.","Fuels;Feature extraction;Combustion;Computational modeling;Data visualization;Data structures;Data models","combustion;data analysis;digital simulation;natural sciences computing;statistical analysis","large scale simulations;topology based data segmentation;data analysis;scientific process;single pass extracts;hierarchical merge tree;feature representation;burning cells;turbulent combustion simulation;statistical analysis","","82","1","65","","17 Dec 2010","","","IEEE","IEEE Journals"
"How Hierarchical Topics Evolve in Large Text Corpora","W. Cui; S. Liu; Z. Wu; H. Wei",Microsoft Research; Microsoft Research; Nankai University; Zhejiang University,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2281","2290","Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.","1941-0506","","10.1109/TVCG.2014.2346433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875938","Hierarchical topic visualization;evolutionary tree clustering;data transformation","Document handling;Text mining;Context awareness;Data visualization;Text analysis;Algorithm design and analysis","text analysis","hierarchical topics;large text corpora;topic trees sequence;document organisation;interactive visual text analysis;complex evolutionary patterns;evolutionary tree cut algorithm;tree cut;time based visualization;stable layout algorithm","Cluster Analysis;Communication;Computer Graphics;Crowdsourcing;Humans;Informatics;Task Performance and Analysis","81","","43","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems","N. Cao; C. Shi; S. Lin; J. Lu; Y. -R. Lin; C. -Y. Lin",IBM T. J. Watson Research Center; IBM T. J. Watson Research Center; IBM T. J. Watson Research Center; IBM T. J. Watson Research Center; University of Pissburg; IBM T. J. Watson Research Center,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","280","289","Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.","1941-0506","","10.1109/TVCG.2015.2467196","U.S. Defense Advanced Research Projects Agency (DARPA); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7185421","Anomaly Detection;Social Media;Visual Analysis;Anomaly Detection;Social Media;Visual Analysis","Data visualization;Visualization;Twitter;Electronic mail;Feature extraction;Context;Data models","data analysis;data visualisation;learning (artificial intelligence);security of data","social bot detection challenge;triangle grid;user behavior;machine learning techniques;anomaly detection;online communication system;anomalous user behavior;visual analysis system;Targetvue system","Computer Graphics;Humans;Internet;Social Behavior;Social Media;User-Computer Interface","81","","45","IEEE","11 Aug 2015","","","IEEE","IEEE Journals"
"Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data","N. Sauber; H. Theisel; H. -p. Seidel","Max-Planck-Inst. fur Inf., Saarbrucken; Max-Planck-Inst. fur Inf., Saarbrucken; Max-Planck-Inst. fur Inf., Saarbrucken","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","917","924","We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the Multifield-Graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets.","1941-0506","","10.1109/TVCG.2006.165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015447","Visualization;multifield;correlation","Data visualization;Computational modeling;Computer simulation;Computer science;Tensile stress","data visualisation;rendering (computer graphics)","multifield-graph method;data visualization;3D multifield scalar data;3D volume visualization technique;correlation field","","80","","28","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"Visualizing Changes of Hierarchical Data using Treemaps","Y. Tu; H. Shen",Computer Science and Engineering Department at the Ohio State University; Computer Science and Engineering Department at the Ohio State University,"IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1286","1293","While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap's stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.","1941-0506","","10.1109/TVCG.2007.70529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376152","Treemap;tree comparison;visualize changes;treemap layout algorithm.","Data visualization;Displays;File systems;Switches;Computer science;Data engineering;Stability;Software tools;Data analysis;Spirals","data visualisation;tree data structures","hierarchical data visualization;visual patterns;treemap layout algorithm;treemap snapshots;software tool","","79","6","14","","5 Nov 2007","","","IEEE","IEEE Journals"
"Divided Edge Bundling for Directional Network Data","D. Selassie; B. Heller; J. Heer",Stanford University; Stanford University; Stanford University,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2354","2363","The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten & van Wijk's force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns.","1941-0506","","10.1109/TVCG.2011.190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065002","Graph visualization;aggregation;node-link diagrams;edge bundling;physical simulation.","Encoding;Graphics;Image edge detection;Data visualization","data visualisation;directed graphs;matrix algebra;pattern clustering","directional network data;node link diagram;graph theory;directed edge bundling;graph connectivity;directional edge patterns;graph topology;visualization;matrix diagrams;clustered graphs","","78","4","19","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Modeling, animating, and rendering complex scenes using volumetric textures","F. Neyret","iMAGIS, IMAG, Grenoble, France","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1998","4","1","55","70","Complex repetitive scenes containing forests, foliage, grass, hair, or fur, are challenging for common modeling and rendering tools. The amount of data, the tediousness of modeling and animation tasks, and the cost of realistic rendering have caused such kind of scene to see only limited use even in high-end productions. The author describes how the use of volumetric textures is well suited to such scenes. These primitives can greatly simplify modeling and animation tasks. More importantly, they can be very efficiently rendered using ray tracing with few aliasing artifacts. The main idea, initially introduced by Kajiya and Kay (1989), is to represent a pattern of 3D geometry in a reference volume, that is tiled over an underlying surface much like a regular 2D texture. In our contribution, the mapping is independent of the mesh subdivision, the pattern can contain any kind of shape, and it is prefiltered at different scales as for MIP-mapping. Although the model encoding is volumetric, the rendering method differs greatly from traditional volume rendering. A volumetric texture only exists in the neighborhood of a surface, and the repeated instances (called texels) of the reference volume are spatially deformed. Furthermore, each voxel of the reference volume contains a key feature which controls the reflectance function that represents aggregate intravoxel geometry. This allows for ray tracing of highly complex scenes with very few aliasing artifacts, using a single ray per pixel (for the part of the scene using the volumetric texture representation). The major technical considerations of our method lie in the ray-path determination and in the specification of the reflectance function.","1941-0506","","10.1109/2945.675652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=675652","","Animation;Layout;Ray tracing;Geometry;Surface texture;Reflectivity;Hair;Costs;Production;Shape","computer animation;rendering (computer graphics);image texture;realistic images;ray tracing;computational geometry","modeling;animation;rendering;complex scenes;volumetric textures;complex repetitive scenes;realistic rendering;ray tracing;aliasing;3D geometry;mesh subdivision;volume rendering;reflectance function;aggregate intravoxel geometry;three dimensional geometry","","78","16","28","","6 Aug 2002","","","IEEE","IEEE Journals"
"The Design Space of Implicit Hierarchy Visualization: A Survey","H. Schulz; S. Hadlak; H. Schumann","University of Rostock, Rostock; University of Rostock, Rostock; University of Rostock, Rostock","IEEE Transactions on Visualization and Computer Graphics","17 Feb 2011","2011","17","4","393","411","Apart from explicit node-link representations, implicit visualizations and especially the Treemap as their frontrunner have acquired a solid position among the available techniques to visualize hierarchies. Their advantage is a highly space-efficient graphical representation that does not require explicit drawing of edges. In this paper, we survey the design space for this class of visualization techniques. We establish the design space along the four axes of dimensionality, edge representation, node representation, and layout by examining existing implicit hierarchy visualization techniques. The survey is completed by casting some light into regions of the design space that have not yet been explored. Our design space is not a mere theoretical construct, but a practically usable tool for rapid visualization development. To that end, we discuss a software implementation of the introduced design space.","1941-0506","","10.1109/TVCG.2010.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473227","Information visualization;hierarchy visualization;Treemaps;visualization design space;rapid visualization prototyping.","Data visualization;Tree graphs;Prototypes;Solids;Layout;Casting;Space exploration;Software prototyping;Encoding;Computer graphics","data visualisation;software prototyping","implicit hierarchy visualization;explicit node-link representations;treemap;space-efficient graphical representation;dimensionality aspect;edge representation aspect;node representation aspect;layout aspect;design space;rapid visualization development","","78","1","79","","27 May 2010","","","IEEE","IEEE Journals"
"Topological fisheye views for visualizing large graphs","E. R. Gansner; Y. Koren; S. C. North","AT&T Shannon Labs., AT&T Res., Florham Park, NJ, USA; AT&T Shannon Labs., AT&T Res., Florham Park, NJ, USA; AT&T Shannon Labs., AT&T Res., Florham Park, NJ, USA","IEEE Transactions on Visualization and Computer Graphics","23 May 2005","2005","11","4","457","468","Graph drawing is a basic visualization tool that works well for graphs having up to hundreds of nodes and edges. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, multiscale, and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we propose a topological zooming method. It precomputes a hierarchy of coarsened graphs that are combined on-the-fly into renderings, with the level of detail dependent on distance from one or more foci. A related geometric distortion method yields constant information density displays from these renderings.","1941-0506","","10.1109/TVCG.2005.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1432691","Index Terms- Topological fisheye;large graph visualization.","Nonlinear distortion;Data visualization;Tree graphs;Navigation;Animation;Linear algebra;Statistics;Humans;Large screen displays;Phase distortion","data visualisation;rendering (computer graphics);computational geometry;graphs","topological fisheye views;large graph visualization;graph drawing;occlusion;geometric distortion method","Algorithms;Computer Graphics;Database Management Systems;Databases, Factual;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Online Systems;User-Computer Interface","78","4","29","","23 May 2005","","","IEEE","IEEE Journals"
"Visual Analysis of Topic Competition on Social Media","P. Xu; Y. Wu; E. Wei; T. -Q. Peng; S. Liu; J. J. H. Zhu; H. Qu",Hong Kong University of Science and Technology; Microsoft Research Asia; Shanghai Jiao Tong University; Nanyang Technological University; Microsoft Research Asia; City University of Hong Kong; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2012","2021","How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.","1941-0506","","10.1109/TVCG.2013.221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634134","Visual analytics;Data visualization;Mathematical model;Recruitment;Social network services;agenda-setting;Social media visuaization;topic competition;information diffusion;information propagation","Visual analytics;Data visualization;Mathematical model;Recruitment;Social network services","data visualisation;social networking (online)","visual analysis techniques;Tweets;2012 United States presidential election;Occupy Wall Street movement;public agenda;storyline style visualization;ThemeRiver;information diffusion process;social aspects;topical aspects;visual design;metaphoric interpretation;timeline visualization;public attention competition;topic competition model;topic competitiveness;opinion leaders;social media","Algorithms;Computer Graphics;Data Mining;Image Interpretation, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Social Media;User-Computer Interface","78","","50","","16 Oct 2013","","","IEEE","IEEE Journals"
"Visual Analysis of the Air Pollution Problem in Hong Kong","H. Qu; W. Chan; A. Xu; K. Chung; K. Lau; P. Guo",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Beijing Normal University; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Beijing Normal University,"IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1408","1415","We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.","1941-0506","","10.1109/TVCG.2007.70523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376168","Weather data visualization;polar system;parallel coordinates;air pollution;visual analytics.","Air pollution;Data visualization;Wind speed;Environmentally friendly manufacturing techniques;Industrial pollution;Power generation;Pattern analysis;Visual analytics;Cities and towns;Vehicles","air pollution;data visualisation;graph theory;meteorology","air pollution problem;Hong Kong;weather data visualization;circular pixel bar charts;polar systems;enhanced parallel coordinates;S-shape axis;weighted complete graphs","Air Pollutants;Air Pollution;Air Pollution;Computer Simulation;Environmental Monitoring;Hong Kong;Imaging, Three-Dimensional;Models, Theoretical;User-Computer Interface","77","4","23","","5 Nov 2007","","","IEEE","IEEE Journals"
"Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering","A. Endert; P. Fiaux; C. North",Virginia Polytechnic Institute and State University; Virginia Polytechnic Institute and State University; Virginia Polytechnic Institute and State University,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2879","2888","Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users' analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user's reasoning and intuition.","1941-0506","","10.1109/TVCG.2012.260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327294","User Interaction;visualization;sensemaking;analytic reasoning;visual analytics","Semantics;User interfaces;Analytical models;Visual analytics;Mathematical model","data visualisation;inference mechanisms","semantic interaction;sensemaking;analytical reasoning;model steering;visual analytic tools;cognitively demanding task;mathematical models;visualization;human intuition;expressive interactions;spatially clustering data;parametric modifications;clustering model;visual analytic prototype;ForceSPIRE;keyword weighting","","76","2","36","","8 Oct 2012","","","IEEE","IEEE Journals"
"Color Design for Illustrative Visualization","L. Wang; J. Giesen; K. T. McDonnell; P. Zolliker; K. Mueller",Stony Brook University; Friedrich-Schiller-Universität Jena; Dowling College; EMPA Dübendorf; Stony Brook University,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1739","1754","Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework's use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.","1941-0506","","10.1109/TVCG.2008.118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658198","Index Terms—;Color design;volume rendering;transparency;user study evaluation;conjoint analysis;illustrative visualization","Color;Data visualization;Layout;Graphics;Knowledge based systems;Rendering (computer graphics);Testing;Humans;Visual perception;Engines","colour graphics;data visualisation;knowledge based systems;rendering (computer graphics)","color design;illustrative visualization;effective color palettes;occluded objects;visual aesthetics;knowledge-based system;scene composition;semi-transparent layer rendering;perceptual color maps","","75","1","37","","24 Oct 2008","","","IEEE","IEEE Journals"
"DICON: Interactive Visual Analysis of Multidimensional Clusters","N. Cao; D. Gotz; J. Sun; H. Qu",Hong Kong University of Science and Technology; IBM T.J. Watson Research Center; IBM T.J. Watson Research Center; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2581","2590","Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.","1941-0506","","10.1109/TVCG.2011.188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065026","Visual Analysis;Clustering;Information Visualization.","Visualization;Clustering algorithms;Encoding;Image color analysis;Information analysis;Algorithm design and analysis","data analysis;data structures;data visualisation;embedded systems;interactive systems;pattern clustering;statistical distributions","DICON;interactive visual analysis;multidimensional cluster;fundamental data analysis technique;complex data;high-level statistical information;cluster quality;multidimensional attribute display;icon-based cluster visualization;statistical information;layout algorithm;user interaction;clutter reduction","Algorithms;Cluster Analysis;Computer Graphics;Data Interpretation, Statistical;Databases, Factual;Humans;User-Computer Interface","75","","40","","3 Nov 2011","","","IEEE","IEEE Journals"
"EvoRiver: Visual Analysis of Topic Coopetition on Social Media","G. Sun; Y. Wu; S. Liu; T. Peng; J. J. H. Zhu; R. Liang",Zhejiang University of Technology; Microsoft Research; Microsoft Research; Nanyang Technological University; City University of Hong Kong; Zhejiang University of Technology,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1753","1762","Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).","1941-0506","","10.1109/TVCG.2014.2346919","National Natural Science Foundation of China(grant numbers:61379076); Program for New Century Excellent Talents in University(grant numbers:NCET-12-1087); Natural Science Foundation of Zhejiang Province(grant numbers:LR14F020002); HKRGC GRF(grant numbers:CityU 154412); Microsoft(grant numbers:NTU M4061358.060); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875992","Topic coopetition;information diffusion;information propagation;time-based visualization","Visual analytics;Social network services;Cooperation;Media;Data visualization","Internet;social networking (online)","EvoRiver;topic coopetition;social media;public attention;visual analytics system;indepth analysis;coopetition recruitment;coopetition distraction effects;close functional approximation;Twitter data sets","Computer Graphics;Humans;Informatics;Information Dissemination;Models, Theoretical;Social Media","75","","46","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Fast construction of k-nearest neighbor graphs for point clouds","M. Connor; P. Kumar","Florida State University, Tallahassee; Florida State University, Tallahassee","IEEE Transactions on Visualization and Computer Graphics","18 May 2010","2010","16","4","599","608","We present a parallel algorithm for k-nearest neighbor graph construction that uses Morton ordering. Experiments show that our approach has the following advantages over existing methods: 1) faster construction of k-nearest neighbor graphs in practice on multicore machines, 2) less space usage, 3) better cache efficiency, 4) ability to handle large data sets, and 5) ease of parallelization and implementation. If the point set has a bounded expansion constant, our algorithm requires one-comparison-based parallel sort of points, according to Morton order plus near-linear additional steps to output the k-nearest neighbor graph.","1941-0506","","10.1109/TVCG.2010.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383353","Nearest neighbor searching;point-based graphics;k-nearest neighbor graphics;Morton ordering;parallel algorithms.","Concurrent computing;Parallel algorithms;Multicore processing;Three-dimensional displays;Computer graphics;Visualization;Surface reconstruction;Algorithm design and analysis","computational geometry;graph theory;parallel algorithms;pattern classification","k-nearest neighbor graphs;point clouds;parallel algorithm;Morton ordering;multicore machines","Algorithms;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Theoretical;User-Computer Interface","74","6","29","","15 Jan 2010","","","IEEE","IEEE Journals"
"Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations","S. van den Elzen; J. J. van Wijk","Department of Mathematic and Computer Science, Eindhoven University of Technology, The Netherlands; Department of Mathematic and Computer Science, Eindhoven University of Technology, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2310","2319","Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.","1941-0506","","10.1109/TVCG.2014.2346441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875972","Multivariate networks;Selections of interest;Interaction;Direct manipulation","Data visualization;Clutter;Network topology;Context awareness;Image color analysis","graphical user interfaces;network theory (graphs);topology","multivariate network presentation;ubiquitous network data;e-mail traffic;large-multivariate networks;topological network structure;network links;network nodes;network topology;multivariate network exploration;multivariate network analysis;structural analysis;multivariate data analysis;Detail-to-Overview-via-Selections-and-Aggregations;DOSA framework;high-level infographic-style overviews;real-world datasets","","74","","47","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Real-Time Path Planning in Dynamic Virtual Environments Using Multiagent Navigation Graphs","A. Sud; E. Andersen; S. Curtis; M. C. Lin; D. Manocha","One Microsoft Way, Redmond; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2008","2008","14","3","526","538","We present a novel approach for efficient path planning and navigation of multiple virtual agents in complex dynamic scenes. We introduce a new data structure, Multiagent Navigation Graph (MaNG), which is constructed using first- and second-order Voronoi diagrams. The MaNG is used to perform route planning and proximity computations for each agent in real time. Moreover, we use the path information and proximity relationships for the local dynamics computation of each agent by extending a social force model [15]. We compute the MaNG using graphics hardware and present culling techniques to accelerate the computation. We also address undersampling issues and present techniques to improve the accuracy of our algorithm. Our algorithm is used for real-time multiagent planning in pursuit-evasion, terrain exploration, and crowd simulation scenarios consisting of hundreds of moving agents, each with a distinct goal.","1941-0506","","10.1109/TVCG.2008.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4441711","Computational Geometry and Object Modeling;Geometric algorithms;languages;and systems;Three-Dimensional Graphics and Realism;Animation;Virtual reality;Computational Geometry and Object Modeling;Geometric algorithms;languages;and systems;Three-Dimensional Graphics and Realism;Animation;Virtual reality","Path planning;Virtual environment;Navigation;Layout;Data structures;Graphics;Hardware;Acceleration;Pursuit algorithms;Computational modeling","computational geometry;multi-agent systems;navigation;path planning;robots;virtual reality","real-time path planning;dynamic virtual environments;multiagent navigation graphs;multiple virtual agents;Voronoi diagrams;social force model;culling techniques;undersampling issues;pursuit-evasion;terrain exploration;crowd simulation","Algorithms;Computer Graphics;Computer Systems;Data Display;Decision Support Techniques;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Motion;Numerical Analysis, Computer-Assisted;Robotics;Signal Processing, Computer-Assisted;User-Computer Interface","74","4","45","","2 Feb 2008","","","IEEE","IEEE Journals"
"Visualizing Mobility of Public Transportation System","W. Zeng; C. -W. Fu; S. M. Arisona; A. Erath; H. Qu","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; University of Applied Sciences; ETH Zurich; Hong Kong University of Science and Technology","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1833","1842","Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.","1941-0506","","10.1109/TVCG.2014.2346893","Singapore National Research Foundation (NRF) and ETH Zurich, the MOE Tier-2 fund (MOE2011-T2¿2-041 (ARC 5/12)), the MOE Tier-1 fund (RG 29/11), and the National Basic Research Program(grant numbers:2014CB340304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876029","Mobility;public transportation;visual analytics","Transportation;Data visualization;Urban areas;Visual analytics;Schedules;Radiofrequency identification;Urban areas","data visualisation;public transport;traffic engineering computing","passenger mobility visualization;public transportation system;PTS;shared transportation services;massive transportation services;network visualization methods;network topology;mobility-related factors;isochrone map view;geographical information;isotime flow map view;temporal information;OD-pair journey view;origin-destination pair;parallel isoline representation;mobility information visualization;PTS mobility model","Computer Graphics;Geographic Information Systems;Humans;Spatio-Temporal Analysis;Transportation","74","","42","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context","A. Barsky; T. Munzner; J. Gardy; R. Kincaid","University of British Columbia; University of British Columbia; University of British Columbia; Agilent Labs, Agilent Technologies","IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1253","1260","Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.","1941-0506","","10.1109/TVCG.2008.117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658137","Index Terms—;Graph layout;systems biology visualization;small multiples;design study","Visualization;Biological system modeling;Biological systems;Context modeling;Immune system;Collaborative tools;Displays;Performance analysis;Data analysis;Cells (biology)","biology computing;data visualisation;decision theory;graph theory;iterative methods;knowledge representation","multiple experimental condition visualization;interaction graph layout;biological system;iterative process;living cells reaction observation;dynamic knowledge representation;drawing package;data information display;design decision;cerebral tool","Biology;Computer Graphics;Computer Simulation;Models, Biological;Proteome;Signal Transduction;Software;User-Computer Interface","73","","42","","24 Oct 2008","","","IEEE","IEEE Journals"
"Multi-Level Graph Layout on the GPU","Y. Frishman; A. Tal","Technion, Israel Institute of Technology; Technion, Israel Institute of Technology","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1310","1319","This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented.","1941-0506","","10.1109/TVCG.2007.70580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376155","Graph layout;GPU;graph partitioning.","Partitioning algorithms;Acceleration;Application software;Visualization;High performance computing;Parallel programming;Computer architecture;Quality management;Network topology;Web and internet services","computer graphics;graph theory;parallel programming","multi-level graph layout;directed graph layout;general multi-level scheme;spectral partitioning;data parallel programming model;naturally unstructured graph;multi-core architectures;Internet service provider;graph partitioning","","73","1","41","","5 Nov 2007","","","IEEE","IEEE Journals"
"Automatic isosurface propagation using an extrema graph and sorted boundary cell lists","T. Itoh; K. Koyamada","Res. Lab., IBM Japan Ltd., Tokyo, Japan; Res. Lab., IBM Japan Ltd., Tokyo, Japan","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","4","319","327","A high-performance algorithm for generating isosurfaces is presented. In our method, guides to searching for cells intersected by an isosurface are generated as a pre-process. These guides are two kinds of cell lists: an extrema graph, and sorted lists of boundary cells. In an extrema graph, extremum points are connected by arcs, and each arc has a list of cells through which it passes. At the same time, all boundary cells are sorted according to their minimum and maximum values, and two sorted lists are then generated. Isosurfaces are generated by visiting adjacent intersected cells in order. Here, the starting cells for this process are found by searching in an extrema graph and in sorted boundary cell lists. In this process, isosurfaces appear to propagate themselves. Our algorithm is efficient, since it visits only cells that are intersected by an isosurface and cells whose IDs are included in the guides. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described in this paper show the efficiency of the algorithm.","1941-0506","","10.1109/2945.485619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485619","","Isosurfaces;Visualization;Displays;Numerical simulation;Temperature;Electronic mail;Costs;Intrusion detection;Benchmark testing;Power engineering computing","data visualisation;computational geometry;graph theory;surface fitting","automatic isosurface propagation;extrema graph;sorted boundary cell lists;high-performance algorithm;isosurface generation;searching;arcs;sorted lists;adjacent intersected cells;benchmark;visualization","","72","1","10","","6 Aug 2002","","","IEEE","IEEE Journals"
"Analyzing and Tracking Burning Structures in Lean Premixed Hydrogen Flames","P. Bremer; G. Weber; V. Pascucci; M. Day; J. Bell","Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore; Lawrence Berkeley National Laboratory, Berkeley and University of California, Davis, Davis; University of Utah, Salt Lake City; Lawrence Berkeley National Laboratory, Berkeley; Lawrence Berkeley National Laboratory, Berkeley","IEEE Transactions on Visualization and Computer Graphics","15 Jan 2010","2010","16","2","248","260","This paper presents topology-based methods to robustly extract, analyze, and track features defined as subsets of isosurfaces. First, we demonstrate how features identified by thresholding isosurfaces can be defined in terms of the Morse complex. Second, we present a specialized hierarchy that encodes the feature segmentation independent of the threshold while still providing a flexible multiresolution representation. Third, for a given parameter selection, we create detailed tracking graphs representing the complete evolution of all features in a combustion simulation over several hundred time steps. Finally, we discuss a user interface that correlates the tracking information with interactive rendering of the segmented isosurfaces enabling an in-depth analysis of the temporal behavior. We demonstrate our approach by analyzing three numerical simulations of lean hydrogen flames subject to different levels of turbulence. Due to their unstable nature, lean flames burn in cells separated by locally extinguished regions. The number, area, and evolution over time of these cells provide important insights into the impact of turbulence on the combustion process. Utilizing the hierarchy, we can perform an extensive parameter study without reprocessing the data for each set of parameters. The resulting statistics enable scientists to select appropriate parameters and provide insight into the sensitivity of the results with respect to the choice of parameters. Our method allows for the first time to quantitatively correlate the turbulence of the burning process with the distribution of burning regions, properly segmented and selected. In particular, our analysis shows that counterintuitively stronger turbulence leads to larger cell structures, which burn more intensely than expected. This behavior suggests that flames could be stabilized under much leaner conditions than previously anticipated.","1941-0506","","10.1109/TVCG.2009.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5128904","Visualization;data analysis;topological data analysis;Morse complex;Reeb graph;feature detection;feature tracking;combustion simulations;burning regions.","Hydrogen;Fires;Isosurfaces;Combustion;Robustness;User interfaces;Computer graphics;Information analysis;Numerical simulation;Statistical distributions","combustion;feature extraction;flames;graph theory;graphical user interfaces;image representation;image resolution;image segmentation;interactive systems;numerical analysis;rendering (computer graphics)","burning structures;lean premixed hydrogen flames;topology;isosurfaces;Morse complex;feature segmentation;flexible multiresolution representation;tracking graphs;user interface;interactive rendering;numerical simulations;combustion process","Computer Graphics;Computer Simulation;Fires;Hot Temperature;Hydrogen;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Chemical;Rheology;User-Computer Interface","71","","37","","26 Jun 2009","","","IEEE","IEEE Journals"
"Radiance caching for efficient global illumination computation","J. Krivanek; P. Gautron; S. Pattanaik; K. Bouatouch","IRISA, Rennes, France; IRISA, Rennes, France; NA; NA","IEEE Transactions on Visualization and Computer Graphics","25 Jul 2005","2005","11","5","550","561","In this paper, we present a ray tracing-based method for accelerated global illumination computation in scenes with low-frequency glossy BRDFs. The method is based on sparse sampling, caching, and interpolating radiance on glossy surfaces. In particular, we extend the irradiance caching scheme proposed by Ward et al. (1988) to cache and interpolate directional incoming radiance instead of irradiance. The incoming radiance at a point is represented by a vector of coefficients with respect to a hemispherical or spherical basis. The surfaces suitable for interpolation are selected automatically according to the roughness of their BRDF. We also propose a novel method for computing translational radiance gradient at a point.","1941-0506","","10.1109/TVCG.2005.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471692","Index Terms- Global illumination;ray tracing;hemispherical harmonics;spherical harmonics;directional distribution.","Lighting;Interpolation;Ray tracing;Acceleration;Layout;Monte Carlo methods;Sampling methods;Computer science;Rough surfaces;Surface roughness","ray tracing;lighting;brightness;Monte Carlo methods;image sampling;interpolation","radiance caching;global illumination computation;ray tracing;low-frequency glossy BRDF scenes;sparse sampling;irradiance caching scheme;radiance interpolation;hemispherical harmonics;spherical harmonics","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Lighting","70","12","54","IEEE","25 Jul 2005","","","IEEE","IEEE Journals"
"Visual Exploration of Sparse Traffic Trajectory Data","Z. Wang; T. Ye; M. Lu; X. Yuan; H. Qu; J. Yuan; Q. Wu","Peking University; Peking University; Peking University; Peking University; Hong Kong University of Science and Technology; Nanjing Intelligent Transportation Systems Co., Ltd; Nanjing Intelligent Transportation Systems Co., Ltd","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1813","1822","In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.","1941-0506","","10.1109/TVCG.2014.2346746","National Natural Science Foundation of China(grant numbers:61170204); Hong Kong University of Science and Technology(grant numbers:SRFI11EG 15PG); National Natural Science Foundation of China(grant numbers:61232012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876014","Sparse Traffic Trajectory;Traffic Visualization;Dynamic Graph Visualization;Traffic Congestion","Trajectory;Visual analytics;Data visualization;Aircraft navigation","data visualisation;road pricing (tolls);road vehicles;traffic engineering computing","visual exploration;sparse traffic trajectory data;visual analysis system;transportation cells;road vehicles;macrotraffic analysis;macrotraffic patterns;trajectory aggregation techniques;cell status pattern;intercell flow pattern;traffic congestion;traffic flows;route selection","Cities;Computer Graphics;Computer Simulation;Humans;Informatics;Motion;Motor Vehicles","70","","46","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Benefitting InfoVis with Visual Difficulties","J. Hullman; E. Adar; P. Shah",University of Michigan School of Information; University of Michigan School of Information; University of Michigan,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2213","2222","Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative ""chartjunk"" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.","1941-0506","","10.1109/TVCG.2011.175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064986","Desirable difficulites;cognitive efficiency;active processing;engagement;individual differences.","Psychology;Data visualization;Time factors;Cognition","cognition;data visualisation;psychology","visual difficulty;well-cited theory;visualization design;visual representation;distracting elements;decorative chartjunk;extraneous information;information visualizations;InfoVis practitioners;InfoVis researchers;information visualization practitioners;information visualization researchers;graph design;efficiency-based design theory;visual information representations;cross-disciplinary research;user understanding;visualization interaction;cognitive difficulty;psychology;visual displays;nonefficient visual elements","Cognition;Comprehension;Computer Graphics;Humans;Learning;Models, Psychological;User-Computer Interface;Visual Perception","69","","70","","3 Nov 2011","","","IEEE","IEEE Journals"
"Hardware-assisted visibility sorting for unstructured volume rendering","S. P. Callahan; M. Ikits; J. L. D. Comba; C. T. Silva","Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA; Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2005","2005","11","3","285","295","Harvesting the power of modern graphics hardware to solve the complex problem of real-time rendering of large unstructured meshes is a major research goal in the volume visualization community. While, for regular grids, texture-based techniques are well-suited for current GPUs, the steps necessary for rendering unstructured meshes are not so easily mapped to current hardware. We propose a novel volume rendering technique that simplifies the CPU-based processing and shifts much of the sorting burden to the GPU, where it can be performed more efficiently. Our hardware-assisted visibility sorting algorithm is a hybrid technique that operates in both object-space and image-space. In object-space, the algorithm performs a partial sort of the 3D primitives in preparation for rasterization. The goal of the partial sort is to create a list of primitives that generate fragments in nearly sorted order. In image-space, the fragment stream is incrementally sorted using a fixed-depth sorting network. In our algorithm, the object-space work is performed by the CPU and the fragment-level sorting is done completely on the GPU. A prototype implementation of the algorithm demonstrates that the fragment-level sorting achieves rendering rates of between one and six million tetrahedral cells per second on an ATI Radeon 9800.","1941-0506","","10.1109/TVCG.2005.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407861","Index Terms- Volume visualization;graphics processors;visibility sorting.","Sorting;Rendering (computer graphics);Hardware;Sampling methods;Graphics;Visualization;Image segmentation;Streaming media;Prototypes;Computational fluid dynamics","rendering (computer graphics);data visualisation;image texture;mesh generation;visibility","hardware-assisted visibility sorting algorithm;real-time volume rendering;graphics hardware;unstructured mesh;volume visualization;regular grid;texture-based technique;object-space;image-space;3D primitives;graphics processor","Algorithms;Artificial Intelligence;Cluster Analysis;Computer Graphics;Equipment Design;Equipment Failure Analysis;Image Enhancement;Image Enhancement;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface","69","1","44","","21 Mar 2005","","","IEEE","IEEE Journals"
"ManiWordle: Providing Flexible Control over Wordle","K. Koh; B. Lee; B. Kim; J. Seo",Seoul National University; Microsoft Research; Seoul National University; Seoul National University,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1190","1197","Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired ""art work,"" harnessing the power behind the ever-increasing popularity of Wordle.","1941-0506","","10.1109/TVCG.2010.175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613458","Interaction design;direct manipulation;flexibilty-usability tradeoff;tag-cloud;participatory visualization;user study.","Layout;Tag clouds;Visualization;Color;Instruction sets;Spirals;Usability","data visualisation;text analysis","ManiWordle;flexible control;wordle;multifarious tag-clouding techniques;aesthetic layout;participatory culture;Wordle-based visualization tool;custom manipulations;typography;design rationale;interaction techniques;layout tweaking;user satisfaction;art work","","69","5","30","","28 Oct 2010","","","IEEE","IEEE Journals"
"Efficient and Accurate Sound Propagation Using Adaptive Rectangular Decomposition","N. Raghuvanshi; R. Narain; M. C. Lin","University of North Carolina, Chapel Hill, Chapel Hill; University of North Carolina, Chapel Hill, Chapel Hill; University of North Carolina, Chapel Hill, Chapel Hill","IEEE Transactions on Visualization and Computer Graphics","17 Jul 2009","2009","15","5","789","801","Accurate sound rendering can add significant realism to complement visual display in interactive applications, as well as facilitate acoustic predictions for many engineering applications, like accurate acoustic analysis for architectural design (Monks et al., 2000). Numerical simulation can provide this realism most naturally by modeling the underlying physics of wave propagation. However, wave simulation has traditionally posed a tough computational challenge. In this paper, we present a technique which relies on an adaptive rectangular decomposition of 3D scenes to enable efficient and accurate simulation of sound propagation in complex virtual environments. It exploits the known analytical solution of the wave equation in rectangular domains, and utilizes an efficient implementation of the discrete cosine transform on graphics processors (GPU) to achieve at least a 100-fold performance gain compared to a standard finite-difference time-domain (FDTD) implementation with comparable accuracy, while also being 10-fold more memory efficient. Consequently, we are able to perform accurate numerical acoustic simulation on large, complex scenes in the kilohertz range. To the best of our knowledge, it was not previously possible to perform such simulations on a desktop computer. Our work thus enables acoustic analysis on large scenes and auditory display for complex virtual environments on commodity hardware.","1941-0506","","10.1109/TVCG.2009.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5165582","Sound propagation;computational acoustics;auralization;FDTD.","Acoustic propagation;Computational modeling;Layout;Acoustic applications;Numerical simulation;Virtual environment;Finite difference methods;Time domain analysis;Displays;Acoustical engineering","acoustic signal processing;acoustic wave propagation;discrete cosine transforms;finite difference time-domain analysis;rendering (computer graphics);solid modelling;virtual reality;wave equations","sound propagation;adaptive rectangular decomposition;sound rendering;visual display;interactive application;acoustic prediction;3D scene;complex virtual environment;wave equation;discrete cosine transform;graphics processor;finite-difference time-domain;numerical acoustic simulation;acoustic analysis;auditory display;commodity hardware","","67","18","51","","17 Jul 2009","","","IEEE","IEEE Journals"
"IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs","T. Dwyer; Y. Koren; K. Marriott","Monash University, Australia; AT&T Labs — Research; Monash University, Australia","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","821","828","We extend the popular force-directed approach to network (or graph) layout to allow separation constraints, which enforce a minimum horizontal or vertical separation between selected pairs of nodes. This simple class of linear constraints is expressive enough to satisfy a wide variety of application-specific layout requirements, including: layout of directed graphs to better show flow; layout with non-overlapping node labels; and layout of graphs with grouped nodes (called clusters). In the stress majorization force-directed layout process, separation constraints can be treated as a quadratic programming problem. We give an incremental algorithm based on gradient projection for efficiently solving this problem. The algorithm is considerably faster than using generic constraint optimization techniques and is comparable in speed to unconstrained stress majorization. We demonstrate the utility of our technique with sample data from a number of practical applications including gene-activation networks, terrorist networks and visualization of high-dimensional data.","1941-0506","","10.1109/TVCG.2006.156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015435","Graph drawing;layout;constraints;stress majorization;force directed algorithms;multidimensional scaling.","Stress;Clustering algorithms;Data visualization;Robustness;Quadratic programming;Constraint optimization;Engineering drawings;Industrial relations;Cells (biology);Complex networks","","","","67","3","22","","20 Nov 2006","","","IEEE","IEEE Journals"
"A particle system for interactive visualization of 3D flows","J. Kruger; P. Kipfer; P. Konclratieva; R. Westermann","Dept. of Comput. Sci., Technische Univ. Munchen, Garching, Germany; Dept. of Comput. Sci., Technische Univ. Munchen, Garching, Germany; Dept. of Comput. Sci., Technische Univ. Munchen, Garching, Germany; Dept. of Comput. Sci., Technische Univ. Munchen, Garching, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","744","756","We present a particle system for interactive visualization of steady 3D flow fields on uniform grids. For the amount of particles we target, particle integration needs to be accelerated and the transfer of these sets for rendering must be avoided. To fulfill these requirements, we exploit features of recent graphics accelerators to advect particles in the graphics processing unit (GPU), saving particle positions in graphics memory, and then sending these positions through the GPU again to obtain images in the frame buffer. This approach allows for interactive streaming and rendering of millions of particles and it enables virtual exploration of high resolution fields in a way similar to real-world experiments. The ability to display the dynamics of large particle sets using visualization options like shaded points or oriented texture splats provides an effective means for visual flow analysis that is far beyond existing solutions. For each particle, flow quantities like vorticity magnitude and A2 are computed and displayed. Built upon a previously published GPU implementation of a sorting network, visibility sorting of transparent particles is implemented. To provide additional visual cues, the GPU constructs and displays visualization geometry like particle lines and stream ribbons.","1941-0506","","10.1109/TVCG.2005.87","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512024","Index Terms- Flow visualization;particle tracing;programmable graphics hardware;visibility sorting;visualization geometry.","Data visualization;Graphics;Computational modeling;Rendering (computer graphics);Displays;Sorting;Geometry;Acceleration;Particle accelerators;Streaming media","virtual reality;interactive systems;data visualisation;rendering (computer graphics);real-time systems;image texture","particle system;interactive visualization;steady 3D flow field;uniform grids;particle integration;rendering;graphics accelerator;graphics processing unit;graphics memory;frame buffer;interactive streaming;real-world experiment;image texture splat;visual flow analysis;sorting network;visibility sorting;visualization geometry;article lines;stream ribbon","Algorithms;Computer Simulation;Computer Systems;Data Display;Environment;Imaging, Three-Dimensional;Models, Theoretical;Online Systems;Rheology;User-Computer Interface","66","1","46","IEEE","26 Sep 2005","","","IEEE","IEEE Journals"
"CGLX: A Scalable, High-Performance Visualization Framework for Networked Display Environments","K. Doerr; F. Kuester","University of California, San Diego, La Jolla; University of California, San Diego, La Jolla","IEEE Transactions on Visualization and Computer Graphics","10 Jan 2011","2011","17","3","320","332","The Cross Platform Cluster Graphics Library (CGLX) is a flexible and transparent OpenGL-based graphics framework for distributed, high-performance visualization systems. CGLX allows OpenGL based applications to utilize massively scalable visualization clusters such as multiprojector or high-resolution tiled display environments and to maximize the achievable performance and resolution. The framework features a programming interface for hardware-accelerated rendering of OpenGL applications on visualization clusters, mimicking a GLUT-like (OpenGL-Utility-Toolkit) interface to enable smooth translation of single-node applications to distributed parallel rendering applications. CGLX provides a unified, scalable, distributed OpenGL context to the user by intercepting and manipulating certain OpenGL directives. CGLX's interception mechanism, in combination with the core functionality for users to register callbacks, enables this framework to manage a visualization grid without additional implementation requirements to the user. Although CGLX grants access to its core engine, allowing users to change its default behavior, general development can occur in the context of a standalone desktop. The framework provides an easy-to-use graphical user interface (GUI) and tools to test, setup, and configure a visualization cluster. This paper describes CGLX's architecture, tools, and systems components. We present performance and scalability tests with different types of applications, and we compare the results with a Chromium-based approach.","1941-0506","","10.1109/TVCG.2010.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453361","Distributed/network graphics;distributed applications;information interfaces and representation (HCI);information technology and systems;distributed systems.","Visualization;Displays;Graphics;Rendering (computer graphics);Graphical user interfaces;Testing;Libraries;Parallel programming;Engines;Scalability","data visualisation;graphical user interfaces;pattern clustering;rendering (computer graphics)","networked display environments;cross platform cluster graphics library;OpenGL based graphics framework;visualization systems;hardware accelerated rendering;GLUT like interface;graphical user interface;chromium based approach","Computer Graphics;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Software;User-Computer Interface","66","","26","","22 Apr 2010","","","IEEE","IEEE Journals"
"Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research","J. Johansson; C. Forsell","Norrköping Visualization Center C/Linköping University, Sweden; Norrköping Visualization Center C/Linköping University, Sweden","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","579","588","The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed.","1941-0506","","10.1109/TVCG.2015.2466992","Vetenskapsrådet(grant numbers:2013-4939); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192677","Survey;evaluation;guidelines;parallel coordinates.;Survey;evaluation;guidelines;parallel coordinates","Standards;Three-dimensional displays;Visualization;Layout;Clutter;Correlation;Guidelines","data analysis","parallel coordinates evaluation;multivariate data analysis;user-centred evaluations","","66","","50","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Style Grammars for Interactive Visualization of Architecture","D. G. Aliaga; P. A. Rosen; D. R. Bekins","Purdue Univ., Lafayette; Purdue Univ., Lafayette; Purdue Univ., Lafayette","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","786","797","Interactive visualization of architecture provides a way to quickly visualize existing or novel buildings and structures. Such applications require both fast rendering and an effortless input regimen for creating and changing architecture using high-level editing operations that automatically fill in the necessary details. Procedural modeling and synthesis is a powerful paradigm that yields high data amplification and can be coupled with fast-rendering techniques to quickly generate plausible details of a scene without much or any user interaction. Previously, forward generating procedural methods have been proposed where a procedure is explicitly created to generate particular content. In this paper, we present our work in inverse procedural modeling of buildings and describe how to use an extracted repertoire of building grammars to facilitate the visualization and quick modification of architectural structures and buildings. We demonstrate an interactive application where the user draws simple building blocks and, using our system, can automatically complete the building ""in the style of other buildings using view-dependent texture mapping or nonphotorealistic rendering techniques. Our system supports an arbitrary number of building grammars created from user subdivided building models and captured photographs. Using only edit, copy, and paste metaphors, the entire building styles can be altered and transferred from one building to another in a few operations, enhancing the ability to modify an existing architectural structure or to visualize a novel building in the style of the others.","1941-0506","","10.1109/TVCG.2007.1024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293021","Display algorithms;image-based rendering;modeling packages;visualization systems and software.","Buildings;Power generation;Layout;Rendering (computer graphics);Computer architecture;Computer graphics;Data visualization;Inverse problems;Software algorithms;Software packages","architectural CAD;data visualisation;rendering (computer graphics);structural engineering computing","interactive visualization;nonphotorealistic rendering techniques;inverse procedural modeling;building grammars;architectural structures;view-dependent texture mapping;photographs","Algorithms;Architecture as Topic;Computer Graphics;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Natural Language Processing;User-Computer Interface;Vocabulary, Controlled","66","7","31","","20 Aug 2007","","","IEEE","IEEE Journals"
"Interactive Level-of-Detail Rendering of Large Graphs","M. Zinsmaier; U. Brandes; O. Deussen; H. Strobelt",Uni Konstanz; Uni Konstanz; Uni Konstanz; Uni Konstanz,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2486","2495","We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.","1941-0506","","10.1109/TVCG.2012.238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327254","Graph visualization;OpenGL;edge aggregation","Rendering (computer graphics);Aggregates;Image edge detection;Data visualization;Image color analysis","rendering (computer graphics)","interactive level-of-detail rendering;straight-line graph drawings;edge cumulation;density-based node aggregation;common graphics hardware;graph data","","65","1","28","","8 Oct 2012","","","IEEE","IEEE Journals"
"KelpFusion: A Hybrid Set Visualization Technique","W. Meulemans; N. H. Riche; B. Speckmann; B. Alper; T. Dwyer",TU Eindhoven; Microsoft Research; TU Eindhoven; University of California Santa Barbara; Monash University,"IEEE Transactions on Visualization and Computer Graphics","11 Sep 2013","2013","19","11","1846","1858","We present KelpFusion: a method for depicting set membership of items on a map or other visualization using continuous boundaries. KelpFusion is a hybrid representation that bridges hull techniques such as Bubble Sets and Euler diagrams and line- and graph-based techniques such as LineSets and Kelp Diagrams. We describe an algorithm based on shortest-path graphs to compute KelpFusion visualizations. Based on a single parameter, the shortest-path graph varies from the minimal spanning tree to the convex hull of a point set. Shortest-path graphs aim to capture the shape of a point set and smoothly adapt to sets of varying densities. KelpFusion fills enclosed faces based on a set of simple legibility rules. We present the results of a controlled experiment comparing KelpFusion to Bubble Sets and LineSets. We conclude that KelpFusion outperforms Bubble Sets both in accuracy and completion time and outperforms LineSets in completion time.","1941-0506","","10.1109/TVCG.2013.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6509874","Information visualization;visualization techniques and methodologies","Visualization;Silicon;Resource management;Shape;Geometry;Filling;Accuracy","data visualisation;set theory;trees (mathematics)","hybrid set visualization technique;KelpFusion;continuous boundaries;hull techniques;bubble sets;Euler diagrams;line-based techniques;graph-based techniques;LineSets;kelp diagrams;shortest-path graphs;spanning tree;convex hull","","65","","19","","29 Apr 2013","","","IEEE","IEEE Journals"
"The Topology ToolKit","J. Tierny; G. Favelier; J. A. Levine; C. Gueunet; M. Michaux","Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France; Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France; University of Arizona, USA; Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France; Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","832","842","This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code. online documentation and video tutorials are available on TTK's website [108].","1941-0506","","10.1109/TVCG.2017.2743938","Programme d'Investissements d'Avenir FSN2(grant numbers:P112017-2661376/DOS0021427); National Science Foundation(grant numbers:IIS-1654221); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017627","Topological data analysis;scalar data;data segmentation;feature extraction;bivariate data;uncertain data","Data visualization;Algorithm design and analysis;Data analysis;Tools;Software algorithms;Data structures;Software","computational geometry;data analysis;data structures;data visualisation;graph theory;software architecture;solid modelling","topological abstractions;topological data simplification;cached triangulation data structure;direct accesses;TTK features;Topology ToolKit;software platform;topological analysis;scalar data;topological data analysis;standard data analysis tool;integral lines;persistence diagrams;persistence curves;contour trees;Morse-Smale complexes;tight integration;algorithmic software engineering challenges;TTK website","","64","","118","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Timelines Revisited: A Design Space and Considerations for Expressive Storytelling","M. Brehmer; B. Lee; B. Bach; N. H. Riche; T. Munzner","Microsoft Research, Redmond, WA; Microsoft Research, Redmond, WA; Harvard University, Cambridge, MA; Microsoft Research, Redmond, WA; University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Visualization and Computer Graphics","28 Jul 2017","2017","23","9","2151","2164","There are many ways to visualize event sequences as timelines. In a storytelling context where the intent is to convey multiple narrative points, a richer set of timeline designs may be more appropriate than the narrow range that has been used for exploratory data analysis by the research community. Informed by a survey of 263 timelines, we present a design space for storytelling with timelines that balances expressiveness and effectiveness, identifying 14 design choices characterized by three dimensions: representation, scale, and layout. Twenty combinations of these choices are viable timeline designs that can be matched to different narrative points, while smooth animated transitions between narrative points allow for the presentation of a cohesive story, an important aspect of both interactive storytelling and data videos. We further validate this design space by realizing the full set of viable timeline designs and transitions in a proof-of-concept sandbox implementation that we used to produce seven example timeline stories. Ultimately, this work is intended to inform and inspire the design of future tools for storytelling with timelines.","1941-0506","","10.1109/TVCG.2016.2614803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581076","Timelines;storytelling;narrative visualization;design space;animated transitions","Data visualization;Visualization;Context;Layout;Videos;History;Biographies","computer aided instruction;data analysis;data structures;data visualisation;interactive systems","expressive storytelling;event sequence visualization;timeline designs;data analysis;representation dimension;scale dimension;layout dimension;animated transitions;story presentation;interactive storytelling;data videos","","64","","102","IEEE","3 Oct 2016","","","IEEE","IEEE Journals"
"Visualizing Business Data with Generalized Treemaps","R. Vliegen; J. J. van Wijk; E. -J. van der Linden",MagnaView; Technische Universiteit Eindhoven; Magnaview,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","789","796","Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles.","1941-0506","","10.1109/TVCG.2006.200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015431","Information visualization;treemap;business graphics;hierarchical data","Data visualization","business data processing;business graphics;data models;data visualisation;tree data structures","business data visualization;generalized treemap algorithm;business graphics;layout algorithm;squarified algorithm;histogram;pie chart;hierarchical data visualization","","64","3","19","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"Evaluating Quality of Screen Content Images Via Structural Variation Analysis","K. Gu; J. Qiao; X. Min; G. Yue; W. Lin; D. Thalmann","Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, BeijingChina; Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, BeijingChina; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; EPFL, Lausanne, CH, Switzerland","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2018","2018","24","10","2689","2701","With the quick development and popularity of computers, computer-generated signals have drastically invaded into our daily lives. Screen content image is a typical example, since it also includes graphic and textual images as components as compared with natural scene images which have been deeply explored, and thus screen content image has posed novel challenges to current researches, such as compression, transmission, display, quality assessment, and more. In this paper, we focus our attention on evaluating the quality of screen content images based on the analysis of structural variation, which is caused by compression, transmission, and more. We classify structures into global and local structures, which correspond to basic and detailed perceptions of humans, respectively. The characteristics of graphic and textual images, e.g., limited color variations, and the human visual system are taken into consideration. Based on these concerns, we systematically combine the measurements of variations in the above-stated two types of structures to yield the final quality estimation of screen content images. Thorough experiments are conducted on three screen content image quality databases, in which the images are corrupted during capturing, compression, transmission, etc. Results demonstrate the superiority of our proposed quality model as compared with state-of-the-art relevant methods.","1941-0506","","10.1109/TVCG.2017.2771284","National Natural Science Foundation of China(grant numbers:61703009,61533002); Nova Programme Interdisciplinary Cooperation Project(grant numbers:Z161100004916041); Singapore MoE Tier 1 Project(grant numbers:M4011379,RG141/14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100977","Computer-generated signals;screen content images;quality evaluation;structural variation;human visual system","Visualization;Measurement;Brain modeling;Mathematical model;Image coding;Image quality","image colour analysis;natural scenes","structural variation analysis;graphic images;textual images;natural scene images;screen content image quality databases;computer-generated signal;human visual system","","62","","56","IEEE","9 Nov 2017","","","IEEE","IEEE Journals"
"Visual exploration of complex time-varying graphs","G. Kumar; M. Garland","University of Illinois at Urbana-Champaign, IL, USA; NVIDIA","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","805","812","Many graph drawing and visualization algorithms, such as force-directed layout and line-dot rendering, work very well on relatively small and sparse graphs. However, they often produce extremely tangled results and exhibit impractical running times for highly non-planar graphs with large edge density. And very few graph layout algorithms support dynamic time-varying graphs; applying them independently to each frame produces distracting temporally incoherent visualizations. We have developed a new visualization technique based on a novel approach to hierarchically structuring dense graphs via stratification. Using this structure, we formulate a hierarchical force-directed layout algorithm that is both efficient and produces quality graph layouts. The stratification of the graph also allows us to present views of the data that abstract away many small details of its structure. Rather than displaying all edges and nodes at once, resulting in a convoluted rendering, we present an interactive tool that filters edges and nodes using the graph hierarchy and allows users to drill down into the graph for details. Our layout algorithm also accommodates time-varying graphs in a natural way, producing a temporally coherent animation that can be used to analyze and extract trends from dynamic graph data. For example, we demonstrate the use of our method to explore financial correlation data for the U.S. stock market in the period from 1990 to 2005. The user can easily analyze the time-varying correlation graph of the market, uncovering information such as market sector trends, representative stocks for portfolio construction, and the interrelationship of stocks over time.","1941-0506","","10.1109/TVCG.2006.193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015433","Graph and network visualization;financial data visualization;hierarchy visualization;time series data","Data visualization;Animation;Data mining;Tree graphs;Layout;Heuristic algorithms;Filters;Algorithm design and analysis;Stock markets;Information analysis","","","","62","","25","","20 Nov 2006","","","IEEE","IEEE Journals"
"iVisDesigner: Expressive Interactive Design of Information Visualizations","D. Ren; T. Höllerer; X. Yuan","Department of Computer Science, University of California, Santa Barbara; Department of Computer Science, University of California, Santa Barbara; Key Laboratory of Machine Perception (Ministry of Education), School of EECS","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2092","2101","We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.","1941-0506","","10.1109/TVCG.2014.2346291","U.S. Army Research Office under MURI(grant numbers:W911NF-09-1-0553); Office of Naval Research(grant numbers:N00014-14-1-0133); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876042","Visualization design;Interactive Design;Interaction;Expressiveness;Web-based visualization","Data visualization;Information analysis;Data visualization;Web and internet services;Programming profession","data visualisation;Internet","iVisDesigner system;information visualization;Web-based system;textual programming;interactive expressiveness;conceptual modularity;information visualization design space;responsive graph layouts;brushing interaction;linking interaction;illustrative visualization designs","","62","","40","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Bas-Relief Generation Using Adaptive Histogram Equalization","X. Sun; P. L. Rosin; R. R. Martin; F. C. Langbein","Cardiff University, Cardiff; Cardiff University, Cardiff; Cardiff University, Cardiff; Cardiff University, Cardiff","IEEE Transactions on Visualization and Computer Graphics","12 May 2009","2009","15","4","642","653","An algorithm is presented to automatically generate bas-reliefs based on adaptive histogram equalization (AHE), starting from an input height field. A mesh model may alternatively be provided, in which case a height field is first created via orthogonal or perspective projection. The height field is regularly gridded and treated as an image, enabling a modified AHE method to be used to generate a bas-relief with a user-chosen height range. We modify the original image-contrast-enhancement AHE method to use gradient weights also to enhance the shape features of the bas-relief. To effectively compress the height field, we limit the height-dependent scaling factors used to compute relative height variations in the output from height variations in the input; this prevents any height differences from having too great effect. Results of AHE over different neighborhood sizes are averaged to preserve information at different scales in the resulting bas-relief. Compared to previous approaches, the proposed algorithm is simple and yet largely preserves original shape features. Experiments show that our results are, in general, comparable to and in some cases better than the best previously published methods.","1941-0506","","10.1109/TVCG.2009.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4760139","Bas-relief;adaptive histogram equalization;feature enhancement.","Histograms;Adaptive equalizers;Image coding;Shape;Production;Costs;Sun;Mesh generation;Layout;Automation","computational geometry;image enhancement;mesh generation","bas-relief generation;adaptive histogram equalization;input height field;mesh model;image contrast enhancement AHE method;gradient weights;shape features;height dependent scaling factor","","61","","27","","23 Jan 2009","","","IEEE","IEEE Journals"
"Communicating centrality in policy network drawings","U. Brandes; P. Kenis; D. Wagner","Dept. of Math. & Comput. Sci., Passau Univ., Germany; NA; NA","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2003","2003","9","2","241","253","We introduce a network visualization technique that supports an analytical method applied in the social sciences. Policy network analysis is an approach to study policy making structures, processes, and outcomes, thereby concentrating on relations between policy actors. An important operational concept for the analysis of policy networks is the notion of centrality, i.e., the distinction of actors according to their importance in a relational structure. We integrate this measure in a layout model for networks by mapping structural to geometric centrality. Thus, centrality values and network data can be presented simultaneously and explored interactively.","1941-0506","","10.1109/TVCG.2003.1196010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196010","","Intelligent networks;Social network services;Public policy;Data visualization;Solid modeling;Information analysis;Drugs;Instruments;Collaboration;Multidimensional systems","social sciences computing;data visualisation;graphs","network visualization technique;social sciences;policy network analysis;policy making structures;policy making processes;policy making outcomes;operational concept;centrality;relational structure;geometric centrality;structural centrality;force-directed placement","","61","1","31","IEEE","29 Apr 2003","","","IEEE","IEEE Journals"
"Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets","J. Zhao; C. Collins; F. Chevalier; R. Balakrishnan","University of Toronto; University of Ontario Institute of Technology; University of Toronto, Canada; University of Toronto, Canada","IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2080","2089","Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.","1941-0506","","10.1109/TVCG.2013.167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634163","Data visualization;Market research;Faceted searches;Information filters;visual analytics;Faceted browsing;network exploration;dynamic query;interaction;information visualization","Data visualization;Market research;Faceted searches;Information filters","data integration;data visualisation","implicit relations;explicit relations;faceted dataset;explicit relational references;data exploration;PivotSlice interactive visualization technique;faceted browsing;direct manipulation metaphor;multifocus multiscale tabular view;visual exploration process;sensemaking process;live search;online data integration;graphical interaction history;smoothly animated visual state transitions;information visualization","Algorithms;Computer Graphics;Data Mining;Database Management Systems;Databases, Factual;User-Computer Interface","61","3","39","","16 Oct 2013","","","IEEE","IEEE Journals"
"Vectorizing Cartoon Animations","S. Zhang; T. Chen; Y. Zhang; S. Hu; R. R. Martin","Tsinghua University, Beijing; Tsinghua University, Beijing; Tsinghua University, Beijing; Tsinghua University, Beijing; Cardiff University, Cardif","IEEE Transactions on Visualization and Computer Graphics","12 May 2009","2009","15","4","618","629","We present a system for vectorizing 2D raster format cartoon animations. The output animations are visually flicker free, smaller in file size, and easy to edit. We identify decorative lines separately from colored regions. We use an accurate and semantically meaningful image decomposition algorithm, supporting an arbitrary color model for each region. To ensure temporal coherence in the output, we reconstruct a universal background for all frames and separately extract foreground regions. Simple user-assistance is required to complete the background. Each region and decorative line is vectorized and stored together with their motions from frame to frame. The contributions of this paper are: 1) the new trapped-ball segmentation method, which is fast, supports nonuniformly colored regions, and allows robust region segmentation even in the presence of imperfectly linked region edges, 2) the separate handling of decorative lines as special objects during image decomposition, avoiding results containing multiple short, thin oversegmented regions, and 3) extraction of a single patch-based background for all frames, which provides a basis for consistent, flicker-free animations.","1941-0506","","10.1109/TVCG.2009.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745633","Cartoon vectorization;trapped-ball segmentation;image decomposition;foreground extraction.","Animation;Image decomposition;Image segmentation;Coherence;Layout;Image reconstruction;Robustness;Cultural differences;Image converters;Displays","computer animation;feature extraction;image colour analysis;image segmentation","2D raster format cartoon animations;flicker-free animations;arbitrary color model;image decomposition algorithm;foreground region extraction;trapped-ball segmentation method;patch-based background","","61","2","23","","9 Jan 2009","","","IEEE","IEEE Journals"
"A Comparison of User-Generated and Automatic Graph Layouts","T. Dwyer; B. Lee; D. Fisher; K. I. Quinn; P. Isenberg; G. Robertson; C. North",Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research; University of Calgary; Microsoft Research; Virginia Tech,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","961","968","The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.","1941-0506","","10.1109/TVCG.2009.109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290700","Graph layout;network layout;automatic layout algorithms;user-generated layout;graph-drawing aesthetics","Algorithm design and analysis;Computer displays;Mice;Design optimization;Social network services;Human factors;Automatic control;Sorting","graph theory;social networking (online);user interfaces","user-generated layouts;automatic graph layouts;multitouch interaction;tabletop display;mouse interaction;desktop computer;physics-based layout;circular automatic layouts;orthogonal automatic layouts","","60","","19","","23 Oct 2009","","","IEEE","IEEE Journals"
"Learning Layouts for Single-PageGraphic Designs","P. O’Donovan; A. Agarwala; A. Hertzmann","Department of Computer Science , University of Toronto, Bahen Centre, 40 St. George Street, Toronto, Canada; Adobe Research, Adobe Systems Inc., Seattle; Department of Computer Science , University of Toronto, 10 King’s College Rd, Rm 3302, Toronto, Canada","IEEE Transactions on Visualization and Computer Graphics","1 Jul 2014","2014","20","8","1200","1213","This paper presents an approach for automatically creating graphic design layouts using a new energy-based model derived from design principles. The model includes several new algorithms for analyzing graphic designs, including the prediction of perceived importance, alignment detection, and hierarchical segmentation. Given the model, we use optimization to synthesize new layouts for a variety of single-page graphic designs. Model parameters are learned with Nonlinear Inverse Optimization (NIO) from a small number of example layouts. To demonstrate our approach, we show results for applications including generating design layouts in various styles, retargeting designs to new sizes, and improving existing designs. We also compare our automatic results with designs created using crowdsourcing and show that our approach performs slightly better than novice designers.","1941-0506","","10.1109/TVCG.2014.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777138","Graphic design;layout;modeling;learning;crowdsourcing;nonlinear inverse optimization","Layout;Computational modeling;Optimization;Predictive models;Algorithm design and analysis;Face","computer graphics;optimisation","learning layouts;graphic design layouts;energy-based model;design principles;perceived importance prediction;alignment detection;hierarchical segmentation;single-page graphic designs;model parameters;nonlinear inverse optimization;NIO;crowdsourcing;novice designers","","60","","39","OAPA","21 Mar 2014","","","IEEE","IEEE Journals"
"An Advanced Evenly-Spaced Streamline Placement Algorithm","Z. Liu; R. Moorhead; J. Groner","HPC2 / GRI / Visualization Analysis and Imaging Lab, PO Box 9627, Mississippi State University, MS 39762-9627; HPC2 / GRI / Visualization Analysis and Imaging Lab, PO Box 9627, Mississippi State University, MS 39762-9627; HPC2 / GRI / Visualization Analysis and Imaging Lab, PO Box 9627, Mississippi State University, MS 39762-9627","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","965","972","This paper presents an advanced evenly-spaced streamline placement algorithm for fast, high-quality, and robust layout of flow lines. A fourth-order Runge-Kutta integrator with adaptive step size and error control is employed for rapid accurate streamline advection. Cubic Hermite polynomial interpolation with large sample-spacing is adopted to create fewer evenly-spaced samples along each streamline to reduce the amount of distance checking. We propose two methods to enhance placement quality. Double queues are used to prioritizetopological seeding and to favor long streamlines to minimize discontinuities. Adaptive distance control based on the local flow variance is explored to reduce cavities. Furthermore, we propose a universal, effective, fast, and robust loop detection strategy to address closed and spiraling streamlines. Our algorithm is an order-of-magnitude faster than Jobard and Lefer's algorithm [8] with better placement quality and over 5 times faster than Mebarki et al.'s algorithm [9] with comparable placement quality, but with a more robust solution to loop detection.","1941-0506","","10.1109/TVCG.2006.116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015453","Flow visualization;evenly-spaced streamlines;streamline placement;seeding strategy;closed streamlines.","Streaming media;Visualization;Iterative algorithms;Programmable control;Adaptive control;Polynomials;Interpolation;Error correction;Noise robustness;Pixel","computational fluid dynamics;data visualisation;flow visualisation;interpolation;Runge-Kutta methods","advanced evenly-spaced streamline placement algorithm;flow line layout;fourth-order Runge-Kutta integrator;adaptive step size;error control;rapid accurate streamline advection;cubic Hermite polynomial interpolation;sample-spacing;distance checking;placement quality;double queues;topological seeding;adaptive distance control;local flow variance;robust loop detection strategy","","59","","20","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"A Comparative Study of Desktop, Fishtank, and Cave Systems for the Exploration of Volume Rendered Confocal Data Sets","Prabhat; A. Forsberg; M. Katzourin; K. Wharton; M. Slater","Brown Univ., Providence; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2008","2008","14","3","551","563","We present a participant study that compares biological data exploration tasks using volume renderings of laser confocal microscopy data across three environments that vary in level of immersion: a desktop, fishtank, and cave system. For the tasks, data, and visualization approach used in our study, we found that subjects qualitatively preferred and quantitatively performed better in the cave compared with the fishtank and desktop. Subjects performed real-world biological data analysis tasks that emphasized understanding spatial relationships including characterizing the general features in a volume, identifying colocated features, and reporting geometric relationships such as whether clusters of cells were coplanar. After analyzing data in each environment, subjects were asked to choose which environment they wanted to analyze additional data sets in - subjects uniformly selected the cave environment.","1941-0506","","10.1109/TVCG.2007.70433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359501","Virtual reality;Evaluation/methodology;Applications;Virtual reality;Evaluation/methodology;Applications","Data analysis;Data visualization;Microscopy;Cells (biology);Virtual reality;Virtual environment;Collaboration;Layout;Three dimensional displays;Costs","data visualisation;rendering (computer graphics);virtual reality","desktop;fishtank;cave systems;volume rendered confocal data sets;biological data exploration;volume rendering;laser confocal microscopy data;data visualization;biological data analysis;spatial relationships","Algorithms;Computer Graphics;Ecosystem;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Microscopy, Confocal;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted","58","","26","","21 Mar 2008","","","IEEE","IEEE Journals"
"TreePlus: Interactive Exploration of Networks with Enhanced Tree Layouts","Bongshin Lee; C. S. Parr; C. Plaisant; B. B. Bederson; V. D. Veksler; W. D. Gray; C. Kotfila","Dept. of Comput. Sci., Maryland Univ., College Park, MD; NA; NA; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1414","1426","Despite extensive research, it is still difficult to produce effective interactive layouts for large graphs. Dense layout and occlusion make food webs, ontologies, and social networks difficult to understand and interact with. We propose a new interactive Visual Analytics component called TreePlus that is based on a tree-style layout. TreePlus reveals the missing graph structure with visualization and interaction while maintaining good readability. To support exploration of the local structure of the graph and gathering of information from the extensive reading of labels, we use a guiding metaphor of ""Plant a seed and watch it grow.” It allows users to start with a node and expand the graph as needed, which complements the classic overview techniques that can be effective at (but often limited to) revealing clusters. We describe our design goals, describe the interface, and report on a controlled user study with 28 participants comparing TreePlus with a traditional graph interface for six tasks. In general, the advantage of TreePlus over the traditional interface increased as the density of the displayed data increased. Participants also reported higher levels of confidence in their answers with TreePlus and most of them preferred TreePlus.","1941-0506","","10.1109/TVCG.2006.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703363","Graph visualization;information visualization;navigation techniques;interaction techniques;evaluation/methodology;graphical user interfaces;Piccolo Zoomable User Interface (ZUI) Toolkit.","Tree graphs;Ontologies;Data visualization;Social network services;Visual analytics;Watches;Navigation;Graphical user interfaces;User interfaces;Sociology","data visualisation;graphical user interfaces;hidden feature removal;interactive systems;trees (mathematics)","Graph visualization;information visualization;navigation techniques;interaction techniques;evaluation/methodology;graphical user interfaces;Piccolo Zoomable User Interface (ZUI) Toolkit.","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Biological;Pattern Recognition, Automated;Software;User-Computer Interface","58","1","41","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"egoSlider: Visual Analysis of Egocentric Network Evolution","Y. Wu; N. Pitipornvivat; J. Zhao; S. Yang; G. Huang; H. Qu",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Autodesk Research; Huawei Technologies Co. Ltd.; Huawei Technologies Co. Ltd.; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","260","269","Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.","1941-0506","","10.1109/TVCG.2015.2468151","HK RGC GRF(grant numbers:618313); National Basic Research Program of China (973 Program)(grant numbers:2014CB340304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192725","Egocentric network;dynamic graph;network visualization;glyph-based design;visual analytics;Egocentric network;dynamic graph;network visualization;glyph-based design;visual analytics","Visualization;Data visualization;Microscopy;Feature extraction;Measurement;Social network services;Data analysis","data visualisation;graph theory;pattern recognition;social networking (online)","egoSlider;visual analysis;egocentric network evolution;ego-network;social network analysis;evolutionary patterns;time-varying graph structures;graph visualization;DBLP publication records;baseline visualization","Computer Graphics;Ego;Female;Humans;Internet;Male;Models, Theoretical;Social Networking;Software","58","2","53","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Perceptual Organization in User-Generated Graph Layouts","F. van Ham; B. Rogowitz",IBM Research; IBM Research,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1333","1339","Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were “masked” by extraneous edges we were able to measure observers’ sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.","1941-0506","","10.1109/TVCG.2008.155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658147","Index Terms—;Network layout visualization;perceptual organization;graph layout;user studies","Humans;Clustering algorithms;Algorithm design and analysis;Particle measurements;Concrete;Data visualization;Neural networks;Communication networks;Social network services;Performance analysis","data visualisation;graph theory","perceptual organization;user-generated graph layouts;visual representations;edge crossings;edge-lengths uniformity;network layout visualization","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Biological;Neural Networks (Computer);Pattern Recognition, Automated;User-Computer Interface;Visual Perception","57","1","22","IEEE","24 Oct 2008","","","IEEE","IEEE Journals"
"Revealing Patterns and Trends of Mass Mobility Through Spatial and Temporal Abstraction of Origin-Destination Movement Data","G. Andrienko; N. Andrienko; G. Fuchs; J. Wood","Fraunhofer Institute IAIS, Sankt Augustin, Germany; Fraunhofer Institute IAIS, Sankt Augustin, Germany; Fraunhofer Institute IAIS, Sankt Augustin, Germany; City University, London, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","28 Jul 2017","2017","23","9","2120","2136","Origin-destination (OD) movement data describe moves or trips between spatial locations by specifying the origins, destinations, start, and end times, but not the routes travelled. For studying the spatio-temporal patterns and trends of mass mobility, individual OD moves of many people are aggregated into flows (collective moves) by time intervals. Time-variant flow data pose two difficult challenges for visualization and analysis. First, flows may connect arbitrary locations (not only neighbors), thus making a graph with numerous edge intersections, which is hard to visualize in a comprehensible way. Even a single spatial situation consisting of flows in one time step is hard to explore. The second challenge is the need to analyze long time series consisting of numerous spatial situations. We present an approach facilitating exploration of long-term flow data by means of spatial and temporal abstraction. It involves a special way of data aggregation, which allows representing spatial situations by diagram maps instead of flow maps, thus reducing the intersections and occlusions pertaining to flow maps. The aggregated data are used for clustering of time intervals by similarity of the spatial situations. Temporal and spatial displays of the clustering results facilitate the discovery of periodic patterns and longer-term trends in the mass mobility behavior.","1941-0506","","10.1109/TVCG.2016.2616404","VaVeL(grant numbers:688380); SoBigData(grant numbers:654024); BigData4ATM(grant numbers:699260); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7587808","Movement data;mobility behavior;spatial flow situation;flow map","Time series analysis;Market research;Data visualization;Complexity theory;Electronic mail;Visualization;Clutter","data aggregation;data analysis;data visualisation;graph theory;pattern clustering;time series","mass mobility;spatial abstraction;temporal abstraction;origin-destination movement data;OD movement data;spatio-temporal patterns;time-variant flow data;data visualization;data analysis;graph;time series;data aggregation;diagram maps;flow maps;clustering;periodic pattern discovery","","57","","56","IEEE","11 Oct 2016","","","IEEE","IEEE Journals"
"Crest lines for surface segmentation and flattening","G. Stylianou; G. Farin","Dept. of Comput. Sci. & Eng., Cyprus Coll., Nicosia, Cyprus; NA","IEEE Transactions on Visualization and Computer Graphics","12 Jul 2004","2004","10","5","536","544","We present a method for extracting feature curves called crest lines from a triangulated surface. Then, we calculate the geodesic Voronoi diagram of crest lines to segment the surface into several regions. Afterward, barycentric surface flattening using theory from graph embeddings is implemented and, using the geodesic Voronoi diagram, we develop a faster surface flattening algorithm.","1941-0506","","10.1109/TVCG.2004.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310279","Index Terms- Crest lines;curvature;segmentation;surface flattening.","Surface fitting;Biomedical imaging;Brain;Surface texture;Image segmentation;Cerebral cortex;Shape;Conformal mapping;Feature extraction;Medical simulation","medical image processing;computational geometry;feature extraction;differential geometry;graph theory;surface fitting;curve fitting;image segmentation","feature curve extraction;crest line;triangulated surface segmentation;geodesic Voronoi diagram;barycentric surface flattening algorithm;graph embedding theory","Algorithms;Artificial Intelligence;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted","56","1","27","","12 Jul 2004","","","IEEE","IEEE Journals"
"How Capacity Limits of Attention Influence Information Visualization Effectiveness","S. Haroz; D. Whitney","University of California, Davis; University of California, Berkeley","IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2402","2410","In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users’ abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization’s intended use.","1941-0506","","10.1109/TVCG.2012.233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327245","Perception;attention;color;motion;user study;nominal axis;layout;goal-oriented design","Visualization;Layout;Data visualization;Image color analysis;Color;Accuracy;Time factors","data visualisation","information visualization effectiveness;visual feature type;visual elements;visible objects","","56","","35","IEEE","8 Oct 2012","","","IEEE","IEEE Journals"
"Perceptual Guidelines for Creating Rectangular Treemaps","N. Kong; J. Heer; M. Agrawala","University of California, Berkeley; Stanford University; University of California, Berkeley","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","990","998","Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.","1941-0506","","10.1109/TVCG.2010.186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613436","Graphical Perception;Visualization;Treemaps;Rectangular Area;Visual Encoding;Experiment;Mechanical Turk","Encoding;Accuracy;Data visualization;Visualization;Layout;Bars;Guidelines","data visualisation;tree data structures","perceptual guideline;rectangular treemap;space-filling visualization;limited display space;hierarchical data;design parameter;rectangle luminance;visual encoding;design guideline;rectangle aspect ratio;hierarchical bar chart display;data density;length-encoded bar chart;area-encoded treemap;nonleaf tree node;treemap layout","","56","","45","","28 Oct 2010","","","IEEE","IEEE Journals"
"Calibration, Registration, and Synchronization for High Precision Augmented Reality Haptics","M. Harders; G. Bianchi; B. Knoerlein; G. Szekely","ETH Zurich, Zurich; ETH Zurich, Zurich; ETH Zurich, Zurich; ETH Zurich, Zurich","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2008","2009","15","1","138","149","In our current research we examine the application of visuo-haptic augmented reality setups in medical training. To this end, highly accurate calibration, system stability, and low latency are indispensable prerequisites. These are necessary to maintain user immersion and avoid breaks in presence which potentially diminish the training outcome. In this paper we describe the developed calibration methods for visuo-haptic integration, the hybrid tracking technique for stable alignment of the augmentation, and the distributed framework ensuring low latency and component synchronization. Finally, we outline an early prototype system based on the multimodal augmented reality framework. The latter allows colocated visuo-haptic interaction with real and virtual scene components in a simplified open surgery setting.","1941-0506","","10.1109/TVCG.2008.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4492774","Haptics;Augmented Reality;Haptics;Augmented Reality","Calibration;Augmented reality;Haptic interfaces;Delay;Stability;Prototypes;Student members;Associate members;Layout;Surgery","augmented reality;biomedical education;calibration;computer based training;medical computing;surgery;synchronisation;tracking","visuo-haptic augmented reality;medical training;user immersion;calibration methods;hybrid tracking technique;component synchronization;open surgery","Algorithms;Calibration;Computer Graphics;Computer Peripherals;Information Storage and Retrieval;Information Storage and Retrieval;Switzerland;Touch;User-Computer Interface","55","2","34","","18 Apr 2008","","","IEEE","IEEE Journals"
"Fast ray-tracing of rectilinear volume data using distance transforms","M. Sramek; A. Kaufman","Comm. for Sci. Visualizations, Austrian Acad. of Sci., Vienna, Austria; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2000","6","3","236","252","The paper discusses and experimentally compares distance based acceleration algorithms for ray tracing of volumetric data with an emphasis on the Chessboard Distance (CD) voxel traversal. The acceleration of this class of algorithms is achieved by skipping empty macro regions, which are defined for each background voxel of the volume. Background voxels are labeled in a preprocessing phase by a value, defining the macro region size, which is equal to the voxel distance to the nearest foreground voxel. The CD algorithm exploits the chessboard distance and defines the ray as a nonuniform sequence of samples positioned at voxel faces. This feature assures that no foreground voxels are missed during the scene traversal. Further, due to parallelepipedal shape of the macro region, it supports accelerated visualization of cubic, regular, and rectilinear grids. The CD algorithm is suitable for all modifications of the ray tracing/ray casting techniques being used in volume visualization and volume graphics. However, when used for rendering based on local surface interpolation, it also enables fast search of intersections between rays and the interpolated surface, further improving speed of the process.","1941-0506","","10.1109/2945.879785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=879785","","Ray tracing;Acceleration;Computer graphics;Rendering (computer graphics);Layout;Casting;Data visualization;Data structures;Algorithm design and analysis;Testing","ray tracing;transforms;rendering (computer graphics);data visualisation;interpolation","fast ray tracing;rectilinear volume data;distance transforms;distance based acceleration algorithms;volumetric data;Chessboard Distance voxel traversal;empty macro region skipping;background voxel;preprocessing phase;macro region size;voxel distance;foreground voxel;CD algorithm;nonuniform sequence;voxel faces;scene traversal;parallelepipedal shape;macro region;accelerated visualization;rectilinear grids;ray casting techniques;volume visualization;volume graphics;rendering;local surface interpolation;fast search;interpolated surface","","55","1","29","","6 Aug 2002","","","IEEE","IEEE Journals"
"Multithreaded Hybrid Feature Tracking for Markerless Augmented Reality","T. Lee; T. Hollerer","University of California, Los Angeles, Los Angeles; University of California, Santa Barbara, Santa Barbara","IEEE Transactions on Visualization and Computer Graphics","16 Mar 2009","2009","15","3","355","368","We describe a novel markerless camera tracking approach and user interaction methodology for augmented reality (AR) on unprepared tabletop environments. We propose a real-time system architecture that combines two types of feature tracking. Distinctive image features of the scene are detected and tracked frame-to-frame by computing optical flow. In order to achieve real-time performance, multiple operations are processed in a synchronized multi-threaded manner: capturing a video frame, tracking features using optical flow, detecting distinctive invariant features, and rendering an output frame. We also introduce user interaction methodology for establishing a global coordinate system and for placing virtual objects in the AR environment by tracking a user's outstretched hand and estimating a camera pose relative to it. We evaluate the speed and accuracy of our hybrid feature tracking approach, and demonstrate a proof-of-concept application for enabling AR in unprepared tabletop environments, using bare hands for interaction.","1941-0506","","10.1109/TVCG.2008.190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4653490","Virtual reality;Scene Analysis;Virtual reality;Scene Analysis","Augmented reality;Cameras;Optical computing;Image motion analysis;Real time systems;Computer architecture;Layout;Optical detectors;Computer vision;Rendering (computer graphics)","augmented reality;feature extraction;image sequences;user interfaces","multithreaded hybrid feature tracking;markerless augmented reality;markerless camera tracking;user interaction;unprepared tabletop;real-time system architecture;image features;optical flow","Artificial Intelligence;Computer Graphics;Computer Simulation;Hand;Hand;Humans;Imaging, Three-Dimensional;Models, Biological;Pattern Recognition, Automated;User-Computer Interface","55","3","38","","16 Mar 2009","","","IEEE","IEEE Journals"
"3D Tooth Segmentation and Labeling Using Deep Convolutional Neural Networks","X. Xu; C. Liu; Y. Zheng","Chinese Academy of Sciences, Shanghai, China; Chinese Academy of Sciences, Shanghai, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","27 May 2019","2019","25","7","2336","2348","In this paper, we present a novel approach for 3D dental model segmentation via deep Convolutional Neural Networks (CNNs). Traditional geometry-based methods tend to receive undesirable results due to the complex appearance of human teeth (e.g., missing/rotten teeth, feature-less regions, crowding teeth, extra medical attachments, etc.). Furthermore, labeling of individual tooth is hardly enabled in traditional tooth segmentation methods. To address these issues, we propose to learn a generic and robust segmentation model by exploiting deep Neural Networks, namely NNs. The segmentation task is achieved by labeling each mesh face. We extract a set of geometry features as face feature representations. In the training step, the network is fed with those features, and produces a probability vector, of which each element indicates the probability a face belonging to the corresponding model part. To this end, we extensively experiment with various network structures, and eventually arrive at a 2-level hierarchical CNNs structure for tooth segmentation: one for teeth-gingiva labeling and the other for inter-teeth labeling. Further, we propose a novel boundary-aware tooth simplification method to significantly improve efficiency in the stage of feature extraction. After CNNs prediction, we do graph-based label optimization and further refine the boundary with an improved version of fuzzy clustering. The accuracy of our mesh labeling method exceeds that of the state-of-art geometry-based methods, reaching 99.06 percent measured by area which is directly applicable in orthodontic CAD systems. It is also robust to any possible foreign matters on model surface, e.g., air bubbles, dental accessories, and many more.","1941-0506","","10.1109/TVCG.2018.2839685","National Natural Science Foundation of China(grant numbers:61502306); China Young 1000 Talents Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362667","Boundary-aware simplification;3D mesh segmentation;deep convolutional neural networks;fuzzy clustering","Teeth;Dentistry;Feature extraction;Labeling;Three-dimensional displays;Solid modeling;Image segmentation","CAD;convolutional neural nets;dentistry;feature extraction;geometry;graph theory;image representation;image segmentation;medical image processing;optimisation;pattern clustering;probability","deep convolutional neural networks;3D dental model segmentation;human teeth;feature-less regions;generic segmentation model;robust segmentation model;segmentation task;mesh face;geometry features;face feature representations;network structures;2-level hierarchical CNNs structure;teeth-gingiva labeling;inter-teeth labeling;feature extraction;mesh labeling method;geometry-based methods;3D tooth segmentation methods;probability vector;boundary-aware tooth simplification method;graph-based label optimization;fuzzy clustering;orthodontic CAD systems","Algorithms;Dentition;Humans;Imaging, Three-Dimensional;Neural Networks, Computer;Radiography, Dental;Tomography, X-Ray Computed;Tooth","54","","80","IEEE","22 May 2018","","","IEEE","IEEE Journals"
"A network architecture supporting consistent rich behavior in collaborative interactive applications","J. Marsh; M. Glencross; S. Pettifer; R. Hubbold","Sch. of Comput. Sci., Manchester Univ., UK; Sch. of Comput. Sci., Manchester Univ., UK; Sch. of Comput. Sci., Manchester Univ., UK; Sch. of Comput. Sci., Manchester Univ., UK","IEEE Transactions on Visualization and Computer Graphics","20 Mar 2006","2006","12","3","405","416","Network architectures for collaborative virtual reality have traditionally been dominated by client-server and peer-to-peer approaches, with peer-to-peer strategies typically being favored where minimizing latency is a priority and client-server where consistency is key. With increasingly sophisticated behavior models and the demand for better support for haptics, we argue that neither approach provides sufficient support for these scenarios nor, thus, a hybrid architecture is required. We discuss the relative performance of different distribution strategies in the face of real network conditions and illustrate the problems they face. Finally, we present an architecture that successfully meets many of these challenges and demonstrate its use in a distributed virtual prototyping application which supports simultaneous collaboration for assembly, maintenance, and training applications utilizing haptics","1941-0506","","10.1109/TVCG.2006.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608027","Virtual reality;network architecture and design;haptic I/O;computer-supported collaborative work;computer-supported cooperative work;simulation;modeling;and visualization;client/server;distributed applications;computer-aided design.","Intelligent networks;Collaboration;Haptic interfaces;Application software;Delay;Virtual prototyping;Collaborative work;Virtual reality;Peer to peer computing;Computer architecture","groupware;haptic interfaces;virtual prototyping;virtual reality","network architecture;collaborative interactive applications;virtual reality;distributed virtual prototyping;haptics","Communication;Computer Communication Networks;Computer Graphics;Cooperative Behavior;Signal Processing, Computer-Assisted;User-Computer Interface","54","","50","","20 Mar 2006","","","IEEE","IEEE Journals"
"Efficient Morse Decompositions of Vector Fields","G. Chen; K. Mischaikow; R. S. Laramee; E. Zhang","Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","23 May 2008","2008","14","4","848","862","Existing topology-based vector field analysis techniques rely on the ability to extract the individual trajectories such as fixed points, periodic orbits, and separatrices that are sensitive to noise and errors introduced by simulation and interpolation. This can make such vector field analysis unsuitable for rigorous interpretations. We advocate the use of Morse decompositions, which are robust with respect to perturbations, to encode the topological structures of a vector field in the form of a directed graph, called a Morse connection graph (MCG). While an MCG exists for every vector field, it need not be unique. Previous techniques for computing MCGs, while fast, are overly conservative and usually result in MCGs that are too coarse to be useful for the applications. To address this issue, we present a new technique for performing Morse decomposition based on the concept of tau-maps, which typically provides finer MCGs than existing techniques. Furthermore, the choice of tau provides a natural trade-off between the fineness of the MCGs and the computational costs. We provide efficient implementations of Morse decomposition based on tau-maps, which include the use of forward and backward mapping techniques and an adaptive approach in constructing better approximations of the images of the triangles in the meshes used for simulation. Furthermore, we propose the use of spatial tau-maps in addition to the original temporal tau-maps. These techniques provide additional trade-offs between the quality of the MCGs and the speed of computation. We demonstrate the utility of our technique with various examples in the plane and on surfaces including engine simulation data sets.","1941-0506","","10.1109/TVCG.2008.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4447667","Flow analysis;Visualization;Flow analysis;Visualization","Data visualization;Orbits;Computational modeling;Topology;Electrocardiography;Computer Society;Interpolation;Computational fluid dynamics;Heat engines;Bifurcation","approximation theory;computational fluid dynamics;data visualisation;directed graphs;flow simulation;interpolation;mesh generation","Morse decomposition;topology-based vector field analysis;simulation;interpolation;perturbation;directed graph;Morse connection graph;MCG;mesh generation;spatial tau-map;temporal tau-map;approximation theory;data visualisation;flow combinatorialization","Algorithms;Computer Graphics;Computer Simulation;Models, Theoretical;Motion;Numerical Analysis, Computer-Assisted;Rheology;User-Computer Interface","54","","38","","8 Feb 2008","","","IEEE","IEEE Journals"
"Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees","J. Tierny; A. Gyulassy; E. Simon; V. Pascucci","Scientific Computing and Imaging Institute, University of Utah; Scientific Computing and Imaging Institute, University of Utah; Dassault Systemes; Scientific Computing and Imaging Institute, University of Utah","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1177","1184","This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in R^3. We introduce a procedure called ""loop surgery"" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning.The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets.We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.","1941-0506","","10.1109/TVCG.2009.163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290727","Reeb graph;scalar field topology;isosurfaces;topological simplification","Surgery;Tree graphs;Data visualization;Isosurfaces;Data mining;Topology;Algorithm design and analysis;Stress;Scalability;Level set","computational complexity;data visualisation;graph theory;mesh generation","loop surgery;volumetric meshes;Reeb graphs;contour trees;scalar function;time complexity;mechanical design pressure analysis","","54","","29","IEEE","23 Oct 2009","","","IEEE","IEEE Journals"
"Multidimensional Projection for Visual Analytics: Linking Techniques with Distortions, Tasks, and Layout Enrichment","L. G. Nonato; M. Aupetit","University of São Paulo, São Paulo, Brazil; Qatar Computing Research Institute, Hamad Bin Khalifa University Doha, Qatar","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2019","2019","25","8","2650","2673","Visual analysis of multidimensional data requires expressive and effective ways to reduce data dimensionality to encode them visually. Multidimensional projections (MDP) figure among the most important visualization techniques in this context, transforming multidimensional data into scatter plots whose visual patterns reflect some notion of similarity in the original data. However, MDP come with distortions that make these visual patterns not trustworthy, hindering users to infer actual data characteristics. Moreover, the patterns present in the scatter plots might not be enough to allow a clear understanding of multidimensional data, motivating the development of layout enrichment methodologies to operate together with MDP. This survey attempts to cover the main aspects of MDP as a visualization and visual analytic tool. It provides detailed analysis and taxonomies as to the organization of MDP techniques according to their main properties and traits, discussing the impact of such properties for visual perception and other human factors. The survey also approaches the different types of distortions that can result from MDP mappings and it overviews existing mechanisms to quantitatively evaluate such distortions. A qualitative analysis of the impact of distortions on the different analytic tasks performed by users when exploring multidimensional data through MDP is also presented. Guidelines for choosing the best MDP for an intended task are also provided as a result of this analysis. Finally, layout enrichment schemes to debunk MDP distortions and/or reveal relevant information not directly inferable from the scatter plot are reviewed and discussed in the light of new taxonomies. We conclude the survey providing future research axes to fill discovered gaps in this domain.","1941-0506","","10.1109/TVCG.2018.2846735","Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:302643/2013-3); Sao Paulo Research Foundation FAPESP(grant numbers:2016/04391-2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8383983","Multidimensional projection;dimensionality reduction;multidimensional scaling;error analysis;layout enrichment","Visualization;Layout;Distortion;Task analysis;Taxonomy;Data visualization;Visual perception","data analysis;data mining;data visualisation","data characteristics;visualization techniques;multidimensional projection;MDP distortions;MDP mappings;visual perception;MDP techniques;visual analytic tool;layout enrichment methodologies;visual patterns;scatter plot;multidimensional projections figure;data dimensionality;multidimensional data;visual analytics","","54","","182","IEEE","13 Jun 2018","","","IEEE","IEEE Journals"
"Multiscale visualization using data cubes","C. Stolte; D. Tang; P. Hanrahan","Dept. of Comput. Sci., Stanford Univ., CA, USA; Dept. of Comput. Sci., Stanford Univ., CA, USA; Dept. of Comput. Sci., Stanford Univ., CA, USA","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2003","2003","9","2","176","187","Most analysts start with an overview of the data before gradually refining their view to be more focused and detailed. Multiscale pan-and-zoom systems are effective because they directly support this approach. However, generating abstract overviews of large data sets is difficult and most systems take advantage of only one type of abstraction: visual abstraction. Furthermore, these existing systems limit the analyst to a single zooming path on their data and thus to a single set of abstract views. This paper presents: 1) a formalism for describing multiscale visualizations of data cubes with both data and visual abstraction and 2) a method for independently zooming along one or more dimensions by traversing a zoom graph with nodes at different levels of detail. As an example of how to design multiscale visualizations using our system, we describe four design patterns using our formalism. These design patterns show the effectiveness of multiscale visualization of general relational databases.","1941-0506","","10.1109/TVCG.2003.1196005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196005","","Data visualization;Relational databases;Switches;Visual databases;Polarization;Graphics;Data analysis;Filters;Filtering","data structures;data visualisation;visual databases","multiscale visualization;database visualization;graphic formalism;data cubes;relational databases;zoom graph;visual abstraction","","54","12","29","","29 Apr 2003","","","IEEE","IEEE Journals"
"Supine and Prone Colon Registration Using Quasi-Conformal Mapping","W. Zeng; J. Marino; K. Chaitanya Gurijala; X. Gu; A. Kaufman",Stony Brook University; Stony Brook University; Stony Brook University; Stony Brook University; Stony Brook University,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1348","1357","In virtual colonoscopy, CT scans are typically acquired with the patient in both supine (facing up) and prone (facing down) positions. The registration of these two scans is desirable so that the user can clarify situations or confirm polyp findings at a location in one scan with the same location in the other, thereby improving polyp detection rates and reducing false positives. However, this supine-prone registration is challenging because of the substantial distortions in the colon shape due to the patient's change in position. We present an efficient algorithm and framework for performing this registration through the use of conformal geometry to guarantee that the registration is a diffeomorphism (a one-to-one and onto mapping). The taeniae coli and colon flexures are automatically extracted for each supine and prone surface, employing the colon geometry. The two colon surfaces are then divided into several segments using the flexures, and each segment is cut along a taenia coli and conformally flattened to the rectangular domain using holomorphic differentials. The mean curvature is color encoded as texture images, from which feature points are automatically detected using graph cut segmentation, mathematic morphological operations, and principal component analysis. Corresponding feature points are found between supine and prone and are used to adjust the conformal flattening to be quasi-conformal, such that the features become aligned. We present multiple methods of visualizing our results, including 2D flattened rendering, corresponding 3D endoluminal views, and rendering of distortion measurements. We demonstrate the efficiency and efficacy of our registration method by illustrating matched views on both the 2D flattened colon images and in the 3D volume rendered colon endoluminal view. We analytically evaluate the correctness of the results by measuring the distance between features on the registered colons.","1941-0506","","10.1109/TVCG.2010.200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613475","Data registration;geometry-based techniques;medical visualization;mathematical foundations for visualization.","Colon;Conformal mapping;Feature extraction;Surface morphology;Visualization;Three dimensional displays;Harmonic analysis","computerised tomography;conformal mapping;graph theory;image registration;image segmentation;image texture;medical image processing;principal component analysis;rendering (computer graphics)","supine colon registration;prone colon registration;quasiconformal mapping;virtual colonoscopy;CT scans;polyp findings;polyp detection rates;supine-prone registration;substantial distortions;colon shape;conformal geometry;diffeomorphism;taeniae coli;colon flexures;colon geometry;colon surfaces;rectangular domain;holomorphic differentials;mean curvature;texture images;graph cut segmentation;mathematic morphological operations;principal component analysis;conformal flattening;2D flattened rendering;3D endoluminal views;distortion measurements;registration method;2D flattened colon images;3D volume rendered colon endoluminal view","Algorithms;Colon;Colonography, Computed Tomographic;Computer Graphics;Computer Simulation;Humans;Imaging, Three-Dimensional;Models, Anatomic;Prone Position;Supine Position","54","1","39","IEEE","28 Oct 2010","","","IEEE","IEEE Journals"
"The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration","C. Viau; M. J. McGuffin; Y. Chiricota; I. Jurisica",École de technologie supérieure; École de technologie supérieure; Université du Québec à Chicoutimi; Ontario Cancer Institute,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1100","1108","A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.","1941-0506","","10.1109/TVCG.2010.205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613448","interactive graph drawing;network layout;attribute-driven layout;parallel coordinates;scatterplot matrix;radial menu","Layout;Three dimensional displays;Visualization;Measurement;Joining processes;Data visualization;Principal component analysis","data visualisation;matrix algebra","FlowVizMenu;parallel scatterplot matrix;hybrid multidimensional visualization;network exploration;multivariate network;multidimensional view;graph selection;radial menu;node-link diagram;force-directed layout;Scatterplot Staircase;user feedback","","54","1","39","","28 Oct 2010","","","IEEE","IEEE Journals"
"Vectorized Radviz and Its Application to Multiple Cluster Datasets","J. Sharko; G. Grinstein; K. A. Marx","Dept. of Comput. Sci., Univ. of Massachusetts - Lowell, Lowell, MA; Dept. of Comput. Sci., Univ. of Massachusetts - Lowell, Lowell, MA; NA","IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1444","1427","Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.","1941-0506","","10.1109/TVCG.2008.173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658161","Index Terms—;Visualization;Radviz;Vectorized Radviz;Clustering;Multiple Clustering;Cluster Ensembles;Flattening Datasets","Clustering algorithms;Partitioning algorithms;Displays;Iris;Data visualization;Heuristic algorithms;Voting","computational geometry;data visualisation;pattern clustering","multiple cluster dataset;vectorized radviz radial visualization;dimensional anchor;data flattening;data cluster ensemble;circle circumference","","54","","29","","24 Oct 2008","","","IEEE","IEEE Journals"
"ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories","P. Xu; H. Mei; L. Ren; W. Chen",Bosch Research North America; Zhejiang University; Bosch Research North America; Zhejiang University,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","291","300","Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey's graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.","1941-0506","","10.1109/TVCG.2016.2598664","973 Program of China(grant numbers:2015CB352503); NSFC(grant numbers:61232012,61422211); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536610","Temporal Data;Marey's Graph;Visual Analytics;Manufacturing;Smart Factory;Connected Industry;Industry 4.0","Data visualization;Visual analytics;Industries;Manufacturing processes;Real-time systems","assembling;data aggregation;data analysis;data visualisation;factory automation;Internet;manufacturing processes;production engineering computing","ViDX;visual diagnostics;assembly line performance;smart factory;visual analytics;Industry 4.0;Industrial Internet;data exploration;manufacturing site;visual aggregation;manufacturing process","","54","","36","IEEE","9 Aug 2016","","","IEEE","IEEE Journals"
"Configuring Hierarchical Layouts to Address Research Questions","A. Slingsby; J. Dykes; J. Wood",City University London; City University London; City University London,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","977","984","We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.","1941-0506","","10.1109/TVCG.2009.128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290702","Geovisualization;hierarchical;layout;guidelines;exploratory;notation.","Layout;Displays;Visualization;Guidelines;Shape;Stacking;Marketing and sales;Facial animation;Containers;Graphics","data visualisation;geography;temporal databases;visual databases","hierarchical layouts;research questions;hierarchical displays;multivariate datasets;dimensional stacking;space-filling rectangular layouts;cognitive load","","53","","38","","23 Oct 2009","","","IEEE","IEEE Journals"
"DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation","S. Rufiange; M. J. McGuffin",école de technologie supérieure; école de technologie supérieure,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2556","2565","Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.","1941-0506","","10.1109/TVCG.2013.149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634116","Animation;Computer graphics;Prototypes;difference map;Dynamic networks;hybrid visualization;taxonomy;evolution;animation","Animation;Computer graphics;Prototypes","computer animation;data visualisation;graph theory","DiffAni;dynamic graph;difference maps;animation;hybrid visualization;diff tiles","Algorithms;Computer Graphics;Image Enhancement;Information Storage and Retrieval;Software;Subtraction Technique;User-Computer Interface;Video Recording","53","2","43","","16 Oct 2013","","","IEEE","IEEE Journals"
"Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions","J. Stahnke; M. Dörk; B. Müller; A. Thom",Potsdam University of Applied Sciences; Potsdam University of Applied Sciences; Potsdam University of Applied Sciences; Potsdam University of Applied Sciences,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2015","2016","22","1","629","638","We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.","1941-0506","","10.1109/TVCG.2015.2467717","HERE, Nokia company; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192695","Information visualization;interactivity;dimensionality reduction;multidimensional scaling;Information visualization;interactivity;dimensionality reduction;multidimensional scaling","Data visualization;Visualization;Distortion;Heating;Approximation error;Stress;Prototypes","data reduction;data visualisation","dimensionality reductions arrangements;dimensionality reductions errors;integrated interaction techniques;dimensionality-reduced data interpretation;dimensionality-reduced data interrogation;projection techniques;high-dimensional information space;planar layout;data projections;approximation errors;interactive methods;data dimensions;projection space;Web-based system;data analysts;multidimensional datasets;information visualization","","52","","31","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Time-varying contour topology","B. . -S. Sohn; Chandrajit Bajaj","Dept. og Comput. Sci., Texas Univ., Austin, TX, USA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Nov 2005","2006","12","1","14","25","The contour tree has been used to compute the topology of isosurfaces, generate a minimal seed set for accelerated isosurface extraction, and provide a user interface to segment individual contour components in a scalar field. In this paper, we extend the benefits of the contour tree to time-varying data visualization. We define temporal correspondence of contour components and describe an algorithm to compute the correspondence information in time-dependent contour trees. A graph representing the topology changes of time-varying isosurfaces is constructed in real-time for any selected isovalue using the precomputed correspondence information. Quantitative properties, such as surface area and volume of contour components, are computed and labeled on the graph. This topology change graph helps users to detect significant topological and geometric changes in time-varying isosurfaces. The graph is also used as an interactive user interface to segment, track, and visualize the evolution of any selected contour components over time.","1941-0506","","10.1109/TVCG.2006.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1541996","Contour tree;level set topology;feature tracking;time-varying volume visualization.","Topology;Isosurfaces;Data visualization;Computed tomography;Data mining;User interfaces;Tree graphs;Computational modeling;Rendering (computer graphics);Level set","trees (mathematics);graphical user interfaces;data visualisation;computational geometry;surface fitting","time-varying contour topology;contour tree;isosurface extraction;data visualization;graph theory;interactive user interface","Algorithms;Computer Graphics;Computer Systems;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;Time Factors;User-Computer Interface","52","","28","IEEE","21 Nov 2005","","","IEEE","IEEE Journals"
"Visual Reasoning about Social Networks Using Centrality Sensitivity","C. Correa; T. Crnovrsanin; K. Ma","Lawerence Livermore National Laboratory, Livermore; University of California at Davis, Davis; University of California at Davis, Davis","IEEE Transactions on Visualization and Computer Graphics","14 Nov 2011","2012","18","1","106","120","In this paper, we study the sensitivity of centrality metrics as a key metric of social networks to support visual reasoning. As centrality represents the prestige or importance of a node in a network, its sensitivity represents the importance of the relationship between this and all other nodes in the network. We have derived an analytical solution that extracts the sensitivity as the derivative of centrality with respect to degree for two centrality metrics based on feedback and random walks. We show that these sensitivities are good indicators of the distribution of centrality in the network, and how changes are expected to be propagated if we introduce changes to the network. These metrics also help us simplify a complex network in a way that retains the main structural properties and that results in trustworthy, readable diagrams. Sensitivity is also a key concept for uncertainty analysis of social networks, and we show how our approach may help analysts gain insight on the robustness of key network metrics. Through a number of examples, we illustrate the need for measuring sensitivity, and the impact it has on the visualization of and interaction with social and other scale-free networks.","1941-0506","","10.1109/TVCG.2010.260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669304","Social network visualization;centrality;sensitivity analysis;eigenvector and Markov importance.","Sensitivity;Visualization;Social network services;Markov processes;Cognition;Layout","complex networks;data visualisation;inference mechanisms;social networking (online)","visual reasoning;social networks;centrality metrics sensitivity;feedback;random walks;complex network;uncertainty analysis;scale free networks","Algorithms;Cluster Analysis;Computer Simulation;Databases, Factual;Markov Chains;Models, Theoretical;Reproducibility of Results;Sensitivity and Specificity;Social Support","52","","48","","17 Dec 2010","","","IEEE","IEEE Journals"
"VisComplete: Automating Suggestions for Visualization Pipelines","D. Koop; C. E. Scheidegger; S. P. Callahan; J. Freire; C. T. Silva","Sch. of Comput., Univ. of Utah, Salt Lake City, UT; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1691","1698","Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.","1941-0506","","10.1109/TVCG.2008.174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658192","Index Terms—;Scientific Workflows;Scientific Visualization;Auto Completion","Pipelines;Data visualization;Visual databases;Open source software;Software systems;Computer interfaces;Data flow computing;Feedback;Programming profession;Reproducibility of results","data visualisation;graph theory","visualization pipelines;analysis pipelines;pipeline subgraphs;open-source scientific workflow system","","51","2","39","","24 Oct 2008","","","IEEE","IEEE Journals"
"AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation","A. Chandak; C. Lauterbach; M. Taylor; Z. Ren; D. Manocha",UNC-Chapel Hill; UNC-Chapel Hill; UNC-Chapel Hill; UNC-Chapel Hill; UNC-Chapel Hill,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1707","1722","We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.","1941-0506","","10.1109/TVCG.2008.111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658194","Index Terms—;Sound propagation;interactive system;auralization","Acoustic propagation;Layout;Acoustic diffraction;Computational modeling;Solid modeling;Virtual environment;Interactive systems;Visualization;Auditory displays;Real time systems","data visualisation;interactive systems;ray tracing;rendering (computer graphics)","adaptive frustum tracing;interactive sound propagation;scene primitives;edge diffraction;specular reflection","","50","13","43","","24 Oct 2008","","","IEEE","IEEE Journals"
"Graph Visualization Techniques for Web Clustering Engines","E. Di Giacomo; W. Didimo; L. Grilli; G. Liotta","Dipt. di Ingegneria Elettronica e dell'Informazione, Univ. degli Studi di Perugia; Dipt. di Ingegneria Elettronica e dell'Informazione, Univ. degli Studi di Perugia; Dipt. di Ingegneria Elettronica e dell'Informazione, Univ. degli Studi di Perugia; Dipt. di Ingegneria Elettronica e dell'Informazione, Univ. degli Studi di Perugia","IEEE Transactions on Visualization and Computer Graphics","22 Jan 2007","2007","13","2","294","304","One of the most challenging issues in mining information from the World Wide Web is the design of systems that present the data to the end user by clustering them into meaningful semantic categories. We show that the analysis of the results of a clustering engine can significantly take advantage of enhanced graph drawing and visualization techniques. We propose a graph-based user interface for Web clustering engines that makes it possible for the user to explore and visualize the different semantic categories and their relationships at the desired level of detail","1941-0506","","10.1109/TVCG.2007.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069238","Web search;clustering;information visualization;visualization systems and software;visualization techniques and methodologies;graphical user interfaces.","Graphical user interfaces;Search engines;Data visualization;Web pages;Tree data structures;Web sites;User interfaces;Software systems;Web search;Organizing","graph theory;graphical user interfaces;information retrieval;Internet;search engines","graph visualization;Web clustering engines;information mining;World Wide Web;semantic categories;graph drawing;graph-based user interface;Web search;information visualization;graphical user interfaces","Algorithms;Cluster Analysis;Computer Graphics;Database Management Systems;Databases, Factual;Information Dissemination;Information Storage and Retrieval;Internet;Pattern Recognition, Automated;Semantics;User-Computer Interface","50","","21","","22 Jan 2007","","","IEEE","IEEE Journals"
"Online Visual Analytics of Text Streams","S. Liu; J. Yin; X. Wang; W. Cui; K. Cao; J. Pei","School of SoftwareState Key Lab of Intell. Tech. & Sys.TNList LabTsinghua University; Tsinghua University; Tsinghua University; Microsoft Research; Tsinghua University; Simon Fraser University, Burnaby, BC, Canada","IEEE Transactions on Visualization and Computer Graphics","20 Sep 2016","2016","22","11","2451","2466","We present an online visual analytics approach to helping users explore and understand hierarchical topic evolution in high-volume text streams. The key idea behind this approach is to identify representative topics in incoming documents and align them with the existing representative topics that they immediately follow (in time). To this end, we learn a set of streaming tree cuts from topic trees based on user-selected focus nodes. A dynamic Bayesian network model has been developed to derive the tree cuts in the incoming topic trees to balance the fitness of each tree cut and the smoothness between adjacent tree cuts. By connecting the corresponding topics at different times, we are able to provide an overview of the evolving hierarchical topics. A sedimentation-based visualization has been designed to enable the interactive analysis of streaming text data from global patterns to local details. We evaluated our method on real-world datasets and the results are generally favorable.","1941-0506","","10.1109/TVCG.2015.2509990","National Key Technologies R&D Program of China(grant numbers:2015BAF23B03); National Natural Science Foundation of China(grant numbers:61373070,61272225,61572274); Microsoft Research Fund(grant numbers:FY15-RES-OPP-112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360233","Streaming text data;evolutionary tree clustering;streaming tree cut;streaming topic visualization","Visualization;Bayes methods;Heuristic algorithms;Data visualization;Electronic mail;Algorithm design and analysis;Clustering algorithms","belief networks;data analysis;data visualisation;text analysis","online visual analytics;hierarchical topic evolution;high-volume text streams;streaming tree cuts;topic trees;user-selected focus nodes;dynamic Bayesian network model;adjacent tree cuts;sedimentation-based visualization;interactive analysis;streaming text data;global patterns","","50","","46","IEEE","17 Dec 2015","","","IEEE","IEEE Journals"
"GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation","M. Kahng; N. Thorat; D. H. Chau; F. B. Viégas; M. Wattenberg",Georgia Institute of Technology; Google Brain; Georgia Institute of Technology; Google Brain; Google Brain,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","310","320","Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with <italic>Generative Adversarial Networks</italic> (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process's intermediate results. GAN Lab tightly integrates an <italic>model overview graph</italic> that summarizes GAN's structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as <italic>step-by-step</italic> training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using <italic>TensorFlow.js</italic>, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.","1941-0506","","10.1109/TVCG.2018.2864500","NSF(grant numbers:IIS-1563816,CNS-1704701,TWC-1526254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440049","Deep learning;information visualization;visual analytics;generative adversarial networks;machine learning;interactive experimentation;explorable explanations","Gallium nitride;Machine learning;Tools;Generative adversarial networks;Generators;Training;Data visualization","data visualisation;interactive systems;learning (artificial intelligence);network theory (graphs);online front-ends","GAN Lab;interactive visual experimentation;interactive visualization tool;complex deep learning models;GAN structure;Web browsers;generative adversarial networks;TensorFlow;complex deep generative models","","49","","44","OAPA","19 Aug 2018","","","IEEE","IEEE Journals"
"Interactive Comparison of Scalar Fields Based on Largest Contours with Applications to Flow Visualization","D. Schneider; A. Wiebel; H. Carr; M. Hlawitschka; G. Scheuermann",University of Leipzig; University of Leipzig; University College Dublin; University of Leipzig; University of Leipzig,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1475","1482","Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.","1941-0506","","10.1109/TVCG.2008.143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658165","Index Terms—;Scalar topology;comparative visualization;contour tree;largest contours;flow visualization","Data visualization;Isosurfaces;Fluid flow;Tree graphs;Data mining;Computer vision;Volume measurement;Navigation;Topology;Shape","computer graphics;edge detection;flow visualisation","scalar fields;flow visualization;contour segmentation;topological simplification;volumetric similarity measure;contour trees;complex fluid flow datasets","","49","","36","","24 Oct 2008","","","IEEE","IEEE Journals"
"Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards","J. Walny; B. Lee; P. Johns; N. Henry Riche; S. Carpendale",University of Calgary; Microsoft Research; Microsoft Research; Microsoft Research; University of Calgary,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2779","2788","Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.","1941-0506","","10.1109/TVCG.2012.275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327284","Pen and touch;interaction;Wizard of Oz;whiteboard;data exploration","Context awareness;Sociology;Statistical analysis;Data visualization;Writing","data visualisation;interactive systems;user interfaces","pen-and-touch interaction;data exploration;interactive whiteboard;information visualization;bar graph;line graph;scatterplot;WIMP interface paradigm;Windows-icons-menus-and-pointer;cascading menus;dialog boxes;control panel;Wizard of Oz study;interactive visualization interface","","49","8","47","IEEE","8 Oct 2012","","","IEEE","IEEE Journals"
"Asymmetric Relations in Longitudinal Social Networks","U. Brandes; B. Nick",University of Konstanz; University of Konstanz,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2283","2290","In modeling and analysis of longitudinal social networks, visual exploration is used in particular to complement and inform other methods. The most common graphical representations for this purpose appear to be animations and small multiples of intermediate states, depending on the type of media available. We present an alternative approach based on matrix representation of gestaltlines (a combination of Tufte's sparklines with glyphs based on gestalt theory). As a result, we obtain static, compact, yet data-rich diagrams that support specifically the exploration of evolving dyadic relations and persistent group structure, although at the expense of cross-sectional network views and indirect linkages.","1941-0506","","10.1109/TVCG.2011.169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064994","Network Visualization;Social Networks;Time Series Data;Visual Knowledge Discovery and Representation;Glyphbased Techniques.","Social network services;Data visualization;Image color analysis","data mining;matrix algebra;social networking (online)","longitudinal social network;visual exploration;graphical representation;intermediate state;matrix representation;gestaltlines;Tufte's sparklines;glyphs;gestalt theory;data rich diagram;dyadic relation;persistent group structure;cross-sectional network;indirect linkages;asymmetric relation","","48","1","59","","3 Nov 2011","","","IEEE","IEEE Journals"
"Automatic Metro Map Layout Using Multicriteria Optimization","J. Stott; P. Rodgers; J. C. Martínez-Ovando; S. G. Walker","University of Kent, Canterbury; University of Kent, Canterbury; University of Kent, Canterbury; University of Kent, Canterbury","IEEE Transactions on Visualization and Computer Graphics","11 Nov 2010","2011","17","1","101","114","This paper describes an automatic mechanism for drawing metro maps. We apply multicriteria optimization to find effective placement of stations with a good line layout and to label the map unambiguously. A number of metrics are defined, which are used in a weighted sum to find a fitness value for a layout of the map. A hill climbing optimizer is used to reduce the fitness value, and find improved map layouts. To avoid local minima, we apply clustering techniques to the map-the hill climber moves both stations and clusters when finding improved layouts. We show the method applied to a number of metro maps, and describe an empirical study that provides some quantitative evidence that automatically-drawn metro maps can help users to find routes more efficiently than either published maps or undistorted maps. Moreover, we have found that, in these cases, study subjects indicate a preference for automatically-drawn maps over the alternatives.","1941-0506","","10.1109/TVCG.2010.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406516","Information visualization;diagram layout;graph drawing.","Optimization methods;Application software;System testing;Visualization;Geometry;Network topology;Navigation;Humans;Computer networks;Cancer","geographic information systems;optimisation;pattern clustering","automatic metro map layout;multicriteria optimization;automatic mechanism;metro map drawings;hill climbing optimizer;clustering techniques;published maps;undistorted maps","Algorithms;Computer Graphics;Computer Simulation;Computer-Aided Design;Humans;Information Storage and Retrieval;Maps as Topic;Pattern Recognition, Automated;Software;User-Computer Interface","48","1","29","","5 Feb 2010","","","IEEE","IEEE Journals"
"Dynamic Network Visualization withExtended Massive Sequence Views","S. v. d. Elzen; D. Holten; J. Blaas; J. J. van Wijk","Department of Mathematics and Computer Science, Eindhoven University of Technology, The Netherlands, and SynerScope BV, The Netherlands; SynerScope BV, , Eindhoven, The Netherlands; SynerScope BV, , Eindhoven, The Netherlands; Department of Mathematics and Computer Science, Eindhoven University of Technology, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","1 Jul 2014","2014","20","8","1087","1099","Networks are present in many fields such as finance, sociology, and transportation. Often these networks are dynamic: they have a structural as well as a temporal aspect. In addition to relations occurring over time, node information is frequently present such as hierarchical structure or time-series data. We present a technique that extends the Massive Sequence View ( msv) for the analysis of temporal and structural aspects of dynamic networks. Using features in the data as well as Gestalt principles in the visualization such as closure, proximity, and similarity, we developed node reordering strategies for the msv to make these features stand out that optionally take the hierarchical node structure into account. This enables users to find temporal properties such as trends, counter trends, periodicity, temporal shifts, and anomalies in the network as well as structural properties such as communities and stars. We introduce the circular msv that further reduces visual clutter. In addition, the (circular) msv is extended to also convey time-series data associated with the nodes. This enables users to analyze complex correlations between edge occurrence and node attribute changes. We show the effectiveness of the reordering methods on both synthetic and a rich real-world dynamic network data set.","1941-0506","","10.1109/TVCG.2013.263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6674295","Dynamic networks;reordering;optimization;time-series;hierarchy","Visualization;Image color analysis;Market research;Data visualization;Radiation detectors;Communities;Animation","data visualisation;optimisation;time series","dynamic network visualization;extended massive sequence views;temporal aspect;Gestalt principles;hierarchical node structure;time-series data;reordering","","48","","44","IEEE","25 Nov 2013","","","IEEE","IEEE Journals"
"An Information-Aware Framework for Exploring Multivariate Data Sets","A. Biswas; S. Dutta; H. Shen; J. Woodring",The Ohio State University; The Ohio State University; The Ohio State University; Los Alamos National Laboratory,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2683","2692","Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.","1941-0506","","10.1109/TVCG.2013.133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634187","Uncertainty;Mutual information;Information technology;Entropy;Isosurfaces;Layout;multivariate uncertainty;Information theory;framework;isosurface","Uncertainty;Mutual information;Information technology;Entropy;Isosurfaces;Layout","data analysis;data models;data visualisation;entropy;graph theory;pattern classification","variable interaction;PCP;parallel coordinates plots;variable isocontours;variable relationship analysis;information metrics;information based importance;mutual information;variable representation;graph model;variable classification;entropy;variable similarity;variable saliency;visualization research;information content measurement;information theory;multivariate data set exploration;information-aware framework","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Statistical;Multivariate Analysis;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface","47","","46","","16 Oct 2013","","","IEEE","IEEE Journals"
"GraphSplatting: visualizing graphs as continuous fields","R. van Liere; W. de Leeuw","Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands; Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2003","2003","9","2","206","212","This paper introduces GraphSplatting, a technique which transforms a graph into a two-dimensional scalar field. The scalar field can be rendered as a color coded map, a height field, or a set of contours. Splat fields allow for the visualization of arbitrarily large graphs without cluttering. They provide density information which can be used to determine the structure of the graph. The construction, visualization, and interaction with splat fields is discussed. Two applications illustrate the usage of GraphSplatting.","1941-0506","","10.1109/TVCG.2003.1196007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196007","","Data visualization;Rendering (computer graphics);Displays;Layout;Graphics;Hardware;Multidimensional systems;Citation analysis","graphs;data visualisation","GraphSplatting;2D scalar field;color coded map;height field;arbitrarily large graphs;density information;splat fields","","47","","13","","29 Apr 2003","","","IEEE","IEEE Journals"
"Temporal MDS Plots for Analysis of Multivariate Data","D. Jäckle; F. Fischer; T. Schreck; D. A. Keim","University of Konstanz, Germany; University of Konstanz, Germany; Graz University of Technology, Austria; University of Konstanz, Germany","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","141","150","Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.","1941-0506","","10.1109/TVCG.2015.2467553","EU project Visual Analytics for Sense-making in Criminal Intelligence Analysis (VALCRI)(grant numbers:FP7-SEC-2013-608142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192673","Multivariate Data;Time Series;Data Reduction;Multidimensional Scaling;Multivariate Data;Time Series;Data Reduction;Multidimensional Scaling","Data visualization;Visualization;Correlation;Security;Communication networks;Indexes;Layout","data analysis;data visualisation;time series","temporal MDS plots;multivariate data analysis;multivariate time series data;computer networks;healthcare;social networks;financial markets;dimensionality reduction methods;PCA;multivariate data visualization;multivariate patterns;temporal multidimensional scaling;TMDS;temporal one-dimensional MDS plots;sliding window approach;plot alignment;multidimensional similarity;network security","","47","1","41","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"An Evaluation of Depth Enhancing Perceptual Cues for Vascular Volume Visualization in Neurosurgery","M. Kersten-Oertel; S. J. Chen; D. L. Collins","McGill University, Montreal; McGill University, Montreal; McGill University , Montreal","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2014","2014","20","3","391","403","Cerebral vascular images obtained through angiography are used by neurosurgeons for diagnosis, surgical planning, and intraoperative guidance. The intricate branching of the vessels and furcations, however, make the task of understanding the spatial three-dimensional layout of these images challenging. In this paper, we present empirical studies on the effect of different perceptual cues (fog, pseudo-chromadepth, kinetic depth, and depicting edges) both individually and in combination on the depth perception of cerebral vascular volumes and compare these to the cue of stereopsis. Two experiments with novices and one experiment with experts were performed. The results with novices showed that the pseudo-chromadepth and fog cues were stronger cues than that of stereopsis. Furthermore, the addition of the stereopsis cue to the other cues did not improve relative depth perception in cerebral vascular volumes. In contrast to novices, the experts also performed well with the edge cue. In terms of both novice and expert subjects, pseudo-chromadepth and fog allow for the best relative depth perception. By using such cues to improve depth perception of cerebral vasculature, we may improve diagnosis, surgical planning, and intraoperative guidance.","1941-0506","","10.1109/TVCG.2013.240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620865","Depth cues;stereo;chromadepth;fog;volume rendering;vascular data;vessels;angiography","Rendering (computer graphics);Angiography;Three-dimensional displays;Surgery;Stereo image processing;Kinetic theory","biomedical MRI;data visualisation;neurophysiology;surgery","depth enhancing perceptual cues;vascular volume visualization;neurosurgery;cerebral vascular images;angiography;spatial three-dimensional layout;pseudo-chromadepth cues;fog cues;stereopsis cue;relative depth perception;edge cue","Adult;Angiography;Brain;Cerebrovascular Circulation;Depth Perception;Female;Humans;Image Processing, Computer-Assisted;Male;Middle Aged;Neurosurgical Procedures;Young Adult","46","","45","","4 Oct 2013","","","IEEE","IEEE Journals"
"Charticulator: Interactive Construction of Bespoke Chart Layouts","D. Ren; B. Lee; M. Brehmer","University of California, Santa Barbara; Microsoft Research; Microsoft Research","IEEE Transactions on Visualization and Computer Graphics","27 Nov 2018","2019","25","1","789","799","We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulator's conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com.","1941-0506","","10.1109/TVCG.2018.2865158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440827","Interactive visualization authoring;Chart layout design;Glyph design;Constraint-based design;Reusable chart layout","Layout;Tools;Visualization;Programming;Data visualization;Transforms","authoring systems;constraint satisfaction problems;data visualisation;graph theory;interactive systems;user interfaces","bespoke chart layouts;interactive authoring tool;mathematical layout constraints;constraint-based layout approach;charticulator;chart construction interfaces;constraint-solving algorithm;glyphs;constraint satisfaction;visualization tool","","46","","68","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Focus+Context Metro Maps","Y. -S. Wang; M. -T. Chi",National Chiao Tung University; National Chengchi University,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2528","2535","We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.","1941-0506","","10.1109/TVCG.2011.205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065020","Focus+context visualization;metro map;octilinear layout;graph labeling;optimization.","Layout;Graphics;Optimization;Nonlinear distortion","cartography;graph theory;mobile handsets;railways","focus+context metro maps;metro map visualization;modern city;mobile devices;octilinear transportation lines;regular station distances;energy terms;graph cuts method;train arrival time","","46","1","26","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Graph Drawing Aesthetics—Created by Users, Not Algorithms","H. C. Purchase; C. Pilcher; B. Plimmer","University of Glasgow, Glasgow; University of Auckland, Auckland; University of Auckland, Auckland","IEEE Transactions on Visualization and Computer Graphics","14 Nov 2011","2012","18","1","81","92","Prior empirical work on layout aesthetics for graph drawing algorithms has concentrated on the interpretation of existing graph drawings. We report on experiments which focus on the creation and layout of graph drawings: participants were asked to draw graphs based on adjacency lists, and to lay them out ""nicely.” Two interaction methods were used for creating the drawings: a sketch interface which allows for easy, natural hand movements, and a formal point-and-click interface similar to a typical graph editing system. We find, in common with many other studies, that removing edge crossings is the most significant aesthetic, but also discover that aligning nodes and edges to an underlying grid is important. We observe that the aesthetics favored by participants during creation of a graph drawing are often not evident in the final product and that the participants did not make a clear distinction between the processes of creation and layout. Our results suggest that graph drawing systems should integrate automatic layout with the user's manual editing process, and provide facilities to support grid-based graph creation.","1941-0506","","10.1109/TVCG.2010.269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674033","Evaluation/methodology;graphs and networks;user interfaces.","Layout;Humans;Algorithm design and analysis;Interviews;Education;Computer science;Electronic mail","computational geometry;graph theory","graph drawing aesthetics;adjacency lists;interaction methods;sketch interface;formal point-and-click interface;graph editing system;edge crossings","","46","","19","","23 Dec 2010","","","IEEE","IEEE Journals"
"MGV: a system for visualizing massive multidigraphs","J. Abello; J. Korn","Shannon Labs., AT&T Labs-Research, Florham Park, NJ, USA; NA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2002","8","1","21","38","Describes MGV (Massive Graph Visualizer), an integrated visualization and exploration system for massive multidigraph navigation. It adheres to the visual information-seeking mantra: overview first, zoom and filter, then details on demand. MGV's only assumption is that the vertex set of the underlying digraph corresponds to the set of leaves of a pre-determined tree T. MGV builds an out-of-core graph hierarchy and provides mechanisms to plug in arbitrary visual representations for each graph hierarchy slice. Navigation from one level to another of the hierarchy corresponds to the implementation of a drill-down interface. In order to provide the user with navigation control and interactive response, MGV incorporates a number of visualization techniques like interactive pixel-oriented 2D and 3D maps, statistical displays, color maps, multi-linked views and a zoomable label-based interface. This makes the association of geographic information and graph data very natural. To automate the creation of the vertex set hierarchy for MGV, we use the notion of graph sketches. They can be thought of as visual indices that guide the navigation of a multigraph too large to fit on the available display. MGV follows the client-server paradigm and it is implemented in C and Java-3D. We highlight the main algorithmic and visualization techniques behind the tools and, along the way, point out several possible application scenarios. Our techniques are being applied to multigraphs defined on vertex sets with sizes ranging from 100 million to 250 million vertices.","1941-0506","","10.1109/2945.981849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981849","","Navigation;Data visualization;Random access memory;Read-write memory;Filters;Tree graphs;Plugs;Automatic control;Three dimensional displays;Two dimensional displays","data visualisation;directed graphs;client-server systems;geographic information systems;tree searching;tree data structures","Massive Graph Visualizer;MGV;graph exploration system;massive multidigraph navigation;visual information-seeking;overview;zooming;filtering;details on demand;vertex set;tree leaves;out-of-core graph hierarchy;arbitrary visual representations;drill-down interface;navigation control;interactive response;visualization techniques;interactive pixel-oriented maps;statistical displays;color maps;multi-linked views;zoomable label-based interface;geographic information;graph sketches;visual indices;client-server paradigm;C implementation;Java-3D implementation;algorithmic techniques;application scenarios;external memory;massive data sets","","46","","46","","7 Aug 2002","","","IEEE","IEEE Journals"
"MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots","C. Hurter; A. Telea; O. Ersoy","DSNA, IRIT, Toulouse France; University of Groningen; University of Groningen","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2600","2609","We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.","1941-0506","","10.1109/TVCG.2011.223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065028","Semantic lenses;magic lenses;graph bundling;attribute filtering.","Lenses;Semantics;Filtering theory;Shape analysis;Data visualization","data handling;data visualisation;graph theory","MoleView;semantic lens;large element based plots;interactive multivariate relational data exploration;scatter plot;graph layout;distance based repulsion;straight line node link graph drawings;bundled edge graph layouts;brushing based technique;air traffic control;road traffic control;medical imaging;software comprehension","Angiography;Computer Graphics;Computer Simulation;Databases, Factual;Humans;Multivariate Analysis;Semantics;User-Computer Interface","46","7","35","","3 Nov 2011","","","IEEE","IEEE Journals"
"On the Visualization of Social and other Scale-Free Networks","Y. Jia; J. Hoberock; M. Garland; J. Hart",UIUC; UIUC; NVIDIA; UIUC,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1285","1292","This paper proposes novel methods for visualizing specifically the large power-law graphs that arise in sociology and the sciences. In such cases a large portion of edges can be shown to be less important and removed while preserving component connectedness and other features (e.g. cliques) to more clearly reveal the networkpsilas underlying connection pathways. This simplification approach deterministically filters (instead of clustering) the graph to retain important node and edge semantics, and works both automatically and interactively. The improved graph filtering and layout is combined with a novel computer graphics anisotropic shading of the dense crisscrossing array of edges to yield a full social network and scale-free graph visualization system. Both quantitative analysis and visual results demonstrate the effectiveness of this approach.","1941-0506","","10.1109/TVCG.2008.151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658141","Index Terms—;Scale-free network;edge filtering;betweenness centrality;anisotropic shading","Visualization;Filtering;Sociology;Anisotropic magnetoresistance;Displays;Stochastic processes;Filters;Layout;Computer graphics;Social network services","complex networks;data visualisation;graph theory;network theory (graphs);statistical distributions","data visualization;social network;scale-free network;power-law distribution;sociology;edge semantics;node semantics;graph filtering;computer graphics anisotropic shading;dense crisscrossing array","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Theoretical;Social Support;User-Computer Interface","46","","32","","24 Oct 2008","","","IEEE","IEEE Journals"
"Stereoscopic Highlighting: 2D Graph Visualization on Stereo Displays","B. Alper; T. Hollerer; J. Kuchera-Morin; A. Forbes","UC Santa Barbara, MAT; UC Santa Barbara, CS; UC Santa Barbara, MAT; UC Santa Barbara, MAT","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2325","2333","In this paper we present a new technique and prototype graph visualization system, stereoscopic highlighting, to help answer accessibility and adjacency queries when interacting with a node-link diagram. Our technique utilizes stereoscopic depth to highlight regions of interest in a 2D graph by projecting these parts onto a plane closer to the viewpoint of the user. This technique aims to isolate and magnify specific portions of the graph that need to be explored in detail without resorting to other highlighting techniques like color or motion, which can then be reserved to encode other data attributes. This mechanism of stereoscopic highlighting also enables focus+context views by juxtaposing a detailed image of a region of interest with the overall graph, which is visualized at a further depth with correspondingly less detail. In order to validate our technique, we ran a controlled experiment with 16 subjects comparing static visual highlighting to stereoscopic highlighting on 2D and 3D graph layouts for a range of tasks. Our results show that while for most tasks the difference in performance between stereoscopic highlighting alone and static visual highlighting is not statistically significant, users performed better when both highlighting methods were used concurrently. In more complicated tasks, 3D layout with static visual highlighting outperformed 2D layouts with a single highlighting method. However, it did not outperform the 2D layout utilizing both highlighting techniques simultaneously. Based on these results, we conclude that stereoscopic highlighting is a promising technique that can significantly enhance graph visualizations for certain use cases.","1941-0506","","10.1109/TVCG.2011.234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064999","Graph visualization;stereo displays;virtual reality.","Two dimensional displays;Graphics;Stereo image processing;Data visualization;Image color analysis","data visualisation;graph theory;three-dimensional displays","stereoscopic highlighting;2D graph visualization;stereo displays;data attributes;focus+context views;static visual highlighting;3D layout;2D layout","","46","","30","","3 Nov 2011","","","IEEE","IEEE Journals"
"Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats","F. Mansmann; D. A. Keim; S. C. North; B. Rexroad; D. Sheleheda","Univ. of Konstanz, Konstanz; Univ. of Konstanz, Konstanz; Univ. of Konstanz, Konstanz; Univ. of Konstanz, Konstanz; Univ. of Konstanz, Konstanz","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1105","1112","The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.","1941-0506","","10.1109/TVCG.2007.70522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376129","Information visualization;network security;network monitoring;treemap","Telecommunication traffic;Computerized monitoring;IP networks;Data security;Data visualization;Computer security;Stability;Protection;Data analysis;Continents","data visualisation;Internet;IP networks;security of data;telecommunication network planning;telecommunication security;telecommunication traffic","network traffic;resource planning;interactive monitoring;security threats interpretation;Internet;personal computers;network infrastructure;interactive visualization;IP address space;Treemap","","46","2","21","","5 Nov 2007","","","IEEE","IEEE Journals"
"Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists","S. Ghani; B. C. Kwon; S. Lee; J. S. Yi; N. Elmqvist","School of Electrical and Computer Engineering, Purdue University; School of Industrial Engineering, Purdue University; Brian Lamb School of Communication, Purdue University; School of Industrial Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University","IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2032","2041","Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.","1941-0506","","10.1109/TVCG.2013.223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634091","Social network services;Visual analytics;Data visualization;Complexity theory;Design methodology;User centered design;qualitative evaluation;Design study;user-centered design;node-link diagrams;multimodal graphs;interaction","Social network services;Visual analytics;Data visualization;Complexity theory;Design methodology;User centered design","data visualisation;network theory (graphs);pattern recognition;social networking (online);social sciences computing","multimodal social network analysis;social science;organization asymmetric relations;coauthorship pattern analysis;mSNA;visual analytics tools;formative design process;visual representation;parallel node-link bands;PNLB;network metrics","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Theoretical;Reproducibility of Results;Sensitivity and Specificity;Social Media;Social Sciences;User-Computer Interface","46","","55","","16 Oct 2013","","","IEEE","IEEE Journals"
"ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity","K. Vrotsou; J. Johansson; M. Cooper","Norrköping Visualization and Interaction Studio, Linköping University; Norrköping Visualization and Interaction Studio, Linköping University; Norrköping Visualization and Interaction Studio, Linköping University","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","945","952","The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today's information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.","1941-0506","","10.1109/TVCG.2009.117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290698","interactive visual exploration;event-based data;sequence identification;graph similarity;node similarity","Frequency;Computational complexity;Information analysis;Data mining;Marketing and sales;Predictive models;History;Urban planning;Medical treatment;Medical services","computational complexity;data mining;graph theory","ActiviTree;interactive visual sequence exploration;event-based data;graph similarity;complex event-based temporal data;algorithmic search mechanisms;computational complexity;interactive visual data mining;Web searching","","45","","27","","23 Oct 2009","","","IEEE","IEEE Journals"
"Comprehensible Visualization for Augmented Reality","D. Kalkofen; E. Mendez; D. Schmalstieg","Graz University of Technology, Graz; Graz University of Technology, Graz; Graz University of Technology, Graz","IEEE Transactions on Visualization and Computer Graphics","20 Jan 2009","2009","15","2","193","204","This article presents interactive visualizations to support the comprehension of spatial relationships between virtual and real world objects for augmented reality (AR) applications. To enhance the clarity of such relationships we discuss visualization techniques and their suitability for AR. We apply them on different AR applications with different goals, e.g. in X-Ray vision or in applications which draw a user's attention to an object of interest. We demonstrate how Focus and Context (F+C) visualizations are used to affect the user's perception of hidden or nearby objects by presenting contextual information in the area of augmentation. We discuss the organization and the possible sources of data for visualizations in augmented reality and present cascaded and multi level F+C visualizations to address complex, cluttered scenes that are inevitable in real environments. This article also shows filters and tools to interactively control the amount of augmentation. It compares the impact of real world context preserving to a pure virtual and uniform enhancement of these structures for augmentations of real world imagery. Finally this paper discusses the stylization of sparse object representations for AR to improve x-ray vision.","1941-0506","","10.1109/TVCG.2008.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4569839","Graphs and networks;Interaction techniques;Graphics data structures and data types;Artificial;augmented;and virtual realities;Style guides;Graphs and networks;Interaction techniques;Graphics data structures and data types;Artificial;augmented;and virtual realities;Style guides","Augmented reality;Data visualization;Focusing;Layout;Computer displays;Rendering (computer graphics);Needles;Filters;X-ray imaging;Computer graphics","augmented reality;data visualisation","comprehensible visualization;augmented reality;interactive visualizations;Focus and Context visualizations;contextual information;data structures","Computer Graphics;Humans;Image Enhancement;Imaging, Three-Dimensional;User-Computer Interface","45","19","22","","18 Jul 2008","","","IEEE","IEEE Journals"
"Efficient conservative visibility culling using the prioritized-layered projection algorithm","J. T. Klosowski; C. T. Silva","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2001","7","4","365","379","We propose a novel conservative visibility culling technique based on the Prioritized-Layered Projection (PLP) algorithm. PLP is a time-critical rendering technique that computes, for a given viewpoint, a partially correct image by rendering only a subset of the geometric primitives, those that PLP determines to be most likely visible. Our new algorithm builds on PLP and provides an efficient way of finding the remaining visible primitives. We do this by adding a second phase to PLP which uses image-space techniques for determining the visibility status of the remaining geometry. Another contribution of our work is to show how to efficiently implement such image-space visibility queries using currently available OpenGL hardware and extensions. We report on the implementation of our techniques on several graphics architectures, analyze their complexity, and discuss a possible hardware extension that has the potential to further increase performance.","1941-0506","","10.1109/2945.965350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965350","","Projection algorithms;Rendering (computer graphics);Geometry;Computer graphics;Hardware;Time factors;Image generation;Computer architecture;Performance analysis;Layout","rendering (computer graphics);computational geometry;computational complexity","conservative visibility culling;Prioritized-Layered Projection algorithm;rendering;partially correct image;geometric primitives;graphics architectures;complexity;interactive rendering","","45","10","33","","6 Aug 2002","","","IEEE","IEEE Journals"
"Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks","A. Srinivasan; J. Stasko",Georgia Institute of Technology; Georgia Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","511","521","Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. Only recently have other forms of interaction begun to appear, such as natural language or touch-based interaction, though usually operating only independently. Prior evaluations of natural language interfaces for visualization have indicated potential value in combining direct manipulation and natural language as complementary interaction techniques. We hypothesize that truly multimodal interfaces for visualization, those providing users with freedom of expression via both natural language and touch-based direct manipulation input, may provide an effective and engaging user experience. Unfortunately, however, little work has been done in exploring such multimodal visualization interfaces. To address this gap, we have created an architecture and a prototype visualization system called Orko that facilitates both natural language and direct manipulation input. Specifically, Orko focuses on the domain of network visualization, one that has largely relied on WIMP-based interfaces and direct manipulation interaction, and has little or no prior research exploring natural language interaction. We report results from an initial evaluation study of Orko, and use our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.","1941-0506","","10.1109/TVCG.2017.2745219","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019860","Multimodal interaction;network visualization;natural language input;direct manipulation;multitouch input","Data visualization;Natural languages;Visualization;Taxonomy;Prototypes;Mice;Speech","data visualisation;interactive systems;natural language interfaces","Orko;multimodal interaction;visual exploration;data visualization systems;direct manipulation interfaces;natural language interfaces;complementary interaction techniques;direct manipulation input;prototype visualization system;multimodal network visualization interfaces;touch-based direct manipulation input;WIMP-based interfaces","","45","","70","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Similarity Preserving Snippet-Based Visualization of Web Search Results","E. Gomez-Nieto; F. S. Roman; P. Pagliosa; W. Casaca; E. S. Helou; M. C. F. de Oliveira; L. G. Nonato","Universidade de São Paulo, São Carlos and San Pablo Catholic University, Arequipa; Universidade de São Paulo, São Carlos; Universidade Federal de Mato Grosso do Sul, Campo Grande; Universidade de São Paulo, São Carlos; Universidade de São Paulo, São Carlos; Universidade de São Paulo, São Carlos; Universidade de São Paulo, São Carlos","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2014","2014","20","3","457","470","Internet users are very familiar with the results of a search query displayed as a ranked list of snippets. Each textual snippet shows a content summary of the referred document (or webpage) and a link to it. This display has many advantages, for example, it affords easy navigation and is straightforward to interpret. Nonetheless, any user of search engines could possibly report some experience of disappointment with this metaphor. Indeed, it has limitations in particular situations, as it fails to provide an overview of the document collection retrieved. Moreover, depending on the nature of the query for example, it may be too general, or ambiguous, or ill expressed the desired information may be poorly ranked, or results may contemplate varied topics. Several search tasks would be easier if users were shown an overview of the returned documents, organized so as to reflect how related they are, content wise. We propose a visualization technique to display the results of web queries aimed at overcoming such limitations. It combines the neighborhood preservation capability of multidimensional projections with the familiar snippet-based representation by employing a multidimensional projection to derive two-dimensional layouts of the query search results that preserve text similarity relations, or neighborhoods. Similarity is computed by applying the cosine similarity over a ""bag-of-wordsâ' vector representation of collection built from the snippets. If the snippets are displayed directly according to the derived layout, they will overlap considerably, producing a poor visualization. We overcome this problem by defining an energy functional that considers both the overlapping among snippets and the preservation of the neighborhood structure as given in the projected layout. Minimizing this energy functional provides a neighborhood preserving two-dimensional arrangement of the textual snippets with minimum overlap. The resulting visualization conveys both a global view of the query results and visual groupings that reflect related results, as illustrated in several examples shown.","1941-0506","","10.1109/TVCG.2013.242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6629989","Multidimensional projection;web search visualization","Visualization;Layout;Search engines;Vectors;Optimization;Web pages;Navigation","data visualisation;document handling;Internet;query processing;search engines","similarity preserving snippet based visualization;Web search results;Internet;search query;textual snippet;referred document;Web page;search engines;document collection retrieval;Web queries;query search;text similarity;energy functional","","45","1","35","","11 Oct 2013","","","IEEE","IEEE Journals"
"A Novel Visualization Technique for Electric Power Grid Analytics","P. C. Wong; K. Schneider; P. Mackey; H. Foote; G. Chin Jr.; R. Guttromson; J. Thomas","Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland","IEEE Transactions on Visualization and Computer Graphics","16 Mar 2009","2009","15","3","410","423","The application of information visualization holds tremendous promise for the electric power industry, but its potential has so far not been sufficiently exploited by the visualization community. Prior work on visualizing electric power systems has been limited to depicting raw or processed information on top of a geographic layout. Little effort has been devoted to visualizing the physics of the power grids, which ultimately determines the condition and stability of the electricity infrastructure. Based on this assessment, we developed a novel visualization system prototype, GreenGrid, to explore the planning and monitoring of the North American Electricity Infrastructure. The paper discusses the rationale underlying the GreenGrid design, describes its implementation and performance details, and assesses its strengths and weaknesses against the current geographic-based power grid visualization. We also present a case study using GreenGrid to analyze the information collected moments before the last major electric blackout in the Western United States and Canada, and a usability study to evaluate the practical significance of our design in simulated real-life situations. Our result indicates that many of the disturbance characteristics can be readily identified with the proper form of visualization.","1941-0506","","10.1109/TVCG.2008.197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4695829","Applications;Information visualization;Visualization systems and software;Visualization techniques and methodologies;Applications;Information visualization;Visualization systems and software;Visualization techniques and methodologies","Visualization;Power systems;Power grids;Physics;Power system stability;Prototypes;Power system planning;Information analysis;Usability;Analytical models","data visualisation;electricity supply industry;geographic information systems;power system analysis computing;power system economics","visualization technique;electric power grid analytics;electric power industry;geographic layout;GreenGrid;North American electricity infrastructure;geographic-based power grid visualization;electric blackout;Western United States;Canada","Computer Graphics;Computer Simulation;Ecosystem;Electricity;Imaging, Three-Dimensional;Models, Theoretical;Power Plants;User-Computer Interface","44","1","32","","16 Mar 2009","","","IEEE","IEEE Journals"
"A Task Taxonomy for Network Evolution Analysis","J. Ahn; C. Plaisant; B. Shneiderman","University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2014","2014","20","3","365","376","Visualization has proven to be a useful tool for understanding network structures. Yet the dynamic nature of social media networks requires powerful visualization techniques that go beyond static network diagrams. To provide strong temporal network visualization tools, designers need to understand what tasks the users have to accomplish. This paper describes a taxonomy of temporal network visualization tasks. We identify the 1) entities, 2) properties, and 3) temporal features, which were extracted by surveying 53 existing temporal network visualization systems. By building and examining the task taxonomy, we report which tasks are well covered by existing systems and make suggestions for designing future visualization tools. The feedback from 12 network analysts helped refine the taxonomy.","1941-0506","","10.1109/TVCG.2013.238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620874","Network visualization;network evolution;temporal analysis;task taxonomy;design space","Visualization;Taxonomy;Social network services;Data visualization;Communities;Evolution (biology);Compounds","data visualisation;evolutionary computation;social networking (online)","network evolution analysis;task taxonomy;data visualisation;network structures;social media networks;visualization techniques;static network diagrams;temporal network visualization tools;temporal network visualization systems","","44","","96","","4 Oct 2013","","","IEEE","IEEE Journals"
"HOLA: Human-like Orthogonal Network Layout","S. Kieffer; T. Dwyer; K. Marriott; M. Wybrow",Monash University and NICTA Victoria; Monash University; Monash University and NICTA Victoria; Monash University,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","349","358","Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new “human-centred” methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand.","1941-0506","","10.1109/TVCG.2015.2467451","Australian Government through the Department of Communications and the Australian Research Council; ICT Centre of Excellence Program(grant numbers:DP140100077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192690","Graph layout;orthogonal layout;automatic layout algorithms;user-generated layout;graph-drawing aesthetics;Graph layout;orthogonal layout;automatic layout algorithms;user-generated layout;graph-drawing aesthetics","Layout;Algorithm design and analysis;Manuals;Standards;Software algorithms;Visualization;Software","data visualisation;graph theory;human factors","human-centred methodology;higher-quality layout;multistage frameworks;automatic network layout algorithms;human-like orthogonal network layout;HOLA","Algorithms;Computational Biology;Computer Graphics;Humans;User-Computer Interface","44","","36","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning","F. Block; M. S. Horn; B. C. Phillips; J. Diamond; E. M. Evans; C. Shen",Harvard University; Northwestern University; Harvard University; University of Nebraska State Museum; University of Michigan; Harvard University,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2789","2798","In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.","1941-0506","","10.1109/TVCG.2012.272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327285","Informal science education;collaborative learning;large tree visualizations;multi-touch interaction","Collaboration;Layout;Navigation;Phylogeny;Rendering (computer graphics);Data visualization;Information science","biology computing;computer aided instruction;data visualisation;groupware;iterative methods;rendering (computer graphics);user interfaces","DeepTree exhibit;Tree of Life visualization;informal learning;multiuser interactive visualization;multitouch interactive visualization;collaborative learning;evolutionary concept;iterative process;active learning;fractal-based tree layout;visual complexity reduction;custom rendering;navigation engine;multiuser interface;collaborative exploration","Algorithms;Archaea;Bacteria;Biology;Boston;Computer Graphics;Eukaryota;Exhibits as Topic;Humans;Information Dissemination;Phylogeny","44","","55","","8 Oct 2012","","","IEEE","IEEE Journals"
"Applications of Forman's discrete Morse theory to topology visualization and mesh compression","T. Lewiner; H. Lopes; G. Tavares","Dept. de Matematica, Pontificia Univ. Catolica do Rio de Janeiro, Brazil; Dept. de Matematica, Pontificia Univ. Catolica do Rio de Janeiro, Brazil; Dept. de Matematica, Pontificia Univ. Catolica do Rio de Janeiro, Brazil","IEEE Transactions on Visualization and Computer Graphics","12 Jul 2004","2004","10","5","499","508","Morse theory is a powerful tool for investigating the topology of smooth manifolds. It has been widely used by the computational topology, computer graphics, and geometric modeling communities to devise topology-based algorithms and data structures. Forman introduced a discrete version of this theory which is purely combinatorial. We aim to build, visualize, and apply the basic elements of Forman's discrete Morse theory. We intend to use some of those concepts to visually study the topology of an object. As a basis, an algorithmic construction of optimal Forman's discrete gradient vector fields is provided. This construction is then used to topologically analyze mesh compression schemes, such as Edgebreaker and Grow&Fold. In particular, we prove that the complexity class of the strategy optimization of Grow&Fold is MAX-SNP hard.","1941-0506","","10.1109/TVCG.2004.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310275","Index Terms- Discrete mathematics;hypergraphs;data compaction and compression;computer fraphics;computer-aided design.","Topology;Geometry;Application software;Data visualization;Computer graphics;Solid modeling;Data structures;Algorithm design and analysis;Mathematics;Compaction","graph theory;data visualisation;data compression;computational geometry;optimisation;mesh generation;computational complexity","smooth manifold topology;computational topology;computer graphics;geometric modeling;topology-based algorithm;data structure;Forman's discrete Morse theory;object topology;algorithmic construction;gradient vector field;mesh compression scheme;Edgebreaker;Grow&Fold;complexity class;strategy optimization;MAX-SNP hard;topology visualization;discrete mathematics;hypergraphs;data compression;computer-aided design","Algorithms;Artificial Intelligence;Computer Graphics;Computer-Aided Design;Data Compression;Finite Element Analysis;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Signal Processing, Computer-Assisted;User-Computer Interface","43","","21","","12 Jul 2004","","","IEEE","IEEE Journals"
"Bundled Visualization of DynamicGraph and Trail Data","C. Hurter; O. Ersoy; S. I. Fabrikant; T. R. Klein; A. C. Telea","ENAC/LII, University of Toulouse, 7 Avenue E. Belin, France; University of Groningen, The Netherlands; Department of Geography, University of Zürich, winterthurerstr. 190, Zurich 8057, Switzerland; University of Groningen, The Netherlands; Department of Mathematics and Computing Science, University of Groningen, Nijenborgh 9, Groningen 9747 AG, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","1 Jul 2014","2014","20","8","1141","1157","Depicting change captured by dynamic graphs and temporal paths, or trails, is hard. We present two techniques for simplified visualization of such data sets using edge bundles. The first technique uses an efficient image-based bundling method to create smoothly changing bundles from streaming graphs. The second technique adds edge-correspondence data atop of any static bundling algorithm, and is best suited for graph sequences. We show how these techniques can produce simplified visualizations of streaming and sequence graphs. Next, we show how several temporal attributes can be added atop of our dynamic graphs. We illustrate our techniques with data sets from aircraft monitoring, software engineering, and eye-tracking of static and dynamic scenes.","1941-0506","","10.1109/TVCG.2013.246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6636295","Dynamic graph visualization;edge bundling;software visualization;trajectories visualization;eye tracking","Cloning;Visualization;Image edge detection;Animation;Image color analysis;Streaming media;Layout","data visualisation;gaze tracking;graph theory;program visualisation","dynamic graph visualization;trail data visualization;temporal paths;data sets visualization;edge bundles;image-based bundling method;smoothly changing bundles;edge-correspondence data;static bundling algorithm;graph sequences;streaming graph visualizations;sequence graph visualizations;aircraft monitoring;software engineering;eye-tracking;static scenes;dynamic scenes","","43","","66","IEEE","18 Oct 2013","","","IEEE","IEEE Journals"
"Controlled topology simplification","Taosong He; Lichan Hong; A. Varshney; S. W. Wang","Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA; Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA; Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1996","2","2","171","184","We present a simple, robust, and practical method for object simplification for applications where gradual elimination of high frequency details is desired. This is accomplished by converting an object into multi resolution volume rasters using a controlled filtering and sampling technique. A multiresolution triangle mesh hierarchy can then be generated by applying the Marching Cubes algorithm. We further propose an adaptive surface generation algorithm to reduce the number of triangles generated by the standard Marching Cubes. Our method simplifies the topology of objects in a controlled fashion. In addition, at each level of detail, multilayered meshes can be used for an efficient antialiased rendering.","1941-0506","","10.1109/2945.506228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506228","","Topology;Rendering (computer graphics);Geometry;Frequency;Multiresolution analysis;Sampling methods;Virtual reality;Layout;Robustness","rendering (computer graphics);computational geometry;topology;antialiasing","controlled topology simplification;object simplification;high frequency details;multi resolution volume rasters;controlled filtering;sampling technique;multiresolution triangle mesh hierarchy;Marching Cubes algorithm;adaptive surface generation algorithm;standard Marching Cubes;multilayered meshes;efficient antialiased rendering","","43","8","44","","6 Aug 2002","","","IEEE","IEEE Journals"
"Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations","M. J. McGuffin; I. Jurisica",Ecole de technologie superieure; Ontario Cancer Institute,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","937","944","We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.","1941-0506","","10.1109/TVCG.2009.151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290697","interactive graph drawing;network layout;radial menus;marking menus;hotbox;biological networks","Visualization;Layout;Navigation;Software packages;Displays;Bioinformatics;Mice;Keyboards;Usability;Biology computing","biology computing;data visualisation;graph theory;interactive systems","network visualizations;interaction techniques;selecting subgraphs;lasso selection;interactive graph visualization;NAViGaTOR;software package;biological networks;usability study","Computational Biology;Computer Graphics;Principal Component Analysis;Software;User-Computer Interface","43","4","19","","23 Oct 2009","","","IEEE","IEEE Journals"
"TransCAIP: A Live 3D TV System Using a Camera Array and an Integral Photography Display with Interactive Control of Viewing Parameters","Y. Taguchi; T. Koike; K. Takahashi; T. Naemura","The University of Tokyo, Tokyo; Hitachi, Ltd., Kanagawa; The University of Tokyo, Tokyo; The University of Tokyo, Tokyo","IEEE Transactions on Visualization and Computer Graphics","17 Jul 2009","2009","15","5","841","852","The system described in this paper provides a real-time 3D visual experience by using an array of 64 video cameras and an integral photography display with 60 viewing directions. The live 3D scene in front of the camera array is reproduced by the full-color, full-parallax autostereoscopic display with interactive control of viewing parameters. The main technical challenge is fast and flexible conversion of the data from the 64 multicamera images to the integral photography format. Based on image-based rendering techniques, our conversion method first renders 60 novel images corresponding to the viewing directions of the display, and then arranges the rendered pixels to produce an integral photography image. For real-time processing on a single PC, all the conversion processes are implemented on a GPU with GPGPU techniques. The conversion method also allows a user to interactively control viewing parameters of the displayed image for reproducing the dynamic 3D scene with desirable parameters. This control is performed as a software process, without reconfiguring the hardware system, by changing the rendering parameters such as the convergence point of the rendering cameras and the interval between the viewpoints of the rendering cameras.","1941-0506","","10.1109/TVCG.2009.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4785464","Virtual reality;three-dimensional displays;display algorithms;image-based rendering.","Three dimensional TV;Cameras;Photography;Three dimensional displays;Control systems;Rendering (computer graphics);Image converters;Layout;Real time systems;Pixel","digital photography;interactive television;real-time systems;rendering (computer graphics);stereo image processing;three-dimensional displays;three-dimensional television;video cameras;virtual reality","TransCAIP;live 3D TV system;camera array;integral photography display;interactive control;real-time 3D visual experience;video camera;live 3D scene;full-color full-parallax autostereoscopic display;multicamera image;image-based rendering;GPGPU;virtual reality","","43","6","34","","20 Feb 2009","","","IEEE","IEEE Journals"
"A Maxent-Stress Model for Graph Layout","E. R. Gansner; Y. Hu; S. North","AT&T Labs Research, Florham Park; AT&T Labs Research, Florham Park; AT&T Labs Research, Florham Park","IEEE Transactions on Visualization and Computer Graphics","5 Apr 2013","2013","19","6","927","940","In some applications of graph visualization, input edges have associated target lengths. Dealing with these lengths is a challenge, especially for large graphs. Stress models are often employed in this situation. However, the traditional full stress model is not scalable due to its reliance on an initial all-pairs shortest path calculation. A number of fast approximation algorithms have been proposed. While they work well for some graphs, the results are less satisfactory on graphs of intrinsically high dimension, because some nodes may be placed too close together, or even share the same position. We propose a solution, called the maxent-stress model, which applies the principle of maximum entropy to cope with the extra degrees of freedom. We describe a force-augmented stress majorization algorithm that solves the maxent-stress model. Numerical results show that the algorithm scales well, and provides acceptable layouts for large, nonrigid graphs. This also has potential applications to scalable algorithms for statistical multidimensional scaling (MDS) with variable distances.","1941-0506","","10.1109/TVCG.2012.299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6329372","Graph drawing;metric embedding;low-dimensional embedding","Stress;Layout;Computational modeling;Entropy;Force;Springs;Approximation methods","approximation theory;data visualisation;graph theory;maximum entropy methods","maxent-stress model;graph layout;graph visualization;graph edge;graph length;all-pairs shortest path calculation;fast approximation algorithm;maximum entropy principle;force-augmented stress majorization algorithm;statistical multidimensional scaling","","42","","40","","11 Oct 2012","","","IEEE","IEEE Journals"
"A comparative study between RadViz and Star Coordinates","M. Rubio-Sánchez; L. Raya; F. Díaz; A. Sanchez",URJC; U-tad; UPM; URJC and CCS,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","619","628","RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.","1941-0506","","10.1109/TVCG.2015.2467324","Ministerio de Ciencia e Innovación(grant numbers:TIN2011-29542-C02-01); Human Brain Project; Cajal Blue Brain Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192699","RadViz;Star coordinates;Exploratory data analysis;Cluster analysis;Classication;Outlier detection;RadViz;Star coordinates;Exploratory data analysis;Cluster analysis;Classification;Outlier detection","Distributed databases;Data visualization;Layout;Springs;Shape;Data analysis;Nonlinear distortion","data analysis;data visualisation","RadViz coordinate;Star coordinate;projection-based multivariate visualization techniques;radial layouts;nonlinear normalization step;sparse data analysis;exploratory data analysis;nonlinear distortions;outlier detection;linear mappings","","42","","45","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"ABySS-Explorer: Visualizing Genome Sequence Assemblies","C. B. Nielsen; S. D. Jackman; I. Birol; S. J. M. Jones","BC Cancer Agency, Genome Sciences Centre; BC Cancer Agency, Genome Sciences Centre; BC Cancer Agency, Genome Sciences Centre; BC Cancer Agency, Genome Sciences Centre","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","881","888","One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data.","1941-0506","","10.1109/TVCG.2009.116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290690","Bioinformatics visualization;design study;DNA sequence;genome assembly","Genomics;Bioinformatics;Assembly;Sequences;Data visualization;Inspection;Encoding;Large-scale systems;Displays;Feedback","bioinformatics;data visualisation;DNA;genomics;interactive systems","ABySS-Explorer;genome sequence assemblies;genome sequencing projects;genome assembly process;visualization tools;interactive graph display;pen-and-paper based analysis tasks;user feedback;DNA sequence data;bioinformatics visualization","Base Sequence;Chromosome Mapping;Computational Biology;Computer Graphics;DNA","42","","25","","23 Oct 2009","","","IEEE","IEEE Journals"
"Exemplar-based Visualization of Large Document Corpus (InfoVis2009-1115)","Y. Chen; L. Wang; M. Dong; J. Hua","Wayne State University, Detroit, MI; Wayne State University, Detroit, MI; Wayne State University, Detroit, MI; Wayne State University, Detroit, MI","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1161","1168","With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.","1941-0506","","10.1109/TVCG.2009.140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290725","Exemplar;large-scale document visualization;multidimensional projection.","Data visualization;Web sites;Multidimensional systems;Drugs;Text mining;Principal component analysis;Computer science;Matrix decomposition;Large-scale systems;Indexing","biology computing;data visualisation;iterative methods;optimisation","exemplar-based visualization;large document corpus;text corpus;text visualization;matrix approximation;iterative optimization;parameter embedding","","42","","24","","23 Oct 2009","","","IEEE","IEEE Journals"
"Frame Field Singularity Correctionfor Automatic Hexahedralization","T. Jiang; J. Huang; Y. Wang; Y. Tong; H. Bao","State Key Lab of CAD&CG, Zhejiang University, Room 408, Mengminwei Building, Yuhangtang Road 388, Hangzhou, China; State Key Lab of CAD&CG, Zhejiang University, Room 408, Mengminwei Building, Yuhangtang Road 388, Hangzhou, China; Microsoft; Michigan State University, Engineering Building, 428 S. Shaw Lane #3115, East Lansing; State Key Lab of CAD&CG, Zhejiang University, Room 408, Mengminwei Building, Yuhangtang Road 388, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","1 Jul 2014","2014","20","8","1189","1199","We present an automatic hexahedralization tool, based on a systematic treatment that removes some of the singularities that would lead to degenerate volumetric parameterization. Such singularities could be abundant in automatically generated frame fields guiding the interior and boundary layouts of the hexahedra in an all hexahedral mesh. We first give the mathematical definitions of the inadmissible singularities prevalent in frame fields, including newly introduced surface singularity types. We then give a practical framework for adjusting singularity graphs by automatically modifying the rotational transition of frames between charts (cells of a tetrahedral mesh for the volume) to resolve the issues detected in the internal and boundary singularity graph. After applying an additional re-smoothing of the frame field with the modified transition conditions, we cut the volume into a topologically trivial domain, with the original topology encoded by the self-intersections of the boundary of the domain, and solve a mixed integer problem on this domain for a global parameterization. Finally, a properly connected hexahedral mesh is constructed from the integer isosurfaces of (u,v,w) in the parameterization. We demonstrate the applicability of the method on complex shapes, and discuss its limitations.","1941-0506","","10.1109/TVCG.2013.250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654167","Automatic hexahedral meshing;frame field;field singularity;volumetric parameterization","Image edge detection;Mesh generation;Compounds;Topology;Shape;Convergence;Vectors","graph theory;integer programming;mesh generation","frame field singularity correction;automatic hexahedralization;volumetric parameterization;hexahedral mesh;inadmissible singularities;surface singularity types;boundary singularity graph;internal singularity graph;mixed integer problem;global parameterization","","42","","26","IEEE","4 Nov 2013","","","IEEE","IEEE Journals"
"Interactive virtual relighting of real scenes","C. Loscos; G. Drettakis; L. Robert","INRIA, Montbonnot Saint Martin, France; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2000","6","4","289","305","Computer augmented reality (CAR) is a rapidly emerging field which enables users to mix real and virtual worlds. Our goal is to provide interactive tools to perform common illumination, i.e., light interactions between real and virtual objects, including shadows and relighting (real and virtual light source modification). In particular, we concentrate on virtually modifying real light source intensities and inserting virtual lights and objects into a real scene; such changes can be very useful for virtual lighting design and prototyping. To achieve this, we present a three-step method. We first reconstruct a simplified representation of real scene geometry using semiautomatic vision-based techniques. With the simplified geometry, and by adapting recent hierarchical radiosity algorithms, we construct an approximation of real scene light exchanges. We next perform a preprocessing step, based on the radiosity system, to create unoccluded illumination textures. These replace the original scene textures which contained real light effects such as shadows from real lights. This texture is then modulated by a ratio of the radiosity (which can be changed) over a display factor which corresponds to the radiosity for which occlusion has been ignored. Since our goal is to achieve a convincing relighting effect, rather than an accurate solution, we present a heuristic correction process which results in visually plausible renderings. Finally, we perform an interactive process to compute new illumination with modified real and virtual light intensities.","1941-0506","","10.1109/2945.895874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=895874","","Layout;Lighting;Augmented reality;Light sources;Image reconstruction;Geometry;Solid modeling;Casting;Virtual prototyping;Approximation algorithms","augmented reality;image processing;interactive systems;lighting;brightness;rendering (computer graphics)","interactive virtual relighting;real scenes;augmented reality;heuristic correction process;shadows;virtual lighting design;real scene geometry;semiautomatic vision;radiosity;unoccluded illumination texture;rendering","","42","28","33","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Keeping Multiple Views Consistent: Constraints, Validations, and Exceptions in Visualization Authoring","Z. Qu; J. Hullman",University of Washington; University of Washington,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","468","477","Visualizations often appear in multiples, either in a single display (e.g., small multiples, dashboard) or across time or space (e.g., slideshow, set of dashboards). However, existing visualization design guidelines typically focus on single rather than multiple views. Solely following these guidelines can lead to effective yet inconsistent views (e.g., the same field has different axes domains across charts), making interpretation slow and error-prone. Moreover, little is known how consistency balances with other design considerations, making it difficult to incorporate consistency mechanisms in visualization authoring software. We present a wizard-of-oz study in which we observed how Tableau users achieve and sacrifice consistency in an exploration-to-presentation visualization design scenario. We extend (from our prior work) a set of encoding-specific constraints defining consistency across multiple views. Using the constraints as a checklist in our study, we observed cases where participants spontaneously maintained consistent encodings and warned cases where consistency was overlooked. In response to the warnings, participants either revised views for consistency or stated why they thought consistency should be overwritten. We categorize participants' actions and responses as constraint validations and exceptions, depicting the relative importance of consistency and other design considerations under various circumstances (e.g., data cardinality, available encoding resources, chart layout). We discuss automatic consistency checking as a constraint-satisfaction problem and provide design implications for communicating inconsistencies to users.","1941-0506","","10.1109/TVCG.2017.2744198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017651","Visualization Design;Qualitative Study;Evaluation","Encoding;Data visualization;Image color analysis;Visualization;Adaptation models;Color;Guidelines","constraint satisfaction problems;constraint theory;data visualisation","dashboard;visualization design guidelines;visualization authoring software;exploration-to-presentation visualization design scenario;consistent encodings;constraint validations;automatic consistency checking;consistency mechanisms;encoding-specific constraints;constraint-satisfaction;Tableau users","","42","","34","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Visualization of Parameter Space for Image Analysis","A. J. Pretorius; M. -A. Bray; A. E. Carpenter; R. A. Ruddle","School of Computing, University of Leeds; Broad Institute of MIT and Harvard; Broad Institute of MIT and Harvard; School of Computing, University of Leeds","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2402","2411","Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.","1941-0506","","10.1109/TVCG.2011.253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065007","Information visualization;visual analytics;parameter space;image analysis;sampling.","Information processing;Image analysis;Algorithm design and analysis;Sampling methods","data visualisation;image sampling;medical image processing","parameter space visualization;parameter optimization process;parameter sampling;interactive visual exploration;visual analysis;custom sampling plug-in;CellProfiler;biomedical image analysis framework;interactive visualization;Paramorama","Algorithms;Androstadienes;Cell Line;Cell Nucleus;Cell Nucleus;Chromones;Computer Graphics;Computer Simulation;Humans;Image Processing, Computer-Assisted;Morpholines;Software;User-Computer Interface","42","2","27","","3 Nov 2011","","","IEEE","IEEE Journals"
"DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks","J. Wang; L. Gou; H. -W. Shen; H. Yang",The Ohio State University; Visa Research; The Ohio State University; Visa Research,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","288","298","Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent's experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.","1941-0506","","10.1109/TVCG.2018.2864504","US Department of Energy Los Alamos National Laboratory(grant numbers:47145); UT-Battelle LLC contract(grant numbers:4000159447); NSF(grant numbers:IIS-1250752,IIS-1065025); US Department of Energy(grant numbers:DE-SC0007444,DE-DC0012495); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454905","Deep Q-Network (DQN);reinforcement learning;model interpretation;visual analytics","Training;Games;Visual analytics;Data visualization;Analytical models;Learning (artificial intelligence);Machine learning","computer games;data visualisation;learning (artificial intelligence);neural nets","DQNViz;deep Q-Network;deep reinforcement learning model;intelligent agent;optimal actions;professional human players;superhuman performance;sophisticated behaviors;DQN agent;visual analytics system;blind training process;experience space;DQN models;Atari games;deep learning experts;breakout game;reward patterns;action space;model training process","","41","","55","IEEE","5 Sep 2018","","","IEEE","IEEE Journals"
"Improving the Readability of Clustered Social Networks using Node Duplication","N. y. Henr; A. Bezerianos; J. -D. Fekete",INRIA-LRI and Univ. of Sydney; NICTA; INRIA,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1317","1324","Exploring communities is an impor tant task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are impor tant for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.","1941-0506","","10.1109/TVCG.2008.141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658145","Index Terms—;Clustering;Graph Visualization;Node Duplications;Social Networks","Social network services;Clustering;Layout;Communities","data visualisation;graph theory;pattern clustering;social sciences computing","social network visualization;node duplication;clustering method;group actor;graph readability","Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Theoretical;Social Support;User-Computer Interface","41","2","32","IEEE","24 Oct 2008","","","IEEE","IEEE Journals"
"AllAboard: Visual Exploration of Cellphone Mobility Data to Optimise Public Transport","G. Di Lorenzo; M. Sbodio; F. Calabrese; M. Berlingerio; F. Pinelli; R. Nair","IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate; IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate; IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate; IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate; IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate; IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2015","2016","22","2","1036","1050","The deep penetration of mobile phones offers cities the ability to opportunistically monitor citizens' mobility and use data-driven insights to better plan and manage services. With large scale data on mobility patterns, operators can move away from the costly, mostly survey based, transportation planning processes, to a more data-centric view, that places the instrumented user at the center of development. In this framework, using mobile phone data to perform transit analysis and optimization represents a new frontier with significant societal impact, especially in developing countries. In this paper we present AllAboard, an intelligent tool that analyses cellphone data to help city authorities in visually exploring urban mobility and optimizing public transport. This is performed within a self contained tool, as opposed to the current solutions which rely on a combination of several distinct tools for analysis, reporting, optimisation and planning. An interactive user interface allows transit operators to visually explore the travel demand in both space and time, correlate it with the transit network, and evaluate the quality of service that a transit network provides to the citizens at very fine grain. Operators can visually test scenarios for transit network improvements, and compare the expected impact on the travellers' experience. The system has been tested using real telecommunication data for the city of Abidjan, Ivory Coast, and evaluated from a data mining, optimisation and user prospective.","1941-0506","","10.1109/TVCG.2015.2440259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7117451","Spatio-temporal mining;cellphone data;visual exploration;urban data mobility;transit network","Optimization;Urban areas;Data mining;Mobile handsets;Planning;Visualization;Antennas","data mining;data visualisation;interactive systems;mobile handsets;optimisation;planning;public transport;user interfaces","deep penetration;mobile phones;citizen mobility monitoring;data-driven insights;service management;service planning;large scale data;mobility patterns;survey based transportation planning processes;data-centric view;instrumented user;mobile phone data;transit analysis;AllAboard;intelligent tool;cellphone data analysis;visually exploring urban mobility;public transport optimization;self contained tool;interactive user interface;travel demand;traveller experience;telecommunication data;city of Abidjan;Ivory Coast;data mining;user prospective","Cell Phone;Cities;Computer Graphics;Cote d'Ivoire;Data Mining;Humans;Software;Spatio-Temporal Analysis;Transportation","40","2","34","IEEE","3 Jun 2015","","","IEEE","IEEE Journals"
"Joint Contour Nets","H. Carr; D. Duke","School of Computing, University of Leeds, Woodhouse Lane, Leeds, W. Yorks LS2 9JT, United Kingdom; School of Computing, University of Leeds, Woodhouse Lane, Leeds, W. Yorks LS2 9JT, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","1 Jul 2014","2014","20","8","1100","1113","Contour Trees and Reeb Graphs are firmly embedded in scientific visualization for analysing univariate (scalar) fields. We generalize this analysis to multivariate fields with a data structure called the Joint Contour Net that quantizes the variation of multiple variables simultaneously. We report the first algorithm for constructing the Joint Contour Net, and demonstrate some of the properties that make it practically useful for visualisation, including accelerating computation by exploiting a relationship with rasterisation in the range of the function.","1941-0506","","10.1109/TVCG.2013.269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6684144","Computational topology;contour analysis;contour tree;reeb graph;reeb space;joint contour net;multivariate","Joints;Level set;Slabs;Algorithm design and analysis;Isosurfaces;Jacobian matrices","data structures;data visualisation;trees (mathematics)","contour trees;reeb graphs;scientific visualization;data structure;multivariate fields","","40","","46","OAPA","13 Dec 2013","","","IEEE","IEEE Journals"
"Load-Balanced Parallel Streamline Generation on Large Scale Vector Fields","B. Nouanesengsy; T. Lee; H. Shen",The Ohio State University; The Ohio State University; The Ohio State University,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","1785","1794","Because of the ever increasing size of output data from scientific simulations, supercomputers are increasingly relied upon to generate visualizations. One use of supercomputers is to generate field lines from large scale flow fields. When generating field lines in parallel, the vector field is generally decomposed into blocks, which are then assigned to processors. Since various regions of the vector field can have different flow complexity, processors will require varying amounts of computation time to trace their particles, causing load imbalance, and thus limiting the performance speedup. To achieve load-balanced streamline generation, we propose a workload-aware partitioning algorithm to decompose the vector field into partitions with near equal workloads. Since actual workloads are unknown beforehand, we propose a workload estimation algorithm to predict the workload in the local vector field. A graph-based representation of the vector field is employed to generate these estimates. Once the workloads have been estimated, our partitioning algorithm is hierarchically applied to distribute the workload to all partitions. We examine the performance of our workload estimation and workload-aware partitioning algorithm in several timings studies, which demonstrates that by employing these methods, better scalability can be achieved with little overhead.","1941-0506","","10.1109/TVCG.2011.219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064941","Flow visualization;Parallel processing;3D vector field visualization;Streamlines.","Partitioning algorithms;Cost function;Mathematical model","data visualisation;graph theory;parallel processing;resource allocation","load balanced parallel streamline generation;large scale vector fields;flow complexity;load imbalance;workload aware partitioning algorithm;workload estimation algorithm;graph based representation","","40","","24","","3 Nov 2011","","","IEEE","IEEE Journals"
"Memorability of Visual Features in Network Diagrams","K. Marriott; H. Purchase; M. Wybrow; C. Goncu",Monash University; University of Glasgow; Monash University; Monash University,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2477","2485","We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.","1941-0506","","10.1109/TVCG.2012.245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327253","Network diagrams;graph layout;perceptual theories;visual features;diagram recall;experiment","Visualization;Layout;Algorithm design and analysis;Educational institutions;Shape;Image edge detection;Topology","data visualisation;graph theory;interactive systems;network theory (graphs)","visual feature memorability;network diagrams;cognitive impact;graphs;static network-based visualisations;interactive network-based visualisations;task enabled visual processing;visceral level;parallel edges","","40","","48","","8 Oct 2012","","","IEEE","IEEE Journals"
"Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations","A. G. Landge; J. A. Levine; A. Bhatele; K. E. Isaacs; T. Gamblin; M. Schulz; S. H. Langer; P. Bremer; V. Pascucci","SCI Institute, University of Utah; SCI Institute, University of Utah; Lawrence Livermore National Laboratory; University of California, Davis; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; SCI Institute, University of Utah","IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2467","2476","The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.","1941-0506","","10.1109/TVCG.2012.286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327252","Performance analysis;network traffic visualization;projected graph layouts","Hardware;Data visualization;Layout;Performance evaluation;Supercomputers;Network topology;Computational modeling","data visualisation;laser beams;mainframes;network topology;parallel processing;physics computing;plasma simulation;plasma-beam interactions","network traffic visualization;parallel simulation performance;compute nodes;supercomputers;parallel application developers;packet flow;hardware interconnect;data visualization;network structure;2D view;3D view;physical network topology;parallel multiphysics code pF3D;IBM Blue Gene-P system;laser interaction;plasma interaction","","40","","37","","8 Oct 2012","","","IEEE","IEEE Journals"
"A Systematic Review of Experimental Studies on Data Glyphs","J. Fuchs; P. Isenberg; A. Bezerianos; D. Keim","University of Konstanz, Konstanz, Germany; Inria, Paris, France; Univ Paris Sud, CNRS & Inria, Paris, France; University of Konstanz, Konstanz, Germany","IEEE Transactions on Visualization and Computer Graphics","25 May 2017","2017","23","7","1863","1879","We systematically reviewed 64 user-study papers on data glyphs to help researchers and practitioners gain an informed understanding of tradeoffs in the glyph design space. The glyphs we consider are individual representations of multi-dimensional data points, often meant to be shown in small-multiple settings. Over the past 60 years many different glyph designs were proposed and many of these designs have been subjected to perceptual or comparative evaluations. Yet, a systematic overview of the types of glyphs and design variations tested, the tasks under which they were analyzed, or even the study goals and results does not yet exist. In this paper we provide such an overview by systematically sampling and tabulating the literature on data glyph studies, listing their designs, questions, data, and tasks. In addition we present a concise overview of the types of glyphs and their design characteristics analyzed by researchers in the past, and a synthesis of the study results. Based on our meta analysis of all results we further contribute a set of design implications and a discussion on open research directions.","1941-0506","","10.1109/TVCG.2016.2549018","Consensus project; European Commission’s 7th Framework Programme(grant numbers:ICT-2013.5.4); ICT for Governance and Policy Modelling(grant numbers:611688); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7445239","Survey;glyphs;quantitative evaluation;glyph design","Visualization;Data visualization;Systematics;Layout;Encoding;Guidelines","data handling","data glyphs;glyph design space;multidimensional data points;perceptual evaluation;comparative evaluation","","39","","103","IEEE","31 Mar 2016","","","IEEE","IEEE Journals"
"An Effective Illustrative Visualization Framework Based on Photic Extremum Lines (PELs)","X. Xie; Y. He; F. Tian; H. -S. Seah; X. Gu; H. Qin","School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; Department of Computer Science, Stony Brook University, New York; Department of Computer Science, Stony Brook University, New York","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1328","1335","Conveying shape using feature lines is an important visualization tool in visual computing. The existing feature lines (e.g., ridges, valleys, silhouettes, suggestive contours, etc.) are solely determined by local geometry properties (e.g., normals and curvatures) as well as the view position. This paper is strongly inspired by the observation in human vision and perception that a sudden change in the luminance plays a critical role to faithfully represent and recover the 3D information. In particular, we adopt the edge detection techniques in image processing for 3D shape visualization and present Photic Extremum Lines (PELs) which emphasize significant variations of illumination over 3D surfaces. Comparing with the existing feature lines, PELs are more flexible and offer users more freedom to achieve desirable visualization effects. In addition, the user can easily control the shape visualization by changing the light position, the number of light sources, and choosing various light models. We compare PELs with the existing approaches and demonstrate that PEL is a flexible and effective tool to illustrate 3D surface and volume for visual computing.","1941-0506","","10.1109/TVCG.2007.70538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376158","Surface and volume illustration;illumination;photic extremum lines (PELs);silhouettes;suggestive contours;ridges and valleys;digital geometry processing.","Humans;Image edge detection;Lighting;Data visualization;Layout;Geometry;Image processing;Shape control;Solid modeling","computational geometry;data visualisation;edge detection","3D shape visualization;image processing;edge detection;feature lines;photic extremum lines;illustrative visualization framework","Algorithms;Anatomy, Artistic;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Lighting;Medical Illustration;Models, Anatomic;User-Computer Interface","39","","38","IEEE","5 Nov 2007","","","IEEE","IEEE Journals"
"Exploration of Networks using overview+detail with Constraint-based cooperative layout","T. Dwyer; K. Marriott; F. Schreiber; P. Stuckey; M. Woodward; M. Wybrow",Microsoft Research; Monash University; IPL-Gatersleben; National ICT Australia; The University of Melbourne; Monash University,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1293","1300","A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks.","1941-0506","","10.1109/TVCG.2008.130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658142","Index Terms—;Graph drawing;constraints;stress majorization;force directed algorithms;multidimensional scaling.","Scalability;Clustering algorithms;Technological innovation;Visualization;Routing;Stability;Heuristic algorithms;Network topology;Prototypes;Unified modeling language","data visualisation;graph theory","constraint-based cooperative layout;large network visualization;scalability fast force-based layout algorithms;sophisticated edge routing;constrained graph layout algorithms","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Biological;Signal Transduction;Social Support;User-Computer Interface","39","1","39","","24 Oct 2008","","","IEEE","IEEE Journals"
"How to Display Group Information on Node-Link Diagrams: An Evaluation","R. Jianu; A. Rusu; Y. Hu; D. Taggart","School of Computing and Information Sciences, Florida International University, 11200 SW 8th Street, ECS354, Miami, FL; Department of Computer Science, Rowan University, 201 Mullica Hill Road, Glassboro, NJ; AT&T Labs Research, 180 Park Ave., Florham Park, NJ; Department of Computer Science, Rowan University, 201 Mullica Hill Road, Glassboro, NJ","IEEE Transactions on Visualization and Computer Graphics","24 Sep 2014","2014","20","11","1530","1541","We present the results of evaluating four techniques for displaying group or cluster information overlaid on node-link diagrams: node coloring, GMap, BubbleSets, and LineSets. The contributions of the paper are three fold. First, we present quantitative results and statistical analyses of data from an online study in which approximately 800 subjects performed 10 types of group and network tasks in the four evaluated visualizations. Specifically, we show that BubbleSets is the best alternative for tasks involving group membership assessment; that visually encoding group information over basic node-link diagrams incurs an accuracy penalty of about 25 percent in solving network tasks; and that GMap's use of prominent group labels improves memorability. We also show that GMap's visual metaphor can be slightly altered to outperform BubbleSets in group membership assessment. Second, we discuss visual characteristics that can explain the observed quantitative differences in the four visualizations and suggest design recommendations. This discussion is supported by a small scale eye-tracking study and previous results from the visualization literature. Third, we present an easily extensible user study methodology.","1941-0506","","10.1109/TVCG.2014.2315995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787045","Networks;sets;clustering;evaluation;user study","Data visualization;Cluster approximation;Image color analysis;Approximation algorithms;Encoding;Algorithm design and analysis","data visualisation;statistical analysis","group information;node-link diagrams;cluster information;node coloring;GMap;BubbleSets;LineSets;statistical analysis;visualizations","","39","","46","IEEE","11 Apr 2014","","","IEEE","IEEE Journals"
"In Situ Exploration of Large Dynamic Networks","S. Hadlak; H. Schulz; H. Schumann",University of Rostock; Graz University of Technology; University of Rostock,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2334","2343","The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.","1941-0506","","10.1109/TVCG.2011.213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065000","Dynamic graph data;multiform visualization;multi-focus+context.","Data visualization;Graphics","data visualisation;graph theory;network theory (graphs)","large dynamic networks;in situ exploration;bot nets;social networks;visualization techniques;network structure;visual analysis;visual representations;mental map;dynamic graph visualization;model versioning;wireless mesh networks","","39","1","51","","3 Nov 2011","","","IEEE","IEEE Journals"
"Interaction Support for Visual Comparison Inspired by Natural Behavior","C. Tominski; C. Forsell; J. Johansson",University of Rostock; Linköping University; Linköping University,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2719","2728","Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.","1941-0506","","10.1109/TVCG.2012.237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327278","Interaction techniques;visual comparison;visualization;human-computer interaction;natural interaction","Visualization;Data visualization;Shape;Layout;Animation;Navigation;Computers","data analysis;data visualisation","interaction support;visual comparison;natural behavior;interactive data exploration;interactive data analysis;interaction concept;complementary visual cues;integrated interaction technique;visualization technique","","39","","51","","8 Oct 2012","","","IEEE","IEEE Journals"
"Semiautomatic Transfer Function Initialization for Abdominal Visualization Using Self-Generating Hierarchical Radial Basis Function Networks","M. A. Selver; C. Guzelis","Department of Electrical and Electronics Engineering, Dokuz Eylul University, 35160 Buca, Izmir, Turkey; Department of Electrical and Electronics Engineering, Dokuz Eylul University, 35160 Buca, Izmir, Turkey","IEEE Transactions on Visualization and Computer Graphics","16 Mar 2009","2009","15","3","395","409","Being a tool that assigns optical parameters used in interactive visualization, Transfer Functions (TF) have important effects on the quality of volume rendered medical images. Unfortunately, finding accurate TFs is a tedious and time consuming task because of the trade off between using extensive search spaces and fulfilling the physician's expectations with interactive data exploration tools and interfaces. By addressing this problem, we introduce a semi-automatic method for initial generation of TFs. The proposed method uses a Self Generating Hierarchical Radial Basis Function Network to determine the lobes of a Volume Histogram Stack (VHS) which is introduced as a new domain by aligning the histograms of slices of a image series. The new self generating hierarchical design strategy allows the recognition of suppressed lobes corresponding to suppressed tissues and representation of the overlapping regions which are parts of the lobes but can not be represented by the Gaussian bases in VHS. Moreover, approximation with a minimum set of basis functions provides the possibility of selecting and adjusting suitable units to optimize the TF. Applications on different CT/MR data sets show enhanced rendering quality and reduced optimization time in abdominal studies.","1941-0506","","10.1109/TVCG.2008.198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721434","Volume visualization;Transfer function design;medical image;Hierarchical radial basis function networks;multiscale analysis;Volume histogram stack","Transfer functions;Abdomen;Radial basis function networks;Histograms;Biomedical optical imaging;Optical network units;Data visualization;Rendering (computer graphics);Biomedical imaging;Computed tomography","data visualisation;Gaussian processes;image recognition;interactive systems;medical image processing;radial basis function networks;rendering (computer graphics);statistical analysis;transfer functions","semiautomatic transfer function initialization;interactive abdominal visualization;self-generating hierarchical radial basis function network;volume rendered medical image;volume histogram stack;suppressed lobe recognition;suppressed tissue recognition;Gaussian base","Algorithms;Computer Graphics;Computer Simulation;Humans;Imaging, Three-Dimensional;Models, Biological;Pattern Recognition, Automated;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Radiography, Abdominal;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface","39","1","43","IEEE","16 Mar 2009","","","IEEE","IEEE Journals"
"S<sc>ummit</sc>: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations","F. Hohman; H. Park; C. Robinson; D. H. Polo Chau",Georgia Tech.; Georgia Tech.; Georgia Tech.; Georgia Tech.,"IEEE Transactions on Visualization and Computer Graphics","27 Nov 2019","2020","26","1","1096","1106","Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.","1941-0506","","10.1109/TVCG.2019.2934659","NSF(grant numbers:IIS-1563816,CNS-1704701,TWC-1526254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807294","Deep learning interpretability;visual analytics;scalable summarization;attribution graph","Neurons;Biological neural networks;Feature extraction;Data visualization;Computational modeling;Predictive models;Visualization","data visualisation;feature extraction;graph theory;image classification;image representation;interactive systems;Internet;learning (artificial intelligence);neural net architecture;public domain software","Web browsers;computer vision model;representation learning;Summit visualization;image classifier;interactive visualizations;neural network feature visualization;deep learning model;interactive system;neural network predictions;decision-making tasks;attribution summarizations;deep learning interpretability;neural network architecture","","39","","60","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization","R. C. Basole; T. Clear; M. Hu; H. Mehrotra; J. Stasko",Georgia Tech; Georgia Tech; Georgia Tech; Georgia Tech; Georgia Tech,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2526","2535","Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.","1941-0506","","10.1109/TVCG.2013.209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634088","Companies;Ecosystems;Interactive systems;Data visualization;Mobile communication;network visualization;Business ecosystems;market research;strategic analysis;design study;interaction","Companies;Ecosystems;Interactive systems;Data visualization;Mobile communication","commerce;data visualisation;interactive systems;market opportunities","dotlink360;market segments;global networks;interactive visualization;business ecosystems;interfirm relationships","Algorithms;Commerce;Computer Graphics;Computer Simulation;Ecosystem;Interinstitutional Relations;Models, Organizational;User-Computer Interface","39","","51","","16 Oct 2013","","","IEEE","IEEE Journals"
"Visual Correlation Analysis of Numerical and Categorical Data on the Correlation Map","Z. Zhang; K. T. McDonnell; E. Zadok; K. Mueller","Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY; Department of Mathematics and Computer Science, Dowling College, Oakdale, NY; Filesystems and Storage Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY; Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2014","2015","21","2","289","303","Correlation analysis can reveal the complex relationships that often exist among the variables in multivariate data. However, as the number of variables grows, it can be difficult to gain a good understanding of the correlation landscape and important intricate relationships might be missed. We previously introduced a technique that arranged the variables into a 2D layout, encoding their pairwise correlations. We then used this layout as a network for the interactive ordering of axes in parallel coordinate displays. Our current work expresses the layout as a correlation map and employs it for visual correlation analysis. In contrast to matrix displays where correlations are indicated at intersections of rows and columns, our map conveys correlations by spatial proximity which is more direct and more focused on the variables in play. We make the following new contributions, some unique to our map: (1) we devise mechanisms that handle both categorical and numerical variables within a unified framework, (2) we achieve scalability for large numbers of variables via a multi-scale semantic zooming approach, (3) we provide interactive techniques for exploring the impact of value bracketing on correlations, and (4) we visualize data relations within the sub-spaces spanned by correlated variables by projecting the data into a corresponding tessellation of the map.","1941-0506","","10.1109/TVCG.2014.2350494","National Science Foundation(grant numbers:1050477,0959979,0937854,1117132); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6881685","Visual analytics;visual correlation analysis;categorical data;information visualization;interactive interfaces","Correlation;Visualization;Layout;Data visualization;Correlation coefficient;Optimization;Numerical models","correlation methods;data analysis;data visualisation;interactive systems","visual correlation analysis;categorical data;numerical data;correlation map;spatial proximity;multiscale semantic zooming;interactive techniques;value bracketing;map tessellation","","39","","37","USGov","21 Aug 2014","","","IEEE","IEEE Journals"
"A User Study on Curved Edges in Graph Visualization","K. Xu; C. Rooney; P. Passmore; D. -H. Ham; P. H. Nguyen",Middlesex University; Middlesex University; Middlesex University; Chonnam National University; Middlesex University,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2449","2456","Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.","1941-0506","","10.1109/TVCG.2012.189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327250","Graph;visualization;curved edges;evaluation","Visualization;Layout;Educational institutions;Optimization;Software;Analysis of variance;User interfaces","data visualisation;graph theory","graph visualization;edge curvature;graph readability;graph task;node-link diagram;edge variation;connectivity determination;shortest path;node degree;common neighbor;subjective rating","","38","","35","","8 Oct 2012","","","IEEE","IEEE Journals"
"A real-time photo-realistic visual flythrough","D. Cohen-Or; E. Rich; U. Lerner; V. Shenkar","Tilsat System Eng., Bnei-Brak, Israel; Tilsat System Eng., Bnei-Brak, Israel; Tilsat System Eng., Bnei-Brak, Israel; Tilsat System Eng., Bnei-Brak, Israel","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1996","2","3","255","265","In this paper we present a comprehensive flythrough system which generates photo-realistic images in true real-time. The high performance is due to an innovative rendering algorithm based on a discrete ray casting approach, accelerated by ray coherence and multiresolution traversal. The terrain as well as the 3D objects are represented by a textured mapped voxel-based model. The system is based on a pure software algorithm and is thus portable. It was first implemented on a workstation and then ported to a general-purpose parallel architecture to achieve real-time performance.","1941-0506","","10.1109/2945.537308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=537308","","Image generation;Aerospace simulation;Cameras;Rendering (computer graphics);Computational modeling;Hardware;Casting;Parallel architectures;Computer simulation;Layout","rendering (computer graphics);aerospace simulation;data visualisation;parallel algorithms;real-time systems;software portability","visual flythrough;photo-realistic images;rendering algorithm;discrete ray casting;ray coherence;multiresolution traversal;textured;mapped;real-time performance;portable;terrain visualization;parallel rendering;flight simulator;voxel-based modeling;visual simulations","","38","2","15","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Interactive Visual Analysis of Families of Function Graphs","Z. Konyha; K. Matkovic; D. Gracanin; M. Jelovic; H. Hauser","IEEE Computer Society; VRVis Res. Center, Vienna; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1373","1385","The analysis and exploration of multidimensional and multivariate data is still one of the most challenging areas in the field of visualization. In this paper, we describe an approach to visual analysis of an especially challenging set of problems that exhibit a complex internal data structure. We describe the interactive visual exploration and analysis of data that includes several (usually large) families of function graphs f_i({\bf{x}},t). We describe analysis procedures and practical aspects of the interactive visual analysis specific to this type of data (with emphasis on the function graph characteristic of the data). We adopted the well-proven approach of multiple, linked views with advanced interactive brushing to assess the data. Standard views such as histograms, scatterplots, and parallel coordinates are used to jointly visualize data. We support iterative visual analysis by providing means to create complex, composite brushes that span multiple views and that are constructed using different combination schemes. We demonstrate that engineering applications represent a challenging but very applicable area for visual analytics. As a case study, we describe the optimization of a fuel injection system in diesel engines of passenger cars.","1941-0506","","10.1109/TVCG.2006.99","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703360","Visual exploration;composite brushing;linked views;time series data;fuel injection system.","Data visualization;Multidimensional systems;Data structures;Data analysis;Histograms;Scattering;Brushes;Visual analytics;Fuels;Diesel engines","data analysis;data structures;data visualisation;graph theory","Visual exploration;composite brushing;linked views;time series data;fuel injection system.","Algorithms;Computer Graphics;Computer Simulation;Data Interpretation, Statistical;Information Storage and Retrieval;Models, Statistical;Multivariate Analysis;Pattern Recognition, Automated;User-Computer Interface","38","","37","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"Reliable path for virtual endoscopy: ensuring complete examination of human organs","Taosong He; Lichan Hong; Dongqing Chen; Zhengrong Liang","Network & Service Manage. Res. Dept., Lucent Technol. Bell Labs., Murray Hill, NJ, USA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2001","7","4","333","342","Virtual endoscopy is a computerized, noninvasive procedure for detecting anomalies inside human organs. Several preliminary studies have demonstrated the benefits and effectiveness of this modality. Unfortunately, previous work cannot guarantee that an existing anomaly will be detected, especially for complex organs with multiple branches. In this paper, we introduce the concept of reliable navigation, which ensures the interior organ surface is fully examined by the physician performing the virtual endoscopy procedure. To achieve this, we propose computing a reliable fly-through path that ensures no blind areas during the navigation. Theoretically, we discuss the criteria of evaluating a reliable path and prove that the problem of generating an optimal reliable path for virtual endoscopy is NP-complete. In practice, we develop an efficient method for the calculation of an effective reliable path. First, a small set of center observation points are automatically located inside the hollow organ. For each observation point, there exists at least one patch of interior surface visible to it, but that cannot be seen from any of the other observation points. These chosen points are then linked with a path that stays in the center of the organ. Finally, new points inside the organ are recursively selected and connected into the path until the entire organ surface is visible from the path. We present encouraging results from experiments on several data sets. For a medium-size volumetric model with several hundred thousand inner voxels, an effective reliable path can be generated in several minutes.","1941-0506","","10.1109/2945.965347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965347","","Endoscopes;Humans;Navigation;Cameras;Reliability theory;Automatic control;Switches;Helium;Biomedical imaging;Computer graphics","path planning;computational complexity;optimisation;medical image processing;visibility;reliability;computerised navigation;data visualisation","virtual endoscopy;computerized noninvasive procedure;human organs examination;anomaly detection;organ branches;reliable navigation;interior organ surface;optimal reliable fly-through path;blind areas;NP-complete problem;center observation points;hollow organ;visibility;recursively selected points;volumetric model;inner voxels;camera control","","38","2","24","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Towards BCI-Based Interfaces for Augmented Reality: Feasibility, Design and Evaluation","H. Si-Mohammed; J. Petit; C. Jeunet; F. Argelaguet; F. Spindler; A. Évain; N. Roussel; G. Casiez; A. Lecuyer","Inria, IRISA, CNRS, Univ. Rennes, Rennes, France; Inria, IRISA, CNRS, Univ. Rennes, Rennes, France; CNBI, EPFL, Geneva, Switzerland; Inria, IRISA, CNRS, Univ. Rennes, Rennes, France; Inria, IRISA, CNRS, Univ. Rennes, Rennes, France; Zebrys, Toulouse, France; Inria Bordeaux, Bordeaux, France; University of Lille, Villeneuve d'Ascq, France; Inria, IRISA, CNRS, Univ. Rennes, Rennes, France","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2020","2020","26","3","1608","1621","Brain-Computer Interfaces (BCIs) enable users to interact with computers without any dedicated movement, bringing new hands-free interaction paradigms. In this paper we study the combination of BCI and Augmented Reality (AR). We first tested the feasibility of using BCI in AR settings based on Optical See-Through Head-Mounted Displays (OST-HMDs). Experimental results showed that a BCI and an OST-HMD equipment (EEG headset and Hololens in our case) are well compatible and that small movements of the head can be tolerated when using the BCI. Second, we introduced a design space for command display strategies based on BCI in AR, when exploiting a famous brain pattern called Steady-State Visually Evoked Potential (SSVEP). Our design space relies on five dimensions concerning the visual layout of the BCI menu; namely: orientation, frame-of-reference, anchorage, size and explicitness. We implemented various BCI-based display strategies and tested them within the context of mobile robot control in AR. Our findings were finally integrated within an operational prototype based on a real mobile robot that is controlled in AR using a BCI and a HoloLens headset. Taken together our results (4 user studies) and our methodology could pave the way to future interaction schemes in Augmented Reality exploiting 3D User Interfaces based on brain activity and BCIs.","1941-0506","","10.1109/TVCG.2018.2873737","Inria Project Lab BCI-Lift; EPFL-Inria International Lab.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481564","Brain-computer interface;augmented reality;user interface;design space;SSVEP;optical see-through;robot control","Augmented reality;Electroencephalography;Headphones;Resists;Aerospace electronics;Integrated optics;Robots","augmented reality;brain-computer interfaces;electroencephalography;helmet mounted displays;medical robotics;medical signal processing;mobile robots;visual evoked potentials","EEG headset;HoloLens headset;mobile robot control;frame-of-reference;steady-state visually evoked potential;brain pattern;head movement;optical see-through head-mounted displays;BCI-based display strategies;hands-free interaction paradigms;brain-computer interfaces;augmented reality","Adult;Augmented Reality;Brain-Computer Interfaces;Electroencephalography;Evoked Potentials, Visual;Feasibility Studies;Head;Humans;Photic Stimulation;Task Performance and Analysis;Young Adult","38","","32","IEEE","4 Oct 2018","","","IEEE","IEEE Journals"
"Visualization of Simulated Urban Spaces: Inferring Parameterized Generation of Streets, Parcels, and Aerial Imagery","C. A. Vanegas; D. G. Aliaga; B. Benes; P. Waddell","Purdue University, West Lafayette; Purdue University, West Lafayette; Purdue University, West Lafayette; University of Washington, Seattle","IEEE Transactions on Visualization and Computer Graphics","16 Mar 2009","2009","15","3","424","435","Urban simulation models and their visualization are used to help regional planning agencies evaluate alternative transportation investments, land use regulations, and environmental protection policies. Typical urban simulations provide spatially distributed data about number of inhabitants, land prices, traffic, and other variables. In this article, we build on a synergy of urban simulation, urban visualization, and computer graphics to automatically infer an urban layout for any time step of the simulation sequence. In addition to standard visualization tools, our method gathers data of the original street network, parcels, and aerial imagery and uses the available simulation results to infer changes to the original urban layout and produce a new and plausible layout for the simulation results. In contrast with previous work, our approach automatically updates the layout based on changes in the simulation data and thus can scale to a large simulation over many years. The method in this article offers a substantial step forward in building integrated visualization and behavioral simulation systems for use in community visioning, planning, and policy analysis. We demonstrate our method on several real cases using a 200 GB database for a 16,300 km2 area surrounding Seattle, Washington.","1941-0506","","10.1109/TVCG.2008.193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4668343","Picture/Image Generation;Information visualization;Visualization techniques and methodologies;Picture/Image Generation;Information visualization;Visualization techniques and methodologies","Data visualization;Computational modeling;Computer simulation;Layout;Land use planning;Urban planning;Transportation;Investments;Protection;Telecommunication traffic","data visualisation;geographic information systems;geophysical signal processing;image processing;land use planning","simulated urban space visualization;aerial imagery;regional planning agency;parameterized street generation;parcel;transportation investment;land use regulation;environmental protection policy;computer graphics;community visioning;GIS;geographic information systems","Cities;Computer Graphics;Computer Simulation;Ecosystem;Geographic Information Systems;Imaging, Three-Dimensional;Maps as Topic;Models, Theoretical;User-Computer Interface","38","1","36","IEEE","16 Mar 2009","","","IEEE","IEEE Journals"
"Browsing Zoomable Treemaps: Structure-Aware Multi-Scale Navigation Techniques","R. Blanch; E. Lecolinet","Univ. of Grenoble 1, Grenoble; NA","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1248","1253","Treemaps provide an interesting solution for representing hierarchical data. However, most studies have mainly focused on layout algorithms and paid limited attention to the interaction with treemaps. This makes it difficult to explore large data sets and to get access to details, especially to those related to the leaves of the trees. We propose the notion of zoomable treemaps (ZTMs), an hybridization between treemaps and zoomable user interfaces that facilitates the navigation in large hierarchical data sets. By providing a consistent set of interaction techniques, ZTMs make it possible for users to browse through very large data sets (e.g., 700,000 nodes dispatched amongst 13 levels). These techniques use the structure of the displayed data to guide the interaction and provide a way to improve interactive navigation in treemaps.","1941-0506","","10.1109/TVCG.2007.70540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376147","Information visualization;multi-scale interaction;structure-aware navigation;zoomable treemaps.","Navigation;User interfaces;Tree graphs;Data visualization;File systems;Filling;Layout","data structures;data visualisation;navigation;user interfaces","interactive navigation;zoomable user interfaces;zoomable treemaps;hierarchical data represention;structure-aware multiscale navigation;zoomable treemap browsing","","37","1","36","","5 Nov 2007","","","IEEE","IEEE Journals"
"Graphical Overlays: Using Layered Elements to Aid Chart Reading","N. Kong; M. Agrawala","University of California, Berkeley; University of California, Berkeley","IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2631","2638","Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts.","1941-0506","","10.1109/TVCG.2012.229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327269","Visualization;overlays;graphical perception;graph comprehension","Visualization;Encoding;Image color analysis;Data mining;Data visualization;Bars;Market research","charts;data visualisation","layered elements;aid chart reading;visualization;aggregating numerical values;World Wide Web;visual elements;chart reading task;cognitive processes;redundant encoding;numerical data label;summary statistics;descriptive text;automated system;user chosen graphical overlays;chart bitmaps;visual marks;interactive overlays;bar charts;pie charts;line charts","","37","10","38","","8 Oct 2012","","","IEEE","IEEE Journals"
"Seeing People in Different Light-Joint Shape, Motion, and Reflectance Capture","C. Theobalt; N. Ahmed; H. Lensch; M. Magnor; H. -P. Seidel","MPI Informatik, Stuhlsatzenhausweg 85, 66123 Saarbruecken, Germany; MPI Informatik, Stuhlsatzenhausweg 85, 66123 Saarbruecken, Germany; MPI Informatik, Stuhlsatzenhausweg 85, 66123 Saarbruecken, Germany; TU Braunschweig, Computer Graphics Lab, Muehlenpfordtstr. 23, 38106 Braunschweig, Germany; MPI Informatik, Stuhlsatzenhausweg 85, 66123 Saarbruecken, Germany","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","663","674","By means of passive optical motion capture, real people can be authentically animated and photo-realistically textured. To import real-world characters into virtual environments, however, surface reflectance properties must also be known. We describe a video-based modeling approach that captures human shape and motion as well as reflectance characteristics from a handful of synchronized video recordings. The presented method is able to recover spatially varying surface reflectance properties of clothes from multiview video footage. The resulting model description enables us to realistically reproduce the appearance of animated virtual actors under different lighting conditions, as well as to interchange surface attributes among different people, e.g., for virtual dressing. Our contribution can be used to create 3D renditions of real-world people under arbitrary novel lighting conditions on standard graphics hardware.","1941-0506","","10.1109/TVCG.2007.1006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293011","3D video;dynamic reflectometry;real-time rendering;relighting.","Shape;Reflectivity;Rendering (computer graphics);Geometry;Animation;Layout;Graphics;Textiles;Video recording;Hardware","computer animation;realistic images;rendering (computer graphics);video recording","passive optical motion capture system;virtual environment;surface reflectance;video-based modeling;multiview video footage;real-time rendering","Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Joints;Joints;Lighting;Models, Biological;Movement;User-Computer Interface","37","9","42","IEEE","20 Aug 2007","","","IEEE","IEEE Journals"
"An Uncertainty-Aware Approach for Exploratory Microblog Retrieval","M. Liu; S. Liu; X. Zhu; Q. Liao; F. Wei; S. Pan","Tsinghua University; Tsinghua University; USTC; Microsoft; Microsoft; University of Maryland, Baltimore County","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","250","259","Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data.","1941-0506","","10.1109/TVCG.2015.2467554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192694","microblog data;mutual reinforcement model;uncertainty modeling;uncertainty visualization;uncertainty propagation;microblog data;mutual reinforcement model;uncertainty modeling;uncertainty visualization;uncertainty propagation","Uncertainty;Twitter;Tagging;Data visualization;Visual analytics;Monte Carlo methods;Data models","data visualisation;information retrieval;Web sites","uncertainty-aware approach;exploratory microblog retrieval;uncertainty-aware visual analytics approach;salient posts retrieval;hashtags retrieval;ranking technique;mutual reinforcement rank;graph node;composite visualization;graph visualization;uncertainty glyph;flow map;high-quality microblog data retrieval","Blogging;Computer Graphics;Humans;Information Storage and Retrieval;Internet;Models, Statistical;Models, Theoretical;Monte Carlo Method","36","","55","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Aura 3D Textures","X. Qin; Y. Yang","Department of Computing Science, Grant MacEwan College, PO Box 1796, Edmonton, AB, Canada, T5J 2P2; Department of Computing Science, University of Alberta, Edmonton, AB T6G 2E8, Canada","IEEE Transactions on Visualization and Computer Graphics","22 Jan 2007","2007","13","2","379","389","This paper presents a new technique, called aura 3D textures, for generating solid textures based on input examples. Our method is fully automatic and requires no user interactions in the process. Given an input texture sample, our method first creates its aura matrix representations and then generates a solid texture by sampling the aura matrices of the input sample constrained in multiple view directions. Once the solid texture is generated, any given object can be textured by the solid texture. We evaluate the results of our method based on extensive user studies. Based on the evaluation results using human subjects, we conclude that our algorithm can generate faithful results of both stochastic and structural textures with an average successful rate of 76.4 percent. Our experimental results also show that the new method outperforms Wei and Levoy's method and is comparable to that proposed by Jagnow et al. (2004)","1941-0506","","10.1109/TVCG.2007.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069245","Aura matrices;basic gray-level aura matrices (BGLAM);solid textures;texture synthesis.","Solids;Surface texture;Sampling methods;Computer graphics;Humans;Stochastic processes;Rendering (computer graphics);Layout;Fires;Clouds","image texture;matrix algebra;solid modelling","aura 3D textures;solid textures;aura matrix representation;stochastic textures;structural textures;gray-level aura matrices;texture synthesis","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Surface Properties","36","","50","","22 Jan 2007","","","IEEE","IEEE Journals"
"Caustics Mapping: An Image-Space Technique for Real-Time Caustics","M. A. Shah; J. Konttinen; S. Pattanaik","School of Electrical Engineering and Computer Science, Engineering III, Room 213, University of Central Florida, Orlando, FL 32816; School of Electrical Engineering and Computer Science, Engineering III, Room 213, University of Central Florida, Orlando, FL 32816; School of Electrical Engineering and Computer Science, Engineering III, Room 213, University of Central Florida, Orlando, FL 32816","IEEE Transactions on Visualization and Computer Graphics","22 Jan 2007","2007","13","2","272","280","In this paper, we present a simple and practical technique for real-time rendering of caustics from reflective and refractive objects. Our algorithm, conceptually similar to shadow mapping, consists of two main parts: creation of a caustic map texture, and utilization of the map to render caustics onto nonshiny surfaces. Our approach avoids performing any expensive geometric tests, such as ray-object intersection, and involves no precomputation; both of which are common features in previous work. The algorithm is well suited for the standard rasterization pipeline and runs entirely on the graphics hardware.","1941-0506","","10.1109/TVCG.2007.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069236","Caustics;real-time rendering;image-space techniques;GPU.","Rendering (computer graphics);Layout;Graphics;Geometry;Ray tracing;Shadow mapping;Testing;Hardware;Optical refraction;Real time systems","image texture;rendering (computer graphics)","caustics mapping;image-space technique;real-time caustics rendering;reflective objects;refractive objects;shadow mapping;caustic map texture;rasterization","Algorithms;Computer Graphics;Computer Systems;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Lighting;Numerical Analysis, Computer-Assisted;User-Computer Interface","36","2","19","IEEE","22 Jan 2007","","","IEEE","IEEE Journals"
"Compressed Adjacency Matrices: Untangling Gene Regulatory Networks","K. Dinkla; M. A. Westenberg; J. J. van Wijk",Eindhoven University of Technology; Eindhoven University of Technology; Eindhoven University of Technology,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2457","2466","We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.","1941-0506","","10.1109/TVCG.2012.208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327251","Network;gene regulation;scale-free;adjacency matrix","Visualization;Computer aided manufacturing;Standards;Sparse matrices;Layout;Bismuth;Proteins","biology computing;data visualisation;genetics;matrix algebra;network theory (graphs)","compressed adjacency matrices;gene regulatory networks;directed networks;structural characteristics;scale-free distribution;standard visualization;node-link diagrams;network characteristics;sparse network;neatly-arranged visualization;motifs;visualization domain;standard adjacency matrix;rearrangement clustering","Algorithms;Computer Graphics;Gene Regulatory Networks;Image Processing, Computer-Assisted","36","1","43","","8 Oct 2012","","","IEEE","IEEE Journals"
"Drawing Road Networks with Focus Regions","J. -H. Haunert; L. Sering",University of Würzburg; University of Würzburg,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2555","2562","Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.","1941-0506","","10.1109/TVCG.2011.191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065023","Cartography;schematic maps;fish-eye view;graph drawing;optimization;quadratic programming.","Cartography;Optimization;Image analysis;Visualization;Distortion measurement;Graphics;Quadratic programming","cartography;convex programming;graph theory;mobile computing;polynomials;quadratic programming;real-time systems;traffic information systems","road networks;mobile maps user;cartographer;user defined focus region;fish-eye projection;map distortion;mapping function;convex quadratic program;polynomial time solution;linear inequalities;edge crossings;prototype tool;real-time system;graph drawing","","36","","33","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Evaluation of Filesystem Provenance Visualization Tools","M. A. Borkin; C. S. Yeh; M. Boyd; P. Macko; K. Z. Gajos; M. Seltzer; H. Pfister",Harvard University; Harvard University; Harvard University; Harvard University; Harvard University; Harvard University; Harvard University,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2476","2485","Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.","1941-0506","","10.1109/TVCG.2013.155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634189","Data visualization;Context awareness;Layout;Encoding;gender differences;Provenance data;graph/network data;hierarchy data;quantitative evaluation","Data visualization;Context awareness;Layout;Encoding","data visualisation;file organisation;gender issues;user interfaces","subjective measures;system activity;quantitative evaluation;Orbiter;node link based tool;data exploration;user mental model;time based hierarchical node grouping method;interactive radial based tree layout;high level summary;node link diagram;visual representation;complex hierarchical structure;filesystem provenance data;filesystem provenance visualization tools","Adult;Algorithms;Artificial Intelligence;Computer Graphics;Databases, Factual;Female;Humans;Image Enhancement;Information Storage and Retrieval;Male;Multimodal Imaging;Pattern Recognition, Visual;Software;Task Performance and Analysis;User-Computer Interface","36","3","54","","16 Oct 2013","","","IEEE","IEEE Journals"
"Rapid Graph Layout Using Space Filling Curves","C. Muelder; K. Ma","University of California, Davis; University of California, Davis","IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1301","1308","Network data frequently arises in a wide variety of fields, and node-link diagrams are a very natural and intuitive representation of such data. In order for a node-link diagram to be effective, the nodes must be arranged well on the screen. While many graph layout algorithms exist for this purpose, they often have limitations such as high computational complexity or node colocation. This paper proposes a new approach to graph layout through the use of space filling curves which is very fast and guarantees that there will be no nodes that are colocated. The resulting layout is also aesthetic and satisfies several criteria for graph layout effectiveness.","1941-0506","","10.1109/TVCG.2008.158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658143","Index Terms—;Information visualization;Graph layout;Space filling curves","Filling;Clustering algorithms;Data visualization;Computational complexity;Social network services;Lenses;Tree graphs","computational complexity;data visualisation;graph theory","node-link diagrams;space filling curves;graph layout;computational complexity;node colocation;graph visualization","","36","","34","","24 Oct 2008","","","IEEE","IEEE Journals"
"Topological Spines: A Structure-preserving Visual Representation of Scalar Fields","C. Correa; P. Lindstrom; P. -T. Bremer",Lawrence Livermore National Lab; Lawrence Livermore National Lab; Lawrence Livermore National Lab,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","1842","1851","We present topological spines−a new visual representation that preserves the topological and geometric structure of a scalar field. This representation encodes the spatial relationships of the extrema of a scalar field together with the local volume and nesting structure of the surrounding contours. Unlike other topological representations, such as contour trees, our approach preserves the local geometric structure of the scalar field, including structural cycles that are useful for exposing symmetries in the data. To obtain this representation, we describe a novel mechanism based on the extraction of extremum graphs−sparse subsets of the Morse-Smale complex that retain the important structural information without the clutter and occlusion problems that arise from visualizing the entire complex directly. Extremum graphs form a natural multiresolution structure that allows the user to suppress noise and enhance topological features via the specification of a persistence range. Applications of our approach include the visualization of 3D scalar fields without occlusion artifacts, and the exploratory analysis of high-dimensional functions.","1941-0506","","10.1109/TVCG.2011.244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064947","Scalar field topology;topological spine;extremum graph;Morse-Smale complex.","Topology;Data visualization;Approximation methods;Manifolds","computational geometry;data visualisation;graph theory;natural sciences computing","topological spines;structure preserving visual representation;scalar fields;geometric structure;contour trees;extremum graphs;Morse-Smale complex;occlusion problems;clutter problems","","36","","36","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"TransGraph: Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data","Y. Gu; C. Wang",Michigan Technological University; Michigan Technological University,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2015","2024","A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the TransGraph, a graph-based representation to visualize hierarchical state transition relationships. The TransGraph not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the TransGraph and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the TransGraph can effectively augment our ability in understanding time-varying data.","1941-0506","","10.1109/TVCG.2011.246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064965","Time-varying data visualization;hierarchical representation;states;transition relationship;user interface.","Data visualization;Hierarchical systems;Histograms;Data mining;User interfaces","data analysis;data mining;data structures;data visualisation;graph theory;probability","time-varying volumetric data analysis;data visualization;occlusion free;transition probability;TransGraph;graph based representation;hierarchical state transition relationships;visual mapping;navigation tool;knowledge extraction","","36","","30","","3 Nov 2011","","","IEEE","IEEE Journals"
"Visual Analysis of Large Graphs Using (X,Y)-Clustering and Hybrid Visualizations","V. Batagelj; F. J. Brandenburg; W. Didimo; G. Liotta; P. Palladino; M. Patrignani","University of Ljubljana, Ljubljana; University of Passau, Passau; Università degli Studi di Perugia, Perugia; Università degli Studi di Perugia, Perugia; Università degli Studi di Perugia, Perugia; Roma Tre University, Roma","IEEE Transactions on Visualization and Computer Graphics","8 Sep 2011","2011","17","11","1587","1598","Many different approaches have been proposed for the challenging problem of visually analyzing large networks. Clustering is one of the most promising. In this paper, we propose a new clustering technique whose goal is that of producing both intracluster graphs and intercluster graph with desired topological properties. We formalize this concept in the (X,Y) -clustering framework, where Y is the class that defines the desired topological properties of intracluster graphs and X is the class that defines the desired topological properties of the intercluster graph. By exploiting this approach, hybrid visualization tools can effectively combine different node-link and matrix-based representations, allowing users to interactively explore the graph by expansion/contraction of clusters without loosing their mental map. As a proof of concept, we describe the system Visual Hybrid (X,Y)-clustering (VHYXY) that implements our approach and we present the results of case studies to the visual analysis of social networks.","1941-0506","","10.1109/TVCG.2010.265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674029","Large graphs;graph clustering;hybrid visualization;visual analytics.","Visualization;Clustering algorithms;Layout;Algorithm design and analysis;Social network services;Computational modeling;Context","data visualisation;graph theory;pattern clustering;social networking (online)","clustering technique;intracluster graphs;topological properties;hybrid visualization tools;node link representation;matrix based representation;mental map;visual analysis;social networks","","36","","56","","23 Dec 2010","","","IEEE","IEEE Journals"
"Visualizing Dynamic Data with Maps","D. Mashima; S. Kobourov; Y. Hu","Georgia Institute of Technology, Atlanta; University of Arizona, Tucson; AT&T Labs Research, Florham Park","IEEE Transactions on Visualization and Computer Graphics","12 Jul 2012","2012","18","9","1424","1437","Maps offer a familiar way to present geographic data (continents, countries), and additional information (topography, geology), can be displayed with the help of contours and heat-map overlays. In this paper, we consider visualizing large-scale dynamic relational data by taking advantage of the geographic map metaphor. We describe a map-based visualization system which uses animation to convey dynamics in large data sets, and which aims to preserve the viewer's mental map while also offering readable views at all times. Our system is fully functional and has been used to visualize user traffic on the Internet radio station last.fm, as well as TV-viewing patterns from an IPTV service. All map images in this paper are available in high-resolution at [CHECK END OF SENTENCE] as are several movies illustrating the dynamic visualization.","1941-0506","","10.1109/TVCG.2011.288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6109250","Information interface and presentation;multimedia information systems;dynamic visualization;graph drawing;spatialization;map-based visualization.","Data visualization;Layout;Animation;Measurement;Clustering algorithms;Heuristic algorithms;Data mining","data visualisation;dynamic programming;geographic information systems","dynamic data visualisation;maps;geographic data;heat map overlays;large scale dynamic relational data;geographic map metaphor;map based visualization system;Internet radio station;TV-viewing patterns;IPTV service","","36","","31","","20 Dec 2011","","","IEEE","IEEE Journals"
"An Efficient Framework for Generating Storyline Visualizations from Streaming Data","Y. Tanahashi; C. Hsueh; K. Ma","VIDI Research Group, University California, Davis, CA; VIDI Research Group, University California, Davis, CA; VIDI Research Group, University California, Davis, CA","IEEE Transactions on Visualization and Computer Graphics","1 May 2015","2015","21","6","730","742","This paper presents a novel framework for applying storyline visualizations to streaming data. The framework includes three components: a new data management scheme for processing and storing the incoming data, a layout construction algorithm specifically designed for incrementally generating storylines from streaming data, and a layout refinement algorithm for improving the legibility of the visualization. By dividing the layout computation to two separate components, one for constructing and another for refining, our framework effectively provides the users with the ability to follow and reason dynamic data. The evaluation studies of our storyline visualization framework demonstrate its efficacy to present streaming data as well as its superior performance over existing methods in terms of both computational efficiency and visual clarity.","1941-0506","","10.1109/TVCG.2015.2392771","National Science Foundation(grant numbers:NSF DRL-1323214,NSF IIS-1255237,NSF IIS-1320229); U.S. Department of Energy(grant numbers:DEFC02-06ER25777,DE-FC02-12ER26072); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7015617","Storyline visualization;streaming data;layout algorithms;time-varying data;Storyline visualization;streaming data;layout algorithms;time-varying data","Data visualization;Layout;Algorithm design and analysis;Visualization;Feeds;Optimization;Social network services","data visualisation;humanities;inference mechanisms","visual clarity;computational efficiency;storyline visualization framework;layout computation;layout refinement algorithm;layout construction algorithm;data management scheme;data streaming;storyline visualization generation","","35","","39","IEEE","20 Jan 2015","","","IEEE","IEEE Journals"
"Evaluation of Graph Sampling: A Visualization Perspective","Y. Wu; N. Cao; D. Archambault; Q. Shen; H. Qu; W. Cui","Hong Kong University of Science and Technology; New York University, Shanghai; Swansea University; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Microsoft Research Asia","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","401","410","Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.","1941-0506","","10.1109/TVCG.2016.2598867","National Basic Research Program of China (973 Program)(grant numbers:2014CB340304); Microsoft Research Asia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539318","Graph visualization;graph sampling;empirical evaluation","Visualization;Measurement;Data visualization;Data mining;Fires;Scalability;Clustering algorithms","data mining;data visualisation;graph theory;sampling methods","graph sampling;scalability issue;graph analysis;graph structural property;degree distribution;clustering coefficient;sampling strategy;node-link visualization;graph mining;visual feature preservation;node-link diagram;metric evaluation","","35","","52","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"Faster isosurface ray tracing using implicit KD-trees","I. Wald; H. Friedrich; G. Marmitt; P. Slusallek; H. -. Seidel","Max-Planck-Inst. fur Inf., Saarbrucken, Germany; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","25 Jul 2005","2005","11","5","562","572","The visualization of high-quality isosurfaces at interactive rates is an important tool in many simulation and visualization applications. Today, isosurfaces are most often visualized by extracting a polygonal approximation that is then rendered via graphics hardware or by using a special variant of preintegrated volume rendering. However, these approaches have a number of limitations in terms of the quality of the isosurface, lack of performance for complex data sets, or supported shading models. An alternative isosurface rendering method that does not suffer from these limitations is to directly ray trace the isosurface. However, this approach has been much too slow for interactive applications unless massively parallel shared-memory supercomputers have been used. In this paper, we implement interactive isosurface ray tracing on commodity desktop PCs by building on recent advances in real-time ray tracing of polygonal scenes and using those to improve isosurface ray tracing performance as well. The high performance and scalability of our approach will be demonstrated with several practical examples, including the visualization of highly complex isosurface data sets, the interactive rendering of hybrid polygonal/isosurface scenes, including high-quality ray traced shading effects, and even interactive global illumination on isosurfaces.","1941-0506","","10.1109/TVCG.2005.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471693","Index Terms- Ray tracing;real-time rendering;isosurface;visualization;global illumination.","Isosurfaces;Ray tracing;Rendering (computer graphics);Data visualization;Layout;Data mining;Graphics;Hardware;Supercomputers;Personal communication networks","ray tracing;rendering (computer graphics);data visualisation;solid modelling;interactive systems;real-time systems;computational geometry;lighting;computer graphic equipment;tree data structures","interactive isosurface ray tracing;implicit KD-trees;high-quality isosurface visualization;polygonal approximation;interactive isosurface rendering;graphics hardware;volume rendering;isosurface quality;shading model;parallel shared-memory supercomputer;real-time ray tracing;polygonal scenes;interactive global illumination;real-time rendering","Algorithms;Computer Graphics;Computer Simulation;Computer Systems;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Biological;Models, Statistical;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique;User-Computer Interface","35","4","35","","25 Jul 2005","","","IEEE","IEEE Journals"
"LDSScanner: Exploratory Analysis of Low-Dimensional Structures in High-Dimensional Datasets","J. Xia; F. Ye; W. Chen; Y. Wang; W. Chen; Y. Ma; A. K. H. Tung",Central South University; Central South University; Zhejiang University; Central South University; Zhejiang University of Finance & Economics; Zhejiang University; National University of Singapore,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","236","245","Many approaches for analyzing a high-dimensional dataset assume that the dataset contains specific structures, e.g., clusters in linear subspaces or non-linear manifolds. This yields a trial-and-error process to verify the appropriate model and parameters. This paper contributes an exploratory interface that supports visual identification of low-dimensional structures in a high-dimensional dataset, and facilitates the optimized selection of data models and configurations. Our key idea is to abstract a set of global and local feature descriptors from the neighborhood graph-based representation of the latent low-dimensional structure, such as pairwise geodesic distance (GD) among points and pairwise local tangent space divergence (LTSD) among pointwise local tangent spaces (LTS). We propose a new LTSD-GD view, which is constructed by mapping LTSD and GD to the <inline-formula><tex-math notation=""LaTeX"">$x$</tex-math><alternatives><inline-graphic xlink:href=""24tvcg01-xia-2744098-ieq-1-source.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> axis and <inline-formula><tex-math notation=""LaTeX"">$y$</tex-math><alternatives><inline-graphic xlink:href=""24tvcg01-xia-2744098-ieq-2-source.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> axis using 1D multidimensional scaling, respectively. Unlike traditional dimensionality reduction methods that preserve various kinds of distances among points, the LTSD-GD view presents the distribution of pointwise LTS (<inline-formula><tex-math notation=""LaTeX"">$x$</tex-math><alternatives><inline-graphic xlink:href=""24tvcg01-xia-2744098-ieq-3-source.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> axis) and the variation of LTS in structures (the combination of <inline-formula><tex-math notation=""LaTeX"">$x$</tex-math><alternatives><inline-graphic xlink:href=""24tvcg01-xia-2744098-ieq-4-source.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> axis and <inline-formula><tex-math notation=""LaTeX"">$y$</tex-math><alternatives><inline-graphic xlink:href=""24tvcg01-xia-2744098-ieq-5-source.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> axis). We design and implement a suite of visual tools for navigating and reasoning about intrinsic structures of a high-dimensional dataset. Three case studies verify the effectiveness of our approach.","1941-0506","","10.1109/TVCG.2017.2744098","National Science Foundation of China(grant numbers:61309009,61422211); National 973 Program of China(grant numbers:2015CB352503); Major Program of National Natural Science Foundation of China(grant numbers:61232012); Open Project Program of the State Key Lab of CAD&CG(grant numbers:A1710); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017645","High-dimensional data;low-dimensional structure;subspace;manifold;visual exploration","Manifolds;Data visualization;Data models;Visualization;Tools;Analytical models;Principal component analysis","","","","35","","44","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Six degree-of-freedom haptic rendering using spatialized normal cone search","D. E. Johnson; P. Willemsen; E. Cohen","Sch. of Comput., Utah Univ., Salt Lake City, UT, USA; Sch. of Comput., Utah Univ., Salt Lake City, UT, USA; Sch. of Comput., Utah Univ., Salt Lake City, UT, USA","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","661","670","This paper describes a haptic rendering algorithm for arbitrary polygonal models using a six degree-of-freedom haptic interface. The algorithm supports activities such as virtual prototyping of complex polygonal models and adding haptic interaction to virtual environments. The underlying collision system computes local extrema in distance between the model controlled by the haptic device and the rest of the scene. The haptic rendering computes forces and torques on the moving model based on these local extrema. The system is demonstrated on models with tens of thousands of triangles and developed in an accessibility application for finding collision-free paths.","1941-0506","","10.1109/TVCG.2005.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512017","Index Terms- Haptic I/O;virtual reality;computer-aided design.","Haptic interfaces;Rendering (computer graphics);Virtual prototyping;Layout;Virtual environment;Application software;System testing;Virtual reality;Design automation;Computer displays","rendering (computer graphics);haptic interfaces;virtual reality;solid modelling;computational geometry;virtual prototyping","six degree-of-freedom haptic rendering;spatialized normal cone search;arbitrary polygonal model;haptic interface;virtual prototyping;collision system;haptic device;virtual reality;computer-aided design","Computer Simulation;Computer Systems;Cybernetics;Data Display;Environment;Humans;Imaging, Three-Dimensional;Man-Machine Systems;Models, Biological;Online Systems;Touch;User-Computer Interface","35","4","24","","26 Sep 2005","","","IEEE","IEEE Journals"
"StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views","Q. Shen; W. Zeng; Y. Ye; S. M. Arisona; S. Schubiger; R. Burkhard; H. Qu",Hong Kong University of Science and Technology; Future Cities LaboratoryETH Zurich; Tongji University; University of Applied Sciences and Arts Northwestern Switzerland FHNW; University of Applied Sciences and Arts Northwestern Switzerland FHNW; Future Cities LaboratoryETH Zurich; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","1004","1013","Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks.","1941-0506","","10.1109/TVCG.2017.2744159","Urban China Initiative 2017; HK RGC GRF(grant numbers:16241916); National 973 Program of China(grant numbers:2014CB340304); ITF(grant numbers:ITS/170/15FP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017655","Urban forms;human scale;street view;visual analytics","Data visualization;Urban areas;Green products;Visual analytics;Correlation;Layout","building management systems;computer vision;data analysis;data visualisation;learning (artificial intelligence);town and country planning","interactive visual analytics system;human-scale urban forms;street view images;two-stage visual exploration;Street Explorer;street-scale;street view patterns;urban environments;urban planning;environment auditing;high-quality urban spaces","Cities;Computer Graphics;Humans;Image Processing, Computer-Assisted;Maps as Topic;User-Computer Interface","35","","47","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement","C. Bryan; K. Ma; J. Woodring","University of California, Davis; University of California, Davis; Los Alamos National Laboratory","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","511","520","Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.","1941-0506","","10.1109/TVCG.2016.2598876","INGVA/LANL; US National Science Foundation(grant numbers:DRL-1323214,IIS-1528203,IIS-1320229); U.S. Department of Energy(grant numbers:DE-FC02-12ER26072); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539294","Narrative visualization;storytelling;annotations;comic strip visualization;time-varying data","Data visualization;Visualization;Strips;Layout;Context;Data analysis;Additives","data visualisation;interactive systems","temporal summary images;narrative visualization;interactive annotation generation;interactive annotation placement;data analysis;data communication;multidimensional data;time-varying data;visualized attributes;salient features;points of interest;POl;TSI;temporal layout;comic strip-style data snapshots;textual annotations;interactive techniques;automatic annotations workflow;visual design process;data storytelling","","35","","46","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"The Data Context Map: Fusing Data and Attributes into a Unified Display","S. Cheng; K. Mueller","Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University and SUNY, Korea; Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University and SUNY, Korea","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","121","130","Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs.","1941-0506","","10.1109/TVCG.2015.2467552","NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194836","High Dimensional Data;Low-Dimensional Embedding;Visual Analytics,;Decision Make;Tradeoffs,;High Dimensional Data;Low-Dimensional Embedding;Visual Analytics;Decision Make;Tradeoffs","Layout;Context;Measurement;Correlation;Optimization;Data visualization;Symmetric matrices","data visualisation;encoding;matrix algebra;sensor fusion","data context map;data fusion;unified display;data matrix visualization;similarity encoding;submatrices;multidimensional scaling type layout;similarity matrix fusion","","35","","37","IEEE","13 Aug 2015","","","IEEE","IEEE Journals"
"3D Modeling of Optically Challenging Objects","J. Park; A. Kak","Purdue Univ., West Lafayette; Purdue Univ., West Lafayette","IEEE Transactions on Visualization and Computer Graphics","21 Jan 2008","2008","14","2","246","262","We present a system for constructing 3D models of real-world objects with optically challenging surfaces. The system utilizes a new range imaging concept called multipeak range imaging, which stores multiple candidates of range measurements for each point on the object surface. The multiple measurements include the erroneous range data caused by various surface properties that are not ideal for structured-light range sensing. False measurements generated by spurious reflections are eliminated by applying a series of constraint tests. The constraint tests based on local surface and local sensor visibility are applied first to individual range images. The constraint tests based on global consistency of coordinates and visibility are then applied to all range images acquired from different viewpoints. We show the effectiveness of our method by constructing 3D models of five different optically challenging objects. To evaluate the performance of the constraint tests and to examine the effects of the parameters used in the constraint tests, we acquired the ground-truth data by painting those objects to suppress the surface-related properties that cause difficulties in range sensing. Experimental results indicate that our method significantly improves upon the traditional methods for constructing reliable 3D models of optically challenging objects.","1941-0506","","10.1109/TVCG.2007.1069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359484","Range data;geometric modeling;image analysis;virtual reality;feature representation;Range data;geometric modeling;image analysis;virtual reality;feature representation","Optical sensors;Testing;Application software;Cameras;Optical reflection;Optical imaging;Solid modeling;Layout;Image sensors;Painting","object recognition;optical images;solid modelling;surface fitting","3D modeling;optically challenging object surface;multipeak range imaging;ground-truth data;multiple range measurement;erroneous range data;spurious reflection","","34","4","42","","21 Jan 2008","","","IEEE","IEEE Journals"
"AmbiguityVis: Visualization of Ambiguity in Graph Layouts","Y. Wang; Q. Shen; D. Archambault; Z. Zhou; M. Zhu; S. Yang; H. Qu",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Swansea University; Zhejiang University of Finance and Economics; Sichuan University; Huawei Co. Ltd.; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","359","368","Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews.","1941-0506","","10.1109/TVCG.2015.2467691","HK RGC GRF(grant numbers:618313); Huawei Co. Ltd; National Natural Science Foundation of China(grant numbers:61303133); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192724","Visual Ambiguity;Visualization;Node-link diagram;Graph layout;Graph visualization;Visual Ambiguity;Visualization;Node-link diagram;Graph layout;Graph visualization","Visualization;Measurement;Layout;Heating;Image edge detection;Entropy;Readability metrics","data visualisation;diagrams;graph theory;network theory (graphs)","AmbiguityVis;ambiguity visualization;graph layouts;node-link diagrams;network exploration;automated graph layout strategy;aesthetic criteria optimization;drawing approach;network structure;visual ambiguity;ambiguous spatial relationships;graph nodes;graph edges;community structure visual overlap;edge bundling ambiguity;metanode ambiguity;edge length;node aggregation;edge aggregation;heatmap-based visualization;visual feedback;graph drawing","","34","","56","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"An Approach to Supporting Incremental Visual Data Classification","J. G. S. Paiva; W. R. Schwartz; H. Pedrini; R. Minghim","Faculty of Computer Science, Federal University of Uberlandia-UFU, Uberlandia, Minas Gerais, Brazil; Department of Computer Science, Federal University of Minas Gerais-UFMG, Belo Horizonte, Minas Gerais, Brazil; Institute of Computing, University of Campinas-UNICAMP, Campinas, Sao Paulo, Brazil; Institute of Mathematics and Computer Science, University of Sao Paulo-USP, Sao Carlos, Sao Paulo, Brazil","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2014","2015","21","1","4","17","Automatic data classification is a computationally intensive task that presents variable precision and is considerably sensitive to the classifier configuration and to data representation, particularly for evolving data sets. Some of these issues can best be handled by methods that support users' control over the classification steps. In this paper, we propose a visual data classification methodology that supports users in tasks related to categorization such as training set selection; model creation, application and verification; and classifier tuning. The approach is then well suited for incremental classification, present in many applications with evolving data sets. Data set visualization is accomplished by means of point placement strategies, and we exemplify the method through multidimensional projections and Neighbor Joining trees. The same methodology can be employed by a user who wishes to create his or her own ground truth (or perspective) from a previously unlabeled data set. We validate the methodology through its application to categorization scenarios of image and text data sets, involving the creation, application, verification, and adjustment of classification models.","1941-0506","","10.1109/TVCG.2014.2331979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6840370","Visual image classification;multidimensional point placement;information visualization","Visualization;Data models;Data visualization;Mathematical model;Training;Computational modeling;Layout","data visualisation;learning (artificial intelligence);pattern classification","incremental visual data classification;classifier configuration;data representation;training set selection;model creation;application and verification;classifier tuning;multidimensional projection;neighbor joining trees;ground truth;classification models","","34","","53","IEEE","19 Jun 2014","","","IEEE","IEEE Journals"
"Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets","A. Lex; C. Partl; D. Kalkofen; M. Streit; S. Gratzl; A. M. Wassermann; D. Schmalstieg; H. Pfister",Harvard University; Graz University of Technology; Graz University of Technology; Johannes Kepler University Linz; Johannes Kepler University Linz; Novartis Institutes for BioMedical Research; Graz University of Technology; Harvard University,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2536","2545","Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.","1941-0506","","10.1109/TVCG.2013.154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634190","Drugs;Portals;Context awareness;Biological system modeling;Data visualization;Bioinformatics;biomolecular data;Pathway visualization;biological networks;subsets;graphs","Drugs;Portals;Context awareness;Biological system modeling;Data visualization;Bioinformatics","biology computing;data analysis;data visualisation","biological pathway map visualization;contextual subsets;biological network complexity;pathway cross-talks;Entourage visualization technique;biological network;experimental data visualization;biological pathway relationship","Algorithms;Animals;Biopolymers;Computer Graphics;Computer Simulation;Humans;Models, Biological;Signal Transduction;User-Computer Interface","34","2","33","","16 Oct 2013","","","IEEE","IEEE Journals"
"Extended Pie Menus for Immersive Virtual Environments","S. Gebhardt; S. Pick; F. Leithold; B. Hentschel; T. Kuhlen","Virtual Reality Group, RWTH Aachen University; Virtual Reality Group, RWTH Aachen University; Institute for Information, Organization and Management, Munich School of Management, LMU MÃ¼nchen; Virtual Reality Group, RWTH Aachen University; Virtual Reality Group, RWTH Aachen University","IEEE Transactions on Visualization and Computer Graphics","13 Mar 2013","2013","19","4","644","651","Pie menus are a well-known technique for interacting with 2D environments and so far a large body of research documents their usage and optimizations. Yet, comparatively little research has been done on the usability of pie menus in immersive virtual environments (IVEs). In this paper we reduce this gap by presenting an implementation and evaluation of an extended hierarchical pie menu system for IVEs that can be operated with a six-degrees-of-freedom input device. Following an iterative development process, we first developed and evaluated a basic hierarchical pie menu system. To better understand how pie menus should be operated in IVEs, we tested this system in a pilot user study with 24 participants and focus on item selection. Regarding the results of the study, the system was tweaked and elements like check boxes, sliders, and color map editors were added to provide extended functionality. An expert review with five experts was performed with the extended pie menus being integrated into an existing VR application to identify potential design issues. Overall results indicated high performance and efficient design.","1941-0506","","10.1109/TVCG.2013.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479193","Pie menus;interaction;user interfaces;user study.","Layout;Usability;Error analysis;Context;Performance evaluation;Atmospheric measurements;Particle measurements","graphical user interfaces;human computer interaction;virtual reality","extended pie menu;immersive virtual environment;2D environment interaction;pie menu usability;IVE;extended hierarchical pie menu system;six-degrees-of-freedom input device;iterative development process;item selection;check box;slider;color map editor;VR application;potential design issue","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface","34","","20","","13 Mar 2013","","","IEEE","IEEE Journals"
"Hierarchical data visualization using a fast rectangle-packing algorithm","T. Itoh; Y. Yamaguchi; Y. Ikehata; Y. Kajinaga","Tokyo Res. Lab., IBM Res., Kanagawa, Japan; Tokyo Res. Lab., IBM Res., Kanagawa, Japan; Tokyo Res. Lab., IBM Res., Kanagawa, Japan; Tokyo Res. Lab., IBM Res., Kanagawa, Japan","IEEE Transactions on Visualization and Computer Graphics","15 Mar 2004","2004","10","3","302","313","We present a technique for the representation of large-scale hierarchical data which aims to provide good overviews of complete structures and the content of the data in one display space. The technique represents the data by using nested rectangles. It first packs icons or thumbnails of the lowest-level data and then generates rectangular borders that enclose the packed data. It repeats the process of generating rectangles that enclose the lower-level rectangles until the highest-level rectangles are packed. We present two rectangle-packing algorithms for placing items of hierarchical data onto display spaces. The algorithms refer to Delaunay triangular meshes connecting the centers of rectangles to find gaps where rectangles can be placed. The first algorithm places rectangles where they do not overlap each other and where the extension of the layout area is minimal. The second algorithm places rectangles by referring to templates describing the ideal positions for nodes of input data. It places rectangles where they do not overlap each other and where the combination of the layout area and the distances between the positions described in the template and the actual positions is minimal. It can smoothly represent time-varying data by referring to templates that describe previous layout results. It is also suitable for semantics-based or design-based data layout by generating templates according to the semantics or design.","1941-0506","","10.1109/TVCG.2004.1272729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272729","","Data visualization;Web pages;Large-scale systems;Computer Society;Computer displays;Joining processes;User interfaces;Navigation;Monitoring;Frequency","data visualisation;mesh generation;computational geometry;computational complexity;data structures","hierarchical data visualization;nested rectangles;rectangular border generation;rectangle-packing algorithms;Delaunay triangular meshes;time-varying data;semantics-based data layout;design-based data layout;display spaces","Algorithms;Computer Graphics;Database Management Systems;Databases, Factual;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;User-Computer Interface","34","3","24","IEEE","15 Mar 2004","","","IEEE","IEEE Journals"
"Memory-Scalable GPU Spatial Hierarchy Construction","Q. Hou; X. Sun; K. Zhou; C. Lauterbach; D. Manocha","Tsinghua University and Microsoft Research Asia, Beijing; Zhejiang University, HangZhou and Microsoft Research Asia. Beijing; Zhejiang University, HangZhou; University of North Carolina at Chapel Hill, Chapel Hill; University of North Carolina at Chapel Hill, Chapel Hill","IEEE Transactions on Visualization and Computer Graphics","17 Feb 2011","2011","17","4","466","474","Recent GPU algorithms for constructing spatial hierarchies have achieved promising performance for moderately complex models by using the breadth-first search (BFS) construction order. While being able to exploit the massive parallelism on the GPU, the BFS order also consumes excessive GPU memory, which becomes a serious issue for interactive applications involving very complex models with more than a few million triangles. In this paper, we propose to use the partial breadth-first search (PBFS) construction order to control memory consumption while maximizing performance. We apply the PBFS order to two hierarchy construction algorithms. The first algorithm is for kd-trees that automatically balances between the level of parallelism and intermediate memory usage. With PBFS, peak memory consumption during construction can be efficiently controlled without costly CPU-GPU data transfer. We also develop memory allocation strategies to effectively limit memory fragmentation. The resulting algorithm scales well with GPU memory and constructs kd-trees of models with millions of triangles at interactive rates on GPUs with 1 GB memory. Compared with existing algorithms, our algorithm is an order of magnitude more scalable for a given GPU memory bound. The second algorithm is for out-of-core bounding volume hierarchy (BVH) construction for very large scenes based on the PBFS construction order. At each iteration, all constructed nodes are dumped to the CPU memory, and the GPU memory is freed for the next iteration's use. In this way, the algorithm is able to build trees that are too large to be stored in the GPU memory. Experiments show that our algorithm can construct BVHs for scenes with up to 20 M triangles, several times larger than previous GPU algorithms.","1941-0506","","10.1109/TVCG.2010.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5648735","Memory bound;kd-tree;bounding volume hierarchy.","Graphics processing unit;Memory management;Algorithm design and analysis;Parallel processing;Ray tracing;Layout;Shape","computer graphic equipment;coprocessors;storage management;tree searching","GPU spatial hierarchy construction;graphics processing unit;breadth-first search construction order;memory consumption;kd-trees algorithm;memory allocation strategy;bounding volume hierarchy construction;memory-scalable GPU","","34","","16","","3 Dec 2010","","","IEEE","IEEE Journals"
"Point-Based Manifold Harmonics","Y. Liu; B. Prabhakaran; X. Guo","University of Texas at Dallas, Richardson; University of Texas at Dallas, Richardson; University of Texas at Dallas, Richardson","IEEE Transactions on Visualization and Computer Graphics","9 Aug 2012","2012","18","10","1693","1703","This paper proposes an algorithm to build a set of orthogonal Point-Based Manifold Harmonic Bases (PB-MHB) for spectral analysis over point-sampled manifold surfaces. To ensure that PB-MHB are orthogonal to each other, it is necessary to have symmetrizable discrete Laplace-Beltrami Operator (LBO) over the surfaces. Existing converging discrete LBO for point clouds, as proposed by Belkin et al. [CHECK END OF SENTENCE], is not guaranteed to be symmetrizable. We build a new point-wisely discrete LBO over the point-sampled surface that is guaranteed to be symmetrizable, and prove its convergence. By solving the eigen problem related to the new operator, we define a set of orthogonal bases over the point cloud. Experiments show that the new operator is converging better than other symmetrizable discrete Laplacian operators (such as graph Laplacian) defined on point-sampled surfaces, and can provide orthogonal bases for further spectral geometric analysis and processing tasks.","1941-0506","","10.1109/TVCG.2011.152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6264046","Point-sampled surface;Laplace-Beltrami operator;eigenfunction.","Manifolds;Symmetric matrices;Eigenvalues and eigenfunctions;Harmonic analysis;Convergence;Laplace equations;Approximation methods","","","","34","","39","","9 Aug 2012","","","IEEE","IEEE Journals"
"Spatialization Design: Comparing Points and Landscapes","M. Tory; D. Sprague; F. Wu; W. Y. So; T. Munzner",University of Victoria; University of Victoria; University of Victoria; University of Victoria; University of British Columbia,"IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1262","1269","Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space.","1941-0506","","10.1109/TVCG.2007.70596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376149","Spatialization;Information Landscape;User Study;Numerosity;3D;2D;Colour;Greyscale;Surface;Points","Data visualization;Surface topography;Encoding;Surface fitting;Two dimensional displays;Visual databases;Three dimensional displays;Spatial databases;Fuel economy;Usability","colour graphics;data visualisation","spatialization design;non-spatial data;spatial layout;visual representations;spatialized data;non-trivial search;point estimation task;point-based displays;information landscapes;colour scale;grey scale","","34","","25","","5 Nov 2007","","","IEEE","IEEE Journals"
"The Visual Causality Analyst: An Interactive Interface for Causal Reasoning","J. Wang; K. Mueller","Computer Science Department, Visual Analytics and Imaging Lab, Stony Brook, NY; Computer Science Department, Visual Analytics and Imaging Lab, Stony Brook, NY","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","230","239","Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.","1941-0506","","10.1109/TVCG.2015.2467931","NSF(grant numbers:1117132); MSIP (Ministry of Science, ICT and Future Planning), Korea; ICT Consilience Creative Program; IITP (Institute for Information & communications Technology Promotion); US Department of Energy (DOE) Office of Basic Energy Sciences; Division of Chemical Sciences, Geosciences; DOE's OBER at Pacific Northwest National Laboratory (PNNL); US DOE by Battelle Memorial Institute(grant numbers:DE-AC06-76RLO); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192729","Visual knowledge discovery;Causality;Hypothesis testing;Visual evidence;High-dimensional data;Visual knowledge discovery;Causality;Hypothesis testing;Visual evidence;High-dimensional data","Correlation;Visualization;Layout;Linear regression;Optimization;Inference algorithms","data analysis;data mining;data visualisation;inference mechanisms;statistical testing","categorical variables;numerical variables;interactive 2D graph view;salient statistical parameters;casual discovery algorithms;data analytics;multivariate dataset;causal reasoning framework;visual causality analyst","","34","1","31","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization","B. Bach; N. H. Riche; C. Hurter; K. Marriott; T. Dwyer","Microsoft Research-Inria Joint Centre, France; Microsoft Research, WA, USA; ENAC, Toulouse, France; Monash University, Melbourne, Australia; Monash University, Melbourne, Australia","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","541","550","In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity.","1941-0506","","10.1109/TVCG.2016.2598958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539373","Network visualization;edge compression;confluent;power graph;bundling","Visualization;Clutter;Layout;Australia;Topology;Systematics;Complex networks","data visualisation;graph theory","unambiguous edge bundling;network visualization;confluent drawings;node-link diagrams;network connectivity;edge-bundling techniques;edge clutter;coalescing lines;spatial proximity;undirected networks;layout method;sand box environment;interactive exploration;edge-compression techniques;power graphs;metro-style;network analysis","","34","","45","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"Video Painting with Space-Time-Varying Style Parameters","M. Kagaya; W. Brendel; Q. Deng; T. Kesterson; S. Todorovic; P. J. Neill; E. Zhang","Oregon State University, Corvallis; Oregon State University, Corvallis; Oregon State University, Corvallis; Oregon State University, Corvallis; Oregon State University, Corvallis; NVidia, Santa Clara; Oregon State University, Corvallis","IEEE Transactions on Visualization and Computer Graphics","11 Nov 2010","2011","17","1","74","87","Artists use different means of stylization to control the focus on different objects in the scene. This allows them to portray complex meaning and achieve certain artistic effects. Most prior work on painterly rendering of videos, however, uses only a single painting style, with fixed global parameters, irrespective of objects and their layout in the images. This often leads to inadequate artistic control. Moreover, brush stroke orientation is typically assumed to follow an everywhere continuous directional field. In this paper, we propose a video painting system that accounts for the spatial support of objects in the images or videos, and uses this information to specify style parameters and stroke orientation for painterly rendering. Since objects occupy distinct image locations and move relatively smoothly from one video frame to another, our object-based painterly rendering approach is characterized by style parameters that coherently vary in space and time. Space-time-varying style parameters enable more artistic freedom, such as emphasis/de-emphasis, increase or decrease of contrast, exaggeration or abstraction of different objects in the scene in a temporally coherent fashion.","1941-0506","","10.1109/TVCG.2010.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406517","Nonphotorealistic rendering;video painting;multistyle painting;tensor field design.","Painting;Rendering (computer graphics);Layout;Focusing;Computer Society;Tensile stress;Stress control;Brushes;Constraint optimization","art;rendering (computer graphics);video signal processing","video painting system;space-time-varying style parameters;video painterly rendering;brush stroke orientation;object-based painterly rendering approach;artistic freedom","Algorithms;Computer Graphics;Computer-Aided Design;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Paintings;Pattern Recognition, Automated;Space Perception;User-Computer Interface;Video Recording","34","2","32","","5 Feb 2010","","","IEEE","IEEE Journals"
"Explanatory and illustrative visualization of special and general relativity","D. Weiskopf; M. Borchers; T. Ertl; M. Falk; O. Fechtig; R. Frank; F. Grave; A. King; U. Kraus; T. Muller; H. . -P. Nollert; I. R. Mendez; H. Ruder; T. Schafhitzel; S. Schar; C. Zahn; M. Zatloukal","Graphics, Visualization, & Usability Lab., Simon Fraser Univ., Burnaby, BC, Canada; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","5 Jun 2006","2006","12","4","522","534","This paper describes methods for explanatory and illustrative visualizations used to communicate aspects of Einstein's theories of special and general relativity, their geometric structure, and of the related fields of cosmology and astrophysics. Our illustrations target a general audience of laypersons interested in relativity. We discuss visualization strategies, motivated by physics education and the didactics of mathematics, and describe what kind of visualization methods have proven to be useful for different types of media, such as still images in popular science magazines, film contributions to TV shows, oral presentations, or interactive museum installations. Our primary approach is to adopt an egocentric point of view: the recipients of a visualization participate in a visually enriched thought experiment that allows them to experience or explore a relativistic scenario. In addition, we often combine egocentric visualizations with more abstract illustrations based on an outside view in order to provide several presentations of the same phenomenon. Although our visualization tools often build upon existing methods and implementations, the underlying techniques have been improved by several novel technical contributions like image-based special relativistic rendering on GPUs, special relativistic 4D ray tracing for accelerating scene objects, an extension of general relativistic ray tracing to manifolds described by multiple charts, GPU-based interactive visualization of gravitational light deflection, as well as planetary terrain rendering. The usefulness and effectiveness of our visualizations are demonstrated by reporting on experiences with, and feedback from, recipients of visualizations and collaborators.","1941-0506","","10.1109/TVCG.2006.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634317","Visualization;explanatory computer graphics;illustrative visualization;special relativity;general relativity;astrophysics;visualization of mathematics;terrain rendering.","Visualization;Rendering (computer graphics);Ray tracing;Astrophysics;Physics education;Mathematics;TV;Acceleration;Layout;Feedback","special relativity;general relativity;rendering (computer graphics);astronomy computing;data visualisation;cosmology","cosmology;astrophysics;physics education;mathematic didactics;egocentric visualizations;image-based special relativistic rendering;special relativistic 4D ray tracing;scene objects;general relativistic ray tracing;GPU-based interactive visualization;gravitational light deflection;planetary terrain rendering;Einstein theory","Computer Graphics;Computer Simulation;Computer-Assisted Instruction;Imaging, Three-Dimensional;Models, Theoretical;Physics;Physics;User-Computer Interface","33","","52","IEEE","5 Jun 2006","","","IEEE","IEEE Journals"
"Extracting objects from range and radiance images","Yizhou Yu; A. Ferencz; J. Malik","Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2001","7","4","351","364","In this paper, we present a pipeline and several key techniques necessary for editing a real scene captured with both cameras and laser range scanners. We develop automatic algorithms to segment the geometry from range images into distinct surfaces, register texture from radiance images with the geometry, and synthesize compact high-quality texture maps. The result is an object-level representation of the scene which can be rendered with modifications to structure via traditional rendering methods. The segmentation algorithm for geometry operates directly on the point cloud from multiple registered 3D range images instead of a reconstructed mesh. It is a top-down algorithm which recursively partitions a point set into two subsets using a pairwise similarity measure. The result is a binary tree with individual surfaces as leaves. Our image registration technique performs a very efficient search to automatically find the camera poses for arbitrary position and orientation relative to the geometry. Thus, we can take photographs from any location without precalibration between the scanner and the camera. The algorithms have been applied to large-scale real data. We demonstrate our ability to edit a captured scene by moving, inserting, and deleting objects.","1941-0506","","10.1109/2945.965349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965349","","Layout;Cameras;Image segmentation;Geometrical optics;Rendering (computer graphics);Partitioning algorithms;Geometry;Pipelines;Surface texture;Clouds","rendering (computer graphics);image registration;image segmentation;augmented reality;image texture;feature extraction","object-level representation;image segmentation;image registration;texture-mapping;image-based modeling;image-based rendering;rendering;augmented reality","","33","","53","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Gaze-Aware Streaming Solutions for the Next Generation of Mobile VR Experiences","P. Lungaro; R. Sjöberg; A. J. F. Valero; A. Mittal; K. Tollmar","KTH Royal Institute of Technology, Stockholm, Sweden; Ericsson Research, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden","IEEE Transactions on Visualization and Computer Graphics","13 Mar 2018","2018","24","4","1535","1544","This paper presents a novel approach to content delivery for video streaming services. It exploits information from connected eye-trackers embedded in the next generation of VR Head Mounted Displays (HMDs). The proposed solution aims to deliver high visual quality, in real time, around the users' fixations points while lowering the quality everywhere else. The goal of the proposed approach is to substantially reduce the overall bandwidth requirements for supporting VR video experiences while delivering high levels of user perceived quality. The prerequisites to achieve these results are: (1) mechanisms that can cope with different degrees of latency in the system and (2) solutions that support fast adaptation of video quality in different parts of a frame, without requiring a large increase in bitrate. A novel codec configuration, capable of supporting near-instantaneous video quality adaptation in specific portions of a video frame, is presented. The proposed method exploits in-built properties of HEVC encoders and while it introduces a moderate amount of error, these errors are indetectable by users. Fast adaptation is the key to enable gaze-aware streaming and its reduction in bandwidth. A testbed implementing gaze-aware streaming, together with a prototype HMD with in-built eye tracker, is presented and was used for testing with real users. The studies quantified the bandwidth savings achievable by the proposed approach and characterize the relationships between Quality of Experience (QoE) and network latency. The results showed that up to 83% less bandwidth is required to deliver high QoE levels to the users, as compared to conventional solutions.","1941-0506","","10.1109/TVCG.2018.2794119","Vinnova; Tobii; Ericsson; KTH; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269373","Eye-tracking;VR;QoE;video streaming;content delivery","Streaming media;Bandwidth;Quality of experience;Visualization;Bit rate;Rendering (computer graphics);Servers","helmet mounted displays;quality of experience;video codecs;video coding;video streaming;virtual reality","HEVC encoders;quality of experience;HMD;VR head mounted displays;mobile VR video experiences;eye tracker;codec configuration;gaze-aware streaming solutions;high QoE levels;near-instantaneous video quality adaptation;user perceived quality;video streaming services;content delivery","","33","","38","IEEE","25 Jan 2018","","","IEEE","IEEE Journals"
"Representing Higher-Order Singularities in Vector Fields on Piecewise Linear Surfaces","W. -c. Li; B. Vallet; N. Ray; B. Levy",INRIA-Alice; INRIA-Alice; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1315","1322","Accurately representing higher-order singularities of vector fields defined on piecewise linear surfaces is a non-trivial problem. In this work, we introduce a concise yet complete interpolation scheme of vector fields on arbitrary triangulated surfaces. The scheme enables arbitrary singularities to be represented at vertices. The representation can be considered as a facet-based ""encoding"" of vector fields on piecewise linear surfaces. The vector field is described in polar coordinates over each facet, with a facet edge being chosen as the reference to define the angle. An integer called the period jump is associated to each edge of the triangulation to remove the ambiguity when interpolating the direction of the vector field between two facets that share an edge. To interpolate the vector field, we first linearly interpolate the angle of rotation of the vectors along the edges of the facet graph. Then, we use a variant of Nielson's side-vertex scheme to interpolate the vector field over the entire surface. With our representation, we remove the bound imposed on the complexity of singularities that a vertex can represent by its connectivity. This bound is a limitation generally exists in vertex-based linear schemes. Furthermore, using our data structure, the index of a vertex of a vector field can be combinatorily determined","1941-0506","","10.1109/TVCG.2006.173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015497","vector field visualization;higher-order singularities;line integral convolution;GPU","Vectors;Piecewise linear techniques;Topology;Interpolation;Data structures;Computational fluid dynamics;Data visualization;Integral equations;Convolution;Computational modeling","computational complexity;computational geometry;data visualisation;graph theory;interpolation;vectors","higher-order singularity representation;vector fields;piecewise linear surfaces;interpolation scheme;arbitrary triangulated surface;facet graph;Nielson side-vertex scheme","Bayes Theorem;Clinical Trials, Phase II as Topic;Humans;Randomized Controlled Trials as Topic;Research Design;Stomach Neoplasms","33","","32","","20 Nov 2006","","","IEEE","IEEE Journals"
"SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance","D. Sacha; M. Kraus; J. Bernard; M. Behrisch; T. Schreck; Y. Asano; D. A. Keim","University of Konstanz, Germany; University of Konstanz, Germany; TU Darmstadt, Germany; University of Konstanz, Germany; Graz University of Technology; University of Tübingen; University of Konstanz, Germany","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","120","130","Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself.","1941-0506","","10.1109/TVCG.2017.2744805","German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019867","Visual Analytics;Interaction;Visual Cluster Analysis;Quality Metrics;Guidance;Self-Organizing Maps;Time Series","Data visualization;Visualization;Time series analysis;Clustering algorithms;Self-organizing feature maps;Algorithm design and analysis;Speech","data analysis;data mining;data visualisation;interactive systems;pattern clustering;self-organising feature maps;time series","exploratory cluster analysis;analytic provenance;core building block;hidden structures;raw datasets;particular groups;visual-interactive cluster analysis techniques;useful clusterings;user interactions;data preprocessing;algorithms;iterative cluster refinement;visual platform;previous analytical activities;earlier cluster refinements;useful patterns;data partitions;pair analytics experiments;interactive data analysis;clustering results;interactive process;self-organizing maps;SOMFlow;data analysis;multistage visual analytics approach;VA;SOM;time series data analysis;flow graph;interestingness measures;pattern discovery;subject matter expert;speech intonation research","","33","","58","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Toward Support-Free 3D Printing: A Skeletal Approach for Partitioning Models","X. Wei; S. Qiu; L. Zhu; R. Feng; Y. Tian; J. Xi; Y. Zheng","Department of Intelligent Manufacturing and Information Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Intelligent Manufacturing and Information Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Intelligent Manufacturing and Information Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Intelligent Manufacturing and Information Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Industrial Engineering, Logistics Management of Hong Kong University of Science and Technology, Hong Kong; Department of Intelligent Manufacturing and Information Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2018","2018","24","10","2799","2812","Minimizing support structures is crucial in reducing 3D printing material and time. Partition-based methods are efficient means in realizing this objective. Although some algorithms exist for support-free fabrication of solid models, no algorithm ever considers the problem of support-free fabrication for shell models (i.e., hollowed meshes). In this paper, we present a skeleton-based algorithm for partitioning a 3D surface model into the least number of parts for 3D printing without using any support structure. To achieve support-free fabrication while minimizing the effect of the seams and cracks that are inevitably induced by the partition, which affect the aesthetics and strength of the final assembled surface, we put forward an optimization system with the minimization of the number of partitions and the total length of the cuts, under the constraints of support-free printing angle. Our approach is particularly tailored for shell models, and it can be applicable to solid models as well. We first rigorously show that the optimization problem is NP-hard and then propose a stochastic method to find an optimal solution to the objectives. We propose a polynomial-time algorithm for a special case when the skeleton graph satisfies the requirement that the number of partitioned parts and the degree of each node are bounded by a small constant. We evaluate our partition method on a number of 3D models and validate our method by 3D printing experiments.","1941-0506","","10.1109/TVCG.2017.2767047","Shanghai Sailing Program(grant numbers:16YF1405500); Shanghai Jiao Tong University(grant numbers:AF0200163); State Key Laboratory of Mechanical Systems and Vibration(grant numbers:MSVZD201505); The National Natural Science Foundation of China(grant numbers:51605290,61502306); China Young 1000 Talents Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8086214","3D printing;skeleton;model partition;support-free","Solid modeling;Three-dimensional displays;Fabrication;Three-dimensional printing;Skeleton;Computational modeling","computational complexity;graph theory;optimisation;solid modelling;three-dimensional printing","support-free 3D printing;support structures minimization;skeleton graph;polynomial-time algorithm;support-free printing angle;3D surface model;skeleton-based algorithm;solid models;support-free fabrication;partition-based methods;partitioning models","","33","","58","IEEE","27 Oct 2017","","","IEEE","IEEE Journals"
"Toward the Light Field Display: Autostereoscopic Rendering via a Cluster of Projectors","R. Yang; X. Huang; S. Li; C. Jaynes","Univ. of Kentucky, Lexington; Univ. of Kentucky, Lexington; NA; NA","IEEE Transactions on Visualization and Computer Graphics","19 Nov 2007","2008","14","1","84","96","Ultimately, a display device should be capable of reproducing the visual effects observed in reality. In this paper, we introduce an autostereoscopic display that uses a scalable array of digital light projectors and a projection screen augmented with microlenses to simulate a light field for a given three-dimensional scene. Physical objects emit or reflect light in all directions to create a light field that can be approximated by the light field display. The display can simultaneously provide many viewers from different viewpoints a stereoscopic effect without head tracking or special viewing glasses. This work focuses on two important technical problems related to the light field display: calibration and rendering. We present a solution to automatically calibrate the light field display using a camera and introduce two efficient algorithms to render the special multiview images by exploiting their spatial coherence. The effectiveness of our approach is demonstrated with a four-projector prototype that can display dynamic imagery with full parallax.","1941-0506","","10.1109/TVCG.2007.70410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359490","virtual reality;display algorithms;projector calibration;image-based rendering;virtual reality;display algorithms;projector calibration;image-based rendering","Rendering (computer graphics);Visual effects;Three dimensional displays;Optical arrays;Lenses;Microoptics;Layout;Head;Glass;Calibration","cameras;computer vision;display devices;rendering (computer graphics);solid modelling;stereo image processing","light field display;autostereoscopic rendering;digital light projectors;three-dimensional scene;microlens screen;camera;multiview images;computer vision algorithms","Algorithms;Cluster Analysis;Computer Graphics;Data Display;Holography;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Lighting;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity","33","1","40","","19 Nov 2007","","","IEEE","IEEE Journals"
"Visual Signatures in Video Visualization","M. Chen; R. Botchen; R. Hashim; D. Weiskopf; T. Ertl; I. Thornton","Dept. of Comput. Sci., Swansea Univ.; NA; Dept. of Comput. Sci., Swansea Univ.; IEEE Computer Society; IEEE Computer Society; NA","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1093","1100","Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events.","1941-0506","","10.1109/TVCG.2006.194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015469","Video visualization;volume visualization;flow visualization;human factors;user study;visual signatures;video processing;optical flow;GPU rendering.","Data visualization;Data mining;Image motion analysis;Pipelines;Human factors;Biomedical optical imaging;Biomedical imaging;Bones;Layout;Computer displays","feature extraction;flow visualisation;human factors;motion estimation;video retrieval;video signal processing","visual signature representation;video visualization;flow visualization technique;video clips","Algorithms;Computer Graphics;Female;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Male;Movement;Pattern Recognition, Visual;Task Performance and Analysis;User-Computer Interface;Video Recording","33","","26","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"Interactive sound rendering in complex and dynamic scenes using frustum tracing","C. Lauterbach; A. Chandak; D. Manocha","Department of Computer Science, Campus Box 3175, Sitterson Hall, University of North Carolina-Chapel Hill, Chapel Hill, NC 27599; Department of Computer Science, Campus Box 3175, Sitterson Hall, University of North Carolina-Chapel Hill, Chapel Hill, NC 27599; Department of Computer Science, Campus Box 3175, Sitterson Hall, University of North Carolina-Chapel Hill, Chapel Hill, NC 27599","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1672","1679","We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.","1941-0506","","10.1109/TVCG.2007.70567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376201","Acoustic propagation;Ray tracing","Layout;Rendering (computer graphics);Ray tracing;Computational modeling;Hardware;Acceleration;Data visualization;Optical reflection;Acoustic reflection;Acoustic beams","acoustic signal processing;interactive systems;ray tracing;rendering (computer graphics)","interactive system;ray packet tracing;virtual scene;complex-dynamic scene;frustum tracing;interactive sound rendering","","32","12","48","","5 Nov 2007","","","IEEE","IEEE Journals"
"Multivariate Data Analysis Using Persistence-Based Filtering and Topological Signatures","B. Rieck; H. Mara; H. Leitte",Interdisciplinary Center for Scientific Computing; Interdisciplinary Center for Scientific Computing; Interdisciplinary Center for Scientific Computing,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2382","2391","The extraction of significant structures in arbitrary high-dimensional data sets is a challenging task. Moreover, classifying data points as noise in order to reduce a data set bears special relevance for many application domains. Standard methods such as clustering serve to reduce problem complexity by providing the user with classes of similar entities. However, they usually do not highlight relations between different entities and require a stopping criterion, e.g. the number of clusters to be detected. In this paper, we present a visualization pipeline based on recent advancements in algebraic topology. More precisely, we employ methods from persistent homology that enable topological data analysis on high-dimensional data sets. Our pipeline inherently copes with noisy data and data sets of arbitrary dimensions. It extracts central structures of a data set in a hierarchical manner by using a persistence-based filtering algorithm that is theoretically well-founded. We furthermore introduce persistence rings, a novel visualization technique for a class of topological features-the persistence intervals-of large data sets. Persistence rings provide a unique topological signature of a data set, which helps in recognizing similarities. In addition, we provide interactive visualization techniques that assist the user in evaluating the parameter space of our method in order to extract relevant structures. We describe and evaluate our analysis pipeline by means of two very distinct classes of data sets: First, a class of synthetic data sets containing topological objects is employed to highlight the interaction capabilities of our method. Second, in order to affirm the utility of our technique, we analyse a class of high-dimensional real-world data sets arising from current research in cultural heritage.","1941-0506","","10.1109/TVCG.2012.248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327243","Topological persistence;multivariate data;clustering","Network topology;Clustering methods;Multivariate data sets","data analysis;data structures;data visualisation;history;information filtering;pattern classification;topology","multivariate data analysis;topological signatures;significant structures extraction;arbitrary high-dimensional data sets;data points classification;problem complexity;stopping criterion;visualization pipeline;algebraic topology;persistent homology;topological data analysis;noisy data;central structures;hierarchical manner;persistence-based filtering algorithm;persistence rings;topological features;large data sets;interactive visualization techniques;parameter space evaluation;relevant structures;analysis pipeline;synthetic data sets;topological objects;interaction capability;high-dimensional real-world data sets;cultural heritage","","32","","40","","8 Oct 2012","","","IEEE","IEEE Journals"
"PizzaText: Text Entry for Virtual Reality Systems Using Dual Thumbsticks","D. Yu; K. Fan; H. Zhang; D. Monteiro; W. Xu; H. -N. Liang","Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, China; Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, China; Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, China; Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, China; Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, China; Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, China","IEEE Transactions on Visualization and Computer Graphics","29 Oct 2018","2018","24","11","2927","2935","We present PizzaText, a circular keyboard layout technique for text entry in virtual reality (VR) environments that uses the dual thumbsticks of a hand-held game controller. Text entry is a common activity in VR environments but remains challenging with existing techniques and keyboard layouts that is largely based on QWERTY. Our technique makes text entry simple, easy, and efficient, even for novice users. The technique uses a hand-held controller because it is still an important input device for users to interact with VR environments. To allow rapid search of characters, PizzaText divides a circle into slices and each slice contains 4 characters. To enable fast selection, the user uses the right thumbstick for traversing the slices, and the left thumbstick for choosing the letters. The design of PizzaText is based on three criteria: efficiency, learnability, and ease-of-use. In our first study, six potential layouts are considered and evaluated. The results lead to a design with 7 slices and 4 letters per slice. The final design is evaluated in a five-day study with 10 participants. The results show that novice users can achieve an average of 8.59 Words per Minute (WPM), while expert users are able to reach 15.85 WPM, with just two hours of training.","1941-0506","","10.1109/TVCG.2018.2868581","XJTLU Key Program Special Fund; XJTLU Research Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456570","Virtual reality;text entry;game controller;dual-joystick input;selection keyboard;circular keyboard layout","Layout;Keyboards;Games;Training;Virtual reality;Google;Fans","computer games;keyboards;virtual reality","virtual reality systems;dual thumbsticks;circular keyboard layout technique;virtual reality environments;hand-held game controller;VR environments;keyboard layouts;hand-held controller;text entry;PizzaText;QWERTY","","32","","58","IEEE","6 Sep 2018","","","IEEE","IEEE Journals"
"The prioritized-layered projection algorithm for visible set estimation","J. T. Klosowski; C. T. Silva","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2000","6","2","108","123","Prioritized-Layered Projection (PLP) is a technique for fast rendering of high depth complexity scenes. It works by estimating the visible polygons of a scene from a given viewpoint incrementally, one primitive at a time. It is not a conservative technique, instead PLP is suitable for the computation of partially correct images for use as part of time-critical rendering systems. From a very high level, PLP amounts to a modification of a simple view-frustum culling algorithm, however, it requires the computation of a special occupancy-based tessellation and the assignment to each cell of the tessellation a solidity value, which is used to compute a special ordering on how primitives get projected. The authors detail the PLP algorithm, its main components, and implementation. They also provide experimental evidence of its performance, including results on two types of spatial tessellation (using octree- and Delaunay-based tessellations), and several datasets. They also discuss several extensions of their technique.","1941-0506","","10.1109/2945.856993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=856993","","Projection algorithms;Rendering (computer graphics);Layout;Time factors;Hardware;Graphics;Scheduling;Computational geometry;Prototypes","rendering (computer graphics);computational geometry;computational complexity;octrees;mesh generation","prioritized-layered projection algorithm;visible set estimation;fast rendering;high depth complexity scenes;visible polygon estimation;partially correct images;time-critical rendering systems;view-frustum culling algorithm;special occupancy based tessellation;solidity value;special ordering;PLP algorithm;spatial tessellation;Delaunay based tessellations;datasets;octree","","32","7","29","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"TopicPanorama: A Full Picture of Relevant Topics","X. Wang; S. Liu; J. Liu; J. Chen; J. Zhu; B. Guo","Tsinghua University, Beijing; Tsinghua University, Beijing; Tsinghua University, Beijing; Tsinghua University, Beijing; Tsinghua University, Beijing; Microsoft Research, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2016","2016","22","12","2508","2521","This paper presents a visual analytics approach to analyzing a full picture of relevant topics discussed in multiple sources, such as news, blogs, or micro-blogs. The full picture consists of a number of common topics covered by multiple sources, as well as distinctive topics from each source. Our approach models each textual corpus as a topic graph. These graphs are then matched using a consistent graph matching method. Next, we develop a level-of-detail (LOD) visualization that balances both readability and stability. Accordingly, the resulting visualization enhances the ability of users to understand and analyze the matched graph from multiple perspectives. By incorporating metric learning and feature selection into the graph matching algorithm, we allow users to interactively modify the graph matching result based on their information needs. We have applied our approach to various types of data, including news articles, tweets, and blog data. Quantitative evaluation and real-world case studies demonstrate the promise of our approach, especially in support of examining a topic-graph-based full picture at different levels of detail.","1941-0506","","10.1109/TVCG.2016.2515592","National Key Technologies R&D Program of China(grant numbers:2015BAF23B03); National Natural Science Foundation of China(grant numbers:61373070,61272225,61572274); Microsoft Research Fund(grant numbers:FY15-RES-OPP-112); National Basic Research Program of China(grant numbers:2013CB329403); National Natural Science Foundation of China(grant numbers:61322308,61332007); Microsoft Research Fund(grant numbers:FY14-RES-SPONSOR-111); National University Student Innovation Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7374750","Topic graph;graph matching;graph visualization;user interactions;level-of-detail","Visual analytics;Graph matching;Algorithm design and analysis;Data models;Games;Smart phones","data analysis;data visualisation;feature selection;graph theory;learning (artificial intelligence);text analysis;Web sites","TopicPanorama;visual analytics approach;microblogs;textual corpus;consistent graph matching method;level-of-detail visualization;LOD;metric learning;feature selection;news articles;tweets;topic-graph-based full picture","","32","","53","IEEE","7 Jan 2016","","","IEEE","IEEE Journals"
"Visualizing Fuzzy Overlapping Communities in Networks","C. Vehlow; T. Reinhardt; D. Weiskopf","VISUS, University of Stuttgart; University of Stuttgart; VISUS, University of Stuttgart","IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2486","2495","An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.","1941-0506","","10.1109/TVCG.2013.232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634179","Communities;Layout;Fuzzy methods;Uncertainty;Image color analysis;Data visualization;uncertainty visualization;Overlapping community visualization;fuzzy clustering;graph visualization","Communities;Layout;Fuzzy methods;Uncertainty;Image color analysis;Data visualization","data visualisation;fuzzy set theory;graph theory","visualizing fuzzy overlapping community;community structure;object attributes;network topology;real-world systems;fuzzy community memberships;visualization approach;node-link diagrams;weighted undirected graphs;membership distribution;layout strategy;visual mappings;social networking;biological interactions;node color;node position","Algorithms;Artificial Intelligence;Computer Simulation;Fuzzy Logic;Image Enhancement;Models, Statistical;User-Computer Interface","32","","53","","16 Oct 2013","","","IEEE","IEEE Journals"
"A Minimal Contouring Approach to the Computation of the Reeb Graph","G. Patane; M. Spagnuolo; B. Falcidieno","Istituto di Matematica Applicata e Tecnologie Inormatiche, Consiglio Nazionale delle Ricerche, Genova; Istituto di Matematica Applicata e Tecnologie Inormatiche, Consiglio Nazionale delle Ricerche, Genova; Istituto di Matematica Applicata e Tecnologie Inormatiche, Consiglio Nazionale delle Ricerche, Genova","IEEE Transactions on Visualization and Computer Graphics","12 May 2009","2009","15","4","583","595","Given a manifold surface M and a continuous scalar function f:Mrarr IR, the Reeb graph of (M, f) is a widely used high-level descriptor of M and its usefulness has been demonstrated for a variety of applications, which range from shape parameterization and abstraction to deformation and comparison. In this context, we propose a novel contouring algorithm for the construction of a discrete Reeb graph with a minimal number of nodes, which correspond to the critical points of f (i.e., minima, maxima, and saddle points) and its level sets passing through the saddle points. In this way, we do not need to sample, sweep, or increasingly sort the f-values. Since most of the computation uses only local information on the mesh connectivity, equipped with the f-values at the surface vertices, the proposed approach is insensitive to noise and requires a small-memory footprint and temporary data structures. Furthermore, we maintain the parametric nature of the Reeb graph with respect to the input scalar function and we efficiently extract the Reeb graph of time-varying maps. Indicating with n and s the number of vertices of M and saddle points of f, the overall computational cost O(sn) is competitive with respect to the O(n log n) cost of previous work. This cost becomes optimal if M is highly sampled or s les log n, as it happens for Laplacian eigenfunctions, harmonic maps, and one-forms.","1941-0506","","10.1109/TVCG.2009.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4770097","Reeb graph;topological graph;Morse theory;computational topology;geometric algorithms;hierarchical segmentations;shape analysis and abstraction.","Shape;Level set;Topology;Data structures;Data mining;Computational efficiency;Cost function;Laplace equations;Eigenvalues and eigenfunctions;Algorithm design and analysis","computational complexity;data structures;graph theory","minimal contouring algorithm;discrete Reeb graph;continuous scalar function;high-level descriptor;saddle point;critical point;small-memory footprint;temporary data structure;time-varying map;Laplacian eigenfunction;harmonic map;mesh connectivity;surface vertex","","31","","54","","2 Feb 2009","","","IEEE","IEEE Journals"
"Edge Compression Techniques for Visualization of Dense Directed Graphs","T. Dwyer; N. Henry Riche; K. Marriott; C. Mears",Monash University; Microsoft Research; Monash University; Monash University,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2596","2605","We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.","1941-0506","","10.1109/TVCG.2013.151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634098","Edge detection;Computer graphics;Modular construction;power graph analysis;Directed graphs;networks;modular decomposition","Edge detection;Computer graphics;Modular construction","constraint handling;data compression;directed graphs","edge compression techniques;dense directed graph visualisation;aggregate connectivity;lossless compression;modular decomposition;power graph analysis;constraint programming;software dependency analysis","Algorithms;Computer Graphics;Data Compression;Image Enhancement;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Sensitivity and Specificity;User-Computer Interface","31","","25","IEEE","16 Oct 2013","","","IEEE","IEEE Journals"
"Embedding Spatio-Temporal Information into Maps by Route-Zooming","G. Sun; R. Liang; H. Qu; Y. Wu","Zhejiang University of Technology, Hangzhou, Zhejiang, China; Zhejiang University of Technology, Hangzhou, Zhejiang, China; Hong Kong University of Science and Technology, Hong Kong; State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","3 Apr 2017","2017","23","5","1506","1519","Analysis and exploration of spatio-temporal data such as traffic flow and vehicle trajectories have become important in urban planning and management. In this paper, we present a novel visualization technique called route-zooming that can embed spatio-temporal information into a map seamlessly for occlusion-free visualization of both spatial and temporal data. The proposed technique can broaden a selected route in a map by deforming the overall road network. We formulate the problem of route-zooming as a nonlinear least squares optimization problem by defining an energy function that ensures the route is broadened successfully on demand while the distortion caused to the road network is minimized. The spatio-temporal information can then be embedded into the route to reveal both spatial and temporal patterns without occluding the spatial context information. The route-zooming technique is applied in two instantiations including an interactive metro map for city tourism and illustrative maps to highlight information on the broadened roads to prove its applicability. We demonstrate the usability of our spatio-temporal visualization approach with case studies on real traffic flow data. We also study various design choices in our method, including the encoding of the time direction and choices of temporal display, and conduct a comprehensive user study to validate our embedded visualization design.","1941-0506","","10.1109/TVCG.2016.2535234","National 973 Program of China(grant numbers:2015CB352503); NSFC(grant numbers:61502416); Zhejiang Provincial NSFC(grant numbers:LR14F020002); Ministry of Science and Technology of China; HK; RGC; GRF(grant numbers:618313); Microsoft Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420745","Spatio-temporal visualization;occlusion-free visualization;least-square optimization","Roads;Data visualization;Context;Trajectory;Optimization;Spatial databases;Nonlinear distortion","data analysis;data visualisation;geographic information systems;interactive systems;minimisation;nonlinear programming;road traffic;spatiotemporal phenomena;traffic engineering computing","spatiotemporal information;spatiotemporal data analysis;spatiotemporal data exploration;vehicle trajectories;urban planning;urban management;occlusion-free visualization;road network deformation;nonlinear least squares optimization;energy function;distortion minimization;temporal patterns;spatial patterns;route-zooming technique;interactive metro map;city tourism;illustrative maps;traffic flow data;temporal display;embedded visualization design","","31","","30","IEEE","26 Feb 2016","","","IEEE","IEEE Journals"
"Garuda: A Scalable Tiled Display Wall Using Commodity PCs","N. Nirnimesh; P. Harish; P. J. Narayanan","Center for Visual Information Technology, International Institute of Information Technology, Gachibowli, Hyderabad, (A.P.), India-500032; Center for Visual Information Technology, International Institute of Information Technology, Gachibowli, Hyderabad, (A.P.), India-500032; Center for Visual Information Technology, International Institute of Information Technology, Gachibowli, Hyderabad, (A.P.), India-500032","IEEE Transactions on Visualization and Computer Graphics","23 Jul 2007","2007","13","5","864","877","Cluster-based tiled display walls can provide cost-effective and scalable displays with high resolution and a large display area. The software to drive them needs to scale too if arbitrarily large displays are to be built. Chromium is a popular software API used to construct such displays. Chromium transparently renders any OpenGL application to a tiled display by partitioning and sending individual OpenGL primitives to each client per frame. Visualization applications often deal with massive geometric data with millions of primitives. Transmitting them every frame results in huge network requirements that adversely affect the scalability of the system. In this paper, we present Garuda, a client-server-based display wall framework that uses off-the-shelf hardware and a standard network. Garuda is scalable to large tile configurations and massive environments. It can transparently render any application built using the Open Scene Graph (OSG) API to a tiled display without any modification by the user. The Garuda server uses an object-based scene structure represented using a scene graph. The server determines the objects visible to each display tile using a novel adaptive algorithm that culls the scene graph to a hierarchy of frustums. Required parts of the scene graph are transmitted to the clients, which cache them to exploit the interframe redundancy. A multicast-based protocol is used to transmit the geometry to exploit the spatial redundancy present in tiled display systems. A geometry push philosophy from the server helps keep the clients in sync with one another. Neither the server nor a client needs to render the entire scene, making the system suitable for interactive rendering of massive models. Transparent rendering is achieved by intercepting the cull, draw, and swap functions of OSG and replacing them with our own. We demonstrate the performance and scalability of the Garuda system for different configurations of display wall. We also show that the serve","1941-0506","","10.1109/TVCG.2007.1049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4276073","Parallel visualization and graphics clusters;visualization over networks;large-scale displays","Displays;Personal communication networks;Layout;Application software;Scalability;Network servers;Geometry","client-server systems;computer displays;data visualisation;open systems","scalable tiled display wall;commodity PC;Chromium;OpenGL;geometric data;client-server-based display wall;off-the-shelf hardware;open scene graph;Garuda server;object-based scene structure;graphics clusters;parallel visualization","Algorithms;Computer Communication Networks;Computer Graphics;Data Display;Equipment Design;Equipment Failure Analysis;Image Enhancement;Image Enhancement;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Microcomputers;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface","31","","45","IEEE","23 Jul 2007","","","IEEE","IEEE Journals"
"Interactive Entity Resolution in Relational Data: A Visual Analytic Tool and Its Evaluation","H. Kang; L. Getoor; B. Shneiderman; M. Bilgic; L. Licamele","University of Maryland , College Park; University of Maryland at College Park, College Park; University of Maryland at College Park, College Park; University of Maryland at College Park, College Park; University of Maryland at College Park, College Park","IEEE Transactions on Visualization and Computer Graphics","15 Jul 2008","2008","14","5","999","1014","Databases often contain uncertain and imprecise references to real-world entities. Entity resolution, the process of reconciling multiple references to underlying real-world entities, is an important data cleaning process required before accurate visualization or analysis of the data is possible. In many cases, in addition to noisy data describing entities, there is data describing the relationships among the entities. This relational data is important during the entity resolution process; it is useful both for the algorithms which determine likely database references to be resolved and for visual analytic tools which support the entity resolution process. In this paper, we introduce a novel user interface, D-Dupe, for interactive entity resolution in relational data. D-Dupe effectively combines relational entity resolution algorithms with a novel network visualization that enables users to make use of an entity's relational context for making resolution decisions. Since resolution decisions often are interdependent, D-Dupe facilitates understanding this complex process through animations which highlight combined inferences and a history mechanism which allows users to inspect chains of resolution decisions. An empirical study with 12 users confirmed the benefits of the relational context visualization on the performance of entity resolution tasks in relational data in terms of time as well as users' confidence and satisfaction.","1941-0506","","10.1109/TVCG.2008.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479458","User interfaces;Human-centered computing;Graphical user interfaces;User-centered design;Information visualization;User interfaces;Human-centered computing;Graphical user interfaces;User-centered design;Information visualization","Visual analytics;Data visualization;Relational databases;Visual databases;Cleaning;Data analysis;User interfaces;Inference algorithms;Animation;History","data visualisation;graphical user interfaces;relational databases","interactive entity resolution;visual analytic tool;graphical user interface;D-Dupe;relational entity resolution algorithm;relational context visualization","Algorithms;Computer Graphics;Database Management Systems;Databases, Factual;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;User-Computer Interface","31","5","41","","10 Jun 2008","","","IEEE","IEEE Journals"
"Morphable Word Clouds for Time-Varying Text Data Visualization","M. Chi; S. Lin; S. Chen; C. Lin; T. Lee","National Chengchi University, Taipei, Taiwan, R.O.C; National Cheng Kung University, Tainan, Taiwan, R.O.C; National Cheng Kung University, Tainan, Taiwan, R.O.C; National Cheng Kung University, Tainan, Taiwan, R.O.C; National Cheng Kung University, Tainan, Taiwan, R.O.C","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2015","2015","21","12","1415","1426","A word cloud is a visual representation of a collection of text documents that uses various font sizes, colors, and spaces to arrange and depict significant words. The majority of previous studies on time-varying word clouds focuses on layout optimization and temporal trend visualization. However, they do not fully consider the spatial shapes and temporal motions of word clouds, which are important factors for attracting people's attention and are also important cues for human visual systems in capturing information from time-varying text data. This paper presents a novel method that uses rigid body dynamics to arrange multi-temporal word-tags in a specific shape sequence under various constraints. Each word-tag is regarded as a rigid body in dynamics. With the aid of geometric, aesthetic, and temporal coherence constraints, the proposed method can generate a temporally morphable word cloud that not only arranges word-tags in their corresponding shapes but also smoothly transforms the shapes of word clouds overtime, thus yielding a pleasing time-varying visualization. Using the proposed frame-by-frame and morphable word clouds, people can observe the overall story of a time-varying text data from the shape transition, and people can also observe the details from the word clouds in frames. Experimental results on various data demonstrate the feasibility and flexibility of the proposed method in morphable word cloud generation. In addition, an application that uses the proposed word clouds in a simulated exhibition demonstrates the usefulness of the proposed method.","1941-0506","","10.1109/TVCG.2015.2440241","Headquarters of University Advancement; National Cheng Kung University; Ministry of Science and Technology(grant numbers:MOST-102-2420-H-004-045-MY3,MOST-103-2221-E-004-008,MOST-104-2221-E-006-044-MY3,MOST-103-2221-E-006-106-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118241","word cloud;time-varying text data;digital storytelling;information visualization;Word cloud;time-varying text data;digital storytelling;information visualization","Tag clouds;Virtual reality;Data visualization;Text mining;Interpolation;Market research;Data analysis;Digital systems;Time-varying systems","data visualisation;text analysis;time-varying systems","time-varying text data visualization;text documents visual representation;rigid body dynamics;multitemporal word-tag arrangement;shape sequence;temporally morphable word cloud;frame-by-frame word clouds","Computer Graphics;Data Mining;Humans;Internet;Semantics;Word Processing","31","","27","IEEE","4 Jun 2015","","","IEEE","IEEE Journals"
"Perception-Based Evaluation of Projection Methods for Multidimensional Data Visualization","R. Etemadpour; R. Motta; J. G. d. S. Paiva; R. Minghim; M. C. F. de Oliveira; L. Linsen","School of Engineering and Science, Jacobs University, Bremen, Germany; Institute of Mathematical Sciences of São Carlos, University of São Paulo, São Carlos, Brazil; Department of Computer Science, Federal University of Uberlândia, Brazil; Institute of Mathematical Sciences of São Carlos, University of São Paulo, São Carlos, Brazil; Institute of Mathematical Sciences of São Carlos, University of São Paulo, São Carlos, Brazil; School of Engineering and Science, Jacobs University, Bremen, Germany","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2014","2015","21","1","81","94","Similarity-based layouts generated by multidimensional projections or other dimension reduction techniques are commonly used to visualize high-dimensional data. Many projection techniques have been recently proposed addressing different objectives and application domains. Nonetheless, very little is known about the effectiveness of the generated layouts from a user's perspective, how distinct layouts from the same data compare regarding the typical visualization tasks they support, or how domain-specific issues affect the outcome of the techniques. Learning more about projection usage is an important step towards both consolidating their role in high-dimensional data analysis and taking informed decisions when choosing techniques. This work provides a contribution towards this goal. We describe the results of an investigation on the performance of layouts generated by projection techniques as perceived by their users. We conducted a controlled user study to test against the following hypotheses: (1) projection performance is task-dependent; (2) certain projections perform better on certain types of tasks; (3) projection performance depends on the nature of the data; and (4) subjects prefer projections with good segregation capability. We generated layouts of high-dimensional data with five techniques representative of different projection approaches. As application domains we investigated image and document data. We identified eight typical tasks, three of them related to segregation capability of the projection, three related to projection precision, and two related to incurred visual cluttering. Answers to questions were compared for correctness against `ground truth' computed directly from the data. We also looked at subject confidence and task completion times. Statistical analysis of the collected data resulted in Hypotheses 1 and 3 being confirmed, Hypothesis 2 being confirmed partially and Hypotheses 4 could not be confirmed. We discuss our findings in comparison with some numerical measures of projection layout quality. Our results offer interesting insight on the use of projection layouts in data visualization tasks and provide a departing point for further systematic investigations.","1941-0506","","10.1109/TVCG.2014.2330617","VisComX center of the Jacobs University; Brazilian financial agencies CNPq and FAPESP; CAPES/DAAD(grant numbers:34/10); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832613","Projections;dimension reduction;multidimensional data;perception-based evaluation","Layout;Data visualization;Image color analysis;Visualization;Principal component analysis;Extraterrestrial measurements","data analysis;data visualisation;pattern clustering;statistical analysis","perception-based evaluation;projection methods;multidimensional data visualization;similarity-based layout;dimension reduction techniques;user perspective;visualization tasks;projection usage;high-dimensional data analysis;projection performance;image data;document data;projection precision;incurred visual cluttering;ground truth;subject confidence;task completion times;statistical analysis","","31","","45","IEEE","12 Jun 2014","","","IEEE","IEEE Journals"
"Stereoscopic Video Synthesis from a Monocular Video","G. Zhang; W. Hua; X. Qin; T. Wong; H. Bao","Zhejiang Univ., Hangzhou; Zhejiang Univ., Hangzhou; Zhejiang Univ., Hangzhou; NA; Zhejiang Univ., Hangzhou","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","686","696","This paper presents an automatic and robust approach to synthesize stereoscopic videos from ordinary monocular videos acquired by commodity video cameras. Instead of recovering the depth map, the proposed method synthesizes the binocular parallax in stereoscopic video directly from the motion parallax in monocular video, The synthesis is formulated as an optimization problem via introducing a cost function of the stereoscopic effects, the similarity, and the smoothness constraints. The optimization selects the most suitable frames in the input video for generating the stereoscopic video frames. With the optimized selection, convincing and smooth stereoscopic video can be synthesized even by simple constant-depth warping. No user interaction is required. We demonstrate the visually plausible results obtained given the input clips acquired by ordinary handheld video camera.","1941-0506","","10.1109/TVCG.2007.1032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293013","Stereoscopic video synthesis;parallax;optimization.","Cameras;Layout;Robustness;Stereo vision;Constraint optimization;Cost function;Iterative algorithms;Visualization;Three dimensional TV;Hardware","image motion analysis;optimisation;stereo image processing;video signal processing","stereoscopic video synthesis;monocular video;depth map;binocular parallax;motion parallax;optimization problem;stereoscopic video frames","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Numerical Analysis, Computer-Assisted;Photogrammetry;Video Recording","31","15","32","","20 Aug 2007","","","IEEE","IEEE Journals"
"StreamExplorer: A Multi-Stage System for Visually Exploring Events in Social Streams","Y. Wu; Z. Chen; G. Sun; X. Xie; N. Cao; S. Liu; W. Cui","State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; Hong Kong University of Science and Technology, Hong Kong; Zhejiang University of Technology, Hangzhou, Zhejiang, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; College of Design and Innovation, Tongji University, Shanghai, China; School of Software, Tsinghua University, Beijing, China; Microsoft Research, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2018","2018","24","10","2758","2772","Analyzing social streams is important for many applications, such as crisis management. However, the considerable diversity, increasing volume, and high dynamics of social streams of large events continue to be significant challenges that must be overcome to ensure effective exploration. We propose a novel framework by which to handle complex social streams on a budget PC. This framework features two components: 1) an online method to detect important time periods (i.e., subevents), and 2) a tailored GPU-assisted Self-Organizing Map (SOM) method, which clusters the tweets of subevents stably and efficiently. Based on the framework, we present StreamExplorer to facilitate the visual analysis, tracking, and comparison of a social stream at three levels. At a macroscopic level, StreamExplorer uses a new glyph-based timeline visualization, which presents a quick multi-faceted overview of the ebb and flow of a social stream. At a mesoscopic level, a map visualization is employed to visually summarize the social stream from either a topical or geographical aspect. At a microscopic level, users can employ interactive lenses to visually examine and explore the social stream from different perspectives. Two case studies and a task-based evaluation are used to demonstrate the effectiveness and usefulness of StreamExplorer.","1941-0506","","10.1109/TVCG.2017.2764459","National 973 Program of China(grant numbers:2015CB352503); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:U1609217); NSFC(grant numbers:61502416,61602409,61672308,61602306); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); Fundamental Research Funds for Central Universities(grant numbers:2016QNA5014); 100 Talents Program of Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074775","Social media visualization;visual analytics;social stream;streaming data;self-organizing map","Data visualization;Visualization;Lenses;Monitoring;Electronic mail;Social network services","data visualisation;graphics processing units;self-organising feature maps;social networking (online)","StreamExplorer;complex social streams;multistage system;visually exploring events;crisis management;budget PC;tailored GPU-assisted self-organizing map method;SOM;tweets;macroscopic level;glyph-based timeline visualization;multi-faceted overview;mesoscopic level;map visualization;microscopic level;interactive lenses;task-based evaluation","Computer Graphics;Disease Outbreaks;Hemorrhagic Fever, Ebola;Humans;Image Processing, Computer-Assisted;Models, Theoretical;Social Media;Sports;User-Computer Interface","31","","50","IEEE","19 Oct 2017","","","IEEE","IEEE Journals"
"What Would a Graph Look Like in this Layout? A Machine Learning Approach to Large Graph Visualization","O. -H. Kwon; T. Crnovrsanin; K. -L. Ma","University of California, Davis; University of California, Davis; University of California, Davis","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","478","488","Using different methods for laying out a graph can lead to very different visual appearances, with which the viewer perceives different information. Selecting a “good” layout method is thus important for visualizing a graph. The selection can be highly subjective and dependent on the given task. A common approach to selecting a good layout is to use aesthetic criteria and visual inspection. However, fully calculating various layouts and their associated aesthetic metrics is computationally expensive. In this paper, we present a machine learning approach to large graph visualization based on computing the topological similarity of graphs using graph kernels. For a given graph, our approach can show what the graph would look like in different layouts and estimate their corresponding aesthetic metrics. An important contribution of our work is the development of a new framework to design graph kernels. Our experimental study shows that our estimation calculation is considerably faster than computing the actual layouts and their aesthetic metrics. Also, our graph kernels outperform the state-of-the-art ones in both time and accuracy. In addition, we conducted a user study to demonstrate that the topological similarity computed with our graph kernel matches perceptual similarity assessed by human users.","1941-0506","","10.1109/TVCG.2017.2743858","National Science Foundation(grant numbers:IIS-1320229,IIS-1528203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017580","Graph visualization;graph layout;aesthetics;machine learning;graph kernel;graphlet","Kernel;Layout;Measurement;Visualization;Inspection;Data visualization;Support vector machines","data visualisation;graph theory;learning (artificial intelligence)","graph kernel;graph look;graph visualization;viewer perceives different information;visual inspection;visual appearances;aesthetic metrics;topological similarity;estimation calculation;perceptual similarity;machine learning","Adolescent;Adult;Algorithms;Computer Graphics;Esthetics;Female;Humans;Machine Learning;Male;Task Performance and Analysis;Young Adult","31","","92","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Algorithms for Labeling Focus Regions","M. Fink; J. -H. Haunert; A. Schulz; J. Spoerhase; A. Wolff",Universität Würzburg; Universität Würzburg; Universität Münster; Universität Würzburg; Universität Würzburg,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2583","2592","In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand.","1941-0506","","10.1109/TVCG.2012.193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327264","Focus+context techniques;data clustering;mobile and ubiquitous visualization;geographic/geospatial visualization","Clustering methods;Gravity;Ubiquitous computing;Labels;Visual analytics;Data visualization;Geospatial analysis","computer graphics;curve fitting;diagrams;pattern clustering","focus region labeling;point site labeling;diagram;mapping service;leader layout;total leader length;boundary labeling problem;polylines;straight-line segment;Bezier curve;facility-location perspective;site clustering","","30","","28","","8 Oct 2012","","","IEEE","IEEE Journals"
"Cubist style rendering from photographs","J. P. Collomosse; P. M. Hall","Dept. of Comput. Sci., Univ. of Bath, UK; Dept. of Comput. Sci., Univ. of Bath, UK","IEEE Transactions on Visualization and Computer Graphics","21 Jan 2004","2003","9","4","443","453","The contribution of the paper is a novel nonphotorealistic rendering (NPR) technique, influenced by the style of Cubist art. Specifically, we are motivated by artists such as Picasso and Braque, who produced art work by composing elements of a scene taken from multiple points of view; paradoxically, such compositions convey a sense of motion without assuming temporal dependence between views. Our method accepts a set of two-dimensional images as input and produces a Cubist style painting with minimal user interaction. We use salient features identified within the image set, such as eyes, noses, and mouths, as compositional elements; we believe the use of such features to be a unique contribution to NPR. Before composing features into a final image, we geometrically distort them to produce the more angular forms common in Cubist art. Finally, we render the composition to give a painterly effect, using an automatic algorithm. This paper describes our method, illustrating the application of our algorithm with a gallery of images. We conclude with a critical appraisal and suggest the use of ""high-level"" features is of interest to NPR.","1941-0506","","10.1109/TVCG.2003.1260739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260739","","Art;Rendering (computer graphics);Painting;Layout;Nose;Appraisal;Image resolution;Eyes;Mouth;Graphics","rendering (computer graphics);art","cubist style rendering;photographs;nonphotorealistic rendering;Cubist art;Picasso;Braque;two-dimensional images;Cubist style painting;minimal user interaction;image set;NPR;painterly effect;automatic algorithm","","30","","43","","21 Jan 2004","","","IEEE","IEEE Journals"
"Efficient Optimization of Common Base Domains for Cross Parameterization","T. -H. Kwok; Y. Zhang; C. C. L. Wang","The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","9 Aug 2012","2012","18","10","1678","1692","Given a set of corresponding user-specified anchor points on a pair of models having similar features and topologies, the cross parameterization technique can establish a bijective mapping constrained by the anchor points. In this paper, we present an efficient algorithm to optimize the complexes and the shape of common base domains in cross parameterization for reducing the distortion of the bijective mapping. The optimization is also constrained by the anchor points. We investigate a new signature, Length-Preserved Base Domain (LPBD), for measuring the level of stretch between surface patches in cross parameterization. This new signature well balances the accuracy of measurement and the computational speed. Based on LPBD, a set of metrics are studied and compared. The best ones are employed in our domain optimization algorithm that consists of two major operators, boundary swapping and patch merging. Experimental results show that our optimization algorithm can reduce the distortion in cross parameterization efficiently.","1941-0506","","10.1109/TVCG.2011.115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928341","Complex domain;optimization;stretch;cross parameterization;surface parameterization.","Shape analysis;Optimization;Layout;Computational modeling;Topology","","","","30","","33","IEEE","23 Jun 2011","","","IEEE","IEEE Journals"
"Fast Construction of SAH BVHs on the Intel Many Integrated Core (MIC) Architecture","I. Wald","Intel Labs, Intel Corp, Santa Clara","IEEE Transactions on Visualization and Computer Graphics","14 Nov 2011","2012","18","1","47","57","We investigate how to efficiently build bounding volume hierarchies (BVHs) with surface area heuristic (SAH) on the Intel Many Integrated Core (MIC) Architecture. To achieve maximum performance, we use four key concepts: progressive 10-bit quantization to reduce cache footprint with negligible loss in BVH quality; an AoSoA data layout that allows efficient streaming and SIMD processing; high-performance SIMD kernels for binning and partitioning; and a parallelization framework with several build-specific optimizations. The resulting system is more than an order of magnitude faster than today's high-end GPU builders for comparable BVHs; it is usually faster even than spatial median builders; it can build SAH BVHs almost as fast as existing GPUs and CPUs- and CPU-based approaches can build regular grids; and in aggregate ""build+render” performance is significantly faster than the best published numbers for either of these systems, be it CPU or GPU, BVH, kd-tree, or grid.","1941-0506","","10.1109/TVCG.2010.251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669303","Bounding volume hierarchies (BVHs);parallel BVH construction;surface area heuristic (SAH);Intel MIC architecture.","Merging;Kernel;Instruction sets;Layout;Arrays;Registers","computer architecture;computer graphic equipment;coprocessors;multiprocessing systems;parallel processing","Intel many integrated core architecture;MIC;bounding volume hierarchies;surface area heuristic;SAH;BVH;AoSoA data layout;SIMD processing;SIMD kernels;parallelization framework;GPU","","30","1","28","","17 Dec 2010","","","IEEE","IEEE Journals"
"Felix: A Topology Based Framework for Visual Exploration of Cosmic Filaments","N. Shivashankar; P. Pranav; V. Natarajan; R. v. d. Weygaert; E. G. P. Bos; S. Rieder","Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Kapteyn Astronomical Institute, University of Groningen, Netherlands; Department of Computer Science and Automation and Supercomputer Education and Research Centre, Indian Institute of Science, Bangalore, India; Kapteyn Astronomical Institute, University of Groningen, Netherlands; Kapteyn Astronomical Institute, University of Groningen, Netherlands; RIKEN Advanced Institute for Computational Science, Japan","IEEE Transactions on Visualization and Computer Graphics","28 Apr 2016","2016","22","6","1745","1759","The large-scale structure of the universe is comprised of virialized blob-like clusters, linear filaments, sheet-like walls and huge near empty three-dimensional voids. Characterizing the large scale universe is essential to our understanding of the formation and evolution of galaxies. The density range of clusters, walls and voids are relatively well separated, when compared to filaments, which span a relatively larger range. The large scale filamentary network thus forms an intricate part of the cosmic web. In this paper, we describe Felix, a topology based framework for visual exploration of filaments in the cosmic web. The filamentary structure is represented by the ascending manifold geometry of the 2-saddles in the Morse-Smale complex of the density field. We generate a hierarchy of Morse-Smale complexes and query for filaments based on the density ranges at the end points of the filaments. The query is processed efficiently over the entire hierarchical Morse-Smale complex, allowing for interactive visualization. We apply Felix to computer simulations based on the heuristic Voronoi kinematic model and the standard ACDM cosmology, and demonstrate its usefulness through two case studies. First, we extract cosmic filaments within and across cluster like regions in Voronoi kinematic simulation datasets. We demonstrate that we produce similar results to existing structure finders. Second, we extract different classes of filaments based on their density characteristics from the ACDM simulation datasets. Filaments that form the spine of the cosmic web, which exist in high density regions in the current epoch, are isolated using Felix. Also, filaments present in void-like regions are isolated and visualized. These filamentary structures are often over shadowed by higher density range filaments and are not easily characterizable and extractable using other filament extraction methodologies.","1941-0506","","10.1109/TVCG.2015.2452919","Department of Science and Technology(grant numbers:SR/S3/EECE/0086/2012); John Templeton Foundation(grant numbers:FP5136-O); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7150427","Morse-Smale complexes;tessellations;cosmology theory;cosmic web;large-scale structure of the universe;Morse-Smale complexes;tessellations;cosmology theory;cosmic web;large-scale structure of the universe","Manifolds;Indexes;Visualization;Three-dimensional displays;Electronic mail;Topology;Geometry","cosmology;Internet","topology based framework;visual exploration;cosmic filaments;Felix;virialized blob-like clusters;linear filaments;sheet-like walls;three-dimensional voids;cosmic Web;Morse-Smale complexes;density field;standard ACDM cosmology;interactive visualization;filament extraction methodologies","","30","","84","IEEE","6 Jul 2015","","","IEEE","IEEE Journals"
"GosperMap: Using a Gosper Curve for Laying Out Hierarchical Data","D. Auber; C. Huet; A. Lambert; B. Renoust; A. Sallaberry; A. Saulnier","University Bordeaux 1, CNRS UMR 5800 LaBRI, INRIA Bordeaux Sud-Ouest, Talence; University Bordeaux 1, CNRS UMR 5800 LaBRI, INRIA Bordeaux Sud-Ouest, Talence; University Bordeaux 1, CNRS UMR 5800 LaBRI, INRIA Bordeaux Sud-Ouest, Talence; University Bordeaux 1, CNRS UMR 5800 LaBRI, INRIA Bordeaux Sud-Ouest, Institut National de l'Audiovisuel, Talence; University Montpellier 3, the CNRS UMR 5506 LIRMM and Pikko; Institut National de l'Audiovisuel, Paris","IEEE Transactions on Visualization and Computer Graphics","11 Sep 2013","2013","19","11","1820","1832","The emergence of very large hierarchies that result from the increase in available data raises many problems of visualization and navigation. On data sets of such scale, classical graph drawing methods do not take advantage of certain human cognitive skills such as shape recognition. These cognitive skills could make it easier to remember the global structure of the data. In this paper, we propose a method that is based on the use of nested irregular shapes. We name it GosperMap as we rely on the use of a Gosper Curve to generate these shapes. By employing human perception mechanisms that were developed by handling, for example, cartographic maps, this technique facilitates the visualization and navigation of a hierarchy. An algorithm has been designed to preserve region containment according to the hierarchy and to set the leaves' sizes proportionally to a property, in such a way that the size of nonleaf regions corresponds to the sum of their children's sizes. Moreover, the input ordering of the hierarchy's nodes is preserved, i.e., the areas that represent two consecutive children of a node in the hierarchy are adjacent to one another. This property is especially useful because it guarantees some stability in our algorithm. We illustrate our technique by providing visualization examples of the repartition of tax money in the US over time. Furthermore, we validate the use of the GosperMap in a professional documentation context and show the stability and ease of memorization for this type of map.","1941-0506","","10.1109/TVCG.2013.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6532285","Treemap;tree layout;hierarchical data visualization;Gosper curve;concave polygon labeling","Data visualization;Layout;Shape;Visualization;Vegetation;Labeling;Fractals","data visualisation;human factors;tree data structures","GosperMap;Gosper curve;hierarchical data;cognitive skills;global data structure;nested irregular shapes;shape generation;human perception mechanisms;cartographic maps;hierarchy navigation;hierarchy visualization;region containment preservation;leaf region size;nonleaf region size;hierarchy node children size;tax money repartitioning;US;professional documentation context;very large data hierarchies","","30","1","60","","14 Jun 2013","","","IEEE","IEEE Journals"
"Open-Box Spectral Clustering: Applications to Medical Image Analysis","T. Schultz; G. L. Kindlmann",University of Bonn; University of Chicago,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2100","2108","Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.","1941-0506","","10.1109/TVCG.2013.181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634089","Image segmentation;Three-dimensional displays;Eigenvalues and eigenfunctions;Laplace equations;Image analysis;Data visualization;Clustering;programming with example;Image segmentation;spectral clustering;high-dimensional embeddings;linked views","Image segmentation;Three-dimensional displays;Eigenvalues and eigenfunctions;Laplace equations;Image analysis;Data visualization;Clustering","biomedical MRI;computerised tomography;data visualisation;graph theory;medical image processing;pattern clustering","open-box spectral clustering;medical image analysis;3D image analysis;tuning parameters;hierarchical clustering;distance measures;graph parameter;Laplacian graph type;three-dimensional data space;segmentation protocols;chest CT;computerised tomography;brain MRI;magnetic resonance imaging","Algorithms;Brain;Brain;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Reproducibility of Results;Sensitivity and Specificity;Tomography, X-Ray Computed","30","2","53","","16 Oct 2013","","","IEEE","IEEE Journals"
"Two-Character Motion Analysis and Synthesis","T. Kwon; Y. -S. Cho; S. I. Park; S. Y. Shin","Seoul Nat. Univ., Seoul; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2008","2008","14","3","707","720","In this paper, we deal with the problem of synthesizing novel motions of standing-up martial arts such as Kickboxing, Karate, and Taekwondo performed by a pair of human-like characters while reflecting their interactions. Adopting an example-based paradigm, we address three non-trivial issues embedded in this problem: motion modeling, interaction modeling, and motion synthesis. For the first issue, we present a semi-automatic motion labeling scheme based on force-based motion segmentation and learning-based action classification. We also construct a pair of motion transition graphs each of which represents an individual motion stream. For the second issue, we propose a scheme for capturing the interactions between two players. A dynamic Bayesian network is adopted to build a motion transition model on top of the coupled motion transition graph that is constructed from an example motion stream. For the last issue, we provide a scheme for synthesizing a novel sequence of coupled motions, guided by the motion transition model. Although the focus of the present work is on martial arts, we believe that the framework of the proposed approach can be conveyed to other two-player motions as well.","1941-0506","","10.1109/TVCG.2008.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4441707","Animation;Statistical;Animation;Statistical","Motion analysis;Art;Animation;Bayesian methods;Motion segmentation;Computer vision;Network synthesis;Layout;Arm;Leg","Bayes methods;graph theory;image classification;image motion analysis;image segmentation;image sequences;learning (artificial intelligence);signal synthesis","two-character motion analysis;standing-up martial arts;kickboxing;karate;taekwondo;example-based paradigm;motion modeling;interaction modeling;motion synthesis;semiautomatic motion-labeling scheme;force-based motion segmentation;learning-based action classification;motion transition graphs;dynamic Bayesian network;motion transition model;coupled motion transition graph;coupled motion sequence","Algorithms;Computer Graphics;Computer Simulation;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Martial Arts;Models, Biological;Movement;Pattern Recognition, Automated;Whole Body Imaging","30","","48","IEEE","2 Feb 2008","","","IEEE","IEEE Journals"
"Visual Analysis of Multivariate State Transition Graphs","A. J. Pretorius; J. J. Van Wijk","Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, PO Box 513, 5600 MB Eindhoven, The Netherlands; Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, PO Box 513, 5600 MB Eindhoven, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","685","692","We present a new approach for the visual analysis of state transition graphs. We deal with multivariate graphs where a number of attributes are associated with every node. Our method provides an interactive attribute-based clustering facility. Clustering results in metric, hierarchical and relational data, represented in a single visualization. To visualize hierarchically structured quantitative data, we introduce a novel technique: the bar tree. We combine this with a node-link diagram to visualize the hierarchy and an arc diagram to visualize relational data. Our method enables the user to gain significant insight into large state transition graphs containing tens of thousands of nodes. We illustrate the effectiveness of our approach by applying it to a real-world use case. The graph we consider models the behavior of an industrial wafer stepper and contains 55 043 nodes and 289 443 edges.","1941-0506","","10.1109/TVCG.2006.192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015418","Graph visualization;multivariate visualization;interactive clustering;state spaces;transition systems;finite state machines.","Data visualization;Tree graphs;Semiconductor device modeling;Industrial relations;State-space methods;Automata;Computer languages;Mathematics;Computer science","data visualisation;diagrams;pattern clustering;tree data structures;trees (mathematics)","visual analysis;multivariate state transition graphs;interactive attribute-based clustering facility;relational data;hierarchically structured quantitative data visualization;bar tree;node-link diagram;arc diagram;industrial wafer stepper","","30","","19","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"Visualization of Heterogeneous Data","M. Cammarano; X. Dong; B. Chan; J. Klingner; J. Talbot; A. Halevy; P. Hanrahan",Stanford University; University of Washington; Stanford University; Stanford University; Stanford University; Google; Stanford University,"IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1200","1207","Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.","1941-0506","","10.1109/TVCG.2007.70617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376141","Data integration;RDF;attribute inference","Data visualization;Resource description framework;Space technology;Mashups;Semantic Web;Data models;Web services;Visual databases;Wikipedia;Government","data integrity;data visualisation","data visualization;resource description framework;semantic Web;Maya Viz u-forms;data integration;data attributes mapping;schema matching problem","","30","3","45","","5 Nov 2007","","","IEEE","IEEE Journals"
"Visualizing Social Media Content with SentenTree","M. Hu; K. Wongsuphasawat; J. Stasko",Georgia Institute of Technology; Twitter Inc.; Georgia Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","621","630","We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.","1941-0506","","10.1109/TVCG.2016.2598590","DARPA XDATA program; National Science Foundation(grant numbers:IIS-1320537); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536200","text visualization;social media;natural language processing;word cloud;Twitter","Visualization;Tag clouds;Media;Context;Twitter;Games;Layout","cloud computing;social networking (online);text analysis","social media content visualization;SentenTree;unstructured social media text;social media posts;word clouds;node-link diagram;social media text collection;word syntactic ordering;word tree","","30","","46","IEEE","8 Aug 2016","","","IEEE","IEEE Journals"
"A Task Taxonomy for Temporal Graph Visualisation","N. Kerracher; J. Kennedy; K. Chalmers","Institute for Informatics & Digital Innovation, Edinburgh Napier University, Edinburgh, United Kingdom; Institute for Informatics & Digital Innovation, Edinburgh Napier University, Edinburgh, United Kingdom; Institute for Informatics & Digital Innovation, Edinburgh Napier University, Edinburgh, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2015","2015","21","10","1160","1172","By extending and instantiating an existing formal task framework, we define a task taxonomy and task design space for temporal graph visualisation. We discuss the process involved in their generation, and describe how the design space can be `sliced and diced' into multiple overlapping task categories, requiring distinct visual techniques for their support. The approach addresses deficiencies in the task literature, offering domain independence, greater task coverage, and unambiguous task specification. The taxonomy and design space capture tasks for temporal graphs, and also static graphs, multivariate graphs, and graph comparison, and will be of value in the design and evaluation of temporal graph visualisation systems.","1941-0506","","10.1109/TVCG.2015.2424889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091028","Taxonomies;Graph/Network Data;Time Series Data;Taxonomies;graph/network data;time series data","Joining processes;Taxonomy;Data models;Data visualization;Sociology;Statistics;Market research","data visualisation;graph theory","task taxonomy;graph comparison;multivariate graphs;static graphs;visual techniques;temporal graph visualisation system","","29","","30","IEEE","21 Apr 2015","","","IEEE","IEEE Journals"
"An Empirical Model of Slope Ratio Comparisons","J. Talbot; J. Gerth; P. Hanrahan",Stanford University; Stanford University; Stanford University,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2613","2620","Comparing slopes is a fundamental graph reading task and the aspect ratio chosen for a plot influences how easy these comparisons are to make. According to Banking to 45°, a classic design guideline first proposed and studied by Cleveland et al., aspect ratios that center slopes around 45° minimize errors in visual judgments of slope ratios. This paper revisits this earlier work. Through exploratory pilot studies that expand Cleveland et al.'s experimental design, we develop an empirical model of slope ratio estimation that fits more extreme slope ratio judgments and two common slope ratio estimation strategies. We then run two experiments to validate our model. In the first, we show that our model fits more generally than the one proposed by Cleveland et al. and we find that, in general, slope ratio errors are not minimized around 45°. In the second experiment, we explore a novel hypothesis raised by our model: that visible baselines can substantially mitigate errors made in slope judgments. We conclude with an application of our model to aspect ratio selection.","1941-0506","","10.1109/TVCG.2012.196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327267","Banking to 45 degrees;slope perception;orientation resolution;aspect ratio selection","Approximation methods;Estimation;Market research;Predictive models;Data models;Slope analysis","data visualisation;graphs","empirical model;slope ratio comparisons;comparing slopes;fundamental graph reading task;classic design guideline;Cleveland experimental design;slope ratio estimation strategies","","29","","15","","8 Oct 2012","","","IEEE","IEEE Journals"
"<sc>Atom</sc>: A Grammar for Unit Visualizations","D. Park; S. M. Drucker; R. Fernandez; N. Elmqvist","University of Maryland, College Park, MD; Microsoft Research, Redmond, WA; University of Maryland, College Park, MD; Microsoft Research, Redmond, WA","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2018","2018","24","12","3032","3043","Unit visualizations are a family of visualizations where every data item is represented by a unique visual mark-a visual unit-during visual encoding. For certain datasets and tasks, unit visualizations can provide more information, better match the user's mental model, and enable novel interactions compared to traditional aggregated visualizations. Current visualization grammars cannot fully describe the unit visualization family. In this paper, we characterize the design space of unit visualizations to derive a grammar that can express them. The resulting grammar is called Atom, and is based on passing data through a series of layout operations that divide the output of previous operations recursively until the size and position of every data point can be determined. We evaluate the expressive power of the grammar by both using it to describe existing unit visualizations, as well as to suggest new unit visualizations.","1941-0506","","10.1109/TVCG.2017.2785807","U.S. National Institutes of Health (NIH)(grant numbers:R01GM114267); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233127","Visualization grammar;unit visualizations;declarative specification","Data visualization;Visualization;Grammar;Scalability;Layout;Clutter","data visualisation;grammars","unit visualizations;visualization grammars;visual mark;Atom;visual encoding;user mental model","Algorithms;Computer Graphics;Databases, Factual;Humans;Image Processing, Computer-Assisted;User-Computer Interface","29","","61","IEEE","21 Dec 2017","","","IEEE","IEEE Journals"
"Augmented Topological Descriptors of Pore Networks for Material Science","D. Ushizima; D. Morozov; G. H. Weber; A. G. C. Bianchi; J. A. Sethian; E. W. Bethel","Lawrence Berkeley National Laboratory; Lawrence Berkeley National Laboratory; Lawrence Berkeley National Laboratory; Lawrence Berkeley National Laboratory; University of California, Berkeley; Lawrence Berkeley National Laboratory","IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2041","2050","One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO<sub>2</sub> in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.","1941-0506","","10.1109/TVCG.2012.200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327208","Reeb graph;persistent homology;topological data analysis;geometric algorithms;segmentation;microscopy","Geophysical measurements;Carbon dioxide;Sequestration;Algorithm design and analysis;Information analysis;Microscopy;Image segmentation","biomineralisation;carbon capture and storage;carbon compounds;computerised tomography;data visualisation;environmental science computing;feature extraction;flow through porous media;flow visualisation;glass;materials science computing;permeability;porosity;synchrotrons;X-ray microscopy","augmented topological descriptors;pore networks;material science;carbon dioxide concentration reduction;captured carbon dioxide geologic storage;underground rock formations;carbon sequestration;media porosity;permeability estimates;pore structure visualization;biomineralization analysis;subsurface process;geometric descriptors;topological descriptors;material permeability;experimental data processing;segmentation;feature extraction;multiscale topological analysis;porous networks;synchrotron-based X-ray computed microtomography;glass beads;jammed packed bead beds;monodispersive material;flow through porous networks","","29","1","25","","8 Oct 2012","","","IEEE","IEEE Journals"
"Computing Reeb Graphs as a Union of Contour Trees","H. Doraiswamy; V. Natarajan","Indian Institute of Science, Bangalore; Indian Institute of Science, Bangalore","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2012","2013","19","2","249","262","The Reeb graph of a scalar function tracks the evolution of the topology of its level sets. This paper describes a fast algorithm to compute the Reeb graph of a piecewise-linear (PL) function defined over manifolds and non-manifolds. The key idea in the proposed approach is to maximally leverage the efficient contour tree algorithm to compute the Reeb graph. The algorithm proceeds by dividing the input into a set of subvolumes that have loop-free Reeb graphs using the join tree of the scalar function and computes the Reeb graph by combining the contour trees of all the subvolumes. Since the key ingredient of this method is a series of union-find operations, the algorithm is fast in practice. Experimental results demonstrate that it outperforms current generic algorithms by a factor of up to two orders of magnitude, and has a performance on par with algorithms that are catered to restricted classes of input. The algorithm also extends to handle large data that do not fit in memory.","1941-0506","","10.1109/TVCG.2012.115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189340","Computational topology;scalar functions;Reeb graphs;level set topology;out-of-core algorithm","Level set;Vegetation;Memory management;Topology;Manifolds;Algorithm design and analysis;Complexity theory","data handling;piecewise linear techniques;set theory;trees (mathematics)","contour tree union;scalar function;topology evolution;level set;piecewise-linear function;nonmanifold;efficient contour tree algorithm;loop-free Reeb graph;join tree;union-find operation;generic algorithm;large data handling","","29","","47","","24 Apr 2012","","","IEEE","IEEE Journals"
"Indexing and Retrieving Motions of Characters in Close Contact","E. S. L. Ho; T. Komura","University of Edinburgh, Edinburgh; University of Edinburgh, Edinburgh","IEEE Transactions on Visualization and Computer Graphics","16 Mar 2009","2009","15","3","481","492","Human motion indexing and retrieval are important for animators due to the need to search for motions in the database which can be blended and concatenated. Most of the previous researches of human motion indexing and retrieval compute the Euclidean distance of joint angles or joint positions. Such approaches are difficult to apply for cases in which multiple characters are closely interacting with each other, as the relationships of the characters are not encoded in the representation. In this research, we propose a topology-based approach to index the motions of two human characters in close contact. We compute and encode how the two bodies are tangled based on the concept of rational tangles. The encoded relationships, which we define as {\it TangleList}, are used to determine the similarity of the pairs of postures. Using our method, we can index and retrieve motions such as one person piggy-backing another, one person assisting another in walking, and two persons dancing / wrestling. Our method is useful to manage a motion database of multiple characters. We can also produce motion graph structures of two characters closely interacting with each other by interpolating and concatenating topologically similar postures and motion clips, which are applicable to 3D computer games and computer animation.","1941-0506","","10.1109/TVCG.2008.199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731251","Animation;Face and gesture recognition","Indexing;Animation;Humans;Databases;Information retrieval;Neck;Content based retrieval;Concatenated codes;Euclidean distance;Legged locomotion","avatars;computational geometry;computer animation;content-based retrieval;database indexing;interpolation;visual databases","human character motion indexing;human character motion retrieval;computer animation;motion database;Euclidean distance;topology-based approach;TangleList encoded relationship;motion graph structure;interpolation method;3D computer game;content-based retrieval;human character interaction;avatars","Abstracting and Indexing as Topic;Algorithms;Computer Graphics;Computer Simulation;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Biological;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","29","","27","IEEE","16 Mar 2009","","","IEEE","IEEE Journals"
"Inductively Generating Euler Diagrams","G. Stapleton; P. Rodgers; J. Howse; L. Zhang","University of Brighton, Brighton, UK; University of Kent, Canterbury, UK; University of Brighton, Brighton, UK; University of Kent, Canterbury, UK","IEEE Transactions on Visualization and Computer Graphics","11 Nov 2010","2011","17","1","88","100","Euler diagrams have a wide variety of uses, from information visualization to logical reasoning. In all of their application areas, the ability to automatically layout Euler diagrams brings considerable benefits. In this paper, we present a novel approach to Euler diagram generation. We develop certain graphs associated with Euler diagrams in order to allow curves to be added by finding cycles in these graphs. This permits us to build Euler diagrams inductively, adding one curve at a time. Our technique is adaptable, allowing the easy specification, and enforcement, of sets of well-formedness conditions; we present a series of results that identify properties of cycles that correspond to the well-formedness conditions. This improves upon other contributions toward the automated generation of Euler diagrams which implicitly assume some fixed set of well-formedness conditions must hold. In addition, unlike most of these other generation methods, our technique allows any abstract description to be drawn as an Euler diagram. To establish the utility of the approach, a prototype implementation has been developed.","1941-0506","","10.1109/TVCG.2010.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406520","Information visualization;diagram layout;diagram generation;Euler diagrams;Venn diagrams.","Visualization;Prototypes","diagrams;formal logic;graph theory;set theory","inductively Euler diagram generation;information visualization;logical reasoning;graphs;well-formedness condition","Algorithms;Computational Biology;Computer Graphics;Data Interpretation, Statistical;Humans;Software","29","","31","","5 Feb 2010","","","IEEE","IEEE Journals"
"Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators","Y. Albo; J. Lanir; P. Bak; S. Rafaeli","University of Haifa, Israel; University of Haifa, Israel; IBM Research Haifa Lab, Haifa, Israel; Sheizaf Rafaeli is with University of Haifa, Israel","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","569","578","A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.","1941-0506","","10.1109/TVCG.2015.2467322","Israel Internet Association-ISOC-IK; Appleseeds Academy; LINKS I-CORE Program of the Planning and Budgeting Committee; The Israel Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192648","Visualization evaluation;radial layout design;composite indicator visualization;experiment;Visualization evaluation;radial layout design;composite indicator visualization;experiment","Radar;Data visualization;Visualization;Benchmark testing;Image color analysis;Urban areas","data visualisation","circle-charts;OECD Betterlife index;flowercharts;radar-charts;CI visualization;information and communication technology;ICT usage;composite indicators;radial visualization","","29","1","35","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Semantics of Directly Manipulating Spatializations","X. Hu; L. Bradel; D. Maiti; L. House; C. North; S. Leman",Virginia Tech; Virginia Tech; Virginia Tech; Virginia Tech; Virginia Tech; Virginia Tech,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2052","2059","When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.","1941-0506","","10.1109/TVCG.2013.188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634115","Data visualization;Cognitive science;Mathematical model;Algorithm design and analysis;Semantics;statistical models;Visual to parametric interaction;visual analytics","Data visualization;Cognitive science;Mathematical model;Algorithm design and analysis;Semantics","data visualisation;statistical analysis;user interfaces","manipulating spatializations;high-dimensional data visualization;parametric projection algorithms;domain knowledge;alternative structures;parameter tweaking;decisive interactions;user interactions;algorithmic input;visual to parametric interaction;statistical model;V2PI interactions;sophisticated weighting scheme;unmoved data points","Algorithms;Artificial Intelligence;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Multimodal Imaging;Pattern Recognition, Automated;Reproducibility of Results;Semantics;Sensitivity and Specificity;User-Computer Interface","29","","23","","16 Oct 2013","","","IEEE","IEEE Journals"
"Shape Synthesis from Sketches via Procedural Models and Convolutional Networks","H. Huang; E. Kalogerakis; E. Yumer; R. Mech","University of Massachusetts Amherst, Amherst, MA; University of Massachusetts Amherst, Amherst, MA; Adobe Research, San Jose, CA; Adobe Research, San Jose, CA","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2017","2017","23","8","2003","2013","Procedural modeling techniques can produce high quality visual content through complex rule sets. However, controlling the outputs of these techniques for design purposes is often notoriously difficult for users due to the large number of parameters involved in these rule sets and also their non-linear relationship to the resulting content. To circumvent this problem, we present a sketch-based approach to procedural modeling. Given an approximate and abstract hand-drawn 2D sketch provided by a user, our algorithm automatically computes a set of procedural model parameters, which in turn yield multiple, detailed output shapes that resemble the user's input sketch. The user can then select an output shape, or further modify the sketch to explore alternative ones. At the heart of our approach is a deep Convolutional Neural Network (CNN) that is trained to map sketches to procedural model parameters. The network is trained by large amounts of automatically generated synthetic line drawings. By using an intuitive medium, i.e., freehand sketching as input, users are set free from manually adjusting procedural model parameters, yet they are still able to create high quality content. We demonstrate the accuracy and efficacy of our method in a variety of procedural modeling scenarios including design of man-made and organic shapes.","1941-0506","","10.1109/TVCG.2016.2597830","US National Science Foundation(grant numbers:CHS-1422441,CHS-1617333); NVidia for GPU donations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530838","Shape synthesis;convolutional neural networks;procedural modeling;sketch-based modeling","Shape;Computational modeling;Three-dimensional displays;Two dimensional displays;Neural networks;Solid modeling;Computer architecture","convolution;data visualisation;learning (artificial intelligence);shape recognition","shape synthesis;procedural models;high quality visual content;complex rule sets;hand-drawn 2D sketch;deep convolutional neural network;CNN;network training;automatically generated synthetic line drawings;intuitive medium","","29","","48","IEEE","3 Aug 2016","","","IEEE","IEEE Journals"
"Taking Word Clouds Apart: An Empirical Investigation of the Design Space for Keyword Summaries","C. Felix; S. Franconeri; E. Bertini",New York University; Northwestern University; New York University,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","657","666","In this paper we present a set of four user studies aimed at exploring the visual design space of what we call keyword summaries: lists of words with associated quantitative values used to help people derive an intuition of what information a given document collection (or part of it) may contain. We seek to systematically study how different visual representations may affect people's performance in extracting information out of keyword summaries. To this purpose, we first create a design space of possible visual representations and compare the possible solutions in this design space through a variety of representative tasks and performance metrics. Other researchers have, in the past, studied some aspects of effectiveness with word clouds, however, the existing literature is somewhat scattered and do not seem to address the problem in a sufficiently systematic and holistic manner. The results of our studies showed a strong dependency on the tasks users are performing. In this paper we present details of our methodology, the results, as well as, guidelines on how to design effective keyword summaries based in our discoveries.","1941-0506","","10.1109/TVCG.2017.2746018","CAPES Foundation; Ministry of Education of Brazil(grant numbers:13235/13-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017641","Word Clouds;Tag Clouds;Text Visualization;Keyword Summaries","Tag clouds;Visualization;Layout;Extraterrestrial measurements;Encoding;Data mining;Systematics","data visualisation;information retrieval;text analysis","keyword summaries;word clouds;visual representations;document collection;quantitative values;performance metrics;visual design space;empirical investigation","","29","","27","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"1.5D Egocentric Dynamic Network Visualization","L. Shi; C. Wang; Z. Wen; H. Qu; C. Lin; Q. Liao","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; IBM Research; IBM Research; Department of Computer Science and Engineering, Hong Kong University of Science and Technology; Department of Computer Science and Technology, Tsinghua University; Department of Computer Science, Central Michigan University","IEEE Transactions on Visualization and Computer Graphics","25 Mar 2015","2015","21","5","624","637","Dynamic network visualization has been a challenging research topic due to the visual and computational complexity introduced by the extra time dimension. Existing solutions are usually good for overview and presentation tasks, but not for the interactive analysis of a large dynamic network. We introduce in this paper a new approach which considers only the dynamic network central to a focus node, also known as the egocentric dynamic network. Our major contribution is a novel 1.5D visualization design which greatly reduces the visual complexity of the dynamic network without sacrificing the topological and temporal context central to the focus node. In our design, the egocentric dynamic network is presented in a single static view, supporting rich analysis through user interactions on both time and network. We propose a general framework for the 1.5D visualization approach, including the data processing pipeline, the visualization algorithm design, and customized interaction methods. Finally, we demonstrate the effectiveness of our approach on egocentric dynamic network analysis tasks, through case studies and a controlled user experiment comparing with three baseline dynamic network visualization methods.","1941-0506","","10.1109/TVCG.2014.2383380","China National 973 project(grant numbers:2014CB340301); NSFC(grant numbers:61379088); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991551","Graph Visualization;1.5D Visualization;Dynamic Network;Egocentric Abstraction;Graph visualization;1.5D visualization;dynamic network;egocentric abstraction","Market research;Layout;Data visualization;Visualization;Electronic mail;Heuristic algorithms;Algorithm design and analysis","computational complexity;data visualisation;graph theory;network theory (graphs)","1.5D egocentric dynamic network visualization design;visual complexity;computational complexity;focus node;topological context;temporal context;static view;user interactions;time dimension;network dimension;data processing pipeline","","28","","49","IEEE","18 Dec 2014","","","IEEE","IEEE Journals"
"Augmented scene modeling and visualization by optical and acoustic sensor integration","A. Fusiello; V. Murino","Dipt. di Inf., Universita degli Studi di Verona, Italy; Dipt. di Inf., Universita degli Studi di Verona, Italy","IEEE Transactions on Visualization and Computer Graphics","13 Sep 2004","2004","10","6","625","636","In this paper, underwater scene modeling from multisensor data is addressed. Acoustic and optical devices aboard an underwater vehicle are used to sense the environment in order to produce an output that is readily understandable even by an inexperienced operator. The main idea is to integrate multiple-sensor data by geometrically registering such data to a model. The geometrical structure of this model is a priori known but not ad hoc designed for this purpose. As a result, the vehicle pose is derived and model objects can be superimposed upon actual images, thus generating an augmented-reality representation. Results on a real underwater scene are reported, showing the effectiveness of the proposed approach.","1941-0506","","10.1109/TVCG.2004.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333661","Index Terms- Augmented reality;enhanced vision;multisensor integration;acoustic imaging;teleoperation;model-view registration;underwater applications.","Layout;Integrated optics;Optical sensors;Acoustic sensors;Solid modeling;Data visualization;Acoustic devices;Underwater acoustics;Optical devices;Underwater vehicles","augmented reality;data visualisation;sensor fusion;underwater vehicles;computational geometry;image representation;image registration;optical sensors;solid modelling","augmented scene modeling;augmented scene visualization;acoustic sensor integration;underwater scene modeling;multisensor data;acoustic devices;optical devices;underwater vehicle;geometrical structure;multisensor integration;acoustic imaging;model-view registration","","28","1","30","","13 Sep 2004","","","IEEE","IEEE Journals"
"Fast Combinatorial Vector Field Topology","J. Reininghaus; C. Lowen; I. Hotz","Zuse Institute Berlin, Berlin; Zuse Institute Berlin, Berlin; Zuse Institute Berlin, Berlin","IEEE Transactions on Visualization and Computer Graphics","4 Aug 2011","2011","17","10","1433","1443","This paper introduces a novel approximation algorithm for the fundamental graph problem of combinatorial vector field topology (CVT). CVT is a combinatorial approach based on a sound theoretical basis given by Forman's work on a discrete Morse theory for dynamical systems. A computational framework for this mathematical model of vector field topology has been developed recently. The applicability of this framework is however severely limited by the quadratic complexity of its main computational kernel. In this work, we present an approximation algorithm for CVT with a significantly lower complexity. This new algorithm reduces the runtime by several orders of magnitude and maintains the main advantages of CVT over the continuous approach. Due to the simplicity of our algorithm it can be easily parallelized to improve the runtime further.","1941-0506","","10.1109/TVCG.2010.235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620895","Flow visualization;graph algorithms.","Approximation algorithms;Topology;Prediction algorithms;Approximation methods;Skeleton;Runtime;Orbits","approximation theory;computational complexity;data analysis;data visualisation;graph theory","combinatorial vector field topology;Morse dynamical systems theory;quadratic complexity;approximation algorithm;vector field visualization;topological data analysis;graph problem","","28","","27","","9 Nov 2010","","","IEEE","IEEE Journals"
"Guided Multiview Ray Tracing for Fast Auralization","M. Taylor; A. Chandak; Q. Mo; C. Lauterbach; C. Schissler; D. Manocha","University of North Carolina at Chapel Hill, Chapel Hill; University of North Carolina at Chapel Hill, Chapel Hill; University of North Carolina at Chapel Hill, Chapel Hill; Google Inc.; University of North Carolina at Chapel Hill, Chapel Hill; University of North Carolina at Chapel Hill, Chapel Hill","IEEE Transactions on Visualization and Computer Graphics","7 Sep 2012","2012","18","11","1797","1810","We present a novel method for tuning geometric acoustic simulations based on ray tracing. Our formulation computes sound propagation paths from source to receiver and exploits the independence of visibility tests and validation tests to dynamically guide the simulation to high accuracy and performance. Our method makes no assumptions of scene layout and can account for moving sources, receivers, and geometry. We combine our guidance algorithm with a fast GPU sound propagation system for interactive simulation. Our implementation efficiently computes early specular paths and first order diffraction with a multiview tracing algorithm. We couple our propagation simulation with an audio output system supporting a high order interpolation scheme that accounts for attenuation, cross fading, and delay. The resulting system can render acoustic spaces composed of thousands of triangles interactively.","1941-0506","","10.1109/TVCG.2012.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6143937","Sound propagation;ray tracing;parallelization","Receivers;Diffraction;Ray tracing;Acoustics;Graphics processing unit;Computational modeling;Accuracy","acoustic wave propagation;audio signal processing;geometry;graphics processing units;interactive systems;interpolation;ray tracing","guided multiview ray tracing algorithm;fast auralization;geometric acoustic simulations;visibility tests;validation tests;scene layout;guidance algorithm;fast GPU sound propagation system;interactive simulation;audio output system;high order interpolation scheme","","28","5","64","","31 Jan 2012","","","IEEE","IEEE Journals"
"Interactive Navigation of Heterogeneous Agents Using Adaptive Roadmaps","R. Gayle; A. Sud; E. Andersen; S. J. Guy; M. C. Lin; D. Manocha","University of North Carolina, Chapel Hill; Microsoft Corp., Redmond; University of Washington, Seattle; University of North Carolina, Chapel Hill; University of North Carolina, Chapel Hill; University of North Carolina, Chapel Hill","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2008","2009","15","1","34","48","We present a novel algorithm for collision-free navigation of a large number of independent agents in complex and dynamic environments. We introduce adaptive roadmaps to perform global path planning for each agent simultaneously. Our algorithm takes into account dynamic obstacles and interagents interaction forces to continuously update the roadmap based on a physically-based dynamics simulator. In order to efficiently update the links, we perform adaptive particle-based sampling along the links. We also introduce the notion of ""link bands"" to resolve collisions among multiple agents. In practice, our algorithm can perform real-time navigation of hundreds and thousands of human agents in indoor and outdoor scenes.","1941-0506","","10.1109/TVCG.2008.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4544511","Three-Dimensional Graphics and Realism;Animation;Simulation;Modeling;and Visualization;Animation;Three-Dimensional Graphics and Realism;Animation;Simulation;Modeling;and Visualization;Animation","Navigation;Aerodynamics;Path planning;Sampling methods;Road accidents;Layout;Motion planning;Humans;Robots;Avatars","collision avoidance;interactive systems;navigation;object-oriented programming","interactive navigation;heterogeneous agents;adaptive roadmaps;collision-free navigation;global path planning;link bands","Algorithms;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Models, Biological;User-Computer Interface","28","1","44","","17 Jun 2008","","","IEEE","IEEE Journals"
"Learning Visualizations by Analogy: Promoting Visual Literacy through Visualization Morphing","P. Ruchikachorn; K. Mueller","Visual Analytics and Imaging Laboratory, Department of Computer Science, Stony Brook University, Stony Brook, NY; Visual Analytics and Imaging Laboratory, Department of Computer Science","IEEE Transactions on Visualization and Computer Graphics","28 Jul 2015","2015","21","9","1028","1044","We propose the concept of teaching (and learning) unfamiliar visualizations by analogy, that is, demonstrating an unfamiliar visualization method by linking it to another more familiar one, where the in-betweens are designed to bridge the gap of these two visualizations and explain the difference in a gradual manner. As opposed to a textual description, our morphing explains an unfamiliar visualization through purely visual means. We demonstrate our idea by ways of four visualization pair examples: data table and parallel coordinates, scatterplot matrix and hyperbox, linear chart and spiral chart, and hierarchical pie chart and treemap. The analogy is commutative i.e. any member of the pair can be the unfamiliar visualization. A series of studies showed that this new paradigm can be an effective teaching tool. The participants could understand the unfamiliar visualization methods in all of the four pairs either fully or at least significantly better after they observed or interacted with the transitions from the familiar counterpart. The four examples suggest how helpful visualization pairings be identified and they will hopefully inspire other visualization morphings and associated transition strategies to be identified.","1941-0506","","10.1109/TVCG.2015.2413786","National Science Foundation (NSF)(grant numbers:IIS-1117132); MSIP(grant numbers:NIPA-2013-H0203-13-1001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061477","Animation;Education;Information Visualization;Literacy;Interaction;Multivariate Visualization;Animation;education;information visualization;literacy;interaction;multivariate visualization","Data visualization;Visualization;Animation;Education;Joining processes;Spirals;Layout","computer literacy;computer science education;data visualisation;teaching","visualization by analogy learning;visual literacy;visualization morphing;unfamiliar visualization teaching method;textual description;parallel coordinates;data table;scatterplot matrix;hyperbox;linear chart;spiral chart;hierarchical pie chart;treemap;associated transition strategy","","28","","50","IEEE","16 Mar 2015","","","IEEE","IEEE Journals"
"Line art illustrations of parametric and implicit forms","G. Elber","Dept. of Comput. Sci., Technion-Israel Inst. of Technol., Haifa, Israel","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1998","4","1","71","81","A technique is presented for line art rendering of scenes composed of freeform surfaces. The line art that is created for parametric surfaces is practically intrinsic and is globally invariant to changes in the surface parameterization. This method is equally applicable for line art rendering of implicit forms, creating a unified line art rendering method for both parametric and implicit forms. This added flexibility exposes a new horizon of special, parameterization independent, line art effects. Moreover, the production of the line art illustrations can be combined with traditional rendering techniques such as transparency and texture mapping. Examples that demonstrate the capabilities of the proposed approach are presented for both the parametric and implicit forms.","1941-0506","","10.1109/2945.675655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=675655","","Subspace constraints;Art;Rendering (computer graphics);Layout;Computer graphics;Ray tracing;Production;Spline;Surface topography;Surface reconstruction","rendering (computer graphics);art;splines (mathematics);image texture;computational geometry","parametric forms;implicit forms;line art rendering;freeform surfaces;parametric surfaces;transparency;texture mapping;sketches;illustrations;line drawings;NURBS","","28","25","29","","6 Aug 2002","","","IEEE","IEEE Journals"
"Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation","B. Saket; P. Simonetto; S. Kobourov; K. Börner",University of Arizona; University of Arizona; University of Arizona; Indiana University,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2231","2240","Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools.","1941-0506","","10.1109/TVCG.2014.2346422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876036","graphs;networks;maps;scatter plots","Image color analysis;Data visualization;Visualization;Diagrams;Layout;Datasets","data visualisation","node diagram;node-link diagram;node-link-group diagram;information visualization;distance notion;principal component analysis;multidimensional scaling;network graph;graph links;dataset visualization;node-based tasks;network-based tasks;group-based tasks","","28","","48","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Real-Time Interaction with a Humanoid Avatar in an Immersive Table Tennis Simulation","S. Rusdorf; G. Brunnett; M. Lorenz; T. Winkler","Dept. of Comput. Sci., Chemnitz Univ. of Technol.; Dept. of Comput. Sci., Chemnitz Univ. of Technol.; Dept. of Comput. Sci., Chemnitz Univ. of Technol.; Dept. of Comput. Sci., Chemnitz Univ. of Technol.","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2007","13","1","15","25","In this paper, we report on the realization of an immersive table tennis simulation. After describing the hardware necessities of our system, we give insight into different aspects of the simulation. In particular, the developed methods for collision detection and physical simulation are presented. The design of the virtual opponent is of crucial importance to realize an enjoyable game. Therefore, we report on the implemented game strategy and the animation of the opponent. Since table tennis is one of the fastest sports, the synchronization of the human player's movements and the visual output on the projection wall is a very challenging problem to solve. To overcome the latencies in our system, we designed a prediction method that allows high speed interaction with our application","1941-0506","","10.1109/TVCG.2007.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015394","Games and infotainment;distributed/network graphics;interaction techniques;virtual reality.","Avatars;Hardware;Virtual reality;Application software;Humans;Delay;Animation;Design methodology;Prediction methods;Graphics","avatars;computer animation;computer games;graphical user interfaces;sport","real-time interaction;humanoid avatar;immersive table tennis simulation;collision detection;physical simulation;virtual opponent design;opponent animation;sports;human player movements","Computer Graphics;Computer Simulation;Computer Systems;Humans;Image Interpretation, Computer-Assisted;Man-Machine Systems;Models, Biological;Software;Tennis;User-Computer Interface","28","1","20","","20 Nov 2006","","","IEEE","IEEE Journals"
"Representing Uncertainty in Graph Edges: An Evaluation of Paired Visual Variables","H. Guo; J. Huang; D. H. Laidlaw","Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2015","2015","21","10","1173","1186","When visualizing data with uncertainty, a common approach is to treat uncertainty as an additional dimension and encode it using a visual variable. The effectiveness of this approach depends on how the visual variables chosen for representing uncertainty and other attributes interact to influence the user's perception of each variable. We report a user study on the perception of graph edge attributes when uncertainty associated with each edge and the main edge attribute are visualized simultaneously using two separate visual variables. The study covers four visual variables that are commonly used for visualizing uncertainty on line graphical primitives: lightness, grain, fuzziness, and transparency. We select width, hue, and saturation for visualizing the main edge attribute and hypothesize that we can observe interference between the visual variable chosen to encode the main edge attribute and that to encode uncertainty, as suggested by the concept of dimensional integrality. Grouping the seven visual variables as color-based, focus-based, or geometry-based, we further hypothesize that the degree of interference is affected by the groups to which the two visual variables belong. We consider two further factors in the study: discriminability level for each visual variable as a factor intrinsic to the visual variables and graph-task type (visual search versus comparison) as a factor extrinsic to the visual variables. Our results show that the effectiveness of a visual variable in depicting uncertainty is strongly mediated by all the factors examined here. Focus-based visual variables (fuzziness, grain, and transparency) are robust to the choice of visual variables for encoding the main edge attribute, though fuzziness has stronger negative impact on the perception of width and transparency has stronger negative impact on the perception of hue than the other uncertainty visual variables. We found that interference between hue and lightness is much greater than that between saturation and lightness, though all three are color-based visual variables. We also found a compound relationship between discriminability level and the degree of dimensional integrality. We discuss the generalizability and limitation of the results and conclude with design considerations for visualizing graph uncertainty derived from these results, including recommended choices of visual variables when the relative importance of data attributes and graph tasks is known.","1941-0506","","10.1109/TVCG.2015.2424872","IIS(grant numbers:IIS-10-18769); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7089294","Visual variable;perception;uncertainty visualization;graph visualization;Visual variable;perception;uncertainty visualization;graph visualization","Visualization;Uncertainty;Encoding;Data visualization;Image color analysis;Accuracy;Interference","computational geometry;data visualisation;graph theory","uncertainty representation;paired-visual variable evaluation;data visualization;user perception;graph edge attributes;line graphical primitives;lightness attribute;grain attribute;fuzziness attribute;transparency attribute;width attribute;hue attribute;saturation attribute;visual variable;uncertainty encoding;dimensional integrality;color-based visual variable;focus-based visual variable;geometry-based visual variable;interference degree;discriminability level;intrinsic factor;graph-task type;focus-based visual variables;color-based visual variables;graph uncertainty visualization;data attributes","","28","","40","IEEE","20 Apr 2015","","","IEEE","IEEE Journals"
"Rethinking Map Legends with Visualization","J. Dykes; J. Wood; A. Slingsby","Dept. of Inf. Sci., City Univ. London, London, UK; Dept. of Inf. Sci., City Univ. London, London, UK; Dept. of Inf. Sci., City Univ. London, London, UK","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","890","899","This design paper presents new guidance for creating map legends in a dynamic environment. Our contribution is a set ofguidelines for legend design in a visualization context and a series of illustrative themes through which they may be expressed. Theseare demonstrated in an applications context through interactive software prototypes. The guidelines are derived from cartographicliterature and in liaison with EDINA who provide digital mapping services for UK tertiary education. They enhance approaches tolegend design that have evolved for static media with visualization by considering: selection, layout, symbols, position, dynamismand design and process. Broad visualization legend themes include: The Ground Truth Legend, The Legend as Statistical Graphicand The Map is the Legend. Together, these concepts enable us to augment legends with dynamic properties that address specificneeds, rethink their nature and role and contribute to a wider re-evaluation of maps as artifacts of usage rather than statements offact. EDINA has acquired funding to enhance their clients with visualization legends that use these concepts as a consequence ofthis work. The guidance applies to the design of a wide range of legends and keys used in cartography and information visualization.","1941-0506","","10.1109/TVCG.2010.191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613425","Cartography;design;Digimap service;legend;online web mapping;visualization","Layout;Data visualization;Visualization;Geospatial analysis;Prototypes;Context","cartography;data visualisation;interactive systems","information visualization;map legend creation;dynamic environment;interactive software;cartography;EDINA;digital mapping service;UK tertiary education;visualization legend","","28","","62","","28 Oct 2010","","","IEEE","IEEE Journals"
"Route Visualization Using Detail Lenses","P. Karnick; D. Cline; S. Jeschke; A. Razdan; P. Wonka","Arizona State University, Tempe; Arizona State University, Tempe; University of Vienna, Austria; Arizona State University, Mesa; Arizona State University, Tempe","IEEE Transactions on Visualization and Computer Graphics","15 Jan 2010","2010","16","2","235","247","We present a method designed to address some limitations of typical route map displays of driving directions. The main goal of our system is to generate a printable version of a route map that shows the overview and detail views of the route within a single, consistent visual frame. Our proposed visualization provides a more intuitive spatial context than a simple list of turns. We present a novel multifocus technique to achieve this goal, where the foci are defined by points of interest (POI) along the route. A detail lens that encapsulates the POI at a finer geospatial scale is created for each focus. The lenses are laid out on the map to avoid occlusion with the route and each other, and to optimally utilize the free space around the route. We define a set of layout metrics to evaluate the quality of a lens layout for a given route map visualization. We compare standard lens layout methods to our proposed method and demonstrate the effectiveness of our method in generating aesthetically pleasing layouts. Finally, we perform a user study to evaluate the effectiveness of our layout choices.","1941-0506","","10.1109/TVCG.2009.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5072215","Route visualization;map visualization;overview and detail techniques.","Lenses;Displays;Data visualization;Labeling;Design methodology;Performance evaluation;Animation;Printing;Mirrors;Navigation","data visualisation","detail lenses;route map displays;multifocus technique;layout metrics;route map visualization","Algorithms;Computer Graphics;Information Storage and Retrieval;Maps as Topic;Pattern Recognition, Automated;Software;User-Computer Interface","28","7","26","","12 Jun 2009","","","IEEE","IEEE Journals"
"The VIS-5D system for easy interactive visualization","B. Hibbard; D. Santek","Space Sci. & Eng. Center, Wisconsin Univ., Madison, WI, USA; Space Sci. & Eng. Center, Wisconsin Univ., Madison, WI, USA","Proceedings of the First IEEE Conference on Visualization: Visualization `90","6 Aug 2002","1990","","","28","35","The VIS-5D system provides highly interactive visual access to five-dimensional data sets containing up to 50 million data points. VIS-5D runs on the Stardent ST-1000 and ST-2000 workstations and generates animated three-dimensional graphics from gridded data sets in real time. It provides a widget-based user interface and fast visual response which allows scientists to interactively explore their data sets. VIS-5D generates literal and intuitive depictions of data, has user controls that are data oriented rather than graphics oriented, and provides a WYSIWYG (what-you-see-is-what-you-get) response. The result is a system that enables scientists to produce and direct their own animations.<<ETX>></ETX>","","0-8186-2083-8","10.1109/VISUAL.1990.146361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=146361","","Animation;Data visualization;Graphics;Workstations;Software tools;Earth;Atmospheric modeling;Hydrology;Land surface temperature;Ocean temperature","computer animation;flow visualisation;graphical user interfaces","literal depictions;VIS-5D system;interactive visualization;five-dimensional data sets;Stardent ST-1000;ST-2000 workstations;animated three-dimensional graphics;widget-based user interface;fast visual response;intuitive depictions;WYSIWYG","","28","1","2","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration","B. Chan; L. Wu; J. Talbot; M. Cammarano; P. Hanrahan",Stanford University; Stanford University; Stanford University; Stanford University; Stanford University,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1213","1220","Wikipedia is an example of the collaborative, semi-structured data sets emerging on the Web. These data sets have large, non-uniform schema that require costly data integration into structured tables before visualization can begin. We present Vispedia, a Web-based visualization system that reduces the cost of this data integration. Users can browse Wikipedia, select an interesting data table, then use a search interface to discover, integrate, and visualize additional columns of data drawn from multiple Wikipedia articles. This interaction is supported by a fast path search algorithm over DBpedia, a semantic graph extracted from Wikipedia's hyperlink structure. Vispedia can also export the augmented data tables produced for use in traditional visualization systems. We believe that these techniques begin to address the ""long tail"" of visualization by allowing a wider audience to visualize a broader class of data. We evaluated this system in a first-use formative lab study. Study participants were able to quickly create effective visualizations for a diverse set of domains, performing data integration as needed.","1941-0506","","10.1109/TVCG.2008.178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658132","Index Terms—;information visualization;data integration;Wikipedia;semantic web;search interface","Wikipedia;Data visualization;Costs;Collaboration;Collaborative software;Data mining;Semantic Web;Eyes;Cleaning;Iterative algorithms","data integrity;data visualisation;Internet;search engines;semantic Web","interactive visual exploration;Wikipedia data;search-based integration;semistructured data;Web;data integration;Web-based visualization system;fast path search algorithm","","28","","34","","24 Oct 2008","","","IEEE","IEEE Journals"
"Visual Adjacency Lists for Dynamic Graphs","M. Hlawatsch; M. Burch; D. Weiskopf","Visualization Research Center (VISUS), University of Stuttgart, Germany; Visualization Research Center (VISUS), University of Stuttgart, Germany; Visualization Research Center (VISUS), University of Stuttgart, Germany","IEEE Transactions on Visualization and Computer Graphics","24 Sep 2014","2014","20","11","1590","1603","We present a visual representation for dynamic, weighted graphs based on the concept of adjacency lists. Two orthogonal axes are used: one for all nodes of the displayed graph, the other for the corresponding links. Colors and labels are employed to identify the nodes. The usage of color allows us to scale the visualization to single pixel level for large graphs. In contrast to other techniques, we employ an asymmetric mapping that results in an aligned and compact representation of links. Our approach is independent of the specific properties of the graph to be visualized, but certain graphs and tasks benefit from the asymmetry. As we show in our results, the strength of our technique is the visualization of dynamic graphs. In particular, sparse graphs benefit from the compact representation. Furthermore, our approach uses visual encoding by size to represent weights and therefore allows easy quantification and comparison. We evaluate our approach in a quantitative user study that confirms the suitability for dynamic and weighted graphs. Finally, we demonstrate our approach for two examples of dynamic graphs.","1941-0506","","10.1109/TVCG.2014.2322594","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6812198","Graph visualization;weighted graphs;dynamic graphs;adjacency lists","Graph theory;Image color analysis;Encoding;Data visualization;Scalability","data visualisation;graph theory","visual encoding;sparse graphs;compact representation;asymmetric mapping;visualization;displayed graph;orthogonal axes;weighted graphs;visual representation;dynamic graphs;visual adjacency lists","","28","","47","IEEE","8 May 2014","","","IEEE","IEEE Journals"
"A Modular Degree-of-Interest Specification for the Visual Analysis of Large Dynamic Networks","J. Abello; S. Hadlak; H. Schumann; H. Schulz","Rutgers University, Piscataway; University of Rostock, Rostock; University of Rostock, Rostock; University of Rostock, Rostock","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2014","2014","20","3","337","350","Large dynamic networks are targets of analysis in many fields. Tracking temporal changes at scale in these networks is challenging due in part to the fact that small changes can be missed or drowned-out by the rest of the network. For static networks, current approaches allow the identification of specific network elements within their context. However, in the case of dynamic networks, the user is left alone with finding salient local network elements and tracking them over time. In this work, we introduce a modular DoI specification to flexibly define what salient changes are and to assign them a measure of their importance in a time-varying setting. The specification takes into account neighborhood structure information, numerical attributes of nodes/edges, and their temporal evolution. A tailored visualization of the DoI specification complements our approach. Alongside a traditional node-link view of the dynamic network, it serves as an interface for the interactive definition of a DoI function. By using it to successively refine and investigate the captured details, it supports the analysis of dynamic networks from an initial view until pinpointing a user's analysis goal. We report on applying our approach to scientific coauthorship networks and give concrete results for the DBLP data set.","1941-0506","","10.1109/TVCG.2013.109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574858","Time-varying graphs;dynamic graph visualization;degree-of-interest","Visualization;Context;Data visualization;Radiation detectors;Educational institutions;Electronic mail;Navigation","formal specification;graph theory","modular degree-of-interest specification;visual analysis;large dynamic networks;static networks;local network elements;structure information;numerical attributes;temporal evolution;tailored visualization;DoI specification complements;dynamic network;interactive definition","","27","","37","","5 Aug 2013","","","IEEE","IEEE Journals"
"A Structure-Based Distance Metric for High-Dimensional Space Exploration with Multidimensional Scaling","J. H. Lee; K. T. McDonnell; A. Zelenyuk; D. Imre; K. Mueller","State University of New York at Stony Brook, Stony Brook; Dowling College, Oakdale; Pacific Northwest National Lab, Richland; Imre Consulting, Richland; State University of New York at Stony Brook, Stony Brook","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2014","2014","20","3","351","364","Although the euclidean distance does well in measuring data distances within high-dimensional clusters, it does poorly when it comes to gauging intercluster distances. This significantly impacts the quality of global, low-dimensional space embedding procedures such as the popular multidimensional scaling (MDS) where one can often observe nonintuitive layouts. We were inspired by the perceptual processes evoked in the method of parallel coordinates which enables users to visually aggregate the data by the patterns the polylines exhibit across the dimension axes. We call the path of such a polyline its structure and suggest a metric that captures this structure directly in high-dimensional space. This allows us to better gauge the distances of spatially distant data constellations and so achieve data aggregations in MDS plots that are more cognizant of existing high-dimensional structure similarities. Our biscale framework distinguishes far-distances from near-distances. The coarser scale uses the structural similarity metric to separate data aggregates obtained by prior classification or clustering, while the finer scale employs the appropriate euclidean distance.","1941-0506","","10.1109/TVCG.2013.101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560006","Information visualization;multivariate visualization;clustering;high-dimensional data;visual analytics","Layout;Euclidean distance;Correlation;Indexes;Data visualization;Extraterrestrial measurements","computational geometry;data visualisation;embedded systems","structure-based distance metric;high-dimensional space exploration;multidimensional scaling;low-dimensional space embedding procedures;polylines pattern;spatially distant data constellations","","27","","32","","16 Jul 2013","","","IEEE","IEEE Journals"
"An Incremental Dimensionality Reduction Method for Visualizing Streaming Multidimensional Data","T. Fujiwara; J. -K. Chou; S. Shilpika; P. Xu; L. Ren; K. -L. Ma","University of California, Davis; University of California, Davis; University of California, Davis; Bosch Research North America; Bosch Research North America; University of California, Davis","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","418","428","Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer's mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets.","1941-0506","","10.1109/TVCG.2019.2934433","National Science Foundation(grant numbers:IIS-1528203,IIS-1741536); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809834","Dimensionality reduction;principal component analysis;streaming data;uncertainty;visual analytics","Data visualization;Layout;Principal component analysis;Dimensionality reduction;Visual analytics;Computational efficiency;Animation","computer animation;data analysis;data reduction;data visualisation;estimation theory;principal component analysis","incremental dimensionality reduction method;multidimensional data analysis;incremental DR solution;geometric transformation;animation methods;optimization method;streaming multidimensional data visualization;incremental PCA method;data dimension variants;data positions estimation","","27","","73","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"Association Analysis for Visual Exploration of Multivariate Scientific Data Sets","X. Liu; H. -W. Shen",The Ohio State University; The Ohio State University,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","955","964","The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data's multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets.","1941-0506","","10.1109/TVCG.2015.2467431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192697","Multivariate data;association analysis;visual exploration;multiple views","Social network services;IP networks;Visualization;Association rules;Analytical models;Isosurfaces","data analysis;data mining;data visualisation","visual exploration;multivariate scientific data set;association analysis method;scalar-level association;information flow;association rules;informativeness concept;uniqueness concept;multiscalar informativeness-uniqueness algorithm;MSIU algorithm","","27","","34","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Bubble Treemaps for Uncertainty Visualization","J. Görtler; C. Schulz; D. Weiskopf; O. Deussen",University of Konstanz; VISUSUniversity of Stuttgart; VISUSUniversity of Stuttgart; University of Konstanz,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","719","728","We present a novel type of circular treemap, where we intentionally allocate extra space for additional visual variables. With this extended visual design space, we encode hierarchically structured data along with their uncertainties in a combined diagram. We introduce a hierarchical and force-based circle-packing algorithm to compute Bubble Treemaps, where each node is visualized using nested contour arcs. Bubble Treemaps do not require any color or shading, which offers additional design choices. We explore uncertainty visualization as an application of our treemaps using standard error and Monte Carlo-based statistical models. To this end, we discuss how uncertainty propagates within hierarchies. Furthermore, we show the effectiveness of our visualization using three different examples: the package structure of Flare, the S&P 500 index, and the US consumer expenditure survey.","1941-0506","","10.1109/TVCG.2017.2743959","German Research Foundation(grant numbers:A01,SFB-TRR 161); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017613","Uncertainty visualization;hierarchy visualization;treemaps;tree layout;circle packing;contours","Uncertainty;Data visualization;Layout;Visualization;Computational modeling;Standards;Indexes","data visualisation;Monte Carlo methods;statistical analysis;tree data structures","extended visual design space;hierarchically structured data;circle-packing algorithm;uncertainty visualization;circular treemap;visual variables;bubble treemaps;nested contour arcs;standard error;Monte Carlo-based statistical model;S&P 500 index;US consumer expenditure survey;Flare","","27","","46","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Geometry-dependent lighting","C. H. Lee; X. Hao; A. Varshney","Nat. Capital Area Med. Simulation Center, Silver Spring, MD, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","23 Jan 2006","2006","12","2","197","207","In this paper, we introduce geometry-dependent lighting that allows lighting parameters to be defined independently and possibly discrepantly over an object or scene based on the local geometry. We present and discuss light collages, a lighting design system with geometry-dependent lights for effective feature-enhanced visualization. Our algorithm segments the objects into local surface patches and places lights that are locally consistent but globally discrepant to enhance the perception of shape. We use spherical harmonics for efficiently storing and computing light placement and assignment. We also outline a method to find the minimal number of light sources sufficient to illuminate an object well with our globally discrepant lighting approach.","1941-0506","","10.1109/TVCG.2006.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580454","Lighting design;scientific illustration;discrepant lighting;light placement;silhouette enhancement;proximity shadows;spherical harmonics.","Geometry;Data visualization;Art;Shape;Light sources;Lighting;Humans;Painting;Layout;Pipelines","computational geometry;lighting;data visualisation","geometry-dependent light;light collage;lighting design system;feature-enhanced visualization;light placement","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Lighting;User-Computer Interface","27","","33","IEEE","23 Jan 2006","","","IEEE","IEEE Journals"
"Hub-based Simulation and Graphics Hardware Accelerated Visualization for Nanotechnology Applications","W. Qiao; M. McLennan; R. Kennell; D. Ebert; G. Klimeck",Purdue University; Purdue University; Purdue University; Purdue University; Purdue University,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1061","1068","The Network for computational nanotechnology (NCN) has developed a science gateway at nanoHUB.org for nanotechnology education and research. Remote users can browse through online seminars and courses, and launch sophisticated nanotechnology simulation tools, all within their Web browser. Simulations are supported by a middleware that can route complex jobs to grid supercomputing resources. But what is truly unique about the middleware is the way that it uses hardware accelerated graphics to support both problem setup and result visualization. This paper describes the design and integration of a remote visualization framework into the nanoHUB for interactive visual analytics of nanotechnology simulations. Our services flexibly handle a variety of nanoscience simulations, render them utilizing graphics hardware acceleration in a scalable manner, and deliver them seamlessly through the middleware to the user. Rendering is done only on-demand, as needed, so each graphics hardware unit can simultaneously support many user sessions. Additionally, a novel node distribution scheme further improves our system's scalability. Our approach is not only efficient but also cost-effective. Only half-dozen render nodes are anticipated to support hundreds of active tool sessions on the nanoHUB. Moreover, this architecture and visual analytics environment provides capabilities that can serve many areas of scientific simulation and analysis beyond nanotechnology with its ability to interactively analyze and visualize multivariate scalar and vector fields","1941-0506","","10.1109/TVCG.2006.150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015465","remote visualization;volume visualization;flow visualization;graphics hardware;nanotechnology simulation.","Graphics;Hardware;Acceleration;Visualization;Nanotechnology;Computational modeling;Middleware;Rendering (computer graphics);Visual analytics;Analytical models","computer graphic equipment;data visualisation;flow visualisation;mesh generation;middleware;nanotechnology;online front-ends;physics computing;rendering (computer graphics)","Hub-based simulation;graphics hardware accelerated visualization;computational nanotechnology application;science gateway;Web browser;middleware;grid supercomputing resources","Computer Graphics;Computer Simulation;Computers;Internet;Models, Theoretical;Nanostructures;Nanostructures;Nanotechnology;Nanotechnology;Signal Processing, Computer-Assisted;User-Computer Interface","27","","47","","20 Nov 2006","","","IEEE","IEEE Journals"
"Human Motion Capture Data Compression by Model-Based Indexing: A Power Aware Approach","S. Chattopadhyay; S. M. Bhandarkar; K. Li","Department of Computer Science, The University of Georgia, 415 Boyd Graduate Studies Research Center, Athens, GA 30602-7404; Department of Computer Science, The University of Georgia, 415 Boyd Graduate Studies Research Center, Athens, GA 30602-7404; Department of Computer Science, The University of Georgia, 415 Boyd Graduate Studies Research Center, Athens, GA 30602-7404","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2007","13","1","5","14","Human motion capture (MoCap) data can be used for animation of virtual human-like characters in distributed virtual reality applications and networked games. MoCap data compressed using the standard MPEG-4 encoding pipeline comprising of predictive encoding (and/or DCT decorrelation), quantization, and arithmetic/Huffman encoding, entails significant power consumption for the purpose of decompression. In this paper, we propose a novel algorithm for compression of MoCap data, which is based on smart indexing of the MoCap data by exploiting structural information derived from the skeletal virtual human model. The indexing algorithm can be fine-controlled using three predefined quality control parameters (QCPs). We demonstrate how an efficient combination of the three QCPs results in a lower network bandwidth requirement and reduced power consumption for data decompression at the client end when compared to standard MPEG-4 compression. Since the proposed algorithm exploits structural information derived from the skeletal virtual human model, it is observed to result in virtual human animation of visually acceptable quality upon decompression","1941-0506","","10.1109/TVCG.2007.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015393","Three-dimensional graphics and realism¿animation;data compaction;and compression.","Humans;Data compression;Indexing;Animation;MPEG 4 Standard;Energy consumption;Virtual reality;Pipelines;Predictive encoding;Discrete cosine transforms","arithmetic codes;computer animation;data compression;Huffman codes;power aware computing;solid modelling;video coding;virtual reality","human motion capture data compression;model-based indexing algorithm;power aware approach;MoCap data compression;virtual human-like character animation;distributed virtual reality applications;networked games;MPEG-4 encoding pipeline;predictive encoding;signal quantization;arithmetic encoding;Huffman encoding;power consumption;skeletal virtual human model;quality control parameters;network bandwidth requirement","Algorithms;Computer Simulation;Data Compression;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Biological;Movement;Video Recording","27","","26","","20 Nov 2006","","","IEEE","IEEE Journals"
"Optimal Camera Placement for Motion Capture Systems","P. Rahimian; J. K. Kearney","Computer Science Department, University of Iowa, Iowa City, IA; Computer Science Department, University of Iowa, Iowa City, IA","IEEE Transactions on Visualization and Computer Graphics","27 Jan 2017","2017","23","3","1209","1221","Optical motion capture is based on estimating the three-dimensional positions of markers by triangulation from multiple cameras. Successful performance depends on points being visible from at least two cameras and on the accuracy of the triangulation. Triangulation accuracy is strongly related to the positions and orientations of the cameras. Thus, the configuration of the camera network has a critical impact on performance. A poor camera configuration may result in a low quality three-dimensional (3D) estimation and consequently low quality of tracking. This paper introduces and compares two methods for camera placement. The first method is based on a metric that computes target point visibility in the presence of dynamic occlusion from cameras with “good” views. The second method is based on the distribution of views of target points. Efficient algorithms, based on simulated annealing, are introduced for estimating the optimal configuration of cameras for the two metrics and a given distribution of target points. The accuracy and robustness of the algorithms are evaluated through both simulation and empirical measurement. Implementations of the two methods are available for download as tools for the community.","1941-0506","","10.1109/TVCG.2016.2637334","National Science Foundation(grant numbers:BCS-1251694,CNS-1305131); US Department of Transportation; Research and Innovative Technology Administration(grant numbers:20.701,DTRT13-G-UTC53); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778256","Optimization methods;simulated annealing;augmented reality;virtual reality","Cameras;Three-dimensional displays;Tracking;Degradation;Virtual reality;Convergence","cameras;estimation theory;image capture;image motion analysis;simulated annealing","optimal camera placement;optical motion capture system;position estimation;camera network configuration;dynamic occlusion;simulated annealing","","27","","30","IEEE","8 Dec 2016","","","IEEE","IEEE Journals"
"Persuading Visual Attention through Geometry","Y. Kim; A. Varshney","Dept. of Comput. Sci. & UMIACS, Univ. of Maryland, College Park, MD; Dept. of Comput. Sci. & UMIACS, Univ. of Maryland, College Park, MD","IEEE Transactions on Visualization and Computer Graphics","23 May 2008","2008","14","4","772","782","Artists, illustrators, photographers, and cinematographers have long used the principles of contrast and composition to guide visual attention. In this paper, we introduce geometry modification as a tool to persuasively direct visual attention. We build upon recent advances in mesh saliency to develop techniques to alter geometry to elicit greater visual attention. Eye-tracking-based user studies show that our approach successfully guides user attention in a statistically significant manner. Our approach operates directly on geometry and, therefore, produces view-independent results that can be used with existing view-dependent techniques of visual persuasion.","1941-0506","","10.1109/TVCG.2007.70624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4384479","Display algorithms;Geometric algorithms;languages;and systems;Visualization techniques and methodologies;Display algorithms;Geometric algorithms;languages;and systems;Visualization techniques and methodologies","Geometry;Art;Humans;Graphics;Filtering;Pipelines;Painting;Smoothing methods;Layout;Motion measurement","art;mesh generation","visual attention;geometry modification;mesh saliency;visual persuasion","Attention;Awareness;Computer Graphics;Cues;Humans;Photic Stimulation;User-Computer Interface;Visual Perception","27","","57","","23 May 2008","","","IEEE","IEEE Journals"
"Smooth Graphs for Visual Exploration of Higher-Order State Transitions","J. Blaas; C. Botha; E. Grundy; M. Jones; R. Laramee; F. Post","Visualization Group, Delft University of Technology, NL; Visualization Group, Delft University of Technology, NL; Visual Computing Group, Swansea University, UK.; Visual Computing Group, Swansea University, UK.; Visual Computing Group, Swansea University, UK.; Visualization Group, Delft University of Technology, NL","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","969","976","In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.","1941-0506","","10.1109/TVCG.2009.181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290701","State transitions;Graph drawing;Time series;Biological data","Data visualization;Frequency;Clustering algorithms","biology computing;graph theory;splines (mathematics);time series","smooth graphs;higher-order state transitions;state sequences;large observational time series;state-graph exploration methods;splines;biological data","Animals;Behavior, Animal;Cluster Analysis;Computational Biology;Computer Graphics;Databases, Factual;Spheniscidae;Time Factors","27","1","23","","23 Oct 2009","","","IEEE","IEEE Journals"
"TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data","J. Walker; R. Borgo; M. W. Jones",Swansea University; Swansea University; Swansea University,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","549","558","Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques.","1941-0506","","10.1109/TVCG.2015.2467751","Leverhulme(grant numbers:RPG-2013-190); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192735","Time-series Exploration;Focus+Context;Lens;Interaction Techniques;Time-series Exploration;Focus+Context;Lens;Interaction Techniques","Data visualization;Layout;Context;Lenses;Visualization;Rivers;Data mining","data analysis;data visualisation;sensor fusion;time series","Timenotes;chart visualization;interaction techniques;time-series data;sensor data;temporal data set visualization;temporal data set analysis;one-dimensional time-series charts;multiscale representations;frequency based interaction;lens based interaction;Stack Zoom;ChronoLenses","","27","","38","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Visualizing Internet Routing Changes","M. Lad; D. Massey; L. Zhang","Computer Science Department, University of California, Los Angeles, 4531G Boelter Hall, Los Angeles, CA 90095-1596; Computer Science Department, Colorado State University, 1873 Campus Delivery, Fort Collins, CO 80523-1873; Computer Science Department, University of California, Los Angeles, 4531G Boelter Hall, Los Angeles, CA 90095-1596","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1450","1460","Today's Internet provides a global data delivery service to millions of end users and routing protocols play a critical role in this service. It is important to be able to identify and diagnose any problems occurring in Internet routing. However, the Internet's sheer size makes this task difficult. One cannot easily extract out the most important or relevant routing information from the large amounts of data collected from multiple routers. To tackle this problem, we have developed Link-Rank, a tool to visualize Internet routing changes at the global scale. Link-Rank weighs links in a topological graph by the number of routes carried over each link and visually captures changes in link weights in the form of a topological graph with adjustable size. Using Link-Rank, network operators can easily observe important routing changes from massive amounts of routing data, discover otherwise unnoticed routing problems, understand the impact of topological events, and infer root causes of observed routing changes","1941-0506","","10.1109/TVCG.2006.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703366","Network visualization;information visualization;Internet routing;interactive graphics;data analysis;visual mining.","Data visualization;Data mining;Routing protocols;Telecommunication traffic;IP networks;Network topology;Aggregates;Web and internet services;Graphics;Data analysis","data visualisation;Internet;routing protocols","Internet;routing protocol;data visualization;topological graph;network visualization","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Internet;Signal Processing, Computer-Assisted;User-Computer Interface","27","","25","","18 Sep 2006","","","IEEE","IEEE Journals"
"Enhancing Light Fields through Ray-Space Stitching","X. Guo; Z. Yu; S. B. Kang; H. Lin; J. Yu","Department of Computer and Information Sciences, University of Delaware, Newark, DE; Adobe Systems Inc, CA; Microsoft Research, Redmond, WA; Department of Computer and Information Sciences, University of Delaware, Newark, DE; Department of Computer and Information Sciences, University of Delaware, Newark, DE","IEEE Transactions on Visualization and Computer Graphics","25 May 2016","2016","22","7","1852","1861","Light fields (LFs) have been shown to enable photorealistic visualization of complex scenes. In practice, however, an LF tends to have a relatively small angular range or spatial resolution, which limits the scope of virtual navigation. In this paper, we show how seamless virtual navigation can be enhanced by stitching multiple LFs. Our technique consists of two key components: LF registration and LF stitching. To register LFs, we use what we call the ray-space motion matrix (RSMM) to establish pairwise ray-ray correspondences. Using Plücker coordinates, we show that the RSMM is a 5 x 6 matrix, which reduces to a 5 x 5 matrix under pure translation and/or in-plane rotation. The final LF stitching is done using multi-resolution, high-dimensional graph-cut in order to account for possible scene motion, imperfect RSMM estimation, and/or undersampling. We show how our technique allows us to create LFs with various enhanced features: extended horizontal and/or vertical field-of-view, larger synthetic aperture and defocus blur, and larger parallax.","1941-0506","","10.1109/TVCG.2015.2476805","National Science Foundation(grant numbers:IIS-CAREER-0845268,IIS-1218156); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244244","Light field enhancement;image based rendering;Light field enhancement;image based rendering","Cameras;Spatial resolution;Rendering (computer graphics);Estimation;Apertures;Visualization;Feature extraction","data visualisation;feature extraction;image enhancement;image motion analysis;rendering (computer graphics)","light field enhancement;ray-space stitching;photorealistic visualization;seamless virtual navigation;LF registration component;LF stitching component;ray-space motion matrix;RSMM;pairwise ray-ray correspondences;Plucker coordinates;multiresolution high-dimensional graph-cut;scene motion;imperfect RSMM estimation","","26","","43","IEEE","7 Sep 2015","","","IEEE","IEEE Journals"
"Interactive visualization of state transition systems","F. van Ham; H. van de Wetering; J. J. van Wijk","Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands; Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands; Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2002","2002","8","4","319","329","A new method for the visualization of state transition systems is presented. Visual information is reduced by clustering nodes, forming a tree structure of related clusters. This structure is visualized in three dimensions with concepts from cone trees and emphasis on symmetry. A number of interactive options are provided as well, allowing the user to superimpose detail information on this tree structure. The resulting visualization enables the user to relate features in the visualization of the state transition graph to semantic concepts in the corresponding process and vice versa.","1941-0506","","10.1109/TVCG.2002.1044518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044518","","Visualization;State-space methods;Tree data structures;Tree graphs;Space technology;Performance analysis;Testing;System recovery;Optimized production technology","data visualisation;trees (mathematics)","interactive visualization;state transition systems;visual information;node clustering;tree structure;3D visualization;cone trees;symmetry;detail information superimposition;state transition graph;semantic concepts","","26","2","15","IEEE","10 Dec 2002","","","IEEE","IEEE Journals"
"Surface Extraction from Multi-field Particle Volume Data Using Multi-dimensional Cluster Visualization","L. Linsen; T. Van Long; P. Rosenthal; S. Rosswog",Jacobs University; Jacobs University; Jacobs University; Jacobs University,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1483","1490","Data sets resulting from physical simulations typically contain a multitude of physical variables. It is, therefore, desirable that visualization methods take into account the entire multi-field volume data rather than concentrating on one variable. We present a visualization approach based on surface extraction from multi-field particle volume data. The surfaces segment the data with respect to the underlying multi-variate function. Decisions on segmentation properties are based on the analysis of the multi-dimensional feature space. The feature space exploration is performed by an automated multi-dimensional hierarchical clustering method, whose resulting density clusters are shown in the form of density level sets in a 3D star coordinate layout. In the star coordinate layout, the user can select clusters of interest. A selected cluster in feature space corresponds to a segmenting surface in object space. Based on the segmentation property induced by the cluster membership, we extract a surface from the volume data. Our driving applications are smoothed particle hydrodynamics (SPH) simulations, where each particle carries multiple properties. The data sets are given in the form of unstructured point-based volume data. We directly extract our surfaces from such data without prior resampling or grid generation. The surface extraction computes individual points on the surface, which is supported by an efficient neighborhood computation. The extracted surface points are rendered using point-based rendering operations. Our approach combines methods in scientific visualization for object-space operations with methods in information visualization for feature-space operations.","1941-0506","","10.1109/TVCG.2008.167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658166","Index Terms—;Multi-field and multi-variate visualization;isosurfaces and surface extraction;point-based visualization;star coordinates;visualization in astrophysics;particle simulations.","Data mining;Data visualization;Hydrodynamics;Computational modeling;Astrophysics;Interpolation;Sampling methods;Space exploration;Clustering methods;Level set","astronomy computing;data visualisation;feature extraction;pattern clustering;rendering (computer graphics)","surface extraction;multifield particle volume data visualization;multidimensional cluster visualization;astrophysical simulation;multivariate function;surface segmentation;multidimensional feature space exploration;automated multidimensional hierarchical clustering method;3D star coordinate layout;smoothed particle hydrodynamic simulation;point-based rendering;scientific visualization;information visualization;object-space operation","","26","","49","","24 Oct 2008","","","IEEE","IEEE Journals"
"ThemeDelta: Dynamic Segmentations over Temporal Topic Models","S. Gad; W. Javed; S. Ghani; N. Elmqvist; T. Ewing; K. N. Hampton; N. Ramakrishnan","Virginia Tech, Blacksburg, VA, USA; General Electric, San Ramon, USA; KACST GIS Technology Innovation Center, Umm Al-Qura University, Makkah, Saudi Arabia; University of Maryland, College Park, MD, USA; Virginia Tech, Blacksburg, VA, USA; Rutgers University, New Brunswick, NJ, USA; Virginia Tech, Blacksburg, VA, USA","IEEE Transactions on Visualization and Computer Graphics","25 Mar 2015","2015","21","5","672","685","We present ThemeDelta, a visual analytics system for extracting and visualizing temporal trends, clustering, and reorganization in time-indexed textual datasets. ThemeDelta is supported by a dynamic temporal segmentation algorithm that integrates with topic modeling algorithms to identify change points where significant shifts in topics occur. This algorithm detects not only the clustering and associations of keywords in a time period, but also their convergence into topics (groups of keywords) that may later diverge into new groups. The visual representation of ThemeDelta uses sinuous, variable-width lines to show this evolution on a timeline, utilizing color for categories, and line width for keyword strength. We demonstrate how interaction with ThemeDelta helps capture the rise and fall of topics by analyzing archives of historical newspapers, of U.S. presidential campaign speeches, and of social messages collected through iNeighbors, a web-based social website. ThemeDelta is evaluated using a qualitative expert user study involving three researchers from rhetoric and history using the historical newspapers corpus.","1941-0506","","10.1109/TVCG.2014.2388208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001093","Language models;time-series segmentation;text analytics;visual representations;Language models;time-series segmentation;text analytics;visual representations","Market research;Data visualization;Tag clouds;Layout;Visual analytics;Heuristic algorithms","data analysis;text analysis;Web sites","US presidential campaign speeches;historical newspapers;Web-based social Website;iNeighbors;keyword strength;topic modeling algorithms;dynamic temporal segmentation algorithm;time-indexed textual datasets;ThemeDelta;visual analytics system;temporal topic models","","26","","49","IEEE","1 Jan 2015","","","IEEE","IEEE Journals"
"Yet Faster Ray-Triangle Intersection (Using SSE4)","J. Havel; A. Herout","Brno University of Technology, Brno; Brno University of Technology, Brno","IEEE Transactions on Visualization and Computer Graphics","11 Mar 2010","2010","16","3","434","438","Ray-triangle intersection is an important algorithm, not only in the field of realistic rendering (based on ray tracing) but also in physics simulation, collision detection, modeling, etc. Obviously, the speed of this well-defined algorithm's implementations is important because calls to such a routine are numerous in rendering and simulation applications. Contemporary fast intersection algorithms, which use SIMD instructions, focus on the intersection of ray packets against triangles. For intersection between single rays and triangles, operations such as horizontal addition or dot product are required. The SSE4 instruction set adds the dot product instruction which can be used for this purpose. This paper presents a new modification of the fast ray-triangle intersection algorithms commonly used, which—when implemented on SSE4—outperforms the current state-of-the-art algorithms. It also allows both a single ray and ray packet intersection calculation with the same precomputed data. The speed gain measurements are described and discussed in the paper.","1941-0506","","10.1109/TVCG.2009.73","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5159346","Ray tracing;geometric algorithms.","Equations;Ray tracing;Layout;Physics;Gain measurement;Graphics;Rendering (computer graphics);Object detection;Time factors;Instruction sets","parallel processing;ray tracing;rendering (computer graphics)","faster ray-triangle intersection;realistic rendering;ray tracing;collision detection;contemporary fast intersection algorithms;SIMD instructions;dot product instruction;speed gain measurements","Algorithms;Computer Simulation;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Light;Models, Theoretical;Programming Languages;Scattering, Radiation;Software","26","3","6","IEEE","7 Jul 2009","","","IEEE","IEEE Journals"
"A Generative Model for Volume Rendering","M. Berger; J. Li; J. A. Levine","Department of Computer Science, University of Arizona, Tucson, AZ; Department of Computer Science, University of Arizona, Tucson, AZ; Department of Computer Science, University of Arizona, Tucson, AZ","IEEE Transactions on Visualization and Computer Graphics","28 Feb 2019","2019","25","4","1636","1650","We present a technique to synthesize and analyze volume-rendered images using generative models. We use the Generative Adversarial Network (GAN) framework to compute a model from a large collection of volume renderings, conditioned on (1) viewpoint and (2) transfer functions for opacity and color. Our approach facilitates tasks for volume analysis that are challenging to achieve using existing rendering techniques such as ray casting or texture-based methods. We show how to guide the user in transfer function editing by quantifying expected change in the output image. Additionally, the generative model transforms transfer functions into a view-invariant latent space specifically designed to synthesize volume-rendered images. We use this space directly for rendering, enabling the user to explore the space of volume-rendered images. As our model is independent of the choice of volume rendering process, we show how to analyze volume-rendered images produced by direct and global illumination lighting, for a variety of volume datasets.","1941-0506","","10.1109/TVCG.2018.2816059","US National Science Foundation(grant numbers:IIS-1654221); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316963","Volume rendering;generative models;deep learning;generative adversarial networks","Rendering (computer graphics);Transfer functions;Solid modeling;Gallium nitride;Image color analysis;Computational modeling;Sensitivity","image colour analysis;rendering (computer graphics);transfer functions","volume rendering process;generative adversarial network framework;GAN framework;volume-rendered image analysis;ray casting;texture-based methods;transfer function;view-invariant latent space;volume-rendered image synthesis;global illumination lighting;direct illumination lighting;generative model transforms transfer functions","","25","","53","IEEE","15 Mar 2018","","","IEEE","IEEE Journals"
"An Adaptive Correspondence Algorithm for Modeling Scenes with Strong Interreflections","Y. Xu; D. G. Aliaga","Purdue University, West Lafayette; Purdue University, West Lafayette","IEEE Transactions on Visualization and Computer Graphics","16 Mar 2009","2009","15","3","465","480","Modeling real-world scenes, beyond diffuse objects, plays an important role in computer graphics, virtual reality, and other commercial applications. One active approach is projecting binary patterns in order to obtain correspondence and reconstruct a densely sampled 3D model. In such structured-light systems, determining whether a pixel is directly illuminated by the projector is essential to decoding the patterns. When a scene has abundant indirect light, this process is especially difficult. In this paper, we present a robust pixel classification algorithm for this purpose. Our method correctly establishes the lower and upper bounds of the possible intensity values of an illuminated pixel and of a non-illuminated pixel. Based on the two intervals, our method classifies a pixel by determining whether its intensity is within one interval but not in the other. Our method performs better than standard method due to the fact that it avoids gross errors during decoding process caused by strong inter-reflections. For the remaining uncertain pixels, we apply an iterative algorithm to reduce the inter-reflection within the scene. Thus, more points can be decoded and reconstructed after each iteration. Moreover, the iterative algorithm is carried out in an adaptive fashion for fast convergence.","1941-0506","","10.1109/TVCG.2008.97","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4569840","Computer Graphics;Three-Dimensional Graphics and Realism;Digitization and Image Capture;Imaging geometry;Computer Graphics;Three-Dimensional Graphics and Realism;Digitization and Image Capture;Imaging geometry","Layout;Iterative decoding;Iterative algorithms;Computer graphics;Virtual reality;Application software;Robustness;Classification algorithms;Upper bound;Convergence","iterative methods;natural scenes;pattern classification","adaptive correspondence algorithm;real-world scene modeling;binary patterns;robust pixel classification;iterative algorithm","Algorithms;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Light;Lighting;Models, Theoretical;Reproducibility of Results;Scattering, Radiation;Sensitivity and Specificity;User-Computer Interface","25","6","34","IEEE","16 Mar 2009","","","IEEE","IEEE Journals"
"Compatible Embedding for 2D Shape Animation","W. V. Baxter III; P. Barla; K. -i. Anjyo","OLM Digital, Inc., Tokyo; INRIA Bordeau University, France; OLM Digital, Inc., Tokyo","IEEE Transactions on Visualization and Computer Graphics","17 Jul 2009","2009","15","5","867","879","We present new algorithms for the compatible embedding of 2D shapes. Such embeddings offer a convenient way to interpolate shapes having complex, detailed features. Compared to existing techniques, our approach requires less user input, and is faster, more robust, and simpler to implement, making it ideal for interactive use in practical applications. Our new approach consists of three parts. First, our boundary matching algorithm locates salient features using the perceptually motivated principles of scale-space and uses these as automatic correspondences to guide an elastic curve matching algorithm. Second, we simplify boundaries while maintaining their parametric correspondence and the embedding of the original shapes. Finally, we extend the mapping to shapes' interiors via a new compatible triangulation algorithm. The combination of our algorithms allows us to demonstrate 2D shape interpolation with instant feedback. The proposed algorithms exhibit a combination of simplicity, speed, and accuracy that has not been achieved in previous work.","1941-0506","","10.1109/TVCG.2009.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815232","Matching;interpolation;morphing;in-betweening;cross-parameterization;multiscale analysis;scale-space;compatible triangulation.","Shape;Animation;Robustness;Interpolation;Feedback;Character generation;Production;Graphics;Layout;Clouds","computer animation;curve fitting;interpolation","2D shape animation;compatible embedding;boundary matching algorithm;salient feature;elastic curve matching algorithm;compatible triangulation algorithm;2D shape interpolation","","25","2","48","IEEE","17 Apr 2009","","","IEEE","IEEE Journals"
"Graph Signatures for Visual Analytics","Pak Chung Wong; H. Foote; G. Chin; P. Mackey; K. Perrine","Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1399","1413","We present a visual analytics technique to explore graphs using the concept of a data signature. A data signature, in our context, is a multidimensional vector that captures the local topology information surrounding each graph node. Signature vectors extracted from a graph are projected onto a low-dimensional scatterplot through the use of scaling. The resultant scatterplot, which reflects the similarities of the vectors, allows analysts to examine the graph structures and their corresponding real-life interpretations through repeated use of brushing and linking between the two visualizations. The interpretation of the graph structures is based on the outcomes of multiple participatory analysis sessions with intelligence analysts conducted by the authors at the Pacific Northwest National Laboratory. The paper first uses three public domain data sets with either well-known or obvious features to explain the rationale of our design and illustrate its results. More advanced examples are then used in a customized usability study to evaluate the effectiveness and efficiency of our approach. The study results reveal not only the limitations and weaknesses of the traditional approach based solely on graph visualization, but also the advantages and strengths of our signature-guided approach presented in the paper.","1941-0506","","10.1109/TVCG.2006.92","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703362","Data and knowledge visualization;information visualization;visualization techniques and methodologies;graphs and networks.","Visual analytics;Network topology;Scattering;Joining processes;Multidimensional systems;Data mining;Data visualization;Intelligent structures;Usability;Terminology","data visualisation;graph theory","Data and knowledge visualization;information visualization;visualization techniques and methodologies;graphs and networks.","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Pattern Recognition, Automated;User-Computer Interface","25","1","38","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"Mesh Layouts for Block-Based Caches","S. Yoon; P. Lindstrom",Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1213","1220","Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy","1941-0506","","10.1109/TVCG.2006.162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015484","Mesh and graph layouts;cache-aware and cache-oblivious layouts;metrics for cache coherence;data locality.","Data visualization;Computer architecture;Application software;Isosurfaces;Data mining;Delay;Spatial coherence;Optimizing compilers;Pattern matching;Strips","cache storage;computational geometry;data visualisation;interactive systems;mesh generation","mesh layouts;block-based caches;computer architectures;block fetching;uncached data element;cache-aware layouts;cache-oblivious layouts;volume meshes;interactive visualization;geometric processing algorithms;unstructured meshes;isosurface extraction;view-dependent rendering","","25","","32","","20 Nov 2006","","","IEEE","IEEE Journals"
"Obliq-3D: a high-level, fast-turnaround 3D animation system","M. A. Najork; M. H. Brown","Syst. Res. Center, Digital Equipment Corp., Palo Alto, CA, USA; Syst. Res. Center, Digital Equipment Corp., Palo Alto, CA, USA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","2","175","193","Describes Obliq-3D, a high-level, fast-turnaround system for building 3D animations. Obliq-3D consists of an interpreted language that is embedded into a 3D animation library. This library is based on a few simple, yet powerful constructs that allow programmers to describe 3D scenes and animations of such scenes. By virtue of its interpretive nature, Obliq-3D provides a fast-turnaround environment. The combination of simplicity and fast turnaround allows programmers to construct nontrivial animations quickly and easily. The paper is divided into three major parts. The first part introduces the basic concepts of Obliq-3D, using a series of graduated examples. The second part shows how the system can be used to implement cone trees. The third part develops a complete animation of Dijkstra's (1959) shortest-path algorithm.<<ETX>></ETX>","1941-0506","","10.1109/2945.468402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468402","","Animation;Visualization;Software libraries;Layout;Tree graphs;Programming profession;Computer graphics;Instruments;LAN interconnection;Algorithm design and analysis","computer animation;solid modelling;tree data structures;software libraries;authoring languages","Obliq-3D;high-level fast-turnaround 3D animation system;interpreted language;3D animation library;3D scene description;cone trees;shortest-path algorithm;3D graphics;information visualization;algorithm animation;scripting language;embedded language","","25","5","33","","6 Aug 2002","","","IEEE","IEEE Journals"
"Octree-R: an adaptive octree for efficient ray tracing","Kyu-Young Whang; Ju-Won Song; Ji-Woong Chang; Ji-Yun Kim; Wan-Sup Cho; Chong-Mok Park; Il-Yeol Song","Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Seoul, South Korea; Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Seoul, South Korea; Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Seoul, South Korea; Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Seoul, South Korea; Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Seoul, South Korea; Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Seoul, South Korea; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","4","343","349","Ray tracing requires many ray-object intersection tests. A way of reducing the number of ray-object intersection tests is to subdivide the space occupied by objects into many nonoverlapping subregions, called voxels, and to construct an octree for the subdivided space. We propose the Octree-R, an octree-variant data structure for efficient ray tracing. The algorithm for constructing the Octree-R first estimates the number of ray-object intersection tests. Then, it partitions the space along the plane that minimizes the estimated number of ray-object intersection tests. We present the results of experiments for verifying the effectiveness of the Octree-R. In the experiment, the Octree-R provides a 4% to 47% performance gain over the conventional octree. The result shows the more skewed the object distribution (as is typical for real data), the more performance gain the Octree-R achieves.","1941-0506","","10.1109/2945.485621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485621","","Ray tracing;Testing;Layout;Performance gain;Data structures;Partitioning algorithms;Computational modeling;Performance evaluation;Shape;Computer science","octrees;ray tracing;rendering (computer graphics)","Octree-R;adaptive octree;ray tracing;ray-object intersection tests;voxels;octree-variant data structure;performance;object distribution","","25","","17","","6 Aug 2002","","","IEEE","IEEE Journals"
"Random-Accessible Compressed Triangle Meshes","S. Yoon; P. Lindstrom",Korea Advanced Institute of Science and Technology (KAIST); Lawrence Livermore National Laboratory,"IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1536","1543","With the exponential growth in size of geometric data, it is becoming increasingly important to make effective use of multilevel caches, limited disk storage, and bandwidth. As a result, recent work in the visualization community has focused either on designing sequential access compression schemes or on producing cache-coherent layouts of (uncompressed) meshes for random access. Unfortunately combining these two strategies is challenging as they fundamentally assume conflicting modes of data access. In this paper, we propose a novel order-preserving compression method that supports transparent random access to compressed triangle meshes. Our decompression method selectively fetches from disk, decodes, and caches in memory requested parts of a mesh. We also provide a general mesh access API for seamless mesh traversal and incidence queries. While the method imposes no particular mesh layout, it is especially suitable for cache-oblivious layouts, which minimize the number of decompression I/O requests and provide high cache utilization during access to decompressed, in-memory portions of the mesh. Moreover, the transparency of our scheme enables improved performance without the need for application code changes. We achieve compression rates on the order of 20:1 and significantly improved I/O performance due to reduced data transfer. To demonstrate the benefits of our method, we implement two common applications as benchmarks. By using cache-oblivious layouts for the input models, we observe 2-6 times overall speedup compared to using uncompressed meshes.","1941-0506","","10.1109/TVCG.2007.70585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376184","Mesh compression;random access;cache-coherent layouts;mesh data structures;external memory algorithms","Bandwidth;Data visualization;Data structures;Memory management;Delay;Space technology;Cache storage;Decoding;Computer displays;Computational modeling","application program interfaces;cache storage;computational geometry;mesh generation","cache-oblivious layout;data transfer;I/O request;API;novel order-preserving compression method;cache-coherent layout;sequential access compression scheme;disk storage;multilevel cache;random-accessible compressed triangle mesh","","25","1","44","","5 Nov 2007","","","IEEE","IEEE Journals"
"Refilming with Depth-Inferred Videos","G. Zhang; Z. Dong; J. Jia; L. Wan; T. Wong; H. Bao","Zhejiang University, Hangzhou; Zhejiang University, Hangzhou; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; Zhejiang University, Hangzhou","IEEE Transactions on Visualization and Computer Graphics","17 Jul 2009","2009","15","5","828","840","Compared to still image editing, content-based video editing faces the additional challenges of maintaining the spatiotemporal consistency with respect to geometry. This brings up difficulties of seamlessly modifying video content, for instance, inserting or removing an object. In this paper, we present a new video editing system for creating spatiotemporally consistent and visually appealing refilming effects. Unlike the typical filming practice, our system requires no labor-intensive construction of 3D models/surfaces mimicking the real scene. Instead, it is based on an unsupervised inference of view-dependent depth maps for all video frames. We provide interactive tools requiring only a small amount of user input to perform elementary video content editing, such as separating video layers, completing background scene, and extracting moving objects. These tools can be utilized to produce a variety of visual effects in our system, including but not limited to video composition, ""predatorrdquo effect, bullet-time, depth-of-field, and fog synthesis. Some of the effects can be achieved in real time.","1941-0506","","10.1109/TVCG.2009.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906990","Video editing;refilming;depth estimation;composition;background completion;layer separation.","Videos;Geometry;Spatiotemporal phenomena;Solid modeling;Layout;Visual effects;Sprites (computer);Data mining;Multimedia communication","feature extraction;video signal processing","depth-inferred videos;still image editing;content-based video editing;moving object extraction","","25","1","32","","2 May 2009","","","IEEE","IEEE Journals"
"VIGOR: Interactive Visual Exploration of Graph Query Results","R. Pienta; F. Hohman; A. Endert; A. Tamersoy; K. Roundy; C. Gates; S. Navathe; D. H. Chau",NA; NA; NA; NA; NA; NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","215","225","Finding patterns in graphs has become a vital challenge in many domains from biological systems, network security, to finance (e.g., finding money laundering rings of bankers and business owners). While there is significant interest in graph databases and querying techniques, less research has focused on helping analysts make sense of underlying patterns within a group of subgraph results. Visualizing graph query results is challenging, requiring effective summarization of a large number of subgraphs, each having potentially shared node-values, rich node features, and flexible structure across queries. We present VIGOR, a novel interactive visual analytics system, for exploring and making sense of query results. VIGOR uses multiple coordinated views, leveraging different data representations and organizations to streamline analysts sensemaking process. VIGOR contributes: (1) an exemplar-based interaction technique, where an analyst starts with a specific result and relaxes constraints to find other similar results or starts with only the structure (i.e., without node value constraints), and adds constraints to narrow in on specific results; and (2) a novel feature-aware subgraph result summarization. Through a collaboration with Symantec, we demonstrate how VIGOR helps tackle real-world problems through the discovery of security blindspots in a cybersecurity dataset with over 11,000 incidents. We also evaluate VIGOR with a within-subjects study, demonstrating VIGOR's ease of use over a leading graph database management system, and its ability to help analysts understand their results at higher speed and make fewer errors.","1941-0506","","10.1109/TVCG.2017.2744898","NSF IGERT(grant numbers:1258425); NSF(grant numbers:IIS-1563816,TWC-1526254,IIS-1217559); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019832","graph querying;subgraph results;query result visualization","Data visualization;Logic gates;Computer security;Database systems;Data mining;Visualization","data mining;data structures;database management systems;graph theory;query processing","interaction technique;node value constraints;leading graph database management system;interactive visual exploration;graph query results;biological systems;graph databases;potentially shared node-values;interactive visual analytics system;analyst sensemaking process;feature-aware subgraph result summarization;VIGOR","","25","","49","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"VoxSegNet: Volumetric CNNs for Semantic Part Segmentation of 3D Shapes","Z. Wang; F. Lu","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2020","2020","26","9","2919","2930","Volumetric representation has been widely used for 3D deep learning in shape analysis due to its generalization ability and regular data format. However, for fine-grained tasks like part segmentation, volumetric data has not been widely adopted compared to other representations. Aiming at delivering an effective volumetric method for 3D shape part segmentation, this paper proposes a novel volumetric convolutional neural network. Our method can extract discriminative features encoding detailed information from voxelized 3D data under limited resolution. To this purpose, a spatial dense extraction (SDE) module is designed to preserve spatial resolution during feature extraction procedure, alleviating the loss of details caused by sub-sampling operations such as max pooling. An attention feature aggregation (AFA) module is also introduced to adaptively select informative features from different abstraction levels, leading to segmentation with both semantic consistency and high accuracy of details. Experimental results demonstrate that promising results can be achieved by using volumetric data, with part segmentation accuracy comparable or superior to state-of-the-art non-volumetric methods.","1941-0506","","10.1109/TVCG.2019.2896310","National Natural Science Foundation of China(grant numbers:61602020,61732016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629927","Shape analysis;semantic segmentation;convolutional neural networks;volumetric models","Three-dimensional displays;Feature extraction;Shape;Semantics;Convolution;Data mining;Task analysis","convolutional neural nets;feature extraction;image representation;image segmentation;learning (artificial intelligence);object recognition","nonvolumetric methods;semantic consistency;informative features;attention feature aggregation module;feature extraction procedure;spatial resolution;spatial dense extraction module;voxelized 3D data;discriminative features;volumetric convolutional neural network;3D shape part segmentation;volumetric data;fine-grained tasks;regular data format;generalization ability;shape analysis;3D deep learning;volumetric representation;3D shapes;semantic part segmentation;volumetric CNN","","25","","49","IEEE","30 Jan 2019","","","IEEE","IEEE Journals"
"BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence","X. Yue; X. Shu; X. Zhu; X. Du; Z. Yu; D. Papadopoulos; S. Liu",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Penn State University,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","162","171","The emerging prosperity of cryptocurrencies, such as Bitcoin, has come into the spotlight during the past few years. Cryptocurrency exchanges, which act as the gateway to this world, now play a dominant role in the circulation of Bitcoin. Thus, delving into the analysis of the transaction patterns of exchanges can shed light on the evolution and trends in the Bitcoin market, and participants can gain hints for identifying credible exchanges as well. Not only Bitcoin practitioners but also researchers in the financial domains are interested in the business intelligence behind the curtain. However, the task of multiple exchanges exploration and comparisons has been limited owing to the lack of efficient tools. Previous methods of visualizing Bitcoin data have mainly concentrated on tracking suspicious transaction logs, but it is cumbersome to analyze exchanges and their relationships with existing tools and methods. In this paper, we present <italic>BitExTract</italic>, an interactive visual analytics system, which, to the best of our knowledge, is the first attempt to explore the evolutionary transaction patterns of Bitcoin exchanges from two perspectives, namely, exchange versus exchange and exchange versus client. In particular, <italic>BitExTract</italic> summarizes the evolution of the Bitcoin market by observing the transactions between exchanges over time via a massive sequence view. A node-link diagram with ego-centered views depicts the trading network of exchanges and their temporal transaction distribution. Moreover, <italic>BitExTract</italic> embeds multiple parallel bars on a timeline to examine and compare the evolution patterns of transactions between different exchanges. Three case studies with novel insights demonstrate the effectiveness and usability of our system.","1941-0506","","10.1109/TVCG.2018.2864814","RGC GRF(grant numbers:16208514); NFSC(grant numbers:61572488,61673241); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440044","Bitcoin exchange;transaction data;comparative analysis;visual analytics;FinTech","Bitcoin;Data visualization;Visualization;Task analysis;Tools","competitive intelligence;data analysis;data visualisation;electronic money;financial data processing;transaction processing","interactive visual analytics system;evolutionary transaction patterns;exchange versus exchange;exchange versus client;Bitcoin market;interactive visualization;bitcoin exchange intelligence;cryptocurrency exchanges;Bitcoin practitioners;multiple exchanges exploration;Bitcoin data visualization;financial domains;business intelligence;BitExTract;massive sequence view;node-link diagram;ego-centered views","","24","","50","IEEE","19 Aug 2018","","","IEEE","IEEE Journals"
"CUBu: Universal Real-Time Bundling for Large Graphs","M. van der Zwan; V. Codreanu; A. Telea","University of Groningen, The Netherlands; SURFsara, Amsterdam, The Netherlands; University of Groningen, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2016","2016","22","12","2550","2563","Visualizing very large graphs by edge bundling is a promising method, yet subject to several challenges: speed, clutter, level-of-detail, and parameter control. We present CUBu, a framework that addresses the above problems in an integrated way. Fully GPU-based, CUBu bundles graphs of up to a million edges at interactive framerates, being over 50 times faster than comparable state-of-the-art methods, and has a simple and intuitive control of bundling parameters. CUBu extends and unifies existing bundling techniques, offering ways to control bundle shapes, separate bundles by edge direction, and shade bundles to create a level-of-detail visualization that shows both the graph core structure and its details. We demonstrate CUBu on several large graphs extracted from real-life application domains.","1941-0506","","10.1109/TVCG.2016.2515611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7374742","Computing methodologies: computer graphics-picture/image generation;Computing methodologies: Computer graphics-methodology and techniques","Image edge detection;Computer graphics;Real-time systems;Scalability;Graphics processing units;Scattering","computational geometry;data visualisation;edge detection;parallel architectures","CUBu bundled image;CUDA-based universal bundling;universal real-time bundling;large graphs visualization;speed;clutter;level-of-detail;parameter control;interactive framerates;intuitive control;bundling parameters;edge direction;graph core structure;computational scalability;bundles geometry","","24","","54","IEEE","7 Jan 2016","","","IEEE","IEEE Journals"
"Coherent Time-Varying Graph Drawing with Multifocus+Context Interaction","K. Feng; C. Wang; H. Shen; T. Lee","National Cheng Kung University, Tainan; Michigan Technological University, Houghton; The Ohio State University, Columbus; National Cheng Kung University, Tainan","IEEE Transactions on Visualization and Computer Graphics","11 Jun 2012","2012","18","8","1330","1342","We present a new approach for time-varying graph drawing that achieves both spatiotemporal coherence and multifocus+context visualization in a single framework. Our approach utilizes existing graph layout algorithms to produce the initial graph layout, and formulates the problem of generating coherent time-varying graph visualization with the focus+context capability as a specially tailored deformation optimization problem. We adopt the concept of the super graph to maintain spatiotemporal coherence and further balance the needs for aesthetic quality and dynamic stability when interacting with time-varying graphs through focus+context visualization. Our method is particularly useful for multifocus+context visualization of time-varying graphs where we can preserve the mental map by preventing nodes in the focus from undergoing abrupt changes in size and location in the time sequence. Experiments demonstrate that our method strikes a good balance between maintaining spatiotemporal coherence and accentuating visual foci, thus providing a more engaging viewing experience for the users.","1941-0506","","10.1109/TVCG.2011.128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963661","Graph drawing;time-varying graphs;spatiotemporal coherence;focus+context visualization.","Layout;Visualization;Context;Heuristic algorithms;Coherence;Data visualization;Spatiotemporal phenomena","graph theory;optimisation","coherent time-varying graph drawing;multifocus+context interaction;spatiotemporal coherence;multifocus+context visualization;graph layout algorithms;coherent time-varying graph visualization;focus+context capability;deformation optimization problem;aesthetic quality;dynamic stability;focus+context visualization;visual foci","","24","","32","","28 Jul 2011","","","IEEE","IEEE Journals"
"Conveying shape with texture: experimental investigations of texture's effects on shape categorization judgments","S. Kim; H. Hagh-Shenas; V. Interrante","Dept. of Comput. Sci. & Eng., Minnesota Univ., Minneapolis, MN, USA; Dept. of Comput. Sci. & Eng., Minnesota Univ., Minneapolis, MN, USA; Dept. of Comput. Sci. & Eng., Minnesota Univ., Minneapolis, MN, USA","IEEE Transactions on Visualization and Computer Graphics","18 May 2004","2004","10","4","471","483","We describe the results of two comprehensive controlled observer experiments intended to yield insight into the following question: If we could design the ideal texture pattern to apply to an arbitrary smoothly curving surface in order to enable its 3D shape to be most accurately and effectively perceived, what would the characteristics of that texture pattern be? We begin by reviewing the results of our initial study in this series, which were presented at the 2003 IEEE Symposium on Information Visualization, and offer an expanded analysis of those findings. We continue by presenting the results of a follow-on study in which we sought to more specifically investigate the separate and combined influences on shape perception of particular texture components, with the goal of obtaining a clearer view of their potential information carrying capacities. In each study, we investigated the observers' ability to identify the intrinsic shape category of a surface patch (elliptical, hyperbolic, cylindrical, or flat) and its extrinsic surface orientation (convex, concave, both, or neither). In our first study, we compared performance under eight different texture type conditions, plus two projection conditions (perspective or orthographic) and two viewing conditions (head-on or oblique). We found that: 1) shape perception was better facilitated, in general, by the bidirectional ""principal direction grid"" pattern than by any of the seven other patterns tested; 2) shape type classification accuracy remained high under the orthographic projection condition for some texture types when the viewpoint was oblique; 3) perspective projection was required for accurate surface orientation classification; and 4) shape classification accuracy was higher when the surface patches were oriented at a (generic) oblique angle to the line of sight than when they were oriented (in a nongeneric pose) to face the viewpoint straight on. In our second study, we compared performance under eight new texture type conditions, redesigned to facilitate gathering insight into the cumulative effects of specific individual directional components in a wider variety of multidirectional texture patterns. We found that shape classification accuracy was equivalently good under a variety of test patterns that included components following either the first or first and second principal directions, in addition to other directions, suggesting that a principal direction grid texture is not the only possible ""best option"" for enhancing shape representation.","1941-0506","","10.1109/TVCG.2004.5","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298804","Three-dimensional graphics and realism;vision and scene understanding;shape perception;shape representation;texture;principal directions.","Surface texture;Shape control;Data visualization;Testing;Computer graphics;Computer displays;Information analysis;Layout;Computer vision;Material properties","image texture;surface fitting;data visualisation;pattern classification;image representation;computer vision","image texture;shape categorization judgments;data visualization;surface orientation;bidirectional principal direction grid pattern;shape type classification accuracy;three-dimensional graphics;shape perception;shape representation","Decision Making;Form Perception;Humans;Pattern Recognition, Visual;Task Performance and Analysis","24","","19","","18 May 2004","","","IEEE","IEEE Journals"
"Data-Driven Visualization and Group Analysis of Multichannel EEG Coherence with Functional Units","M. ten Caat; N. M. Maurits; J. B. T. M. Roerdink","BCN Neuroimaging Center, Univ. of Groningen, Groningen; NA; NA","IEEE Transactions on Visualization and Computer Graphics","23 May 2008","2008","14","4","756","771","A typical data-driven visualization of electroencephalography (EEG) coherence is a graph layout, with vertices representing electrodes and edges representing significant coherences between electrode signals. A drawback of this layout is its visual clutter for multichannel EEG. To reduce clutter, we define a functional unit (FU) as a data-driven region of interest (ROI). An FU is a spatially connected set of electrodes recording pairwise significantly coherent signals, represented in the coherence graph by a spatially connected clique. Earlier we presented two methods to detect FUs, a maximal clique based (MCB) method and a more efficient watershed based (WB) method. To reduce the potential over-segmentation of the WB method, we introduce here an improved watershed based (IWB) method. The WB and IWB method both are up to a factor of 100,000 faster than the MCB method for a typical multichannel setting with 128 EEG channels, thus making interactive visualization of multichannel EEG coherence possible. We also introduce here two novel group maps for data-driven group analysis as extensions of the IWB method. Finally, we employ an extensive case study to evaluate the IWB FU map and the two new group maps for data-driven group analysis.","1941-0506","","10.1109/TVCG.2008.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4433991","Applications;Information visualization;Applications;Information visualization","Visualization;Electroencephalography;Electrodes;SQUIDs;Data analysis;Gold;Electric variables measurement;Scalp;Frequency measurement;Frequency synchronization","data visualisation;electrodes;electroencephalography;medical signal processing","data-driven visualization;multichannel EEG coherence;electroencephalography;graph layout;electrode signal;visual clutter;functional unit;region of interest;maximal clique-based method;time complexity;watershed-based method;data-driven group analysis;group mean coherence map","Algorithms;Brain Mapping;Computer Graphics;Databases, Factual;Diagnosis, Computer-Assisted;Electroencephalography;Humans;User-Computer Interface","24","","48","IEEE","23 May 2008","","","IEEE","IEEE Journals"
"Drawing directed graphs using quadratic programming","T. Dwyer; Y. Koren; K. Marriott","Clayton Sch. of Inf. Technol., Monash Univ., Clayton, Vic., Australia; NA; NA","IEEE Transactions on Visualization and Computer Graphics","5 Jun 2006","2006","12","4","536","548","We describe a new method for visualization of directed graphs. The method combines constraint programming techniques with a high performance force-directed placement (FDP) algorithm. The resulting placements highlight hierarchy in directed graphs while retaining useful properties of FDP; such as emphasis of symmetries and preservation of proximity relations. Our algorithm automatically identifies those parts of the digraph that contain hierarchical information and draws them accordingly. Additionally, those parts that do not contain hierarchy are drawn at the same quality expected from a nonhierarchical, undirected layout algorithm. Our experiments show that this new approach is better able to convey the structure of large digraphs than the most widely used hierarchical graph-drawing method. An interesting application of our algorithm is directional multidimensional scaling (DMDS). DMDS deals with low-dimensional embedding of multivariate data where we want to emphasize the overall flow in the data (e.g., chronological progress) along one of the axes.","1941-0506","","10.1109/TVCG.2006.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634319","Directed graphs;graph drawing;hierarchy;force directed algorithms;majorization;quadratic programming.","Quadratic programming;Visualization;Multidimensional systems;Algorithm design and analysis;Application software;Partitioning algorithms","directed graphs;quadratic programming;constraint handling;data visualisation;computational geometry","directed graph visualization;quadratic programming;constraint programming techniques;force-directed placement algorithm;digraph;undirected layout algorithm;directional multidimensional scaling;multivariate data;directed graph drawing","Computer Graphics;Computer Simulation;Data Display;Databases, Factual;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Linear Models;User-Computer Interface","24","1","26","","5 Jun 2006","","","IEEE","IEEE Journals"
"Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations","J. Waser; H. Ribicic; R. Fuchs; C. Hirsch; B. Schindler; G. Bloschl; E. Groller",VRVis Vienna; VRVis Vienna; ETH Zürich; VRVis Vienna; ETH Zürich; TU Vienna; TU Vienna,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","1872","1881","Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.","1941-0506","","10.1109/TVCG.2011.225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064950","Emergency/Disaster Management;Visual Knowledge Discovery;Visualization System and Toolkit Design;Data-Flow;Meta-Flow;Parameter Study;Uncertainty;Visualization of Control.","Data visualization;Navigation;Disaster management;Control systems;Emergency services;Data visualization","data flow computing;data mining;data visualisation;digital simulation;disasters;emergency services;floods;risk management","steering ensemble simulation;flood disaster management;natural risk;flood emergency response strategy;flood simulation;boundary conditions;World Lines interface;steering information transmission;data flow components;meta flow;standard data flow network;abstract parameter control;visual representation;data flow diagram;steering information visualization;virtual city;visual knowledge discovery","","24","1","48","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Occlusion-Free Animation of Driving Routes for Car Navigation Systems","S. Takahashi; K. Yoshida; K. Shimada; T. Nishita","University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa, Chiba, 227-8561, Japan; University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa, Chiba, 227-8561, Japan; Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, U.S.A.; University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa, Chiba, 227-8561, Japan","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1141","1148","This paper presents a method for occlusion-free animation of geographical landmarks, and its application to a new type of car navigation system in which driving routes of interest are always visible. This is achieved by animating a nonperspective image where geographical landmarks such as mountain tops and roads are rendered as if they are seen from different viewpoints. The technical contribution of this paper lies in formulating the nonperspective terrain navigation as an inverse problem of continuously deforming a 3D terrain surface from the 2D screen arrangement of its associated geographical landmarks. The present approach provides a perceptually reasonable compromise between the navigation clarity and visual realism where the corresponding nonperspective view is fully augmented by assigning appropriate textures and shading effects to the terrain surface according to its geometry. An eye tracking experiment is conducted to prove that the present approach actually exhibits visually-pleasing navigation frames while users can clearly recognize the shape of the driving route without occlusion, together with the spatial configuration of geographical landmarks in its neighborhood","1941-0506","","10.1109/TVCG.2006.167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015475","car navigation systems;nonperspective projection;occlusion-free animation;visual perception;temporal coherence","Animation;Navigation;Roads;Layout;Rendering (computer graphics);Inverse problems;Surface texture;Geometry;Shape;Visual perception","computer animation;driver information systems;navigation;solid modelling","occlusion-free driving routes animation;car navigation systems;occlusion-free geographical landmark animation;nonperspective image;nonperspective terrain navigation;continuously deforming inverse problem;3D terrain surface;2D screen arrangement;visually-pleasing navigation frames","","24","3","24","","20 Nov 2006","","","IEEE","IEEE Journals"
"Real-time 3D human capture system for mixed-reality art and entertainment","T. H. D. Nguyen; T. C. T. Qui; K. Xu; A. D. Cheok; S. L. Teo; Z. Y. Zhou; A. Mallawaarachchi; S. P. Lee; W. Liu; H. S. Teo; L. N. Thang; Y. Li; H. Kato","Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; Res. Techno Plaza, Nanyang Technol. Univ., Singapore; NA","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","706","721","A real-time system for capturing humans in 3D and placing them into a mixed reality environment is presented in this paper. Nine cameras surrounding her capture the subject. Looking through a head-mounted-display with a camera in front pointing at a marker, the user can see the 3D image of this subject overlaid onto a mixed reality scene. The 3D images of the subject viewed from this viewpoint are constructed using a robust and fast shape-from-silhouette algorithm. The paper also presents several techniques to produce good quality and speed up the whole system. The frame rate of our system is around 25 fps using only standard Intel processor-based personal computers. Besides a remote live 3D conferencing and collaborating system, we also describe an application of the system in art and entertainment, named Magic Land, which is a mixed reality environment where captured avatars of human and 3D computer generated virtual animations can form an interactive story and play with each other. This system demonstrates many technologies in human computer interaction: mixed reality, tangible interaction, and 3D communication. The result of the user study not only emphasizes the benefits, but also addresses some issues of these technologies.","1941-0506","","10.1109/TVCG.2005.105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512021","Index Terms- 3D viewpoint;mixed reality;tangible interaction;art;entertainment.","Real time systems;Humans;Virtual reality;Art;Cameras;Layout;Robustness;Microcomputers;Collaboration;Application software","real-time systems;virtual reality;human computer interaction;art;computer animation;entertainment;helmet mounted displays;teleconferencing;groupware","real-time 3D human capture system;mixed-reality art;entertainment;head-mounted-display;camera;fast shape-from-silhouette algorithm;Intel processor-based personal computer;remote live 3D conferencing;collaborating system;Magic Land;3D computer generated virtual animation;human computer interaction;tangible interaction;3D communication","Art;Computer Simulation;Computer Systems;Data Display;Environment;Equipment Design;Equipment Failure Analysis;Humans;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Leisure Activities;Man-Machine Systems;Models, Biological;Multimedia;Online Systems;Signal Processing, Computer-Assisted;User-Computer Interface","24","1","33","","26 Sep 2005","","","IEEE","IEEE Journals"
"ViSizer: A Visualization Resizing Framework","Y. Wu; X. Liu; S. Liu; K. Ma","University of California, Davis, Davis; Microsoft Research Asia, Beijing; Microsoft Research Asia, Beijing; University of California, Davis, Davis","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2012","2013","19","2","278","290","Visualization resizing is useful for many applications where users may use different display devices. General resizing techniques (e.g., uniform scaling) and image-resizing techniques suffer from several drawbacks, as they do not consider the content of the visualizations. This work introduces ViSizer, a perception-based framework for automatically resizing a visualization to fit any display. We formulate an energy function based on a perception model (feature congestion), which aims to determine the optimal deformation for every local region. We subsequently transform the problem into an optimization problem by the energy function. An efficient algorithm is introduced to iteratively solve the problem, allowing for automatic visualization resizing.","1941-0506","","10.1109/TVCG.2012.114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189339","Resizing;visualization framework;perception;focus+context;nonlinear least squares optimization","Visualization;Clutter;Data visualization;Optimization;Context;Layout;Ellipsoids","data visualisation;display devices;image processing;least squares approximations;optimisation","ViSizer;visualization resizing framework;display device;general resizing technique;uniform scaling;image-resizing technique;perception-based framework;energy function;perception model;feature congestion;optimal deformation;optimization problem;nonlinear least squares optimization","","24","3","38","","24 Apr 2012","","","IEEE","IEEE Journals"
"Visual Verification and Analysis of Cluster Detection for Molecular Dynamics","S. Grottel; G. Reina; J. Vrabec; T. Ertl","Univ. Stuttgart, Stuttgart; Univ. Stuttgart, Stuttgart; NA; IEEE Computer Society","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1624","1631","A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.","1941-0506","","10.1109/TVCG.2007.70614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376195","Cluster detection analysis;molecular dynamics visualization;time-dependent scattered data;glyph visualization;out-of-core techniques;evolution graph view","Thermodynamics;Turbines;Interactive systems;Clouds;Energy efficiency;Detection algorithms;Data visualization;Metastasis;Energy resolution;Clustering algorithms","molecular dynamics method;nucleation","visual verification;molecular thermodynamics;vapor-liquid condensation;steam turbines;condensation processes;energy efficiency;molecular datasets;nucleation simulations;potential cluster evolution;molecular cluster detection algorithm","Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Chemical;Models, Molecular;Molecular Conformation;Surface Properties","24","","39","","5 Nov 2007","","","IEEE","IEEE Journals"
"Altering User Movement Behaviour in Virtual Environments","A. L. Simeone; I. Mavridou; W. Powell",University of Portsmouth; University of Bournemouth; University of Portsmouth,"IEEE Transactions on Visualization and Computer Graphics","14 Mar 2017","2017","23","4","1312","1321","In immersive Virtual Reality systems, users tend to move in a Virtual Environment as they would in an analogous physical environment. In this work, we investigated how user behaviour is affected when the Virtual Environment differs from the physical space. We created two sets of four environments each, plus a virtual replica of the physical environment as a baseline. The first focused on aesthetic discrepancies, such as a water surface in place of solid ground. The second focused on mixing immaterial objects together with those paired to tangible objects. For example, barring an area with walls or obstacles. We designed a study where participants had to reach three waypoints laid out in such a way to prompt a decision on which path to follow based on the conflict between the mismatching visual stimuli and their awareness of the real layout of the room. We analysed their performances to determine whether their trajectories were altered significantly from the shortest route. Our results indicate that participants altered their trajectories in presence of surfaces representing higher walking difficulty (for example, water instead of grass). However, when the graphical appearance was found to be ambiguous, there was no significant trajectory alteration. The environments mixing immaterial with physical objects had the most impact on trajectories with a mean deviation from the shortest route of 60 cm against the 37 cm of environments with aesthetic alterations. The co-existance of paired and unpaired virtual objects was reported to support the idea that all objects participants saw were backed by physical props. From these results and our observations, we derive guidelines on how to alter user movement behaviour in Virtual Environments.","1941-0506","","10.1109/TVCG.2017.2657038","Research Accelerator Fund of the University of Portsmouth; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835276","Virtual reality;Locomotion;User behaviour","Legged locomotion;Trajectory;Virtual environments;Visualization;Navigation;Tracking","user interfaces;virtual reality","user movement behaviour;virtual environments;immersive virtual reality systems;virtual replica;physical environment;aesthetic discrepancies;visual stimuli","","23","","52","CCBY","26 Jan 2017","","","IEEE","IEEE Journals"
"Correcting interperspective aliasing in autostereoscopic displays","C. N. Moller; A. R. L. Travis","Dept. of Eng., Cambridge Univ., UK; Dept. of Eng., Cambridge Univ., UK","IEEE Transactions on Visualization and Computer Graphics","31 Jan 2005","2005","11","2","228","236","An image presented on an autostereoscopic system should not contain discontinuities between adjacent views. A viewer should experience a continuous scene when moving from one view to the next. If corresponding points in two perspectives do not spatially abut, a viewer will experience jumps in the scene. This is known as interperspective aliasing. Interperspective aliasing is caused by object features far away from the stereoscopic screen being too small, which results in visual artifacts. By modeling a 3D point as a defocused image point, we can adapt Fourier analysis to devise a depth-dependent filter kernel that allows filtering of a stereoscopic 3D image. For synthetic 3D data, we use a simpler approach, which is to smear the data by a distance proportional to its depth","1941-0506","","10.1109/TVCG.2005.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1388233","Index Terms- 3D;autostereoscopic;interperspective aliasing;filter;blurring;smearing.","Layout;Three dimensional displays;Bandwidth;Frequency;Image analysis;Filters;Filtering;Holography;Kernel;Hardware","antialiasing;computer displays;optical filters;stereo image processing","interperspective aliasing;autostereoscopic displays;3D object modeling;Fourier analysis;depth-dependent filter kernel;smearing;image blurring","Algorithms;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Photogrammetry;Sample Size;Signal Processing, Computer-Assisted;User-Computer Interface;Vision, Binocular","23","6","25","","31 Jan 2005","","","IEEE","IEEE Journals"
"Depth-Fused 3D Imagery on an Immaterial Display","C. Lee; S. DiVerdi; T. Hollerer","University of California Santa Barbara, Santa Barbara; University of California Santa Barbara, Santa Barbara; University of California Santa Barbara, Santa Barbara","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2008","2009","15","1","20","33","We present an immaterial display that uses a generalized form of depth-fused 3D (DFD) rendering to create unencumbered 3D visuals. To accomplish this result, we demonstrate a DFD display simulator that extends the established depth-fused 3D principle by using screens in arbitrary configurations and from arbitrary viewpoints. The feasibility of the generalized DFD effect is established with a user study using the simulator. Based on these results, we developed a prototype display using one or two immaterial screens to create an unencumbered 3D visual that users can penetrate, examining the potential for direct walk-through and reach-through manipulation of the 3D scene. We evaluate the prototype system in formative and summative user studies and report the tolerance thresholds discovered for both tracking and projector errors.","1941-0506","","10.1109/TVCG.2008.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4540094","Three-dimensional displays;Virtual reality;Three-dimensional displays;Virtual reality","Three dimensional displays;Design for disassembly;Large screen displays;Prototypes;Layout;Optical scattering;Virtual prototyping;Rendering (computer graphics);Virtual reality;Computer displays","rendering (computer graphics)","depth-fused 3D imagery;immaterial display;rendering;unencumbered 3D visuals;display simulator","Algorithms;Computer Graphics;Data Display;Holography;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;User-Computer Interface","23","35","23","","13 Jun 2008","","","IEEE","IEEE Journals"
"Face to Face: Evaluating Visual Comparison","B. Ondov; N. Jardine; N. Elmqvist; S. Franconeri","National Institutes of Health, MD, USA; Northwestern University, Evanston, IL, USA; University of Maryland, College Park, MD, USA; Northwestern University, Evanston, IL, USA","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","861","871","Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs.","1941-0506","","10.1109/TVCG.2018.2864884","Intramural Research Program of the National Human Genome Research Institute; National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440856","Graphical perception;visual perception;visual comparison;crowdsourced evaluation","Task analysis;Visualization;Data visualization;Correlation;Bars;Layout;Mirrors","computer animation;crowdsourcing;data visualisation;psychology;visual perception","data visualization;visual comparison designs;intuitive reasoning;crowdsourced experiments;juxtaposed small multiples;animated transitions;staircase procedure;perceptual psychology;low-level perceptual comparison tasks;mirror-symmetric small multiples;overlaid layout","","23","","70","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Interactive Animation of 4D Performance Capture","D. Casas; M. Tejera; J. -Y. Guillemaut; A. Hilton","University of Surrey, Guildford; University of Surrey, Guildford; University of Surrey, Guildford; University of Surrey, Guildford","IEEE Transactions on Visualization and Computer Graphics","19 Mar 2013","2013","19","5","762","773","A 4D parametric motion graph representation is presented for interactive animation from actor performance capture in a multiple camera studio. The representation is based on a 4D model database of temporally aligned mesh sequence reconstructions for multiple motions. High-level movement controls such as speed and direction are achieved by blending multiple mesh sequences of related motions. A real-time mesh sequence blending approach is introduced, which combines the realistic deformation of previous nonlinear solutions with efficient online computation. Transitions between different parametric motion spaces are evaluated in real time based on surface shape and motion similarity. Four-dimensional parametric motion graphs allow real-time interactive character animation while preserving the natural dynamics of the captured performance.","1941-0506","","10.1109/TVCG.2012.314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365634","Character animation;3D video;real-time animation;multiview reconstruction;video-based animation;4D modeling;4D performance capture","Animation;Real-time systems;Databases;Aerospace electronics;Interpolation;Mesh generation;Shape","computer animation;data visualisation;image motion analysis;image representation;solid modelling","interactive animation;4D performance capture;4D parametric motion graph representation;actor performance capture;multiple camera studio;4D model database;mesh sequence reconstruction;high-level movement control;mesh sequence blending approach;parametric motion space;surface shape;motion similarity;four-dimensional parametric motion graph;real-time interactive character animation;natural dynamics","Algorithms;Artificial Intelligence;Computer Graphics;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Locomotion;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique;User-Computer Interface","23","4","43","IEEE","30 Nov 2012","","","IEEE","IEEE Journals"
"LOD Map - A Visual Interface for Navigating Multiresolution Volume Visualization","C. Wang; H. Shen","Department of Computer Science and Engineering, The Ohio State University, 395 Dreese Laboratories, Columbus, OH; Department of Computer Science and Engineering, The Ohio State University, 395 Dreese Laboratories, Columbus, OH","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1029","1036","In multiresolution volume visualization, a visual representation of level-of-detail (LOD) quality is important for us to examine, compare, and validate different LOD selection algorithms. While traditional methods rely on ultimate images for quality measurement, we introduce the LOD map - an alternative representation of LOD quality and a visual interface for navigating multiresolution data exploration. Our measure for LOD quality is based on the formulation of entropy from information theory. The measure takes into account the distortion and contribution of multiresolution data blocks. A LOD map is generated through the mapping of key LOD ingredients to a treemap representation. The ordered treemap layout is used for relative stable update of the LOD map when the view or LOD changes. This visual interface not only indicates the quality of LODs in an intuitive way, but also provides immediate suggestions for possible LOD improvement through visually-striking features. It also allows us to compare different views and perform rendering budget control. A set of interactive techniques is proposed to make the LOD adjustment a simple and easy task. We demonstrate the effectiveness and efficiency of our approach on large scientific and medical data sets","1941-0506","","10.1109/TVCG.2006.159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015461","LOD map;knowledge representation;perceptual reasoning;multiresolution rendering;large volume visualization Author 1:","Navigation;Data visualization;Distortion measurement;Rendering (computer graphics);Signal resolution;Image resolution;Chaos;Entropy;Information theory;Biomedical imaging","data visualisation;graphical user interfaces;image resolution;rendering (computer graphics);trees (mathematics)","LOD map;visual interface;navigation;multiresolution volume visualization;visual representation;level-of-detail quality;entropy measure;information theory;treemap representation;medical data set","Algorithms;Computer Graphics;Diagnostic Imaging;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Anatomic;User-Computer Interface;Visible Human Projects","23","","28","","20 Nov 2006","","","IEEE","IEEE Journals"
"SLAMCast: Large-Scale, Real-Time 3D Reconstruction and Streaming for Immersive Multi-Client Live Telepresence","P. Stotko; S. Krumpen; M. B. Hullin; M. Weinmann; R. Klein",University of Bonn; University of Bonn; University of Bonn; University of Bonn; University of Bonn,"IEEE Transactions on Visualization and Computer Graphics","27 Mar 2019","2019","25","5","2102","2112","Real-time 3D scene reconstruction from RGB-D sensor data, as well as the exploration of such data in VR/AR settings, has seen tremendous progress in recent years. The combination of both these components into telepresence systems, however, comes with significant technical challenges. All approaches proposed so far are extremely demanding on input and output devices, compute resources and transmission bandwidth, and they do not reach the level of immediacy required for applications such as remote collaboration. Here, we introduce what we believe is the first practical client-server system for real-time capture and many-user exploration of static 3D scenes. Our system is based on the observation that interactive frame rates are sufficient for capturing and reconstruction, and real-time performance is only required on the client site to achieve lag-free view updates when rendering the 3D model. Starting from this insight, we extend previous voxel block hashing frameworks by introducing a novel thread-safe GPU hash map data structure that is robust under massively concurrent retrieval, insertion and removal of entries on a thread level. We further propose a novel transmission scheme for volume data that is specifically targeted to Marching Cubes geometry reconstruction and enables a 90% reduction in bandwidth between server and exploration clients. The resulting system poses very moderate requirements on network bandwidth, latency and client-side computation, which enables it to rely entirely on consumer-grade hardware, including mobile devices. We demonstrate that our technique achieves state-of-the-art representation accuracy while providing, for any number of clients, an immersive and fluid lag-free viewing experience even during network outages.","1941-0506","","10.1109/TVCG.2019.2899231","DFG projects KL(grant numbers:KL 1142/11-1,KL 1142/9-2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643537","Remote collaboration;live telepresence;real-time reconstruction;voxel hashing;RGB-D;real-time streaming","Three-dimensional displays;Real-time systems;Telepresence;Collaboration;Bandwidth;Servers;Hardware","augmented reality;client-server systems;data structures;graphics processing units;image reconstruction;multi-threading;rendering (computer graphics);solid modelling;telecontrol","network bandwidth;client-side computation;immersive lag-free viewing experience;fluid lag-free viewing experience;real-time 3D reconstruction;immersive multiclient live telepresence;real-time 3D scene reconstruction;RGB-D sensor data;VR/AR settings;telepresence systems;transmission bandwidth;remote collaboration;real-time capture;many-user exploration;static 3D scenes;interactive frame rates;lag-free view updates;thread level;transmission scheme;client-server system;marching cubes geometry reconstruction;thread-safe GPU hash map data structure;SLAMCast;rendering;3D model;voxel block hashing framework","Computer Communication Networks;Humans;Imaging, Three-Dimensional;Videoconferencing","23","","53","IEEE","17 Feb 2019","","","IEEE","IEEE Journals"
"Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes","S. Hadlak; H. Schumann; C. H. Cap; T. Wollenberg",University of Rostock; University of Rostock; University of Rostock; University of Rostock,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2267","2276","The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.","1941-0506","","10.1109/TVCG.2013.198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634085","Time series analysis;Market research;Image color analysis;Power system dynamics;Current measurement;Time measurement;supergraph clustering;Dynamic networks;visualization","Time series analysis;Market research;Image color analysis;Power system dynamics;Current measurement;Time measurement","data analysis;data visualisation;graph theory;pattern clustering;telecommunication computing;wireless mesh networks","dynamic networks;visual analysis;temporal attribute clustering;substructure discovery;supergraph visualization;node groups;edge groups;temporal clustering;wireless mesh network","Algorithms;Computer Communication Networks;Computer Graphics;Computer Simulation;Models, Theoretical;Subtraction Technique;User-Computer Interface;Wireless Technology","23","1","34","","16 Oct 2013","","","IEEE","IEEE Journals"
"Visual Progression Analysis of Event Sequence Data","S. Guo; Z. Jin; D. Gotz; F. Du; H. Zha; N. Cao","East China Normal University; iDVX labTongji University; University of North Carolina, Chapel Hill; University of Maryland; East China Normal University; iDVX labTongji University","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","417","426","Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET<sup>2</sup>, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET<sup>2</sup>: (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design.","1941-0506","","10.1109/TVCG.2018.2864885","National Natural Science Foundation of China(grant numbers:61602306); Fundamental Research Funds for the Central Universities NSFC(grant numbers:61672231); STCSM(grant numbers:15JC1401700); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Information(grant numbers:U1609220); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440811","Progression Analysis;Visual Analysis;Event Sequence Data","Visualization;Diseases;Aggregates;Data visualization;Pattern matching;Interviews","data analysis;data mining;data visualisation;health care;human factors;medical information systems","unsupervised stage analysis algorithm;critical events;progression analysis algorithm;visual progression analysis;event sequence data;event type;event sequence warping;event representation estimation;data captures;performance evaluation;health care","","23","","49","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"A Radial Adaptation of the Sugiyama Framework for Visualizing Hierarchical Information","C. Bachmaier","Fakultat fur Mathematik und Informatik, Passau Univ.","IEEE Transactions on Visualization and Computer Graphics","4 Sep 2007","2007","13","3","583","594","In radial drawings of hierarchical graphs, the vertices are placed on concentric circles rather than on horizontal lines and the edges are drawn as outward monotone segments of spirals rather than straight lines as it is done in the standard Sugiyama framework. This drawing style is well suited for the visualization of centrality in social networks and similar concepts. Radial drawings also allow a more flexible edge routing than horizontal drawings, as edges can be routed around the center in two directions. In experimental results, this reduces the number of crossings by approximately 30 percent on average. Few crossings are one of the major criteria for human readability. This paper is a detailed description of a complete framework for visualizing hierarchical information in a new radial fashion. Particularly, we briefly cover extensions of the level assignment step to benefit from the increasing perimeters of the circles, present three heuristics for crossing reduction in radial level drawings, and also show how to visualize the results","1941-0506","","10.1109/TVCG.2007.1000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297689","Graph drawing;radial;crossing reduction;Sugiyama framework;spiral segments.","Spirals;Social network services;Data visualization;Tree graphs;Routing;Humans;Web pages","computational geometry;data visualisation;graph theory","Sugiyama framework;hierarchical information visualization;hierarchical graph radial drawings","","22","","34","","4 Sep 2007","","","IEEE","IEEE Journals"
"A Spatially Augmented Reality Sketching Interface for Architectural Daylighting Design","Y. Sheng; T. C. Yapo; C. Young; B. Cutler","Rensselaer Polytechnic Institute, Troy, NY; Rensselaer Polytechnic Institute, Troy, NY; Rensselaer Polytechnic Institute, Troy, NY; Rensselaer Polytechnic Institute, Troy, NY","IEEE Transactions on Visualization and Computer Graphics","11 Nov 2010","2011","17","1","38","50","We present an application of interactive global illumination and spatially augmented reality to architectural daylight modeling that allows designers to explore alternative designs and new technologies for improving the sustainability of their buildings. Images of a model in the real world, captured by a camera above the scene, are processed to construct a virtual 3D model. To achieve interactive rendering rates, we use a hybrid rendering technique, leveraging radiosity to simulate the interreflectance between diffuse patches and shadow volumes to generate per-pixel direct illumination. The rendered images are then projected on the real model by four calibrated projectors to help users study the daylighting illumination. The virtual heliodon is a physical design environment in which multiple designers, a designer and a client, or a teacher and students can gather to experience animated visualizations of the natural illumination within a proposed design by controlling the time of day, season, and climate. Furthermore, participants may interactively redesign the geometry and materials of the space by manipulating physical design elements and see the updated lighting simulation.","1941-0506","","10.1109/TVCG.2009.209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342415","Spatially augmented reality;global illumination;radiosity;and daylighting design.","Augmented reality;Daylighting;Lighting;Rendering (computer graphics);Buildings;Cameras;Layout;Computer graphics;Hybrid power systems;Animation","architectural CAD;augmented reality;computer animation;data visualisation;daylighting;rendering (computer graphics)","augmented reality sketching interface;interactive global illumination;architectural daylight modeling;virtual 3D model;hybrid rendering technique;per-pixel direct illumination;virtual heliodon;animated visualizations","Algorithms;Computer Graphics;Computer-Aided Design;Environment Design;Humans;Image Interpretation, Computer-Assisted;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Lighting;User-Computer Interface","22","1","56","","1 Dec 2009","","","IEEE","IEEE Journals"
"Ambiguity-Free Edge-Bundling for Interactive Graph Visualization","S. Luo; C. Liu; B. Chen; K. Ma","National Taiwan University, Taipei; National Taiwan University, Taipei; National Taiwan University, Taipei; University of California at Davis, Davis","IEEE Transactions on Visualization and Computer Graphics","15 Mar 2012","2012","18","5","810","821","Graph visualization has been widely used to understand and present both global structural and local adjacency information in relational data sets (e.g., transportation networks, citation networks, or social networks). Graphs with dense edges, however, are difficult to visualize because fast layout and good clarity are not always easily achieved. When the number of edges is large, edge bundling can be used to improve the clarity, but in many cases, the edges could be still too cluttered to permit correct interpretation of the relations between nodes. In this paper, we present an ambiguity-free edge-bundling method especially for improving local detailed view of a complex graph. Our method makes more efficient use of display space and supports detail-on-demand viewing through an interactive interface. We demonstrate the effectiveness of our method with public coauthorship network data.","1941-0506","","10.1109/TVCG.2011.104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887331","Graph visualization;network visualization;edge ambiguity;edge congestion;edge bundling;detail-on-demand;interactive navigation.","Image edge detection;Visualization;Layout;Clutter;Data visualization;Routing;Social network services","data visualisation;graph theory","ambiguity-free edge-bundling method;interactive graph visualization;global structural adjacency information;local adjacency information;relational data set;complex graph;display space;detail-on-demand viewing;interactive interface;public coauthorship network data;transportation network;citation network;social network;dense graph edge","","22","3","33","","16 Jun 2011","","","IEEE","IEEE Journals"
"Analysis and Visualization of Discrete Fracture Networks Using a Flow Topology Graph","G. Aldrich; J. D. Hyman; S. Karra; C. W. Gable; N. Makedonska; H. Viswanathan; J. Woodring; B. Hamann","Data Science at Scale Division, (CCS-7), Los Alamos National Laboratory, Los Alamos, NM; Earth and Environmental Sciences Division, (EES-16), Los Alamos National Laboratory, Los Alamos, NM; Earth and Environmental Sciences Division, (EES-16), Los Alamos National Laboratory, Los Alamos, NM; Earth and Environmental Sciences Division, (EES-16), Los Alamos National Laboratory, Los Alamos, NM; Earth and Environmental Sciences Division, (EES-16), Los Alamos National Laboratory, Los Alamos, NM; Earth and Environmental Sciences Division, (EES-16), Los Alamos National Laboratory, Los Alamos, NM; Data Science at Scale Division, (CCS-7), Los Alamos National Laboratory, Los Alamos, NM; Department of Computer Science, Institute for Data Analysis and Visualization, University of California, Davis, CA","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2017","2017","23","8","1896","1909","We present an analysis and visualization prototype using the concept of a flow topology graph (FTG) for characterization of flow in constrained networks, with a focus on discrete fracture networks (DFN), developed collaboratively by geoscientists and visualization scientists. Our method allows users to understand and evaluate flow and transport in DFN simulations by computing statistical distributions, segment paths of interest, and cluster particles based on their paths. The new approach enables domain scientists to evaluate the accuracy of the simulations, visualize features of interest, and compare multiple realizations over a specific domain of interest. Geoscientists can simulate complex transport phenomena modeling large sites for networks consisting of several thousand fractures without compromising the geometry of the network. However, few tools exist for performing higher-level analysis and visualization of simulated DFN data. The prototype system we present addresses this need. We demonstrate its effectiveness for increasingly complex examples of DFNs, covering two distinct use cases - hydrocarbon extraction from unconventional resources and transport of dissolved contaminant from a spent nuclear fuel repository.","1941-0506","","10.1109/TVCG.2016.2582174","Los Alamos National Laboratory - UC Davis Institute of Next-generation Visualization and Analysis (INGVA)(grant numbers:211060-1); LANL Laboratory Directed Research and Development (LDRD)(grant numbers:20140002DR); Los Alamos National Laboratory; LDRD Director's Postdoctoral Fellowship(grant numbers:#20150763PRD4); U.S. Department of Energy Strategic Center for Natural Gas and Oil project; Fundamentals of Unconventional Reservoirs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7494624","Fracture network flow analysis and visualization;flow topology graph;topological path analysis;topological trace clustering;flow in fractured rock;discrete fracture network","Data visualization;Topology;Analytical models;Network topology;Trajectory;Computational modeling;Geometry","data visualisation;graph theory;statistical distributions","discrete fracture networks;flow topology graph;visualization prototype;FTG;geoscientists;visualization scientists;statistical distributions;simulated DFN data;hydrocarbon extraction;nuclear fuel repository","","22","","39","USGov","20 Jun 2016","","","IEEE","IEEE Journals"
"Clique Community Persistence: A Topological Visual Analysis Approach for Complex Networks","B. Rieck; U. Fugacci; J. Lukasczyk; H. Leitte",TU Kaiserslautern; TU Kaiserslautern; TU Kaiserslautern; TU Kaiserslautern,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","822","831","Complex networks require effective tools and visualizations for their analysis and comparison. Clique communities have been recognized as a powerful concept for describing cohesive structures in networks. We propose an approach that extends the computation of clique communities by considering persistent homology, a topological paradigm originally introduced to characterize and compare the global structure of shapes. Our persistence-based algorithm is able to detect clique communities and to keep track of their evolution according to different edge weight thresholds. We use this information to define comparison metrics and a new centrality measure, both reflecting the relevance of the clique communities inherent to the network. Moreover, we propose an interactive visualization tool based on nested graphs that is capable of compactly representing the evolving relationships between communities for different thresholds and clique degrees. We demonstrate the effectiveness of our approach on various network types.","1941-0506","","10.1109/TVCG.2017.2744321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017588","Persistent homology;topological persistence;cliques;complex networks;visual analysis","Tools;Complex networks;Visualization;Layout;Algorithm design and analysis;Shape;Transmission line matrix methods","complex networks;data analysis;data visualisation;graph theory;network theory (graphs)","clique community persistence;topological visual analysis approach;complex networks;interactive visualization tool;clique degrees;network types;cohesive structures;nested graphs","","22","","49","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Collaborative Large-Scale Dense 3D Reconstruction with Online Inter-Agent Pose Optimisation","S. Golodetz; T. Cavallari; N. A. Lord; V. A. Prisacariu; D. W. Murray; P. H. S. Torr",University of OxfordFiveAI Ltd; University of OxfordFiveAI Ltd; University of OxfordFiveAI Ltd; University of Oxford; University of Oxford; University of Oxford,"IEEE Transactions on Visualization and Computer Graphics","29 Oct 2018","2018","24","11","2895","2905","Reconstructing dense, volumetric models of real-world 3D scenes is important for many tasks, but capturing large scenes can take significant time, and the risk of transient changes to the scene goes up as the capture time increases. These are good reasons to want instead to capture several smaller sub-scenes that can be joined to make the whole scene. Achieving this has traditionally been difficult: joining sub-scenes that may never have been viewed from the same angle requires a high-quality camera relocaliser that can cope with novel poses, and tracking drift in each sub-scene can prevent them from being joined to make a consistent overall scene. Recent advances, however, have significantly improved our ability to capture medium-sized sub-scenes with little to no tracking drift: real-time globally consistent reconstruction systems can close loops and re-integrate the scene surface on the fly, whilst new visual-inertial odometry approaches can significantly reduce tracking drift during live reconstruction. Moreover, high-quality regression forest-based relocalisers have recently been made more practical by the introduction of a method to allow them to be trained and used online. In this paper, we leverage these advances to present what to our knowledge is the first system to allow multiple users to collaborate interactively to reconstruct dense, voxel-based models of whole buildings using only consumer-grade hardware, a task that has traditionally been both time-consuming and dependent on the availability of specialised hardware. Using our system, an entire house or lab can be reconstructed in under half an hour and at a far lower cost than was previously possible.","1941-0506","","10.1109/TVCG.2018.2868533","Innovate UK/CCAV(grant numbers:103700); EPSRC(grant numbers:Seebibyte EP/M013774/1); ERC(grant numbers:ERC-2012-AdG 321162-HELIOS); EPSRC/MURI(grant numbers:EP/N019474/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492363","Collaborative;large-scale;dense 3D reconstruction;inter-agent relocalisation;pose graph optimisation","Robots;Collaboration;Three-dimensional displays;Cameras;Buildings;Visualization;Hardware","cameras;distance measurement;image reconstruction;optimisation;pose estimation;regression analysis","large-scale dense 3D reconstruction;online inter-agent pose optimisation;volumetric models;high-quality camera relocaliser;tracking drift;medium-sized sub-scenes;high-quality regression forest-based relocalisers;visual-inertial odometry approach;voxel-based model;consumer-grade hardware","","22","1","57","IEEE","14 Oct 2018","","","IEEE","IEEE Journals"
"Constrained Texture Synthesis via Energy Minimization","G. Ramanarayanan; K. Bala","Department of Computer Science, Cornell University, 594 Rhodes Hall, Ithaca, NY 14853; Department of Computer Science, Cornell University, 5142 Upson Hall, Ithaca, NY 14853","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2007","13","1","167","178","This paper describes CMS (constrained minimization synthesis), a fast, robust texture synthesis algorithm that creates output textures while satisfying constraints. We show that constrained texture synthesis can be posed in a principled way as an energy minimization problem that requires balancing two measures of quality: constraint satisfaction and texture seamlessness. We then present an efficient algorithm for finding good solutions to this problem using an adaptation of graphcut energy minimization. CMS is particularly well suited to detail synthesis, the process of adding high-resolution detail to low-resolution images. It also supports the full image analogies framework, while providing superior image quality and performance. CMS is easily extended to handle multiple constraints on a single output, thus enabling novel applications that combine both user-specified and image-based control","1941-0506","","10.1109/TVCG.2007.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015407","Texture synthesis;detail synthesis;super-resolution;image analogies.","Minimization methods;Collision mitigation;Energy measurement;Automatic control;Robustness;Image quality;Image resolution;Control system synthesis;Pixel;Constraint optimization","constraint theory;graph theory;image texture","CMS texture synthesis algorithm;graphcut energy minimization problem;constrained minimization synthesis;constraint satisfaction;texture seamlessness;user-specified control;image-based control","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Reproducibility of Results;Sensitivity and Specificity","22","3","31","","20 Nov 2006","","","IEEE","IEEE Journals"
"Intelligent Graph Layout Using Many Users' Input","X. Yuan; L. Che; Y. Hu; X. Zhang",Peking University; Peking University; AT&T Labs Research; Peking University,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2699","2708","In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.","1941-0506","","10.1109/TVCG.2012.236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327276","Graph layout;Laplacian matrix;force directed layout;stress model;merging;editing;crowd sourcing","Layout;Laplace equations;Crowdsourcing;Stress;Algorithm design and analysis;Human factors","graph theory;interactive systems;social sciences computing","intelligent graph layout;user input;graph drawing;crowd sourcing manner;Laplacian constrained distance embedding;light-weight interactive system;dynamic viewing;user preference","Algorithms;Computer Graphics;Humans;Metabolic Networks and Pathways;Models, Statistical;Motion Pictures as Topic;Software;User-Computer Interface","22","","33","IEEE","8 Oct 2012","","","IEEE","IEEE Journals"
"Morse Set Classification and Hierarchical Refinement Using Conley Index","G. Chen; Q. Deng; A. Szymczak; R. S. Laramee; E. Zhang","University of Utah, Salt Lake City; Oregon State University, Corvallis; Colorado School of Mines, Golden; Swansea University, Swansea; Oregon State University, Corvallis","IEEE Transactions on Visualization and Computer Graphics","15 Mar 2012","2012","18","5","767","782","Morse decomposition provides a numerically stable topological representation of vector fields that is crucial for their rigorous interpretation. However, Morse decomposition is not unique, and its granularity directly impacts its computational cost. In this paper, we propose an automatic refinement scheme to construct the Morse Connection Graph (MCG) of a given vector field in a hierarchical fashion. Our framework allows a Morse set to be refined through a local update of the flow combinatorialization graph, as well as the connection regions between Morse sets. The computation is fast because the most expensive computation is concentrated on a small portion of the domain. Furthermore, the present work allows the generation of a topologically consistent hierarchy of MCGs, which cannot be obtained using a global method. The classification of the extracted Morse sets is a crucial step for the construction of the MCG, for which the Poincaré index is inadequate. We make use of an upper bound for the Conley index, provided by the Betti numbers of an index pair for a translation along the flow, to classify the Morse sets. This upper bound is sufficiently accurate for Morse set classification and provides supportive information for the automatic refinement process. An improved visualization technique for MCG is developed to incorporate the Conley indices. Finally, we apply the proposed techniques to a number of synthetic and real-world simulation data to demonstrate their utility.","1941-0506","","10.1109/TVCG.2011.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928334","Morse decomposition;vector field topology;upper bound of Conley index;topology refinement;hierarchical refinement.","Indexes;Topology;Orbits;Approximation methods;Upper bound;Trajectory;Electrocardiography","data visualisation;graph theory;mathematics computing;numerical stability;pattern classification;set theory;topology;vectors","Morse set classification;hierarchical refinement;Conley index;Morse decomposition;vector field;numerically stable topological representation;Morse connection graph;flow combinatorialization graph;Poincare index;Betti numbers;visualization technique;synthetic data;real-world simulation data","","22","","40","","23 Jun 2011","","","IEEE","IEEE Journals"
"Poemage: Visualizing the Sonic Topology of a Poem","N. McCurdy; J. Lein; K. Coles; M. Meyer",University of Utah School of Computing; University of Utah Department of English; University of Utah Department of English; University of Utah School of Computing,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","439","448","The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies.","1941-0506","","10.1109/TVCG.2015.2467811","NSF(grant numbers:IIS-1350896); NEH(grant numbers:HD-229002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192712","Visualization in the humanities;design studies;text and document data;graph/network data;Visualization in the humanities;design studies;text and document data;graph/network data","Visualization;Probes;Topology;Context;Pragmatics;Data visualization;Stress","data analysis;data visualisation;interactive systems;literature;text analysis;topology","Poemage;poem sonic topology visualization;digital humanities;distant reading;textual data collection;textual data analysis;synoptic evaluation;close reading;text in-depth analysis;productive meaning;poetry;linguistic devices;problem characterization;data abstraction;sound devices;visualization tool;interactive poem sonic topology exploration;disruptive impact technology;literary studies","Acoustics;Computer Graphics;Humans;Image Processing, Computer-Assisted;Pattern Recognition, Automated;Poetry as Topic","22","","58","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Preserving Minority Structures in Graph Sampling","Y. Zhao; H. Jiang; Q. Chen; Y. Qin; H. Xie; Y. Wu; S. Liu; Z. Zhou; J. Xia; F. Zhou","School of Computer Sciences and Engineering, Central South University, China; School of Computer Sciences and Engineering, Central South University, China; School of Computer Sciences and Engineering, Central South University, China; School of Computer Sciences and Engineering, Central South University, China; School of Computer Sciences and Engineering, Central South University, China; School of Computer Sciences and Engineering, Central South University, China; School of Software, Tsinghua University, China; School of Computer Sciences and Engineering, Central South University, China; School of Computer Sciences and Engineering, Central South University, China; School of InformationZhejiang University of Finance and Economics China","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1698","1708","Sampling is a widely used graph reduction technique to accelerate graph computations and simplify graph visualizations. By comprehensively analyzing the literature on graph sampling, we assume that existing algorithms cannot effectively preserve minority structures that are rare and small in a graph but are very important in graph analysis. In this work, we initially conduct a pilot user study to investigate representative minority structures that are most appealing to human viewers. We then perform an experimental study to evaluate the performance of existing graph sampling algorithms regarding minority structure preservation. Results confirm our assumption and suggest key points for designing a new graph sampling approach named mino-centric graph sampling (MCGS). In this approach, a triangle-based algorithm and a cut-point-based algorithm are proposed to efficiently identify minority structures. A set of importance assessment criteria are designed to guide the preservation of important minority structures. Three optimization objectives are introduced into a greedy strategy to balance the preservation between minority and majority structures and suppress the generation of new minority structures. A series of experiments and case studies are conducted to evaluate the effectiveness of the proposed MCGS.","1941-0506","","10.1109/TVCG.2020.3030428","National Key Research and Development Program of China(grant numbers:2018YFB1700403); National Natural Science Foundation of China(grant numbers:61872388,61872389,61872314,61672538,61672308); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222065","Graph sampling;graph visualization;node-link diagram","Measurement;Image edge detection;Acceleration;Visualization;Bridges;Visual perception;Optimization","computational geometry;data visualisation;graph theory;greedy algorithms;sampling methods","minority structure preservation;graph computations;graph analysis;cut point based algorithm;triangle based algorithm;minocentric graph sampling;graph reduction;greedy strategy;graph visualization","","22","","89","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"TTHRESH: Tensor Compression for Multidimensional Visual Data","R. Ballester-Ripoll; P. Lindstrom; R. Pajarola","Department of Informatics, University of Zürich, Zürich, Switzerland; Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA; Department of Informatics, University of Zürich, Zürich, Switzerland","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2020","2020","26","9","2891","2903","Memory and network bandwidth are decisive bottlenecks when handling high-resolution multidimensional data sets in visualization applications, and they increasingly demand suitable data compression strategies. We introduce a novel lossy compression algorithm for multidimensional data over regular grids. It leverages the higher-order singular-value decomposition (HOSVD), a generalization of the SVD to three dimensions and higher, together with bit-plane, run-length and arithmetic coding to compress the HOSVD transform coefficients. Our scheme degrades the data particularly smoothly and achieves lower mean squared error than other state-of-the-art algorithms at low-to-medium bit rates, as it is required in data archiving and management for visualization purposes. Further advantages of the proposed algorithm include very fine bit rate selection granularity and the ability to manipulate data at very small cost in the compression domain, for example to reconstruct filtered and/or subsampled versions of all (or selected parts) of the data set.","1941-0506","","10.1109/TVCG.2019.2904063","University of Zurich's Forschungskredit Candoc(grant numbers:FK-16-012); U.S. Department of Energy(grant numbers:DE-AC52-07NA27344); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663447","Transform-based compression;scientific visualization;higher-order singular value decomposition;Tucker model;tensor decompositions","Matrix decomposition;Transforms;Encoding;Data visualization;Compression algorithms;Three-dimensional displays","data compression;data visualisation;mean square error methods;singular value decomposition;tensors;transforms","low-to-medium bit rates;mean squared error;HOSVD transform coefficients;arithmetic coding;bit-plane;singular-value decomposition;regular grids;lossy compression algorithm;data compression strategies;visualization applications;high-resolution multidimensional data sets;network bandwidth;multidimensional visual data;tensor compression;TTHRESH;compression domain;fine bit rate selection granularity;data archiving","","22","","45","IEEE","8 Mar 2019","","","IEEE","IEEE Journals"
"Temporal Coherence Strategies for Augmented Reality Labeling","J. B. Madsen; M. Tatzqern; C. B. Madsen; D. Schmalstieg; D. Kalkofen",Aalborg University; Salzburg University of Applied Sciences; Aalborg University; Graz University of Technology; Graz University of Technology,"IEEE Transactions on Visualization and Computer Graphics","14 Mar 2016","2016","22","4","1415","1423","Temporal coherence of annotations is an important factor in augmented reality user interfaces and for information visualization. In this paper, we empirically evaluate four different techniques for annotation. Based on these findings, we follow up with subjective evaluations in a second experiment. Results show that presenting annotations in object space or image space leads to a significant difference in task performance. Furthermore, there is a significant interaction between rendering space and update frequency of annotations. Participants improve significantly in locating annotations, when annotations are presented in object space, and view management update rate is limited. In a follow-up experiment, participants appear to be more satisfied with limited update rate in comparison to a continuous update rate of the view management system.","1941-0506","","10.1109/TVCG.2016.2518318","European Union(grant numbers:FP7-ICT-601139); “CultAR”(grant numbers:FP7-ICT-611526); “Magellan”; Austrian Science Fund (FWF)(grant numbers:P-2402); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383340","","Layout;Three-dimensional displays;Image resolution;Coherence;Force;Animation;Data visualization","augmented reality;data visualisation;rendering (computer graphics);user interfaces","temporal coherence strategies;augmented reality labeling;augmented reality user interfaces;information visualization;image space;object space;rendering space;annotation update frequency;view management update rate","","22","","22","IEEE","14 Jan 2016","","","IEEE","IEEE Journals"
"The User Puzzle—Explaining the Interaction with Visual Analytics Systems","M. Pohl; M. Smuc; E. Mayr",Vienna University of Technology; Danube University Krems; Danube University Krems,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2908","2916","Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories.","1941-0506","","10.1109/TVCG.2012.273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327297","Cognitive theory;visual knowledge discovery;interaction design;reasoning;problem solving","Cognition;Human factors;Visual analytics;Psychology;Problem-solving","cognition;data visualisation;human computer interaction;psychology","user puzzle;visual analytics systems;human reasoning;HCI;psychology;analytical procedures","Cognition;Computer Graphics;Humans;Models, Psychological;User-Computer Interface;Visual Perception","22","","65","","8 Oct 2012","","","IEEE","IEEE Journals"
"Topology-Aware Evenly Spaced Streamline Placement","K. Wu; Z. Liu; S. Zhang; R. J. Moorhead II","Mississippi State University, Starkville; Kitware, Inc., Clifton Park; Mississippi State University, Starkville; Mississippi State University, Starkville","IEEE Transactions on Visualization and Computer Graphics","8 Jul 2010","2010","16","5","791","801","This paper presents a new streamline placement algorithm that produces evenly spaced long streamlines while preserving topological features of a flow field. Singularities and separatrices are extracted to decompose the flow field into topological regions. In each region, a seeding path is selected from a set of streamlines integrated in the orthogonal flow field. The uniform sample points on this path are then used as seeds to generate streamlines in the original flow field. Additional seeds are placed where a large gap between adjacent streamlines occurs. The number of short streamlines is significantly reduced as evenly spaced long streamlines spawned along the seeding paths can fill the topological regions very well. Several metrics for evaluating streamline placement quality are discussed and applied to our method as well as some other approaches. Compared to previous work in uniform streamline placement, our method is more effective in creating evenly spaced long streamlines and preserving topological features. It has the potential to provide both intuitive perception of important flow characteristics and detail reconstruction across visually pleasing streamlines.","1941-0506","","10.1109/TVCG.2009.206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332228","Evenly spaced streamlines;flow topology;flow visualization;seeding strategy;streamline placement.","Topology;Streaming media;Image reconstruction;Iterative algorithms;Visualization;Interpolation;Costs;Design methodology;Robustness;Layout","computer graphics;flow visualisation","seeding path;orthogonal flow field;topology-aware evenly spaced streamline placement algorithm;flow visualization","","22","","20","","13 Nov 2009","","","IEEE","IEEE Journals"
"Transpost: a novel approach to the display and transmission of 360 degrees-viewable 3D solid images","R. Otsuka; T. Hoshino; Y. Horry","Adv. Res. Lab., Hitachi Ltd., Tokyo, Japan; NA; NA","IEEE Transactions on Visualization and Computer Graphics","23 Jan 2006","2006","12","2","178","185","Three-dimensional displays are drawing attention as next-generation devices. Some techniques which can reproduce three-dimensional images prepared in advance have already been developed. However, technology for the transmission of 3D moving pictures in real-time is yet to be achieved. In this paper, we present a novel method for 360-degrees viewable 3D displays and the Transpost system in which we implement the method. The basic concept of our system is to project multiple images of the object, taken from different angles, onto a spinning screen. The key to the method is projection of the images onto a directionally reflective screen with a limited viewing angle. The images are reconstructed to give the viewer a three-dimensional image of the object displayed on the screen. The display system can present images of computer-graphics pictures, live pictures, and movies. Furthermore, the reverse optical process of that in the display system can be used to record images of the subject from multiple directions. The images can then be transmitted to the display in real-time. We have developed prototypes of a 3D display and a 3D human-image transmission system. Our preliminary working prototypes demonstrate new possibilities of expression and forms of communication.","1941-0506","","10.1109/TVCG.2006.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580452","Interaction styles;three-dimensional displays;stereoscopic.","Three dimensional displays;Solids;Computer displays;Motion pictures;Spinning;Image reconstruction;Prototypes;Layout;Laser modes;Data visualization","three-dimensional displays;solid modelling;image reconstruction","3D solid image;three-dimensional display;3D moving picture;360-degrees viewable 3D display;Transpost;transpost system;computer-graphics picture;3D human-image transmission system","Computer Graphics;Computer Terminals;Data Display;Equipment Design;Equipment Failure Analysis;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Pilot Projects;Signal Processing, Computer-Assisted;User-Computer Interface","22","7","19","","23 Jan 2006","","","IEEE","IEEE Journals"
"Using Aging to Visually Uncover Evolutionary Processes on Networks","T. E. Gorochowski; M. di Bernardo; C. S. Grierson","University of Bristol, Bristol; University of Bristol, Bristol and University of Naples Federico II, Napoli; University of Bristol, Bristol","IEEE Transactions on Visualization and Computer Graphics","11 Jun 2012","2012","18","8","1343","1352","Networks are widely used to describe many natural and technological systems. Understanding how these evolve over time poses a challenge for existing visualization techniques originally developed for fixed network structures. We describe a method of incorporating the concept of aging into evolving networks, where nodes and edges store information related to the amount of local evolutionary change they have experienced. This property is used to generate visualizations that ensure stable substructures maintain relatively fixed spatial positions, allowing them to act as visual markers and providing context for evolutionary change elsewhere. By further supplementing these visualizations with color cues, the resultant animations enable a clearer portrayal of the underlying evolutionary process.","1941-0506","","10.1109/TVCG.2011.142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999664","Network evolution;information visualization;graph layout.","Layout;Aging;Visualization;Data visualization;Color;Animation;Stability analysis","computer animation;data visualisation;evolutionary computation;network theory (graphs)","network aging;evolutionary process;visualization techniques;network structures;visual marker;color cues;animation","Algorithms;Computer Communication Networks;Computer Simulation;Humans;Models, Genetic;Social Support;Time Factors","22","","33","IEEE","25 Aug 2011","","","IEEE","IEEE Journals"
"A generic rendering system","J. Dollner; K. Hinrichs","Hasso-Plattner Inst., Potsdam Univ., Germany; NA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2002","8","2","99","118","Describes the software architecture of a rendering system that follows a pragmatic approach to integrating and bundling the power of different low-level rendering systems within an object-oriented framework. The generic rendering system provides higher-level abstractions to existing rendering systems and serves as a framework for developing new rendering techniques. It wraps the functionality of several widely-used rendering systems, defines a unified object-oriented application programming interface and provides an extensible, customizable apparatus for evaluating and interpreting hierarchical scene information. As a fundamental property, individual features of a specific rendering system can be integrated into the generic rending system in a transparent way. The system is based on a state machine, called an ""engine"", which operates on ""rendering components"". Four major categories of rendering components constitute the generic rendering system: ""shapes"" represent geometries, ""attributes"" specify properties assigned to geometries and scenes, ""handlers"" encapsulate rendering algorithms, and ""techniques"" represent evaluation strategies for rendering components. As a proof of concept, we have implemented the described software architecture using the Virtual Rendering System, which currently wraps the functionality of the OpenGL, Radiance, POV Ray and RenderMan systems.","1941-0506","","10.1109/2945.998664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998664","","Rendering (computer graphics);Software architecture;Layout;Geometry;Functional programming;Object oriented programming;Engines;Shape","rendering (computer graphics);object-oriented programming;software architecture;application program interfaces","generic rendering system;software architecture;pragmatic approach;low-level rendering systems;object-oriented framework;high-level abstractions;wrapper;unified object-oriented application programming interface;extensible customizable apparatus;hierarchical scene information;state machine;rendering engine;rendering components;shapes;geometries;rendering attributes;rendering handlers;rendering algorithm encapsulation;rendering techniques;evaluation strategies;Virtual Rendering System;OpenGL;Radiance;POV Ray;RenderMan;object-oriented graphics;multi-pass rendering","","21","","42","","7 Aug 2002","","","IEEE","IEEE Journals"
"A rule-based interactive behavioral animation system for humanoids","H. Noser; D. Thalmann","Multimedia Lab., Zurich Univ., Switzerland; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1999","5","4","281","307","We present a versatile, behavioral, and rule-based animation system that includes autonomous humanoid actors whose behavior is based on synthetic sensors that are used for perceiving the virtual environment. We combine the following in a consistent approach: L-systems, a behavioral production rule system; a particle system; an acoustic environment model, including a speech recognition module; a virtual life network; and a humanoid library. Together, these systems create a real-time-structured virtual environment that both high-level autonomous humanoids and interactive users can easily share.","1941-0506","","10.1109/2945.817347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=817347","","Animation;Virtual environment;Acoustic sensors;Production systems;Sensor systems;Humans;Computer vision;Autonomous agents;Computer graphics;Power system modeling","computer animation;knowledge based systems;virtual reality;speech recognition;interactive systems","rule-based interactive behavioral animation system;humanoids;synthetic sensors;virtual environment;L-systems;behavioral production rule system;particle system;acoustic environment model;speech recognition module;virtual life network","","21","","36","","6 Aug 2002","","","IEEE","IEEE Journals"
"EdWordle: Consistency-Preserving Word Cloud Editing","Y. Wang; X. Chu; C. Bao; L. Zhu; O. Deussen; B. Chen; M. Sedlmair","Shandong University; Shandong University; Shandong University; Southeast University; Konstanz University, VCC SIAT, China; Shandong University; University of Vienna, Austria","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","647","656","We present EdWordle, a method for consistently editing word clouds. At its heart, EdWordle allows users to move and edit words while preserving the neighborhoods of other words. To do so, we combine a constrained rigid body simulation with a neighborhood-aware local Wordle algorithm to update the cloud and to create very compact layouts. The consistent and stable behavior of EdWordle enables users to create new forms of word clouds such as storytelling clouds in which the position of words is carefully edited. We compare our approach with state-of-the-art methods and show that we can improve user performance, user satisfaction, as well as the layout itself.","1941-0506","","10.1109/TVCG.2017.2745859","NSFC-Guangdong Joint Fund(grant numbers:U1501255); NSFC(grant numbers:61379091,91630204); National Key Research & Development Plan of China(grant numbers:2016YFB1001404); Shandong Provincial Natural Science Foundation(grant numbers:2016ZRE27617); NSF of Jiangsu Province(grant numbers:BK20150634); National Foreign 1000 Talent Plan(grant numbers:WQ201344000169); Leading Talents of Guangdong Program(grant numbers:00201509); Fundamental Research Funds of Shandong University; FFG(grant numbers:845898); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017586","Wordle;consistency;text visualization","Tag clouds;Layout;Tools;Visualization;Semantics;Heuristic algorithms;Data visualization","data visualisation;solid modelling;text editing","EdWordle;user performance;user satisfaction;consistency-preserving word cloud editing;constrained rigid body simulation;neighborhood-aware local Wordle algorithm","","21","","41","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Enhanced Spatial Stability with Hilbert and Moore Treemaps","S. Tak; A. Cockburn","University of Canterbury, Christchurch; University of Canterbury, Christchurch","IEEE Transactions on Visualization and Computer Graphics","29 Nov 2012","2013","19","1","141","148","Treemaps are a well known and powerful space-filling visualisation method for displaying hierarchical data. Many alternative treemap algorithms have been proposed, often with the aim being to optimise performance across several criteria, including spatial stability to assist users in locating and monitoring items of interest. In this paper, we demonstrate that spatial stability is not fully captured by the commonly used ""distance change” (DC) metric, and we introduce a new ""location drift” (LD) metric to more fully capture spatial stability. An empirical study examines the validity and usefulness of the location drift metric, showing that it explains some effects on user performance that distance change does not. Next, we introduce ""Hilbert” and ""Moore” treemap algorithms, which are designed to achieve high spatial stability. We assess their performance in comparison to other treemaps, showing that Hilbert and Moore treemaps perform well across all stability metrics.","1941-0506","","10.1109/TVCG.2012.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185545","trees (mathematics);data visualisation;LD;enhanced spatial stability;Hilbert treemaps;Moore treemaps;space-filling visualisation method;hierarchical data;distance change metric;DC;location drift metric;Layout;Measurement;Stability criteria;Algorithm design and analysis;Gravity;Monitoring;spatial stability;Treemap;space-filling curve","Layout;Measurement;Stability criteria;Algorithm design and analysis;Gravity;Monitoring","data visualisation;trees (mathematics)","enhanced spatial stability;Hilbert treemaps;Moore treemaps;space-filling visualisation method;hierarchical data;distance change metric;DC;location drift metric;LD","","21","","18","","17 Apr 2012","","","IEEE","IEEE Journals"
"Exploring Multiple Trees through DAG Representations","M. Graham; J. Kennedy","IEEE Computer Society; Napier Univ, Edinburgh","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1294","1301","We present a directed acyclic graph visualisation designed to allow interaction with a set of multiple classification trees, specifically to find overlaps and differences between groups of trees and individual trees. The work is motivated by the need to find a representation for multiple trees that has the space-saving property of a general graph representation and the intuitive parent-child direction cues present in individual representation of trees. Using example taxonomic data sets, we describe augmentations to the common barycenter DAG layout method that reveal shared sets of child nodes between common parents in a clearer manner. Other interactions such as displaying the multiple ancestor paths of a node when it occurs in several trees, and revealing intersecting sibling sets within the context of a single DAG representation are also discussed.","1941-0506","","10.1109/TVCG.2007.70556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376153","Multiple trees;Directed Acyclic Graph.","Visualization;Tree graphs;Classification tree analysis;Tree data structures;Testing;Merging;Taxonomy;Feedback;History;Bibliographies","data visualisation;directed graphs;merging;pattern classification;trees (mathematics)","multiple trees;DAG representations;directed acyclic graph;DAG visualisation;multiple classification trees;merging","","21","4","42","","5 Nov 2007","","","IEEE","IEEE Journals"
"High-Quality Ultra-Compact Grid Layout of Grouped Networks","V. Yoghourdjian; T. Dwyer; G. Gange; S. Kieffer; K. Klein; K. Marriott",Monash University; Monash University; The University of Melbourne; Monash University; Monash University; Monash University,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","339","348","Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks.","1941-0506","","10.1109/TVCG.2015.2467251","Australian Research Council through Discovery Project(grant numbers:DP140100077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192733","Network visualization;graph drawing;power graph;optimization;large-neighborhood search;Network visualization;graph drawing;power graph;optimization;large-neighborhood search","Layout;Encoding;Optimization;Containers;Standards;Routing;Pipelines","complex networks;computability;graph theory;integer programming;large-scale systems;search problems","high-quality ultra-compact grid layout;grouped networks;fast heuristic techniques;complex multistage pipelines;small graphs;pipeline techniques;orthogonal-style layout;small networks;grouping constraints;ultra-compact grid-like network layout aesthetic;grid arrangements;typographical layout;heuristic-based graph-layout methods;pipeline-based graph-layout methods;MIP;CP;SAT;combinatorial problems;mixed-integer optimization problems;large-neighborhood search meta-heuristic approach","","21","","50","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Planar Hexagonal Meshing for Architecture","Y. Li; Y. Liu; W. Wang","Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong, P.R. China; Microsoft Research Asia, No. 5 Dan Ling Street, Haidian District, Beijing, P.R. China; Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong, P.R. China","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2014","2015","21","1","95","106","Mesh surfaces with planar hexagonal faces, what we refer to as PH meshes, offer an elegant way of paneling freeform architectural surfaces due to their node simplicity (i.e., valence-3 nodes) and naturally appealing layout. We investigate PH meshes to understand how the shape, size, and pattern of PH faces are constrained by surface geometry. This understanding enables us to develop an effective method for paneling freeform architectural surfaces with PH meshes. Our method first constructs an ideal triangulation of a given smooth surface, guided by surface geometry. We show that such an ideal triangulation leads to a Dupin-regular PH mesh via tangent duality on the surface. We have developed several novel and effective techniques for improving undesirable mesh layouts caused by singular behaviors of surface curvature. We compute support structures associated with PH meshes, including exact vertex offsets and approximate edge offsets, as demanded in panel manufacturing. The efficacy of our method is validated by a number of architectural examples.","1941-0506","","10.1109/TVCG.2014.2322367","National Basic Research Program(grant numbers:2011CB302400); NSFC(grant numbers:61272019); Research Grant Council(grant numbers:718209,718010,718311,717012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6846311","Planar hexagonal mesh;ideal triangulation;mesh offset;architectural geometry","Shape;Geometry;Approximation methods;Optimization;Layout;Indexes;Fabrication","architecture;mesh generation;surface fitting","planar hexagonal mesh;mesh surface;PH mesh;freeform architectural surfaces;PH face shape;PH face size;PH face pattern;triangulation;surface geometry;Dupin-regular PH mesh;tangent duality;mesh layout;surface curvature;vertex offset;edge offset;panel manufacturing","","21","","43","IEEE","30 Jun 2014","","","IEEE","IEEE Journals"
"Revisiting Stress Majorization as a Unified Framework for Interactive Constrained Graph Visualization","Y. Wang; Y. Wang; Y. Sun; L. Zhu; K. Lu; C. -W. Fu; M. Sedlmair; O. Deussen; B. Chen","Shandong University; Shandong University; Shandong University; Southeast University; Shandong University; VRHIT SIATChinese University of Hong Kong; University of Vienna, Austria; Konstanz University, VCC SIAT, China; Shandong University","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","489","499","We present an improved stress majorization method that incorporates various constraints, including directional constraints without the necessity of solving a constraint optimization problem. This is achieved by reformulating the stress function to impose constraints on both the edge vectors and lengths instead of just on the edge lengths (node distances). This is a unified framework for both constrained and unconstrained graph visualizations, where we can model most existing layout constraints, as well as develop new ones such as the star shapes and cluster separation constraints within stress majorization. This improvement also allows us to parallelize computation with an efficient GPU conjugant gradient solver, which yields fast and stable solutions, even for large graphs. As a result, we allow the constraint-based exploration of large graphs with 10K nodes - an approach which previous methods cannot support.","1941-0506","","10.1109/TVCG.2017.2745919","NSFC-Guangdong Joint Fund(grant numbers:U1501255); National Key Research & Development Plan of China(grant numbers:2016YFB1001404); National Foreign 1000 Talent Plan(grant numbers:WQ201344000169); Leading Talents of Guangdong Program(grant numbers:00201509); Shandong Provincial Natural Science Foundation(grant numbers:2016ZRE27617); Shenzhen Science and Technology Program(grant numbers:JCYJ20170413162617606); Fundamental Research Funds of Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017634","Graph visualization;stress majorization;constraints","Stress;Layout;Visualization;Springs;Optimization;Computational modeling;Shape","computational geometry;data visualisation;gradient methods;graph theory;graphics processing units;interactive systems;mathematics computing;optimisation;parallel processing","improved stress majorization method;directional constraints;layout constraints;GPU conjugant gradient solver;interactive constrained graph visualization;cluster separation constraints;unconstrained graph visualizations;constrained graph visualizations;node distances;edge lengths;edge vectors;constraint optimization problem","","21","","51","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Spherical Piecewise Constant Basis Functions for All-Frequency Precomputed Radiance Transfer","K. Xu; Y. -T. Jia; H. Fu; S. Hu; C. -L. Tai","Tsinghua Univ., Beijing; NA; NA; Tsinghua Univ., Beijing; NA","IEEE Transactions on Visualization and Computer Graphics","21 Jan 2008","2008","14","2","454","467","This paper presents a novel basis function, called <i>spherical piecewise constant basis function </i>(SPCBF), for precomputed radiance transfer. SPCBFs have several desirable properties: rotatability, ability to represent all-frequency signals, and support for efficient multiple product. By smartly partitioning the illumination sphere into a set of subregions and associating each subregion with an SPCBF valued 1 inside the region and 0 elsewhere, we precompute the light coefficients using the resulting SPCBFs. Efficient rotation of the light representation in SPCBFs is achieved by rotating the domain of SPCBFs. During runtime rendering, we approximate the BRDF and visibility coefficients using the set of SPCBFs for light, possibly rotated, through fast lookup of <i>summed-area table </i>(SAT) and <i>visibility distance table </i>(VDT), respectively. SPCBFs enable new effects such as object rotation in all-frequency rendering of dynamic scenes and on-the-fly BRDF editing under rotating environment lighting. With graphics hardware acceleration, our method achieves real-time frame rates.","1941-0506","","10.1109/TVCG.2007.70442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378369","Computer Graphics;Color;Shading;shadowing;and texture;Real-time Rendering;Precomputed Radiance Transfer;Spherical Piecewise Constant Basis Functions;Computer Graphics;Color;Shading;shadowing;and texture;Real-time Rendering;Precomputed Radiance Transfer;Spherical Piecewise Constant Basis Functions","Layout;Rendering (computer graphics);Lighting;Computer science;Computer Society;Runtime;Graphics;Hardware;Acceleration;Shadow mapping","computer graphic equipment;rendering (computer graphics)","spherical piecewise constant basis functions;all-frequency precomputed radiance transfer;illumination sphere partitioning;light representation;runtime rendering;summed-area table;visibility distance table;graphics hardware acceleration","","21","1","23","","21 Jan 2008","","","IEEE","IEEE Journals"
"SuperMatching: Feature Matching Using Supersymmetric Geometric Constraints","Z. -Q. Cheng; Y. Chen; R. R. Martin; Y. -K. Lai; A. Wang","National University of Defense Technology, Changsha; National University of Defense Technology, Changsha; Cardiff University, Cardiff; Cardiff University, Cardiff; National University of Defense Technology, Changsha","IEEE Transactions on Visualization and Computer Graphics","11 Sep 2013","2013","19","11","1885","1894","Feature matching is a challenging problem at the heart of numerous computer graphics and computer vision applications. We present the SuperMatching algorithm for finding correspondences between two sets of features. It does so by considering triples or higher order tuples of points, going beyond the pointwise and pairwise approaches typically used. SuperMatching is formulated using a supersymmetric tensor representing an affinity metric that takes into account feature similarity and geometric constraints between features: Feature matching is cast as a higher order graph matching problem. SuperMatching takes advantage of supersymmetry to devise an efficient sampling strategy to estimate the affinity tensor, as well as to store the estimated tensor compactly. Matching is performed by an efficient higher order power iteration approach that takes advantage of this compact representation. Experiments on both synthetic and real data show that SuperMatching provides more accurate feature matching than other state-of-the-art approaches for a wide range of 2D and 3D features, with competitive computational cost.","1941-0506","","10.1109/TVCG.2013.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461881","Feature matching;geometric constraints;supersymmetric tensor","Tensile stress;Vectors;Shape;Transmission line matrix methods;Educational institutions;Accuracy;Computational efficiency","feature extraction;geometry;graph theory;image matching;tensors","SuperMatching algorithm;feature matching;supersymmetric geometric constraints;computer graphics;computer vision applications;pointwise approach;pairwise approach;supersymmetric tensor;affinity metric;feature similarity;higher order graph matching problem;sampling strategy;affinity tensor estimation;higher order power iteration approach;2D features;3D features","","21","","43","","14 Feb 2013","","","IEEE","IEEE Journals"
"VERAM: View-Enhanced Recurrent Attention Model for 3D Shape Classification","S. Chen; L. Zheng; Y. Zhang; Z. Sun; K. Xu","Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer, National University of Defense Technology, Changsha, Hunan, P.R. China; Department of Computer Science and Technology, Nanjing University, Nanjing Shi, Jiangsu Sheng, China; Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer, National University of Defense Technology, Changsha, Hunan, P.R. China","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2019","2019","25","12","3244","3257","Multi-view deep neural network is perhaps the most successful approach in 3D shape classification. However, the fusion of multi-view features based on max or average pooling lacks a view selection mechanism, limiting its application in, e.g., multi-view active object recognition by a robot. This paper presents VERAM, a view-enhanced recurrent attention model capable of actively selecting a sequence of views for highly accurate 3D shape classification. VERAM addresses an important issue commonly found in existing attention-based models, i.e., the unbalanced training of the subnetworks corresponding to next view estimation and shape classification. The classification subnetwork is easily overfitted while the view estimation one is usually poorly trained, leading to a suboptimal classification performance. This is surmounted by three essential view-enhancement strategies: 1) enhancing the information flow of gradient backpropagation for the view estimation subnetwork, 2) devising a highly informative reward function for the reinforcement training of view estimation and 3) formulating a novel loss function that explicitly circumvents view duplication. Taking grayscale image as input and AlexNet as CNN architecture, VERAM with 9 views achieves instance-level and class-level accuracy of 95.5 and 95.3 percent on ModelNet10, 93.7 and 92.1 percent on ModelNet40, both are the state-of-the-art performance under the same number of views.","1941-0506","","10.1109/TVCG.2018.2866793","National Natural Science Foundation of China(grant numbers:61373135,61672299,61702281,61532003,61572507,61622212); Postdoctoral Science Foundation of Jiangsu Province of China(grant numbers:1701046A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444765","3D shape classification;multi-view 3D shape recognition;visual attention model;recurrent neural network;reinforcement learning;convolutional neural network","Three-dimensional displays;Image recognition;Solid modeling;Reinforcement learning;Recurrent neural networks;Convolutional neural networks;Computational modeling","backpropagation;convolutional neural nets;image classification;image colour analysis;neural net architecture;recurrent neural nets;shape recognition;stereo image processing","view estimation subnetwork;VERAM;view-enhanced recurrent attention model;view selection;attention-based models;3D shape classification;multiview deep neural network;multiview feature fusion;information flow;gradient backpropagation;grayscale image;AlexNet;CNN architecture;reinforcement training","","21","","50","IEEE","23 Aug 2018","","","IEEE","IEEE Journals"
"Visual Analysis of Cloud Computing Performance Using Behavioral Lines","C. Muelder; B. Zhu; W. Chen; H. Zhang; K. -L. Ma","Department of Computer Science, University of California, Davis, CA; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; Department of Computer Science, University of California, Davis, CA","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2016","2016","22","6","1694","1704","Cloud computing is an essential technology to Big Data analytics and services. A cloud computing system is often comprised of a large number of parallel computing and storage devices. Monitoring the usage and performance of such a system is important for efficient operations, maintenance, and security. Tracing every application on a large cloud system is untenable due to scale and privacy issues. But profile data can be collected relatively efficiently by regularly sampling the state of the system, including properties such as CPU load, memory usage, network usage, and others, creating a set of multivariate time series for each system. Adequate tools for studying such large-scale, multidimensional data are lacking. In this paper, we present a visual based analysis approach to understanding and analyzing the performance and behavior of cloud computing systems. Our design is based on similarity measures and a layout method to portray the behavior of each compute node over time. When visualizing a large number of behavioral lines together, distinct patterns often appear suggesting particular types of performance bottleneck. The resulting system provides multiple linked views, which allow the user to interactively explore the data by examining the data or a selected subset at different levels of detail. Our case studies, which use datasets collected from two different cloud systems, show that this visual based approach is effective in identifying trends and anomalies of the systems.","1941-0506","","10.1109/TVCG.2016.2534558","US National Science Foundation(grant numbers:IIS-1320229); US Department of Energy(grant numbers:DE-SC0007443,DE-SC0012610); National 973 Program of China(grant numbers:2015CB352503); National Science Foundation of China(grant numbers:61232012,61422211); Key Natural Science Foundation of Zhejiang Province(grant numbers:LZ12F02002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422127","Cloud computing;multidimensional data;performance visualization;visual analytics;Cloud computing;multidimensional data;performance visualization;visual analytics","Cloud computing;Data visualization;Visualization;Layout;Measurement;Monitoring;Time series analysis","Big Data;cloud computing;parallel processing","cloud computing performance;behavioral lines;Big Data analytics;parallel computing;storage devices;privacy issues;visual based analysis approach","","21","1","33","IEEE","29 Feb 2016","","","IEEE","IEEE Journals"
"A geometric comparison of algorithms for fusion control in stereoscopic HTDs","Z. Wartell; L. F. Hodges; W. Ribarsky","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2002","8","2","129","143","This paper concerns stereoscopic virtual reality displays in which the head is tracked and the display is stationary, attached to a desk, tabletop or wall. These are called stereoscopic HTDs (head-tracked displays). Stereoscopic displays render two perspective views of a scene, each of which is seen by one eye of the user. Ideally, the user's natural visual system combines the stereo image pair into a single, 3D perceived image. Unfortunately, users often have difficulty fusing the stereo image pair. Researchers use a number of software techniques to reduce fusion problems. This paper geometrically examines and compares a number of these techniques and reaches the following conclusions: In interactive stereoscopic applications, the combination of view placement, scale, and either false eye separation or /spl alpha/-false eye separation can provide fusion control that is geometrically similar to image shifting and image scaling. However, in stereo HTDs, image shifting and image scaling also generate additional geometric artifacts that are not generated by the other methods. We anecdotally link some of these artifacts to exceeding the perceptual limitations of human vision. While formal perceptual studies are still needed, geometric analysis suggests that image shifting and image scaling may be less appropriate than the other methods for interactive, stereo HTDs.","1941-0506","","10.1109/2945.998666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998666","","Displays;Fusion power generation;Virtual reality;Head;Rendering (computer graphics);Layout;Visual system;Application software;Image generation;Humans","tracking;computer displays;computational geometry;sensor fusion;virtual reality;three-dimensional displays;visual perception;human factors;scaling phenomena;rendering (computer graphics)","fusion control algorithms;geometric comparison;stereoscopic head-tracked displays;virtual reality;stationary display;perspective view rendering;stereo image pair fusion;3D perceived image;software techniques;interactive applications;view placement;scale;false eye separation;image shifting;image scaling;geometric artifacts;human visual perception limitations;display distortion","","20","1","43","","7 Aug 2002","","","IEEE","IEEE Journals"
"Adjoints and importance in rendering: an overview","P. H. Christensen","Pixar Animation Studios, Seattle, WA, USA","IEEE Transactions on Visualization and Computer Graphics","25 Jun 2003","2003","9","3","329","340","This survey gives an overview of the use of importance, an adjoint of light, in speeding up rendering. The importance of a light distribution indicates its contribution to the region of most interest-typically the directly visible parts of a scene. Importance can therefore be used to concentrate global illumination and ray tracing calculations where they matter most for image accuracy, while reducing computations in areas of the scene that do not significantly influence the image. In this paper, we attempt to clarify the various uses of adjoints and importance in rendering by unifying them into a single framework. While doing so, we also generalize some theoretical results-known from discrete representations-to a continuous domain.","1941-0506","","10.1109/TVCG.2003.1207441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1207441","","Layout;Integral equations;Rendering (computer graphics);Lighting;Ray tracing;Differential equations;Acceleration;Optimization methods;Finite element methods","rendering (computer graphics)","rendering;light distribution importance;discrete representations","","20","1","80","","25 Jun 2003","","","IEEE","IEEE Journals"
"An infrastructure for realizing custom-tailored augmented reality user interfaces","W. Broll; I. Lindt; J. Ohlenburg; I. Herbst; M. Wittkamper; T. Novotny","Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","722","733","Augmented reality (AR) technologies are rapidly expanding into new application areas. However, the development of AR user interfaces and appropriate interaction techniques remains a complex and time-consuming task. Starting from scratch is more common than building upon existing solutions. Furthermore, adaptation is difficult, often resulting in poor quality and limited flexibility with regard to user requirements. In order to overcome these problems, we introduce an infrastructure for supporting the development of specific AR interaction techniques and their adaptation to individual user needs. Our approach is threefold: a flexible AR framework providing independence from particular input devices and rendering platforms, an interaction prototyping mechanism allowing for fast prototyping of new interaction techniques, and a high-level user interface description, extending user interface descriptions into the domain of AR. The general usability and applicability of the approach is demonstrated by means of three example AR projects.","1941-0506","","10.1109/TVCG.2005.90","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512022","Index Terms- Distributed systems;distributed applications;multimedia information systems;artificial;augmented;and virtual realities;user interfaces;collaborative computing;graphics systems;distributed/network graphics;methodology and techniques;device independence;graphics data structures and data types;interaction techniques;three-dimensional graphics and realism;virtual reality.","Augmented reality;User interfaces;Virtual reality;Application software;Graphics;Prototypes;Computer interfaces;Wearable computers;Computer displays;Iris","augmented reality;data structures;groupware;human computer interaction;multimedia computing;rendering (computer graphics);user interfaces","custom-tailored augmented reality;user interface;rendering platform;interaction prototyping mechanism;distributed system;distributed application;multimedia information systems;artificial reality;augmented reality;virtual reality;collaborative computing;graphics system;distributed-network graphics;device independence;graphics data structure;data type;3D graphics","Algorithms;Computer Simulation;Computer Systems;Cybernetics;Data Display;Environment;Imaging, Three-Dimensional;Man-Machine Systems;Models, Theoretical;Online Systems;User-Computer Interface","20","16","44","IEEE","26 Sep 2005","","","IEEE","IEEE Journals"
"Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations","J. Zhao; M. Glueck; S. Breslav; F. Chevalier; A. Khan",Autodesk Research; Autodesk Research; Autodesk Research; INRIA; Autodesk Research,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","261","270","User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst's manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.","1941-0506","","10.1109/TVCG.2016.2598543","Mitacs through the Mitacs Accelerate program; CPER Nord-Pas de Calais / FEDER DATA Advanced data science & technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536110","Externalization user-authored annotation;exploratory sequential data analysis;graph-based visualization","Data visualization;Semantics;Layout;Visualization;Human computer interaction;Data analysis;Manuals","data analysis;data visualisation;graph theory;human computer interaction;user centred design","annotation graphs;graph-based visualization;data meta-analysis;user-authored annotations;hypothesis generation;key observations;dynamic graph visualization;annotation graph topology;annotation semantics;data selections;mixed-initiative approach;visual graph layout styles;exploratory sequential data analysis;ESDA;task typology;visualization literature;user-centered design process;HCI experiment data","","20","","39","IEEE","8 Aug 2016","","","IEEE","IEEE Journals"
"Articulated Planar Reformation for Change Visualization in Small Animal Imaging","P. Kok; M. Baiker; E. A. Hendriks; F. H. Post; J. Dijkstra; C. W. G. M. Lowik; B. P. F. Lelieveldt; C. P. Botha",NA; NA; NA; NA; NA; NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1396","1404","The analysis of multi-timepoint whole-body small animal CT data is greatly complicated by the varying posture of the subject at different timepoints. Due to these variations, correctly relating and comparing corresponding regions of interest is challenging.In addition, occlusion may prevent effective visualization of these regions of interest. To address these problems, we have developed a method that fully automatically maps the data to a standardized layout of sub-volumes, based on an articulated atlas registration.We have dubbed this process articulated planar reformation, or APR. A sub-volume can be interactively selected for closer inspection and can be compared with the corresponding sub-volume at the other timepoints, employing a number of different comparative visualization approaches. We provide an additional tool that highlights possibly interesting areas based on the change of bone density between timepoints. Furthermore we allow visualization of the local registration error, to give an indication of the accuracy of the registration. We have evaluated our approach on a case that exhibits cancer-induced bone resorption.","1941-0506","","10.1109/TVCG.2010.134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613480","small animal imaging;comparative visualization;multi-timepoint;molecular imaging;articulated planar reformation","Bones;Data visualization;Animals;Layout;Computed tomography;Transforms","biology computing;computerised tomography;data analysis;data visualisation;image registration;medical image processing;molecular biophysics","articulated planar reformation;change visualization;small animal imaging;multitimepoint whole-body small animal CT data analysis;articulated atlas registration;cancer-induced bone resorption","Animals;Bone and Bones;Bone and Bones;Computer Graphics;Computer Simulation;Image Processing, Computer-Assisted;Mice;Models, Anatomic;Posture;Skull;Skull;Tomography, X-Ray Computed","20","","28","","28 Oct 2010","","","IEEE","IEEE Journals"
"Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation","X. Yang; L. Shi; M. Daianu; H. Tong; Q. Liu; P. Thompson","Chinese Academy of Sciences, SKLCSInstitute of Software; Chinese Academy of Sciences, SKLCSInstitute of Software; Imaging Genetics CenterMark & Mary Stevens Institute for Neuroimaging & InformaticsUniversity of Southern California; School of Computing, Informatics and Decision Systems EngineeringArizona State University; Chinese Academy of Sciences, SKLCSInstitute of Software; Imaging Genetics CenterMark & Mary Stevens Institute for Neuroimaging & InformaticsUniversity of Southern California","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","181","190","Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.","1941-0506","","10.1109/TVCG.2016.2598472","China National 973(grant numbers:2014CB340301); Natural Science Foundation of China(grant numbers:61379088); Alzheimer's Disease Neuroimaging Initiative (ADNI) (NIH)(grant numbers:U01 AG024904); DOD ADNI(grant numbers:W81XWH-12-2-0012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7534826","Brain Network;Visual Comparison;Hybrid Representation","Diffusion tensor imaging;Data visualization;Visual analytics;Diseases;Sociology","biology computing;brain;data analysis;data visualisation","blockwise human brain network visual comparison;NodeTrix representation;brain connectomics;brain network representation;ROI based brain networks;region-of-interest;integrated visual analytics framework;two-level ROI block hierarchy;anatomical structure;node-link graph;adjacency matrix design","Aged;Aged, 80 and over;Algorithms;Brain;Computer Graphics;Connectome;Female;Humans;Image Processing, Computer-Assisted;Male;Middle Aged;Models, Neurological;Nerve Net","20","","42","IEEE","5 Aug 2016","","","IEEE","IEEE Journals"
"Computing 2D Constrained Delaunay Triangulation Using the GPU","M. Qi; T. Cao; T. Tan","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore","IEEE Transactions on Visualization and Computer Graphics","19 Mar 2013","2013","19","5","736","748","We propose the first graphics processing unit (GPU) solution to compute the 2D constrained Delaunay triangulation (CDT) of a planar straight line graph (PSLG) consisting of points and edges. There are many existing CPU algorithms to solve the CDT problem in computational geometry, yet there has been no prior approach to solve this problem efficiently using the parallel computing power of the GPU. For the special case of the CDT problem where the PSLG consists of just points, which is simply the normal Delaunay triangulation (DT) problem, a hybrid approach using the GPU together with the CPU to partially speed up the computation has already been presented in the literature. Our work, on the other hand, accelerates the entire computation on the GPU. Our implementation using the CUDA programming model on NVIDIA GPUs is numerically robust, and runs up to an order of magnitude faster than the best sequential implementations on the CPU. This result is reflected in our experiment with both randomly generated PSLGs and real-world GIS data having millions of points and edges.","1941-0506","","10.1109/TVCG.2012.307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6361389","GPGPU;parallel computation;computational geometry;Voronoi diagram;image vectorization","Graphics processing units;Instruction sets;Arrays;Strips;Standards;Color","graphics processing units;mesh generation;parallel architectures","computing 2D constrained Delaunay triangulation;graphics processing unit;CDT;planar straight line graph;PSLG;computational geometry;parallel computing power;CUDA programming model;NVIDIA GPU","Algorithms;Computer Graphics;Image Enhancement;Image Enhancement;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted","20","","30","","26 Nov 2012","","","IEEE","IEEE Journals"
"Efficient Computation of Combinatorial Feature Flow Fields","J. Reininghaus; J. Kasten; T. Weinkauf; I. Hotz","Zuse Institute, Berlin-Dahlem; Zuse Institute, Berlin-Dahlem; Max Planck Institute for Informatics, Saarbrücken; Zuse Institute, Berlin-Dahlem","IEEE Transactions on Visualization and Computer Graphics","12 Jul 2012","2012","18","9","1563","1573","We propose a combinatorial algorithm to track critical points of 2D time-dependent scalar fields. Existing tracking algorithms such as Feature Flow Fields apply numerical schemes utilizing derivatives of the data, which makes them prone to noise and involve a large number of computational parameters. In contrast, our method is robust against noise since it does not require derivatives, interpolation, and numerical integration. Furthermore, we propose an importance measure that combines the spatial persistence of a critical point with its temporal evolution. This leads to a time-aware feature hierarchy, which allows us to discriminate important from spurious features. Our method requires only a single, easy-to-tune computational parameter and is naturally formulated in an out-of-core fashion, which enables the analysis of large data sets. We apply our method to synthetic data and data sets from computational fluid dynamics and compare it to the stabilized continuous Feature Flow Field tracking algorithm.","1941-0506","","10.1109/TVCG.2011.269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060947","Flow visualization;graph algorithms.","Feature extraction;Algorithm design and analysis;Joining processes;Manifolds;Noise measurement;Jacobian matrices;Noise","combinatorial mathematics;computational fluid dynamics;flow visualisation;numerical analysis","combinatorial feature flow field computation;combinatorial algorithm;critical points tracking;2D time-dependent scalar fields;tracking algorithms;numerical schemes;computational parameters;noise robustness;importance measure;spatial persistence;temporal evolution;time-aware feature hierarchy;computational fluid dynamics;flow visualization","","20","","41","","25 Oct 2011","","","IEEE","IEEE Journals"
"Motion Sickness Prediction in Stereoscopic Videos using 3D Convolutional Neural Networks","T. M. Lee; J. Yoon; I. Lee",Yonsei University; Kangwon National University; Yonsei University,"IEEE Transactions on Visualization and Computer Graphics","27 Mar 2019","2019","25","5","1919","1927","In this paper, we propose a three-dimensional (3D) convolutional neural network (CNN)-based method for predicting the degree of motion sickness induced by a 360° stereoscopic video. We consider the user's eye movement as a new feature, in addition to the motion velocity and depth features of a video used in previous work. For this purpose, we use saliency, optical flow, and disparity maps of an input video, which represent eye movement, velocity, and depth, respectively, as the input of the 3D CNN. To train our machine-learning model, we extend the dataset established in the previous work using two data augmentation techniques: frame shifting and pixel shifting. Consequently, our model can predict the degree of motion sickness more precisely than the previous method, and the results have a more similar correlation to the distribution of ground-truth sickness.","1941-0506","","10.1109/TVCG.2019.2899186","National Research Foundation of Korea; MSIT(grant numbers:NRF-2017R1A2B4005469,IITP-2018-0-01419); IITP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642906","360° Stereoscopic video;motion sickness;virtual reality;saliency;machine learning;3D CNN","Videos;Stereo image processing;Three-dimensional displays;Optical imaging;Machine learning;Optical saturation;Optical computing","convolutional neural nets;image motion analysis;image sequences;learning (artificial intelligence);stereo image processing;video signal processing","motion sickness prediction;stereoscopic videos;3D convolutional neural networks;three-dimensional convolutional neural network-based method;eye movement;motion velocity;depth features;3D CNN;machine-learning model;optical flow;disparity maps","","20","","57","IEEE","15 Feb 2019","","","IEEE","IEEE Journals"
"Multiresolution indexing of triangulated irregular networks","J. J. Bartholdi; P. Goldsman","Sch. of Ind. & Syst. Eng., Georgia Inst. of Technol., Atlanta, GA, USA; Sch. of Ind. & Syst. Eng., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Visualization and Computer Graphics","18 May 2004","2004","10","4","484","495","We show how to build a continuous, one-dimensional index of the points on a triangulated irregular network (TIN). The index is constructed by first finding an ordering of the triangles in which consecutive triangles share a vertex or an edge. Then, the space within each triangle is continuously indexed with a space-filling curve that begins at one vertex of the triangle and ends at another. The space-filling curve is oriented such that the first point in each triangle is a vertex shared with the previous triangle and the last point is a vertex shared with the next triangle. Furthermore, our index can be refined locally and, therefore, efficiently when the TIN is augmented by filling any face with another TIN (to make a hierarchical TIN). Such processes arise, for example, in the elaboration of detail on a graphical surface.","1941-0506","","10.1109/TVCG.2004.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298805","Triangulated irregular network;TIN;space-filling curve;hierarchical triangulation;multiresolution triangulation;triangle mesh;spatial index.","Indexing;Tin;Spatial resolution;Geographic Information Systems;Strips;Rendering (computer graphics);Filling;Spatial indexes;Computer graphics;Information retrieval","mesh generation;curve fitting;computational geometry","multiresolution indexing;triangulated irregular networks;space-filling curve;hierarchical triangulation;triangle mesh;spatial index","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Signal Processing, Computer-Assisted","20","","28","","18 May 2004","","","IEEE","IEEE Journals"
"On Delay Adjustment for Dynamic Load Balancing in Distributed Virtual Environments","Y. Deng; R. W. H. Lau",City University of Hong Kong; City University of Hong Kong,"IEEE Transactions on Visualization and Computer Graphics","9 Mar 2012","2012","18","4","529","537","Distributed virtual environments (DVEs) are becoming very popular in recent years, due to the rapid growing of applications, such as massive multiplayer online games (MMOGs). As the number of concurrent users increases, scalability becomes one of the major challenges in designing an interactive DVE system. One solution to address this scalability problem is to adopt a multi-server architecture. While some methods focus on the quality of partitioning the load among the servers, others focus on the efficiency of the partitioning process itself. However, all these methods neglect the effect of network delay among the servers on the accuracy of the load balancing solutions. As we show in this paper, the change in the load of the servers due to network delay would affect the performance of the load balancing algorithm. In this work, we conduct a formal analysis of this problem and discuss two efficient delay adjustment schemes to address the problem. Our experimental results show that our proposed schemes can significantly improve the performance of the load balancing algorithm with neglectable computation overhead.","1941-0506","","10.1109/TVCG.2012.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165133","Multi-server architecture;dynamic load balancing;delay adjustment;distributed virtual environments.","Servers;Silicon;Load management;Delay;Heating;Heuristic algorithms;Load modeling","formal specification;formal verification;resource allocation;virtual reality","distributed virtual environment;massive multiplayer online game;interactive DVE system;multiserver architecture;load partitioning;network delay effect;server load;formal analysis;delay adjustment schemes;dynamic load balancing algorithm","Computer Communication Networks;Computer Graphics;Humans;Online Systems;User-Computer Interface;Video Games","20","","25","","9 Mar 2012","","","IEEE","IEEE Journals"
"Probabilistic Graph Layout for Uncertain Network Visualization","C. Schulz; A. Nocaj; J. Goertler; O. Deussen; U. Brandes; D. Weiskopf",VISUSUniversity of Stuttgart; University of Konstanz; University of Konstanz; University of Konstanz; University of Konstanz; VISUSUniversity of Stuttgart,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","531","540","We present a novel uncertain network visualization technique based on node-link diagrams. Nodes expand spatially in our probabilistic graph layout, depending on the underlying probability distributions of edges. The visualization is created by computing a two-dimensional graph embedding that combines samples from the probabilistic graph. A Monte Carlo process is used to decompose a probabilistic graph into its possible instances and to continue with our graph layout technique. Splatting and edge bundling are used to visualize point clouds and network topology. The results provide insights into probability distributions for the entire network-not only for individual nodes and edges. We validate our approach using three data sets that represent a wide range of network types: synthetic data, protein-protein interactions from the STRING database, and travel times extracted from Google Maps. Our approach reveals general limitations of the force-directed layout and allows the user to recognize that some nodes of the graph are at a specific position just by chance.","1941-0506","","10.1109/TVCG.2016.2598919","German Research Foundation (DFG); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539319","Uncertainty visualization;graph layout;graph visualization;edge bundling;Monte Carlo method","Layout;Probabilistic logic;Uncertainty;Data visualization;Visualization;Probability density function;Probability distribution","data visualisation;diagrams;graph theory;Monte Carlo methods;network theory (graphs);statistical distributions","probabilistic graph layout;uncertain network visualization;node-link diagram;edge probability distribution;Monte Carlo process;probabilistic graph decomposition;synthetic data;protein-protein interaction","","20","","45","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"RCLens: Interactive Rare Category Exploration and Identification","H. Lin; S. Gao; D. Gotz; F. Du; J. He; N. Cao","iDVx Lab, Tongji University, Shanghai Shi, China; iDVx Lab, Tongji University, Shanghai Shi, China; University of North Carolina at Chapel Hill, Chapel Hill, NC; University of Maryland, College Park, MD; Arizona State University, Tempe, AZ; iDVx Lab, Tongji University, Shanghai Shi, China","IEEE Transactions on Visualization and Computer Graphics","25 May 2018","2018","24","7","2223","2237","Rare category identification is an important task in many application domains, ranging from network security, to financial fraud detection, to personalized medicine. These are all applications which require the discovery and characterization of sets of rare but structurally-similar data entities which are obscured within a larger but structurally different dataset. This paper introduces RCLens, a visual analytics system designed to support user-guided rare category exploration and identification. RCLens adopts a novel active learning-based algorithm to iteratively identify more accurate rare categories in response to user-provided feedback. The algorithm is tightly integrated with an interactive visualization-based interface which supports a novel and effective workflow for rare category identification. This paper (1) defines RCLens’ underlying active-learning algorithm; (2) describes the visualization and interaction designs, including a discussion of how the designs support user-guided rare category identification; and (3) presents results from an evaluation demonstrating RCLens’ ability to support the rare category identification process.","1941-0506","","10.1109/TVCG.2017.2711030","National Natural Science Foundation of China(grant numbers:61602306); NSF(grant numbers:IIS-1552654,DMS-1557593); ONR(grant numbers:N00014-15-1-2821); IBM SUR Award; IBM Faculty Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939996","Visual analytics;information visualization;rare category detection;machine learning","Algorithm design and analysis;Data visualization;Visualization;Prototypes;Detection algorithms","data analysis;data handling;data visualisation;learning (artificial intelligence)","interactive rare category exploration;structurally-similar data entities;accurate rare categories;visualization;interaction designs;rare category identification process;structurally different dataset;RCLens;active-learning algorithm","","20","","39","IEEE","6 Jun 2017","","","IEEE","IEEE Journals"
"RelEx: Visualization for Actively Changing Overlay Network Specifications","M. Sedlmair; A. Frank; T. Munzner; A. Butz","University of British Columbia; Bertrand AG, Munich; University of British Columbia; University of Munich (LMU)","IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2729","2738","We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.","1941-0506","","10.1109/TVCG.2012.255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327279","Network visualization;change management;traffic routing;traffic optimization;automotive;design study","Data visualization;Change detection algorithms;Network topology;Automotive engineering;Collaboration;Traffic control","automotive electronics;data visualisation;electronic engineering computing;on-board communications;overlay networks;user centred design","overlay network specification;network visualization design;automotive engineer;traffic pattern;in-car communication network;data abstraction;logical communication specification;physical network;visual network analysis;social network analysis;visualization tool RelEx;user-centered design process;usability testing;summative evaluation;change management","","20","","49","","8 Oct 2012","","","IEEE","IEEE Journals"
"Scanning scene tunnel for city traversing","J. Y. Zheng; Y. Zhou; P. Mili","Dept. of Comput. Sci., Indiana Univ., Indianapolis, IN, USA; Dept. of Comput. Sci., Indiana Univ., Indianapolis, IN, USA; Dept. of Comput. Sci., Indiana Univ., Indianapolis, IN, USA","IEEE Transactions on Visualization and Computer Graphics","23 Jan 2006","2006","12","2","155","167","This paper proposes a visual representation named scene tunnel for capturing urban scenes along routes and visualizing them on the Internet. We scan scenes with multiple cameras or a fish-eye camera on a moving vehicle, which generates a real scene archive along streets that is more complete than previously proposed route panoramas. Using a translating spherical eye, properly set planes of scanning, and unique parallel-central projection, we explore the image acquisition of the scene tunnel from camera selection and alignment, slit calculation, scene scanning, to image integration. The scene tunnels cover high buildings, ground, and various viewing directions and have uniformed resolutions along the street. The sequentially organized scene tunnel benefits texture mapping onto the urban models. We analyze the shape characteristics in the scene tunnels for designing visualization algorithms. After combining this with a global panorama and forward image caps, the capped scene tunnels can provide continuous views directly for virtual or real navigation in a city. We render scene tunnel dynamically by view warping, fast transmission, and flexible interaction. The compact and continuous scene tunnel facilitates model construction, data streaming, and seamless route traversing on the Internet and mobile devices.","1941-0506","","10.1109/TVCG.2006.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580450","Digitizing and scanning;image-based modeling and rendering;imaging geometry;augmented and virtual reality;Web-based interaction.","Layout;Cities and towns;Cameras;Visualization;Internet;Algorithm design and analysis;Vehicles;Buildings;Urban planning;Shape","virtual reality;data visualisation;rendering (computer graphics);image representation;image texture;realistic images;Internet","virtual reality;visual representation;scene tunnel;data visualisation;Internet;fish-eye camera;parallel-central projection;image acquisition;scene scanning;texture mapping;route traversing","Algorithms;Artificial Intelligence;Cities;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;Photogrammetry;Signal Processing, Computer-Assisted;Travel;User-Computer Interface","20","6","24","IEEE","23 Jan 2006","","","IEEE","IEEE Journals"
"Small Multiples with Gaps","W. Meulemans; J. Dykes; A. Slingsby; C. Turkay; J. Wood","giCentre, City University, London; giCentre, City University, London; giCentre, City University, London; giCentre, City University, London; giCentre, City University, London","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","381","390","Small multiples enable comparison by providing different views of a single data set in a dense and aligned manner. A common frame defines each view, which varies based upon values of a conditioning variable. An increasingly popular use of this technique is to project two-dimensional locations into a gridded space (e.g. grid maps), using the underlying distribution both as the conditioning variable and to determine the grid layout. Using whitespace in this layout has the potential to carry information, especially in a geographic context. Yet, the effects of doing so on the spatial properties of the original units are not understood. We explore the design space offered by such small multiples with gaps. We do so by constructing a comprehensive suite of metrics that capture properties of the layout used to arrange the small multiples for comparison (e.g. compactness and alignment) and the preservation of the original data (e.g. distance, topology and shape). We study these metrics in geographic data sets with varying properties and numbers of gaps. We use simulated annealing to optimize for each metric and measure the effects on the others. To explore these effects systematically, we take a new approach, developing a system to visualize this design space using a set of interactive matrices. We find that adding small amounts of whitespace to small multiple arrays improves some of the characteristics of 2D layouts, such as shape, distance and direction. This comes at the cost of other metrics, such as the retention of topology. Effects vary according to the input maps, with degree of variation in size of input regions found to be a factor. Optima exist for particular metrics in many cases, but at different amounts of whitespace for different maps. We suggest multiple metrics be used in optimized layouts, finding topology to be a primary factor in existing manually-crafted solutions, followed by a trade-off between shape and displacement. But the rich range of possible optimized layouts leads us to challenge single-solution thinking; we suggest to consider alternative optimized layouts for small multiples with gaps. Key to our work is the systematic, quantified and visual approach to exploring design spaces when facing a trade-off between many competing criteria-an approach likely to be of value to the analysis of other design spaces.","1941-0506","","10.1109/TVCG.2016.2598542","Marie Sklodowska-Curie Action(grant numbers:MSCA-H2020-IF-2014 656741); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536128","Geographic visualization;small multiples;whitespace;design space;metrics;optimization","Measurement;Layout;Shape;Two dimensional displays;Topology;Space exploration","data visualisation;graphs;matrix algebra;set theory;simulated annealing;topology","small multiples;gaps;single data set views;common frame;view definition;two-dimensional location projection;gridded space;grid maps;layout whitespace;geographic context;metric comprehensive suite construction;data preservation;geographic data sets;simulated annealing;metric optimization;design space visualization;interactive matrix set;2D layouts;topology retention;input maps;multiple metrics;layout optimization;manually-crafted solutions","","20","","41","IEEE","8 Aug 2016","","","IEEE","IEEE Journals"
"Supporting Story Synthesis: Bridging the Gap between Visual Analytics and Storytelling","S. Chen; J. Li; G. Andrienko; N. Andrienko; Y. Wang; P. H. Nguyen; C. Turkay","Fraunhofer Institute IAIS, Sankt Augustin, Germany; College of Intelligence and Computing, Tianjin University, Tianjin, China; Fraunhofer Institute IAIS, Sankt Augustin, Germany; Fraunhofer Institute IAIS, Sankt Augustin, Germany; Microsoft Research Asia, Beijing, China; City, University of London, London, United Kingdom; City, University of London, London, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","28 May 2020","2020","26","7","2499","2516","Visual analytics usually deals with complex data and uses sophisticated algorithmic, visual, and interactive techniques supporting the analysis. Findings and results of the analysis often need to be communicated to an audience that lacks visual analytics expertise. This requires analysis outcomes to be presented in simpler ways than that are typically used in visual analytics systems. However, not only analytical visualizations may be too complex for target audiences but also the information that needs to be presented. Analysis results may consist of multiple components, which may involve multiple heterogeneous facets. Hence, there exists a gap on the path from obtaining analysis findings to communicating them, within which two main challenges lie: information complexity and display complexity. We address this problem by proposing a general framework where data analysis and result presentation are linked by story synthesis, in which the analyst creates and organises story contents. Unlike previous research, where analytic findings are represented by stored display states, we treat findings as data constructs. We focus on selecting, assembling and organizing findings for further presentation rather than on tracking analysis history and enabling dual (i.e., explorative and communicative) use of data displays. In story synthesis, findings are selected, assembled, and arranged in meaningful layouts that take into account the structure of information and inherent properties of its components. We propose a workflow for applying the proposed conceptual framework in designing visual analytics systems and demonstrate the generality of the approach by applying it to two diverse domains, social media and movement analysis.","1941-0506","","10.1109/TVCG.2018.2889054","Fraunhofer Cluster of Excellence; EU in projects DiSIEM and SoBigData; Deutsche Forschungsgemeinschaft; National Natural Science Foundation of China(grant numbers:61602340,61572348); National Key R&D Program of China(grant numbers:2018YFC0809800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585048","Story synthesis;visual analytics;social media;spatio-temporal data","Visual analytics;Rivers;Bridges;Social network services;Tools;Hospitals","computational complexity;data analysis;data visualisation;social networking (online)","social media;movement analysis;story synthesis;complex data;sophisticated algorithmic techniques;visual techniques;interactive techniques;visual analytics expertise;analysis outcomes;visual analytics systems;analytical visualizations;target audiences;multiple heterogeneous facets;analysis findings;information complexity;display complexity;data analysis;result presentation;story contents;analytic findings;data constructs;assembling organizing findings;tracking analysis history;data displays","","20","","70","IEEE","21 Dec 2018","","","IEEE","IEEE Journals"
"Towards Better Bus Networks: A Visual Analytics Approach","D. Weng; C. Zheng; Z. Deng; M. Ma; J. Bao; Y. Zheng; M. Xu; Y. Wu","State Key Lab of CAD&CG, Zhejiang University, China and Zhejiang Lab, Hangzhou, China; Zhejiang Lab, Hangzhou, China; State Key Lab of CAD&CG, Zhejiang University, China and Zhejiang Lab, Hangzhou, China; Zhejiang Lab, Hangzhou, China; JD Intelligent Cities Research, JD Intelligent Cities Business Unit, JD Digits, Beijing, China; JD Intelligent Cities Research, JD Intelligent Cities Business Unit, JD Digits, Beijing, China; School of Information Engineering, Zhengzhou University, Henan Institute of Advanced Technology, Zhengzhou University, Zhengzhou, China; State Key Lab of CAD&CG, Zhejiang University, China and Zhejiang Lab, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","817","827","Bus routes are typically updated every 3-5 years to meet constantly changing travel demands. However, identifying deficient bus routes and finding their optimal replacements remain challenging due to the difficulties in analyzing a complex bus network and the large solution space comprising alternative routes. Most of the automated approaches cannot produce satisfactory results in real-world settings without laborious inspection and evaluation of the candidates. The limitations observed in these approaches motivate us to collaborate with domain experts and propose a visual analytics solution for the performance analysis and incremental planning of bus routes based on an existing bus network. Developing such a solution involves three major challenges, namely, a) the in-depth analysis of complex bus route networks, b) the interactive generation of improved route candidates, and c) the effective evaluation of alternative bus routes. For challenge a, we employ an overview-to-detail approach by dividing the analysis of a complex bus network into three levels to facilitate the efficient identification of deficient routes. For challenge b, we improve a route generation model and interpret the performance of the generation with tailored visualizations. For challenge c, we incorporate a conflict resolution strategy in the progressive decision-making process to assist users in evaluating the alternative routes and finding the most optimal one. The proposed system is evaluated with two usage scenarios based on real-world data and received positive feedback from the experts.","1941-0506","","10.1109/TVCG.2020.3030458","National Natural Science Foundation of China-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:U1609217); National Key R&D Program of China(grant numbers:2018YFB1004300); National Natural Science Foundation of China(grant numbers:61761136020); Natural Science Foundation of Zhejiang Province(grant numbers:LR18F020001); National Natural Science Foundation of China-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:(U1609217)); National Key R&D Program of China(grant numbers:(2018YFB1004300)); National Natural Science Foundation of China(grant numbers:(61761136020)); Natural Science Foundation of Zhejiang Province(grant numbers:(LR18F020001)); Talents Program of Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222274","Bus route planning;spatial decision-making;urban data visual analytics","Visual analytics;Planning;Transportation;Data visualization;Decision making;Urban areas;Knowledge engineering","data visualisation;decision making;optimisation;planning;vehicle routing","automated approaches;visual analytics solution;performance analysis;complex bus route networks;route candidates;decision-making process;travel demands;visual analytics approach;route generation model;alternative bus routes","","20","","84","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"VisOHC: Designing Visual Analytics for Online Health Communities","B. C. Kwon; S. -H. Kim; S. Lee; J. Choo; J. Huh; J. S. Yi",University of Konstanz; University of British Columbia; Purdue University; Korea University; Michigan State University; Purdue University,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","71","80","Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.","1941-0506","","10.1109/TVCG.2015.2467555","National Library of Medicine of the National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192683","Online health communities;visual analytics;conversation analysis;thread visualization;healthcare,;design study,;Online health communities;visual analytics;conversation analysis;thread visualization;healthcare;design study","Message systems;Atmospheric measurements;Particle measurements;Visual analytics;Prototypes;Market research","data analysis;data visualisation;health care;medical administrative data processing","VisOHC system;visual analytics;online health communities;OHC conversation threads;collapsed boxes;visual design;visual variables","Computer Graphics;Data Mining;Health Communication;Health Information Exchange;Humans;Internet;Pattern Recognition, Automated;Social Media;Social Support","20","1","44","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Visual Readability Analysis: How to Make Your Writings Easier to Read","D. Oelke; D. Spretke; A. Stoffel; D. A. Keim","University of Konstanz, Konstanz; University of Konstanz, Konstanz; University of Konstanz, Konstanz; University of Konstanz, Konstanz","IEEE Transactions on Visualization and Computer Graphics","15 Mar 2012","2012","18","5","662","674","We present a tool that is specifically designed to support a writer in revising a draft version of a document. In addition to showing which paragraphs and sentences are difficult to read and understand, we assist the reader in understanding why this is the case. This requires features that are expressive predictors of readability, and are also semantically understandable. In the first part of the paper, we, therefore, discuss a semiautomatic feature selection approach that is used to choose appropriate measures from a collection of 141 candidate readability features. In the second part, we present the visual analysis tool VisRA, which allows the user to analyze the feature values across the text and within single sentences. Users can choose between different visual representations accounting for differences in the size of the documents and the availability of information about the physical and logical layout of the documents. We put special emphasis on providing as much transparency as possible to ensure that the user can purposefully improve the readability of a sentence. Several case studies are presented that show the wide range of applicability of our tool. Furthermore, an in-depth evaluation assesses the quality of the measure and investigates how well users do in revising a text with the help of the tool.","1941-0506","","10.1109/TVCG.2011.266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051432","Document and text processing;feature evaluation and selection.","Vocabulary;Correlation;Training data;Length measurement;Navigation;Visual analytics","learning (artificial intelligence);text analysis","visual readability analysis;semiautomatic feature selection approach;visual analysis tool;visual representations;VisRA;draft version;text processing;document processing","Books;Comprehension;Computer Graphics;Databases, Factual;Humans;Image Processing, Computer-Assisted;Linguistics;Reading;Software;Writing","20","","31","","18 Oct 2011","","","IEEE","IEEE Journals"
"Visualizing Causal Semantics Using Animations","N. R. Kadaba; P. P. Irani; J. Leboe","Department of Computer Science, University of Manitoba; Department of Computer Science, University of Manitoba; Department of Psychology, University of Manitoba","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1254","1261","Michotte's theory of ampliation suggests that causal relationships are perceived by objects animated under appropriate spatiotemporal conditions. We extend the theory of ampliation and propose that the immediate perception of complex causal relations is also dependent on a set of structural and temporal rules. We designed animated representations, based on Michotte's rules, for showing complex causal relationships or causal semantics. In this paper we describe a set of animations for showing semantics such as causal amplification, causal strength, causal dampening, and causal multiplicity. In a two part study we compared the effectiveness of both the static and animated representations. The first study (N=44) asked participants to recall passages that were previously displayed using both types of representations. Participants were 8% more accurate in recalling causal semantics when they were presented using animations instead of static graphs. In the second study (N=112) we evaluated the intuitiveness of the representations. Our results showed that while users were as accurate with the static graphs as with the animations, they were 9% faster in matching the correct causal statements in the animated condition. Overall our results show that animated diagrams that are designed based on perceptual rules such as those proposed by Michotte have the potential to facilitate comprehension of complex causal relations.","1941-0506","","10.1109/TVCG.2007.70528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376148","Causality;visualization;semantics;animated graphs;perception;visualizing cause and effect;graph semantics.","Visualization;Animation;Tires;Spatiotemporal phenomena;Humans;Iron;Fires;Motion pictures;Physics;Uncertainty","behavioural sciences computing;computer animation;data visualisation","causal semantics visualization;animation;complex causal relations;Michotte rules;causal amplification;causal strength;causal dampening;causal multiplicity;static graphs","","20","","21","","5 Nov 2007","","","IEEE","IEEE Journals"
"Visualizing the Intellectual Structure with Paper-Reference Matrices","J. Zhang; C. Chen; J. Li",Drexel University; Drexel University; Drexel University,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1153","1160","Visualizing the intellectual structure of scientific domains using co-cited units such as references or authors has become a routine for domain analysis. In previous studies, paper-reference matrices are usually transformed into reference-reference matrices to obtain co-citation relationships, which are then visualized in different representations, typically as node-link networks, to represent the intellectual structures of scientific domains. Such network visualizations sometimes contain tightly knit components, which make visual analysis of the intellectual structure a challenging task. In this study, we propose a new approach to reveal co-citation relationships. Instead of using a reference-reference matrix, we directly use the original paper-reference matrix as the information source, and transform the paper-reference matrix into an FP-tree and visualize it in a Java-based prototype system. We demonstrate the usefulness of our approach through visual analyses of the intellectual structure of two domains: information visualization and Sloan Digital Sky Survey (SDSS). The results show that our visualization not only retains the major information of co-citation relationships, but also reveals more detailed sub-structures of tightly knit clusters than a conventional node-link network visualization.","1941-0506","","10.1109/TVCG.2009.202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290724","Intellectual Structure;Paper-reference Matrix;FP-tree;Co-citation","Data visualization;Information analysis;Prototypes;Java;Tree data structures;Chaos;Joining processes;Testing;Libraries;Information science","astronomical surveys;astronomy computing;citation analysis;data visualisation;Java;network theory (graphs);pattern clustering;scientific information systems;trees (mathematics)","intellectual structure visualization;paper-reference matrix;scientific domain analysis;co-cited unit;reference analysis;author analysis;reference-reference matrix;co-citation relationship;node-link network visualization;visual analysis;information source;FP-tree;Java-based prototype system;information visualization;Sloan Digital Sky Survey;SDSS;tightly-knit cluster","","20","","35","","23 Oct 2009","","","IEEE","IEEE Journals"
"A Neuron Membrane Mesh Representation for Visualization of Electrophysiological Simulations","S. Lasserre; J. Hernando; S. Hill; F. Schuermann; P. de Miguel Anasagasti; G. A. Jaoude; H. Markram","Ecole Polytechnique Fédérale de Lausanne, Lausanne; Universidad Politécnica de Madrid, Madrid; Ecole Polytechnique Fédérale de Lausanne, Lausanne; Ecole Polytechnique Fédérale de Lausanne, Lausanne; Universidad Politécnica de Madrid, Madrid; Ecole Polytechnique Fédérale de Lausanne, Lausanne; Ecole Polytechnique Fédérale de Lausanne, Lausanne","IEEE Transactions on Visualization and Computer Graphics","12 Dec 2011","2012","18","2","214","227","We present a process to automatically generate three-dimensional mesh representations of the complex, arborized cell membrane surface of cortical neurons (the principal information processing cells of the brain) from nonuniform morphological measurements. Starting from manually sampled morphological points (3D points and diameters) from neurons in a brain slice preparation, we construct a polygonal mesh representation that realistically represents the continuous membrane surface, closely matching the original experimental data. A mapping between the original morphological points and the newly generated mesh enables simulations of electrophysiolgical activity to be visualized on this new membrane representation. We compare the new mesh representation with the state of the art and present a series of use cases and applications of this technique to visualize simulations of single neurons and networks of multiple neurons.","1941-0506","","10.1109/TVCG.2011.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728807","Visualization techniques and methodologies;curve;surface;solid;and object representation;data mapping;neuronal network visualization.","Neurons;Surface morphology;Face;Morphology;Biomembranes;Three dimensional displays;Shape","bioelectric phenomena;biology computing;brain;data visualisation;digital simulation;mesh generation","neuron membrane mesh representation;electrophysiological simulation visualization;three-dimensional mesh representation generation;complex arborized cell membrane surface;cortical neurons;polygonal mesh representation;morphological points","Algorithms;Animals;Brain;Computer Simulation;Electrophysiological Phenomena;Humans;Image Processing, Computer-Assisted;Models, Neurological;Nerve Net;Nerve Net;Neuroimaging;Neurons;Neurons;Reproducibility of Results","19","","41","IEEE","10 Mar 2011","","","IEEE","IEEE Journals"
"A Trajectory-Preserving Synchronization Method for Collaborative Visualization","L. W. f. Li; F. W. b. Li; R. W. h. Lau","Dept. of Comput. Sci., City Univ. of Hong Kong; NA; NA","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","989","996","In the past decade, a lot of research work has been conducted to support collaborative visualization among remote users over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications of collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical system requirement for collaborative visualization is to ensure that remote users would perceive a synchronized view of the shared data. Failing this requirement, the user's ability in performing the desirable collaborative tasks would be affected. In this paper, we propose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is perceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic objects. It also handles the false positive and false negative collision detection problems. The new method is particularly well designed for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the effectiveness of our method through a number of experiments","1941-0506","","10.1109/TVCG.2006.114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015456","Collaborative visualization;network latency;motion synchronization;distributed synchronization.","Collaboration;Data visualization;Collaborative work;Delay;Problem-solving;Network servers;Meteorology;Virtual environment;Fluid dynamics;Broadcasting","data visualisation;groupware;motion control;position control;synchronisation","motion trajectory-preserving synchronization method;collaborative visualization;dynamic object interaction;application participants;network latency;false positive collision detection problems;false negative collision detection problems;content change handling;unpredictable user interventions","","19","","27","","20 Nov 2006","","","IEEE","IEEE Journals"
"Accurate direct illumination using iterative adaptive sampling","M. Donikian; B. Walter; Kavita Bala; S. Fernandez; D. P. Greenberg",NA; NA; NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","20 Mar 2006","2006","12","3","353","364","This paper introduces a new multipass algorithm for efficiently computing direct illumination in scenes with many lights and complex occlusion. Images are first divided into 8times8 pixel blocks and for each point to be shaded within a block, a probability density function (PDF) is constructed over the lights and sampled to estimate illumination using a small number of shadow rays. Information from these samples is then aggregated at both the pixel and block level and used to optimize the PDFs for the next pass. Over multiple passes the PDFs and pixel estimates are updated until convergence. Using aggregation and feedback progressively improves the sampling and automatically exploits both visibility and spatial coherence. We also use novel extensions for efficient antialiasing. Our adaptive multipass approach computes accurate direct illumination eight times faster than prior approaches in tests on several complex scenes","1941-0506","","10.1109/TVCG.2006.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608022","Raytracing;Monte Carlo;shadowing.","Lighting;Sampling methods;Layout;Image sampling;Iterative algorithms;Pixel;Probability density function;Convergence;Feedback;Spatial coherence","antialiasing;hidden feature removal;image sampling;image segmentation;iterative methods;lighting;probability;ray tracing;rendering (computer graphics)","direct illumination;iterative adaptive sampling;multipass algorithm;occlusion;probability density function;shadow rays;visibility;spatial coherence;antialiasing","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Light;Lighting;Photometry;Reproducibility of Results;Sample Size;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface","19","2","25","","20 Mar 2006","","","IEEE","IEEE Journals"
"Data Visualization Optimization via Computational Modeling of Perception","D. Pineo; C. Ware","University of New Hampshire, Durham; University of New Hampshire, Durham","IEEE Transactions on Visualization and Computer Graphics","12 Dec 2011","2012","18","2","309","320","We present a method for automatically evaluating and optimizing visualizations using a computational model of human vision. The method relies on a neural network simulation of early perceptual processing in the retina and primary visual cortex. The neural activity resulting from viewing flow visualizations is simulated and evaluated to produce a metric of visualization effectiveness. Visualization optimization is achieved by applying this effectiveness metric as the utility function in a hill-climbing algorithm. We apply this method to the evaluation and optimization of 2D flow visualizations, using two visualization parameterizations: streaklet-based and pixel-based. An emergent property of the streaklet-based optimization is head-to-tail streaklet alignment. It had been previously hypothesized the effectiveness of head-to-tail alignment results from the perceptual processing of the visual system, but this theory had not been computationally modeled. A second optimization using a pixel-based parameterization resulted in a LIC-like result. The implications in terms of the selection of primitives is discussed. We argue that computational models can be used for optimizing complex visualizations. In addition, we argue that they can provide a means of computationally evaluating perceptual theories of visualization, and as a method for quality control of display methods.","1941-0506","","10.1109/TVCG.2011.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728805","Information visualization;perception;human information processing;neural nets;optimization.","Data visualization;Computational modeling;Visualization;Neurons;Retina;Image color analysis;Data models","biology computing;data visualisation;digital simulation;eye;neural nets;visual perception","data visualization optimization;perception computational modeling;human vision computational model;neural network simulation;retina;primary visual cortex;hill-climbing algorithm;2D flow visualizations;streaklet-based optimization;head-to-tail streaklet alignment;pixel-based parameterization;LIC-like result","Computer Graphics;Computer Simulation;Humans;Models, Neurological;Nerve Net;Retina;Visual Cortex;Visual Perception","19","","38","IEEE","10 Mar 2011","","","IEEE","IEEE Journals"
"Efficient LBM Visual Simulation on Face-Centered Cubic Lattices","K. Petkov; F. Qiu; Z. Fan; A. E. Kaufman; K. Mueller","Stony Brook University, Stony Brook; Stony Brook University, Stony Brook; Stony Brook University, Stony Brook; Stony Brook University, Stony Brook; Stony Brook University, Stony Brook","IEEE Transactions on Visualization and Computer Graphics","17 Jul 2009","2009","15","5","802","814","The Lattice Boltzmann method (LBM) for visual simulation of fluid flow generally employs cubic Cartesian (CC) lattices such as the D3Q13 and D3Q19 lattices for the particle transport. However, the CC lattices lead to suboptimal representation of the simulation space. We introduce the face-centered cubic (FCC) lattice, fD3Q13, for LBM simulations. Compared to the CC lattices, the fD3Q13 lattice creates a more isotropic sampling of the simulation domain and its single lattice speed (i.e., link length) simplifies the computations and data storage. Furthermore, the fD3Q13 lattice can be decomposed into two independent interleaved lattices, one of which can be discarded, which doubles the simulation speed. The resulting LBM simulation can be efficiently mapped to the GPU, further increasing the computational performance. We show the numerical advantages of the FCC lattice on channeled flow in 2D and the flow-past-a-sphere benchmark in 3D. In both cases, the comparison is against the corresponding CC lattices using the analytical solutions for the systems as well as velocity field visualizations. We also demonstrate the performance advantages of the fD3Q13 lattice for interactive simulation and rendering of hot smoke in an urban environment using thermal LBM.","1941-0506","","10.1109/TVCG.2009.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4796194","Lattice Boltzmann method;face-centered cubic;fD3Q13;D3Q13;D3Q19;GPU.","Computational modeling;FCC;Sampling methods;Lattice Boltzmann methods;Fluid flow;Visualization;Layout;Context modeling;Physics computing;Memory","computational geometry;data visualisation;digital simulation;flow;lattice Boltzmann methods;rendering (computer graphics)","LBM visual simulation;face-centered cubic lattices;lattice Boltzmann method;fluid flow;cubic Cartesian lattices;D3Q13 lattices;D3Q19 lattices;particle transport;fD3Q13 lattice;channeled flow;interactive simulation;thermal LBM","","19","1","30","","27 Feb 2009","","","IEEE","IEEE Journals"
"Graph Thumbnails: Identifying and Comparing Multiple Graphs at a Glance","V. Yoghourdjian; T. Dwyer; K. Klein; K. Marriott; M. Wybrow","Monash University, Clayton, Victoria, Australia; Monash University, Clayton, Victoria, Australia; University of Konstanz, Konstanz, Germany; Monash University, Clayton, Victoria, Australia; Monash University, Clayton, Victoria, Australia","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2018","2018","24","12","3081","3095","We propose Graph Thumbnails, small icon-like visualisations of the high-level structure of network data. Graph Thumbnails are designed to be legible in small multiples to support rapid browsing within large graph corpora. Compared to existing graph-visualisation techniques our representation has several advantages: (1) the visualisation can be computed in linear time; (2) it is canonical in the sense that isomorphic graphs will always have identical thumbnails; and (3) it provides precise information about the graph structure. We report the results of two user studies. The first study compares Graph Thumbnails to node-link and matrix views for identifying similar graphs. The second study investigates the comprehensibility of the different representations. We demonstrate the usefulness of this representation for summarising the evolution of protein-protein interaction networks across a range of species.","1941-0506","","10.1109/TVCG.2018.2790961","Australian Research Council Discovery(grant numbers:DP140100077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249874","Network visualisation;circle packing;k-core decomposition;k-connected;network identification;large networks","Visualization;Layout;Data visualization;Proteins;Measurement","data visualisation;graph theory;network theory (graphs)","graph corpora;isomorphic graphs;graph structure;Graph Thumbnails;similar graph identification;graph-visualisation techniques;small icon-like visualisations;high-level network data structure;node-link;matrix views;protein-protein interaction networks","","19","","57","Crown","8 Jan 2018","","","IEEE","IEEE Journals"
"How Visualization Layout Relates to Locus of Control and Other Personality Factors","C. Ziemkiewicz; A. Ottley; R. J. Crouser; A. R. Yauilla; S. L. Su; W. Ribarsky; R. Chang","Brown University, Providence; Tufts University, Medford; Tufts University, Medford; Winthrop University, Rock Hill; Google Inc., Mountain View; UNC, Charlotte; Tufts University, Medford","IEEE Transactions on Visualization and Computer Graphics","6 May 2013","2013","19","7","1109","1121","Existing research suggests that individual personality differences are correlated with a user's speed and accuracy in solving problems with different types of complex visualization systems. We extend this research by isolating factors in personality traits as well as in the visualizations that could have contributed to the observed correlation. We focus on a personality trait known as ""locus of control” (LOC), which represents a person's tendency to see themselves as controlled by or in control of external events. To isolate variables of the visualization design, we control extraneous factors such as color, interaction, and labeling. We conduct a user study with four visualizations that gradually shift from a list metaphor to a containment metaphor and compare the participants' speed, accuracy, and preference with their locus of control and other personality factors. Our findings demonstrate that there is indeed a correlation between the two: participants with an internal locus of control perform more poorly with visualizations that employ a containment metaphor, while those with an external locus of control perform well with such visualizations. These results provide evidence for the externalization theory of visualization. Finally, we propose applications of these findings to adaptive visual analytics and visualization evaluation.","1941-0506","","10.1109/TVCG.2012.180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6297975","Visualization;individual differences;locus of control","Layout;Data visualization;Problem-solving;Correlation;Visual analytics;Electronic mail","data visualisation","visualization layout;locus of control;personality factors;individual personality difference;complex visualization systems;personality traits;LOC;color;interaction;labeling;list metaphor;containment metaphor;adaptive visual analytics;visualization evaluation;visualization externalization theory","Age Factors;Computer Graphics;Extraversion (Psychology);Humans;Internal-External Control;Introversion (Psychology);Personality;Personality Assessment;Sex Factors;Visual Perception","19","1","38","","10 Sep 2012","","","IEEE","IEEE Journals"
"Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis","W. Willett; S. Ginosar; A. Steinitz; B. Hartmann; M. Agrawala",INRIA; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2198","2206","We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.","1941-0506","","10.1109/TVCG.2013.164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634191","Market research;Redundancy;Data analysis;Social network services;Image color analysis;Clustering algorithms;Social Data Analysis;Crowdsourcing","Market research;Redundancy;Data analysis;Social network services;Image color analysis;Clustering algorithms","data analysis;groupware;information filtering;online front-ends;pattern clustering;sorting","redundancy explanation identification;crowdsourced data analysis;explanation provenance expose;crowd-assisted techniques;crowdsourced explanations;color clustering with representative selection;workers browsing behavior;embedded Web browser;provenance information;source-review tasks;explanation-management interface;response filtering;response sorting","Algorithms;Computer Graphics;Data Mining;Databases, Factual;Information Storage and Retrieval;Internet;User-Computer Interface","19","4","23","","16 Oct 2013","","","IEEE","IEEE Journals"
"Kd-Jump: a Path-Preserving Stackless Traversal for Faster Isosurface Raytracing on GPUs","D. M. Hughes; I. S. Lim","School of Computer Science, Bangor University, UK; Computer Science, Bangor University, UK","IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1555","1562","Stackless traversal techniques are often used to circumvent memory bottlenecks by avoiding a stack and replacing return traversal with extra computation. This paper addresses whether the stackless traversal approaches are useful on newer hardware and technology (such as CUDA). To this end, we present a novel stackless approach for implicit kd-trees, which exploits the benefits of index-based node traversal, without incurring extra node visitation. This approach, which we term Kd-Jump, enables the traversal to immediately return to the next valid node, like a stack, without incurring extra node visitation (kd-restart). Also, Kd-Jump does not require global memory (stack) at all and only requires a small matrix in fast constant-memory. We report that Kd-Jump outperforms a stack by 10 to 20% and kd-restar t by 100%. We also present a Hybrid Kd-Jump, which utilizes a volume stepper for leaf testing and a run-time depth threshold to define where kd-tree traversal stops and volume-stepping occurs. By using both methods, we gain the benefits of empty space removal, fast texture-caching and realtime ability to determine the best threshold for current isosurface and view direction.","1941-0506","","10.1109/TVCG.2009.161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290773","Raytracing;isosurface;GPU;parallel computing;volume visualization","Isosurfaces;Data visualization;Hardware;Acceleration;Layout;Computer science;Foot;Aneurysm;Skull;Testing","computer graphics;coprocessors;ray tracing","Kd-Jump;path-preserving stackless traversal;isosurface raytracing;GPU;kd-trees;index-based node traversal","Algorithms;Computer Graphics;Foot;Humans;Image Processing, Computer-Assisted;Skull","19","4","25","","23 Oct 2009","","","IEEE","IEEE Journals"
"Magnostics: Image-Based Search of Interesting Matrix Views for Guided Network Exploration","M. Behrisch; B. Bach; M. Hund; M. Delz; L. Von Rüden; J. Fekete; T. Schreck","University of Konstanz, Germany; Microsoft Research-Inria Joint Centre, Saclay, France; University of Konstanz, Germany; University of Konstanz, Germany; Capgemini, RWTH Aachen University; Inria, Saclay, France; Graz University of Technology, Austria","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","31","40","In this work we address the problem of retrieving potentially interesting matrix views to support the exploration of networks. We introduce Matrix Diagnostics (or Magnostics), following in spirit related approaches for rating and ranking other visualization techniques, such as Scagnostics for scatter plots. Our approach ranks matrix views according to the appearance of specific visual patterns, such as blocks and lines, indicating the existence of topological motifs in the data, such as clusters, bi-graphs, or central nodes. Magnostics can be used to analyze, query, or search for visually similar matrices in large collections, or to assess the quality of matrix reordering algorithms. While many feature descriptors for image analyzes exist, there is no evidence how they perform for detecting patterns in matrices. In order to make an informed choice of feature descriptors for matrix diagnostics, we evaluate 30 feature descriptors-27 existing ones and three new descriptors that we designed specifically for MAGNOSTICS-with respect to four criteria: pattern response, pattern variability, pattern sensibility, and pattern discrimination. We conclude with an informed set of six descriptors as most appropriate for Magnostics and demonstrate their application in two scenarios; exploring a large collection of matrices and analyzing temporal networks.","1941-0506","","10.1109/TVCG.2016.2598467","German Research Foundation (DFG); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7534849","Matrix Visualization;Visual Quality Measures;Quality Metrics;Feature Detection/Selection;Relational Data","Visualization;Data visualization;Feature extraction;Symmetric matrices;Data analysis;Layout;Density measurement","data visualisation;feature extraction;graph theory;image retrieval;matrix algebra","magnostics;image-based search;guided network exploration;interesting matrix view retrieval;matrix diagnostics;visualization technique;scagnostics;scatter plots;visual pattern appearance;topological motif;cluster;bigraph;visually similar matrices;matrix reordering algorithm;feature descriptors;image analysis;matrix pattern detection;pattern response;pattern variability;pattern sensibility;pattern discrimination;temporal network analysis","","19","","49","IEEE","5 Aug 2016","","","IEEE","IEEE Journals"
"Munin: A Peer-to-Peer Middleware for Ubiquitous Analytics and Visualization Spaces","S. K. Badam; E. Fisher; N. Elmqvist","School of Electrical & Computer Engineering, Purdue University, West Lafayette, IN; School of Electrical & Computer Engineering, Purdue University, West Lafayette, IN; School of Electrical & Computer Engineering, Purdue University, West Lafayette, IN","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2014","2015","21","2","215","228","We present Munin, a software framework for building ubiquitous analytics environments consisting of multiple input and output surfaces, such as tabletop displays, wall-mounted displays, and mobile devices. Munin utilizes a service-based model where each device provides one or more dynamically loaded services for input, display, or computation. Using a peer-to-peer model for communication, it leverages IP multicast to replicate the shared state among the peers. Input is handled through a shared event channel that lets input and output devices be fully decoupled. It also provides a data-driven scene graph to delegate rendering to peers, thus creating a robust, fault-tolerant, decentralized system. In this paper, we describe Munin's general design and architecture, provide several examples of how we are using the framework for ubiquitous analytics and visualization, and present a case study on building a Munin assembly for multidimensional visualization. We also present performance results and anecdotal user feedback for the framework that suggests that combining a service-oriented, data-driven model with middleware support for data sharing and event handling eases the design and execution of high performance distributed visualizations.","1941-0506","","10.1109/TVCG.2014.2337337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6851203","Ubiquitous analytics;high-resolution displays;multi-display environments;distributed visualization;framework;Ubiquitous analytics;high-resolution displays;multi-display environments;distributed visualization;framework","Visualization;Data visualization;Rendering (computer graphics);Peer-to-peer computing;Buildings;Computers","computer displays;data visualisation;IP networks;middleware;peer-to-peer computing;rendering (computer graphics);ubiquitous computing","Munin;peer-to-peer middleware;visualization spaces;software framework;ubiquitous analytics environments;tabletop displays;wall-mounted displays;mobile devices;service-based model;IP multicast;shared event channel;data-driven scene graph;rendering;multidimensional visualization;anecdotal user feedback;service-oriented data-driven model;middleware support;high performance distributed visualizations","","19","","64","IEEE","9 Jul 2014","","","IEEE","IEEE Journals"
"Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks","W. Chen; F. Guo; D. Han; J. Pan; X. Nie; J. Xia; X. Zhang",State Key Lab of CAD and CGZhejiang University; State Key Lab of CAD and CGZhejiang University; State Key Lab of CAD and CGZhejiang University; State Key Lab of CAD and CGZhejiang University; State Key Lab of CAD and CGZhejiang University; Central South University; Pennsylvania State University,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","555","565","When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.","1941-0506","","10.1109/TVCG.2018.2865139","National Basic Research Program of China (973 Program)(grant numbers:2018YFB0904503); National Natural Science Foundation of China(grant numbers:61772456,61761136020,U1736109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440813","Large Network Exploration;Structure-Based Exploration;Suggestive Exploration","Visualization;Navigation;Engines;History;Tools;Systems support;Layout","data visualisation;interactive systems;Internet","visualized network;network nodes;structure-based suggestive exploration approach;user request;user interaction;multiple similar structures;unexplored structures;Web-based visual exploration system;global features;local features;vectorized representation","","19","","80","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"<italic>TextTile</italic>: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text","C. Felix; A. V. Pandey; E. Bertini",New York University; New York University; New York University,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","161","170","We describe TextTile, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. TextTile is based on real-world data analysis problems gathered through our interaction with a number of domain experts and provides a general purpose solution to such problems. The system integrates a set of operations that can interchangeably be applied to the structured as well as to unstructured text part of the data to generate useful data summaries. Such summaries are then organized in visual tiles in a grid layout to allow their analysis and comparison. We validate TextTile with task analysis, use cases and a user study showing the system can be easily learned and proficiently used to carry out nontrivial tasks.","1941-0506","","10.1109/TVCG.2016.2598447","Knight Foundation's Prototype Fund; CAPES Foundation, Ministry of Education of Brazil(grant numbers:BEX 13235/13-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539549","Exploratory Text Analysis;Knowledge Discovery;Text Visualization","Data visualization;Collaboration;Data analysis;Visualization;Keyword search;Medical services;Business","data analysis;data visualisation;text analysis","TextTile;interactive data visualization tool;seamless exploratory analysis;structured data analysis;unstructured text analysis;data summaries;visual tiles;task analysis","","19","","43","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"A Steering Algorithm for Redirected Walking Using Reinforcement Learning","R. R. Strauss; R. Ramanujan; A. Becker; T. C. Peck",Davidson College; Davidson College; Davidson College; Davidson College,"IEEE Transactions on Visualization and Computer Graphics","31 Mar 2020","2020","26","5","1955","1963","Redirected Walking (RDW) steering algorithms have traditionally relied on human-engineered logic. However, recent advances in reinforcement learning (RL) have produced systems that surpass human performance on a variety of control tasks. This paper investigates the potential of using RL to develop a novel reactive steering algorithm for RDW. Our approach uses RL to train a deep neural network that directly prescribes the rotation, translation, and curvature gains to transform a virtual environment given a user's position and orientation in the tracked space. We compare our learned algorithm to steer-to-center using simulated and real paths. We found that our algorithm outperforms steer-to-center on simulated paths, and found no significant difference on distance traveled on real paths. We demonstrate that when modeled as a continuous control problem, RDW is a suitable domain for RL, and moving forward, our general framework provides a promising path towards an optimal RDW steering algorithm.","1941-0506","","10.1109/TVCG.2020.2973060","Davidson Research Initiative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998570","Virtual Reality;Locomotion;Redirected Walking;Steering Algorithms;Reinforcement Learning","Legged locomotion;Learning (artificial intelligence);Prediction algorithms;Meters;Tracking;Heuristic algorithms;Space exploration","learning (artificial intelligence);neural nets;virtual reality","RL;reactive steering algorithm;deep neural network;learned algorithm;steer-to-center;simulated paths;optimal RDW steering algorithm;reinforcement learning;human-engineered logic;human performance;control tasks;redirected walking steering algorithms","Algorithms;Computer Graphics;Deep Learning;Humans;Video Games;Virtual Reality;Walking","18","","58","IEEE","13 Feb 2020","","","IEEE","IEEE Journals"
"An Extension of Wilkinson’s Algorithm for Positioning Tick Labels on Axes","J. Talbot; S. Lin; P. Hanrahan",Stanford University; Stanford University; Stanford University,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1036","1043","The non-data components of a visualization, such as axes and legends, can often be just as important as the data itself. They provide contextual information essential to interpreting the data. In this paper, we describe an automated system for choosing positions and labels for axis tick marks. Our system extends Wilkinson's optimization-based labeling approach to create a more robust, full-featured axis labeler. We define an expanded space of axis labelings by automatically generating additional nice numbers as needed and by permitting the extreme labels to occur inside the data range. These changes provide flexibility in problematic cases, without degrading quality elsewhere. We also propose an additional optimization criterion, legibility, which allows us to simultaneously optimize over label formatting, font size, and orientation. To solve this revised optimization problem, we describe the optimization function and an efficient search algorithm. Finally, we compare our method to previous work using both quantitative and qualitative metrics. This paper is a good example of how ideas from automated graphic design can be applied to information visualization.","1941-0506","","10.1109/TVCG.2010.130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613441","axis labeling;nice numbers","Labeling;Optimization;Measurement;Visualization;Search problems;Layout","data visualisation;optimisation;search problems","Wilkinson algorithm;tick label positioning;data visualization;data legend;contextual information;data interpretation;axis tick marks;Wilkinson optimization-based labeling;label formatting;font size;label orientation;optimization function;search algorithm;graphic design;information visualization","","18","","12","","28 Oct 2010","","","IEEE","IEEE Journals"
"Combining hierarchy and energy for drawing directed graphs","L. Carmel; D. Harel; Y. Koren","Dept. of Appl. Math. & Comput. Sci., Weizmann Inst. of Sci., Rehovot, Israel; Dept. of Appl. Math. & Comput. Sci., Weizmann Inst. of Sci., Rehovot, Israel; NA","IEEE Transactions on Visualization and Computer Graphics","14 Jun 2004","2004","10","1","46","57","We present an algorithm for drawing directed graphs which is based on rapidly solving a unique one-dimensional optimization problem for each of the axes. The algorithm results in a clear description of the hierarchy structure of the graph. Nodes are not restricted to lie on fixed horizontal layers, resulting in layouts that convey the symmetries of the graph very naturally. The algorithm can be applied without change to cyclic or acyclic digraphs and even to graphs containing both directed and undirected edges. We also derive a hierarchy index from the input digraph, which quantitatively measures its amount of hierarchy.","1941-0506","","10.1109/TVCG.2004.1260757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260757","","NP-hard problem;Quantization;Vectors;Algorithm design and analysis;Iterative algorithms","directed graphs;optimisation;data visualisation;computational complexity","directed graph drawing;one-dimensional optimization problem;force directed layout;hierarchy energy;Fiedler vector;data visualisation;minimum linear arrangement","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Paintings;Pattern Recognition, Automated;Signal Processing, Computer-Assisted;User-Computer Interface","18","1","23","","14 Jun 2004","","","IEEE","IEEE Journals"
"Drawing Contour Trees in the Plane","C. Heine; D. Schneider; H. Carr; G. Scheuermann","Universität Leipzig, Leipzig; Universität Leipzig, Leipzig; University of Leeds, Leeds; Universität Leipzig, Leipzig","IEEE Transactions on Visualization and Computer Graphics","8 Sep 2011","2011","17","11","1599","1611","The contour tree compactly describes scalar field topology. From the viewpoint of graph drawing, it is a tree with attributes at vertices and optionally on edges. Standard tree drawing algorithms emphasize structural properties of the tree and neglect the attributes. Applying known techniques to convey this information proves hard and sometimes even impossible. We present several adaptions of popular graph drawing approaches to the problem of contour tree drawing and evaluate them. We identify five esthetic criteria for drawing contour trees and present a novel algorithm for drawing contour trees in the plane that satisfies four of these criteria. Our implementation is fast and effective for contour tree sizes usually used in interactive systems (around 100 branches) and also produces readable pictures for larger trees, as is shown for an 800 branch example.","1941-0506","","10.1109/TVCG.2010.270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674034","Contour tree;graph layout.","Layout;Stress;Visualization;Image edge detection;Isosurfaces;Minimization;Clustering algorithms","computational geometry;data visualisation;interactive systems;trees (mathematics)","contour tree compactly;scalar field topology;graph drawing;interactive systems","","18","","40","","23 Dec 2010","","","IEEE","IEEE Journals"
"Implementation and analysis of an image-based global illumination framework for animated environments","J. Nimeroff; J. Dorsey; H. Rushmeier","Dept. of Comput. & Inf. Sci., Pennsylvania Univ., Philadelphia, PA, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1996","2","4","283","298","We describe a new framework for efficiently computing and storing global illumination effects for complex, animated environments. The new framework allows the rapid generation of sequences representing any arbitrary path in a ""view space"" within an environment in which both the viewer and objects move. The global illumination is stored as time sequences of range-images at base locations that span the view space. We present algorithms for determining locations for these base images, and the time steps required to adequately capture the effects of object motion. We also present algorithms for computing the global illumination in the base images that exploit spatial and temporal coherence by considering direct and indirect illumination separately. We discuss an initial implementation using the new framework. Results and analysis of our implementation demonstrate the effectiveness of the individual phases of the approach; we conclude with an application of the complete framework to a complex environment that includes object motion.","1941-0506","","10.1109/2945.556498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556498","","Image analysis;Lighting;Animation;Rendering (computer graphics);Layout;Physics computing;Computer Society;Image motion analysis;Application software;Motion analysis","lighting;computer animation;rendering (computer graphics);ray tracing;brightness","image-based global illumination;computer animation;sequence generation;arbitrary path;time sequences;range-images;object motion;spatial coherence;temporal coherence;rendering;radiosity;ray tracing;walk through","","18","4","32","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Line art rendering via a coverage of isoparametric curves","G. Elber","Dept. of Comput. Sci., Technion-Israel Inst. of Technol., Haifa, Israel","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","3","231","239","A line art nonphotorealistic rendering scheme of scenes composed of freeform surfaces is presented. A freeform surface coverage is constructed using a set of isoparametric curves. The density of the isoparametric curves is set to be a function of the illumination of the surface determined using a simple shading model, or of regions of special importance such as silhouettes. The outcome is one way of achieving an aesthetic and attractive line art rendering that employs isoparametric curve based drawings that is suitable for printing publication.<<ETX>></ETX>","1941-0506","","10.1109/2945.466718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=466718","","Subspace constraints;Rendering (computer graphics);Art;Layout;Printing;Pixel;Geometry;Filling;Lighting;Spline","rendering (computer graphics);art;curve fitting;computational geometry","line art rendering;isoparametric curves;nonphotorealistic rendering scheme;freeform surfaces;illumination;shading model;silhouettes;isoparametric curve based drawings;printing publication;NURBs;gridless halftoning","","18","29","19","","6 Aug 2002","","","IEEE","IEEE Journals"
"MPML3D: Scripting Agents for the 3D Internet","H. Prendinger; S. Ullrich; A. Nakasone; M. Ishizuka","National Institute of Informatics, Tokyo; RWTH Aachen University, Aachen; National Institute of Informatics, Tokyo; University of Tokyo, Tokyo","IEEE Transactions on Visualization and Computer Graphics","14 Mar 2011","2011","17","5","655","668","The aim of this paper is two-fold. First, it describes a scripting language for specifying communicative behavior and interaction of computer-controlled agents (""bots”) in the popular three-dimensional (3D) multiuser online world of ""Second Life” and the emerging ""OpenSimulator” project. While tools for designing avatars and in-world objects in Second Life exist, technology for nonprogrammer content creators of scenarios involving scripted agents is currently missing. Therefore, we have implemented new client software that controls bots based on the Multimodal Presentation Markup Language 3D (MPML3D), a highly expressive XML-based scripting language for controlling the verbal and nonverbal behavior of interacting animated agents. Second, the paper compares Second Life and OpenSimulator platforms and discusses the merits and limitations of each from the perspective of agent control. Here, we also conducted a small study that compares the network performance of both platforms.","1941-0506","","10.1109/TVCG.2010.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467067","Artificial;augmented;and virtual realities;graphical user interfaces;synchronous interaction;visualization;markup languages;scripting languages.","Internet;Second Life;Avatars;Markup languages;Informatics;Animation;Virtual reality;Graphical user interfaces;Visualization;Computer crashes","authoring languages;avatars;computer animation;data visualisation;graphical user interfaces;Internet;software agents","MPML3D;scripting agents;3D Internet;scripting language;computer-controlled agents;bots;Second Life;OpenSimulator;avatar design;multimodal presentation markup language 3D;graphical user interfaces","","18","","63","","20 May 2010","","","IEEE","IEEE Journals"
"Non-Eeuclidean spring embedders","S. G. Kobourov; K. Wampler","Dept. of Comput. Sci., Arizona Univ., Tucson, AZ, USA; NA","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","757","767","We present a conceptually simple approach to generalizing force-directed methods for graph layout from Euclidean geometry to Riemannian geometries. Unlike previous work on non-Euclidean force-directed methods, ours is not limited to special classes of graphs, but can be applied to arbitrary graphs. The method relies on extending the Euclidean notions of distance, angle, and force-interactions to smooth non-Euclidean geometries via projections to and from appropriately chosen tangent spaces. In particular, we formally describe the calculations needed to extend such algorithms to hyperbolic and spherical geometries. We also study the theoretical and practical considerations that arise when working with non-Euclidean geometries.","1941-0506","","10.1109/TVCG.2005.103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512025","Index Terms- Force-directed algorithms;spring embedders;non-Euclidean geometry;hyperbolic space;spherical space;graph drawing;information visualization.","Springs;Information geometry;Computational geometry;Data visualization;Tree graphs;Mesh generation;Layout;Mathematics;Graphics;Hydrogen","data visualisation;computational geometry;graph theory","non-Euclidean spring embedder;force-directed method;graph layout;Euclidean geometry;Riemannian geometry;arbitrary graph;tangent space;hyperbolic geometry;spherical geometry;graph drawing;information visualization","Algorithms;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Theoretical;Signal Processing, Computer-Assisted","18","","25","","26 Sep 2005","","","IEEE","IEEE Journals"
"PedVis: A Structured, Space-Efficient Technique for Pedigree Visualization","C. Tuttle; L. G. Nonato; C. Silva","University of Utah; Universidade do Sao Paulo, Brazil; University of Utah","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1063","1072","Public genealogical databases are becoming increasingly populated with historical data and records of the current population's ancestors. As this increasing amount of available information is used to link individuals to their ancestors, the resulting trees become deeper and more dense, which justifies the need for using organized, space-efficient layouts to display the data. Existing layouts are often only able to show a small subset of the data at a time. As a result, it is easy to become lost when navigating through the data or to lose sight of the overall tree structure. On the contrary, leaving space for unknown ancestors allows one to better understand the tree's structure, but leaving this space becomes expensive and allows fewer generations to be displayed at a time. In this work, we propose that the H-tree based layout be used in genealogical software to display ancestral trees. We will show that this layout presents an increase in the number of displayable generations, provides a nicely arranged, symmetrical, intuitive and organized fractal structure, increases the user's ability to understand and navigate through the data, and accounts for the visualization requirements necessary for displaying such trees. Finally, user-study results indicate potential for user acceptance of the new layout.","1941-0506","","10.1109/TVCG.2010.185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613444","Genealogy;Pedigree;H-Tree","Layout;Data visualization;Binary trees;Navigation;Software;Shape;Context","data visualisation;genetics;history;tree data structures","PedVis;pedigree visualization;public genealogical database;historical data;population ancestor;space-efficient layout;data navigation;tree structure;H-tree based layout;genealogical software;ancestral tree;organized fractal structure;visualization requirement;user acceptance","","18","","35","IEEE","28 Oct 2010","","","IEEE","IEEE Journals"
"Principles and Tools for Collaborative Entity-Based Intelligence Analysis","E. A. Bier; S. K. Card; J. W. Bodnar","Palo Alto Research Center, Inc., Palo Alto; Palo Alto Research Center, Inc., Palo Alto; Science Applications International Corporation, McLean","IEEE Transactions on Visualization and Computer Graphics","15 Jan 2010","2010","16","2","178","191","Software tools that make it easier for analysts to collaborate as a natural part of their work will lead to better analysis that is informed by more perspectives. We are interested to know if software tools can be designed that support collaboration even as they allow analysts to find documents and organize information (including evidence, schemas, and hypotheses). We have modified the Entity Workspace system, described previously, to test such designs. We have evaluated the resulting design in both a laboratory study and a study where it is situated with an analysis team. In both cases, effects on collaboration appear to be positive. Key aspects of the design include an evidence notebook optimized for organizing entities (rather than text characters), information structures that can be collapsed and expanded, visualization of evidence that emphasizes events and documents (rather than emphasizing the entity graph), and a notification system that finds entities of mutual interest to multiple analysts. Long-term tests suggest that this approach can support both top-down and bottom-up styles of analysis.","1941-0506","","10.1109/TVCG.2009.104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5226632","User interfaces;graphical user interfaces (GUI);information search and retrieval;information filtering;information systems applications;miscellaneous;group and organization interfaces;collaborative computing;computer-supported cooperative work;Web-based interaction.","Collaborative tools;Collaborative work;Software tools;Collaborative software;Information analysis;Text analysis;System testing;Laboratories;Design optimization;Organizing","groupware;software tools;user interfaces","collaborative entity;intelligence analysis;software tools;entity workspace system;evidence notebook;information structure;evidence visualization;notification system;top-down analysis style;bottom-up analysis style","Algorithms;Artificial Intelligence;Computer Graphics;Computer Simulation;Cooperative Behavior;Information Storage and Retrieval;Models, Theoretical;Software;User-Computer Interface","18","2","18","","28 Aug 2009","","","IEEE","IEEE Journals"
"TreeNetViz: Revealing Patterns of Networks over Tree Structures","L. Gou; X. L. Zhang",The Pennsylvania State University; The Pennsylvania State University,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2449","2458","Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns.","1941-0506","","10.1109/TVCG.2011.247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065012","Compound graph;network and tree;TreeNetViz;visualization;multiscale and cross-scale.","Graphics;Tree data structures;Algorithm design and analysis;Complexity theory;Data visualization","computational complexity;data visualisation;graph theory;optimisation;tree data structures","TreeNetViz;networks patterns;tree structures;network data;social network;social affiliations;expertise areas;compound graph model;TreeNet graph;radial space filling visualization;circle layout;optimization;visual complexity;visual cluttering","","18","","42","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement","C. Panse; M. Sips; D. Keim; S. North",IEEE Computer Society; IEEE Computer Society; IEEE Computer Society; IEEE Computer Society,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","749","756","In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets.","1941-0506","","10.1109/TVCG.2006.198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015426","Geo-spatial Data;Shape Transformation;Cartogram;Pixel Placement","Shape;Data visualization;Cities and towns;Credit cards;Data analysis;Marketing and sales;Telephony;Cellular phones;Kernel;Genomics","cartography;data visualisation","geo-spatial point set visualization;shape transformation;local pixel placement;PixelMaps;information visualization;spatially-transformed maps;global shape functions;cartogram-based map distortion","","18","","12","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"Visualizing Dynamic Hierarchies in Graph Sequences","C. Vehlow; F. Beck; D. Weiskopf","VISUS, University of Stuttgart, Germany; VISUS, University of Stuttgart, Germany; VISUS, University of Stuttgart, Germany","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2016","2016","22","10","2343","2357","Graphs are used to model relations between objects, where these objects can be grouped hierarchically based on their connectivity. In many applications, the relations change over time and so does the hierarchical group structure. We developed a visualization technique that supports the analysis of the topology and the hierarchical group structure of a dynamic graph and the tracking of changes over time. Each graph of a sequence is visualized by an adjacency matrix, where the hierarchical group structure is encoded within the matrix using indentation and nested contours, complemented by icicle plots attached to the matrices. The density within and between subgroups of the hierarchy is represented within the matrices using a gray scale. To visualize changes, transitions and dissimilarities between the hierarchically structured graphs are shown using a flow metaphor and color coding. The design of our visualization technique allows us to show more than one hierarchical group structure of the same graph by stacking the sequences, where hierarchy comparison is supported not only within but also between sequences. To improve the readability, we minimize the number of crossing curves within and between sequences based on a sorting algorithm that sweeps through the sequences of hierarchies.","1941-0506","","10.1109/TVCG.2015.2507595","DFG; DFG(grant numbers:WE 2836/6-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352369","Dynamic graph;hierarchical graph;graph visualization","Visualization;Data visualization;Topology;Three-dimensional displays;Heuristic algorithms;Sorting;Animation","data visualisation;graph theory;matrix algebra;sorting","dynamic hierarchies visualization;graph sequences;dynamic graph topology;dynamic graph hierarchical group structure;adjacency matrix;nested contours;icicle plots;hierarchically structured graphs;flow metaphor;color coding;sorting algorithm","","18","","55","IEEE","10 Dec 2015","","","IEEE","IEEE Journals"
"Visualizing Ranges over Time on Mobile Phones: A Task-Based Crowdsourced Evaluation","M. Brehmer; B. Lee; P. Isenberg; E. K. Choe","Microsoft Research; Microsoft Research; Inria; The University of Maryland, College Park","IEEE Transactions on Visualization and Computer Graphics","27 Nov 2018","2019","25","1","619","629","In the first crowdsourced visualization experiment conducted exclusively on mobile phones, we compare approaches to visualizing ranges over time on small displays. People routinely consume such data via a mobile phone, from temperatures in weather forecasting apps to sleep and blood pressure readings in personal health apps. However, we lack guidance on how to effectively visualize ranges on small displays in the context of different value retrieval and comparison tasks, or with respect to different data characteristics such as periodicity, seasonality, or the cardinality of ranges. Central to our experiment is a comparison between two ways to lay out ranges: a more conventional linear layout strikes a balance between quantitative and chronological scale resolution, while a less conventional radial layout emphasizes the cyclicality of time and may prioritize discrimination between values at its periphery. With results from 87 crowd workers, we found that while participants completed tasks more quickly with linear layouts than with radial ones, there were few differences in terms of error rate between layout conditions. We also found that participants performed similarly with both layouts in tasks that involved comparing superimposed observed and average ranges.","1941-0506","","10.1109/TVCG.2018.2865234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440812","Evaluation;graphical perception;mobile phones;range visualization;crowdsourcing","Data visualization;Mobile handsets;Temperature distribution;Layout;Task analysis;Encoding;Meteorology","crowdsourcing;data visualisation;Internet;mobile computing;smart phones","data characteristics;personal health apps;blood pressure readings;weather forecasting apps;crowdsourced visualization experiment;task-based crowdsourced evaluation;mobile phone;visualizing ranges;linear layouts","","18","","54","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Where's My Data? Evaluating Visualizations with Missing Data","H. Song; D. A. Szafir",University of Colorado; University of Colorado,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","914","924","Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.","1941-0506","","10.1109/TVCG.2018.2864914","NSF CRII: CHS(grant numbers:1657599); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440857","Information Visualization;Graphical Perception;Time Series Data;Data Wrangling;Imputation","Data visualization;Data integrity;Interpolation;Visualization;Bars;Encoding;Time series analysis","bar charts;data analysis;data visualisation;graph theory;time series","data quality;visualization designers;evaluating visualizations;data collection failures;time series datasets;data analysts perception;line graphs;bar charts","","18","","57","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"behaviorism: a framework for dynamic data visualization","A. Forbes; T. Höllerer; G. Legrady",UCSB; UCSB; UCSB,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1164","1171","While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations we present a new software framework, behaviorism, which provides a wide range of flexibility when working with dynamic information on visual, temporal, and ontological levels, but at the same time providing appropriate abstractions which allow developers to create prototypes quickly which can then easily be turned into robust systems. The core of the framework is a set of three interconnected graphs, each with associated operators: a scene graph for high-performance 3D rendering, a data graph for different layers of semantically-linked heterogeneous data, and a timing graph for sophisticated control of scheduling, interaction, and animation. In particular, the timing graph provides a unified system to add behaviors to both data and visual elements, as well as to the behaviors themselves. To evaluate the framework we look briefly at three different projects all of which required novel visualizations in different domains, and all of which worked with dynamic data in different ways: an interactive ecological simulation, an information art installation, and an information visualization technique.","1941-0506","","10.1109/TVCG.2010.126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613455","Visualization System and Toolkit Design (primary keyword);Time-varying Data;Streaming Data;Animation;Visual Design","Data visualization;Visualization;Rendering (computer graphics);Timing;Data models;Animation;Programming","data visualisation;rendering (computer graphics)","dynamic data visualization;information visualization software;high-performance 3D rendering;information art","","18","","37","","28 Oct 2010","","","IEEE","IEEE Journals"
"A Compute Unified System Architecture for Graphics Clusters Incorporating Data Locality","C. Muller; S. Frey; M. Strengert; C. Dachsbacher; T. Ertl",Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart; Visualisierungsinstitut der Universität Stuttgart,"IEEE Transactions on Visualization and Computer Graphics","12 May 2009","2009","15","4","605","617","We present a development environment for distributed GPU computing targeted for multi-GPU systems, as well as graphics clusters. Our system is based on CUDA and logically extends its parallel programming model for graphics processors to higher levels of parallelism, namely, the PCI bus and network interconnects. While the extended API mimics the full function set of current graphics hardware-including the concept of global memory-on all distribution layers, the underlying communication mechanisms are handled transparently for the application developer. To allow for high scalability, in particular for network-interconnected environments, we introduce an automatic GPU-accelerated scheduling mechanism that is aware of data locality. This way, the overall amount of transmitted data can be heavily reduced, which leads to better GPU utilization and faster execution. We evaluate the performance and scalability of our system for bus and especially network-level parallelism on typical multi-GPU systems and graphics clusters.","1941-0506","","10.1109/TVCG.2008.188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4653488","GPU computing;graphics clusters;parallel programming.;Distributed/network graphics;Graphics Systems;Computer Graphics;Computing Methodologies;Concurrent Programming;Programming Techniques;Software/Software Engineering;Concurrent;distributed;and parallel languages;Language Classifications;Programming Languages Software;Graphics processors;Hardware Architecture;Computing Methodologies","Computer architecture;Graphics;Parallel processing;Concurrent computing;Distributed computing;Hardware;Parallel programming;Scalability;Power generation;Rendering (computer graphics)","computer graphics;coprocessors;parallel programming","compute unified system architecture;graphics clusters;data locality;distributed GPU computing;multi-GPU systems;parallel programming model;graphics processors;PCI bus;network interconnects;graphics hardware;communication mechanism;network-interconnected environment;automatic GPU-accelerated scheduling;GPU utilization;network-level parallelism","","17","","23","","17 Oct 2008","","","IEEE","IEEE Journals"
"Acoustic Classification and Optimization for Multi-Modal Rendering of Real-World Scenes","C. Schissler; C. Loftin; D. Manocha","University of North Carolina, Chapel Hill, NC; University of North Carolina, Chapel Hill, NC; University of North Carolina, Chapel Hill, NC","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2018","2018","24","3","1246","1259","We present a novel algorithm to generate virtual acoustic effects in captured 3D models of real-world scenes for multimodal augmented reality. We leverage recent advances in 3D scene reconstruction in order to automatically compute acoustic material properties. Our technique consists of a two-step procedure that first applies a convolutional neural network (CNN) to estimate the acoustic material properties, including frequency-dependent absorption coefficients, that are used for interactive sound propagation. In the second step, an iterative optimization algorithm is used to adjust the materials determined by the CNN until a virtual acoustic simulation converges to measured acoustic impulse responses. We have applied our algorithm to many reconstructed real-world indoor scenes and evaluated its fidelity for augmented reality applications.","1941-0506","","10.1109/TVCG.2017.2666150","Army Research(grant numbers:W911NF-14-1-0437); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849179","Sound propagation;material optimization;recognition","Three-dimensional displays;Acoustics;Computational modeling;Acoustic materials;Acoustic measurements;Solid modeling;Image reconstruction","acoustic imaging;acoustic wave propagation;augmented reality;convolution;feedforward neural nets;image classification;image reconstruction;iterative methods;optimisation;rendering (computer graphics);solid modelling","measured acoustic impulse responses;virtual acoustic simulation converges;iterative optimization algorithm;frequency-dependent absorption coefficients;CNN;convolutional neural network;acoustic material properties;3D scene reconstruction;multimodal augmented reality;captured 3D models;virtual acoustic effects;multimodal rendering;augmented reality applications;real-world indoor scenes","","17","","51","IEEE","9 Feb 2017","","","IEEE","IEEE Journals"
"Balloon Focus: a Seamless Multi-Focus+Context Method for Treemaps","Y. Tu; H. Shen",the Ohio State University; the Ohio State University,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1157","1164","The treemap is one of the most popular methods for visualizing hierarchical data. When a treemap contains a large number of items, inspecting or comparing a few selected items in a greater level of detail becomes very challenging. In this paper, we present a seamless multi-focus and context technique, called Balloon Focus, that allows the user to smoothly enlarge multiple treemap items served as the foci, while maintaining a stable treemap layout as the context. Our method has several desirable features. First, this method is quite general and can be used with different treemap layout algorithms. Second, as the foci are enlarged, the relative positions among all items are preserved. Third, the foci are placed in a way that the remaining space is evenly distributed back to the non-focus treemap items. When Balloon Focus enlarges the focus items to a maximum degree, the above features ensure that the treemap will maintain a consistent appearance and avoid any abrupt layout changes. In our algorithm, a DAG (Directed Acyclic Graph) is used to maintain the positional constraints, and an elastic model is employed to govern the placement of the treemap items. We demonstrate a treemap visualization system that integrates data query, manual focus selection, and our novel multi-focus+context technique, Balloon Focus, together. A user study was conducted. Results show that with Balloon Focus, users can better perform the tasks of comparing the values and the distribution of the foci.","1941-0506","","10.1109/TVCG.2008.114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658125","Index Terms—;Treemap;focus+context;multi-focus;fisheye;magnification;visualizing query results;multi-scale viewing.","Data visualization;Displays;Tree graphs;Computer science;Manuals;Large-scale systems;File systems;Telecommunication traffic;Navigation;Computer interfaces","data visualisation;directed graphs","multifocus+context method;treemaps;data visualization;balloon focus;directed acyclic graph;data query","","17","","28","","24 Oct 2008","","","IEEE","IEEE Journals"
"Capturing the Design Space of Sequential Space-Filling Layouts","T. Baudel; B. Broeksema",IBM; IBM,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2593","2602","We characterize the design space of the algorithms that sequentially tile a rectangular area with smaller, fixed-surface, rectangles. This space consist of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each of these dimensions describe a particular aspect of such layout tasks. This class of layouts is interesting, because, beyond encompassing simple grids, tables and trees, it also includes all kinds of treemaps involving the placement of rectangles. For instance, Slice and dice, Squarified, Strip and Pivot layouts are various points in this five dimensional space. Many classic statistics visualizations, such as 100% stacked bar charts, mosaic plots and dimensional stacking, are also instances of this class. A few new and potentially interesting points in this space are introduced, such as spiral treemaps and variations on the strip layout. The core algorithm is implemented as a JavaScript prototype that can be used as a layout component in a variety of InfoViz toolkits.","1941-0506","","10.1109/TVCG.2012.205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327265","Layout;visualization models;tables & tree layouts;grids;treemaps (slice and dice;strip;squarified and pivot variations);mosaic plots;dimensional stacking","Layout;Algorithm design and analysis;Tree data structures;Spirals","data visualisation","design space;sequential space-filling layouts;rectangular area;independent dimensions;phrase dimension;recurse dimension;score dimension;size dimension;order dimension;pivot layouts;strip layouts;slice layouts;dice layouts;squarified layouts;tables layouts;tree layouts;statistics visualizations;five dimensional space;stacked bar charts;mosaic plots;dimensional stacking;spiral treemaps;JavaScript prototype;layout component;InfoViz toolkits","","17","1","29","","8 Oct 2012","","","IEEE","IEEE Journals"
"Evaluating Multi-User Selection for Exploring Graph Topology on Wall-Displays","A. Prouzeau; A. Bezerianos; O. Chapuis","Univ Paris-Sud & CNRS (LRI), Inria; Univ Paris-Sud & CNRS (LRI), Inria; Univ Paris-Sud & CNRS (LRI), Inria","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2017","2017","23","8","1936","1951","Wall-displays allow multiple users to simultaneously view and analyze large amounts of information, such as the increasingly complex graphs present in domains like biology or social network analysis. We focus on how pairs explore graphs on a touch enabled wall-display using two techniques, both adapted for collaboration: a basic localized selection, and a propagation selection technique that uses the idea of diffusion/transmission from an origin node. We assess in a controlled experiment the impact of selection technique on a shortest path identification task. Pairs consistently divided space even if the task is not spatially divisible, and for the basic selection technique that has a localized visual effect, it led to parallel work that negatively impacted accuracy. The large visual footprint of the propagation technique led to close coordination, improving speed and accuracy for complex graphs only. We then observed the use of propagation on additional graph topology tasks, confirming pair strategies on spatial division and coordination.","1941-0506","","10.1109/TVCG.2016.2592906","Agence Nationale de la Recherche(grant numbers:ANR-10-EQPX-26-01 "Digiscope"); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516722","Wall-displays;multi-user interaction;graph visualization;selection techniques;co-located collaboration","Visualization;Collaboration;Topology;Navigation;Data visualization;Keyboards;Mice","computer displays;data visualisation;graph theory","multiuser selection;graph topology;wall displays;basic localized selection;propagation selection;graph visualization","","17","","69","IEEE","19 Jul 2016","","","IEEE","IEEE Journals"
"Evaluating ‘Graphical Perception’ with CNNs","D. Haehn; J. Tompkin; H. Pfister",Harvard University; Brown University; Harvard University,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","641","650","Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGill's seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations.","1941-0506","","10.1109/TVCG.2018.2865138","Harvard Human Research Protection Program for fast IRB approval; Harvard Research Computing crew; Boston Fire Department for extinguishing flames in our data center(grant numbers:NSF IIS-1447344,NIH 5U01CA198935); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440806","Machine Perception;Graphical Perception;Deep Learning;Convolutional Neural Networks","Visualization;Task analysis;Bars;Data visualization;Convolutional neural networks;Multilayer perceptrons;Computational modeling","computer vision;convolution;data visualisation;feedforward neural nets;human factors;visual perception","human graphical perception;data visualizations;convolutional neural networks;computer vision tasks;elementary perceptual tasks;network architectures;human task performance;CNNs;visual encodings","","17","","50","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Feature Preserving Mesh Denoising Based on Graph Spectral Processing","G. Arvanitis; A. S. Lalos; K. Moustakas; N. Fakotakis","Department of Electrical and Computer Engineering, University of Patras, Rio, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Rio, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Rio, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Rio, Patras, Greece","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2019","2019","25","3","1513","1527","The increasing interest for reliable generation of large scale scenes and objects has facilitated several real-time applications. Although the resolution of the new generation geometry scanners are constantly improving, the output models, are inevitably noisy, requiring sophisticated approaches that remove noise while preserving sharp features. Moreover, we no longer deal exclusively with individual shapes, but with entire scenes resulting in a sequence of 3D surfaces that are affected by noise with different characteristics due to variable environmental factors (e.g., lighting conditions, orientation of the scanning device). In this work, we introduce a novel coarse-to-fine graph spectral processing approach that exploits the fact that the sharp features reside in a low dimensional structure hidden in the noisy 3D dataset. In the coarse step, the mesh is processed in parts, using a model based Bayesian learning method that identifies the noise level in each part and the subspace where the features lie. In the feature-aware fine step, we iteratively smooth face normals and vertices, while preserving geometric features. Extensive evaluation studies carried out under a broad set of complex noise patterns verify the superiority of our approach as compared to the state-of-the-art schemes, in terms of reconstruction quality and computational complexity.","1941-0506","","10.1109/TVCG.2018.2802926","H2020-PHC-2014 RIA project MyAirCoach(grant numbers:643607); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283576","Spectral smoothing;orthogonal iteration;spectral denoising filtering;feature extraction;level noise estimation","Noise reduction;Three-dimensional displays;Feature extraction;Solid modeling;Face;Noise measurement;Surface treatment","belief networks;computational complexity;feature extraction;graph theory;image denoising;image reconstruction;image resolution;iterative methods;learning (artificial intelligence);mesh generation","geometric features;complex noise patterns;coarse-to-fine graph spectral processing approach;computational complexity;environmental factors;Bayesian learning method;noisy 3D dataset;generation geometry scanners;real-time applications;feature preserving mesh denoising","","17","","53","IEEE","6 Feb 2018","","","IEEE","IEEE Journals"
"Generating Graphs for Visual Analytics through Interactive Sketching","Pak Chung Wong; H. Foote; P. Mackey; K. Perrine; G. Chin","Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA; Pacific Northwest Nat. Lab., Richland, WA","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1386","1398","We introduce an interactive graph generator, GreenSketch, designed to facilitate the creation of descriptive graphs required for different visual analytics tasks. The human-centric design approach of GreenSketch enables users to master the creation process without specific training or prior knowledge of graph model theory. The customized user interface encourages users to gain insight into the connection between the compact matrix representation and the topology of a graph layout when they sketch their graphs. Both the human-enforced and machine-generated randomnesses supported by GreenSketch provide the flexibility needed to address the uncertainty factor in many analytical tasks. This paper describes more than two dozen examples that cover a wide variety of graph creations from a single line of nodes to a real-life small-world network that describes a snapshot of telephone connections. While the discussion focuses mainly on the design of GreenSketch, we include a case study that applies the technology in a visual analytics environment and a usability study that evaluates the strengths and weaknesses of our design approach.","1941-0506","","10.1109/TVCG.2006.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703361","Data and knowledge visualization;information visualization;visualization techniques and methodologies;graphs and networks.","Visual analytics;Visualization;Usability;User interfaces;Topology;Uncertainty;Telephony;Testing;Algorithm design and analysis;Routing protocols","data visualisation;graph theory;interactive systems;matrix algebra;user centred design;user interfaces","Data and knowledge visualization;information visualization;visualization techniques and methodologies;graphs and networks.","Algorithms;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Pattern Recognition, Automated;User-Computer Interface","17","1","32","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"MultiStream: A Multiresolution Streamgraph Approach to Explore Hierarchical Time Series","E. Cuenca; A. Sallaberry; F. Y. Wang; P. Poncelet","University of Montpellier, Montpellier, France; Paul Valéry University of Montpellier, Montpellier, France; CSIRO, Canberra, ACT, Australia; University of Montpellier, Montpellier, France","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2018","2018","24","12","3160","3173","Multiple time series are a set of multiple quantitative variables occurring at the same interval. They are present in many domains such as medicine, finance, and manufacturing for analytical purposes. In recent years, streamgraph visualization (evolved from ThemeRiver) has been widely used for representing temporal evolution patterns in multiple time series. However, streamgraph as well as ThemeRiver suffer from scalability problems when dealing with several time series. To solve this problem, multiple time series can be organized into a hierarchical structure where individual time series are grouped hierarchically according to their proximity. In this paper, we present a new streamgraph-based approach to convey the hierarchical structure of multiple time series to facilitate the exploration and comparisons of temporal evolution. Based on a focus+context technique, our method allows time series exploration at different granularities (e.g., from overview to details). To illustrate our approach, two usage examples are presented.","1941-0506","","10.1109/TVCG.2018.2796591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267086","Streamgraph;stacked graph;time series;aggregation;multiresolution visualization;overview+detail;focus+context;fisheye","Time series analysis;Metals;Rocks;Data visualization;Scalability;Visualization;Navigation","data structures;data visualisation;graph theory;image resolution;time series","multiresolution visualization;multiresolution streamgraph;MultiStream;stacked graph representation;time series exploration","","17","","36","IEEE","23 Jan 2018","","","IEEE","IEEE Journals"
"NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models","S. Liu; Z. Li; T. Li; V. Srikumar; V. Pascucci; P. Bremer",Lawrence Livermore National Laboratory; SCI InstituteUniversity of Utah; School of ComputingUniversity of Utah; School of ComputingUniversity of Utah; SCI InstituteUniversity of Utah; Lawrence Livermore National Laboratory,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","651","660","With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.","1941-0506","","10.1109/TVCG.2018.2865230","U.S. Department of Energy by Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344); NSF(grant numbers:1314896,1602127,1649923,DESC0007446,DE-NA0002375,ER26142,DE-SC0010498); NVIDIA Corporation; DOE/SciDAC(grant numbers:DESC0007446); CCMSC(grant numbers:DE-NA0002375); National Nuclear Security Administration(grant numbers:DE-NA0002375); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454904","Natural Language Processing;Interpretable Machine Learning;Natural Language Inference;Attention Visualization","Natural languages;Task analysis;Neural networks;Visualization;Computational modeling;Analytical models;Predictive models","data visualisation;inference mechanisms;learning (artificial intelligence);natural language processing;neural nets","natural language inference problem;perturbation-driven visual interrogation tool;deep learning;neural network model;linguistic tasks;natural language processing;hard-to-debug-systems;visualization system","","17","","40","IEEE","5 Sep 2018","","","IEEE","IEEE Journals"
"Organizing Search Results with a Reference Map","A. Nocaj; U. Brandes",University of Konstanz; University of Konstanz,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2012","2012","18","12","2546","2555","We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user’s mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.","1941-0506","","10.1109/TVCG.2012.250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327260","Search results;mental map;voronoi treemaps;dynamic graph layout;multidimensional scaling;edge bundling","Search methods;Query processing;Edge detection;Tree data structures","computational geometry;digital libraries;graph theory;knowledge based systems;pattern clustering;query formulation","search result organization;reference map;query hits;interrelated items;digital libraries;knowledge bases;user mental map preservation;multidimensional scaling layout;Voronoi treemap;hierarchical clustering;dynamic graph layout;newspaper articles","","17","","46","IEEE","8 Oct 2012","","","IEEE","IEEE Journals"
"Output-Sensitive Construction of Reeb Graphs","H. Doraiswamy; V. Natarajan","Indian Institute of Science, Bangalore; Indian Institute of Science, Bangalore","IEEE Transactions on Visualization and Computer Graphics","14 Nov 2011","2012","18","1","146","159","The Reeb graph of a scalar function represents the evolution of the topology of its level sets. This paper describes a near-optimal output-sensitive algorithm for computing the Reeb graph of scalar functions defined over manifolds or non-manifolds in any dimension. Key to the simplicity and efficiency of the algorithm is an alternate definition of the Reeb graph that considers equivalence classes of level sets instead of individual level sets. The algorithm works in two steps. The first step locates all critical points of the function in the domain. Critical points correspond to nodes in the Reeb graph. Arcs connecting the nodes are computed in the second step by a simple search procedure that works on a small subset of the domain that corresponds to a pair of critical points. The paper also describes a scheme for controlled simplification of the Reeb graph and two different graph layout schemes that help in the effective presentation of Reeb graphs for visual analysis of scalar fields. Finally, the Reeb graph is employed in four different applications-surface segmentation, spatially-aware transfer function design, visualization of interval volumes, and interactive exploration of time-varying data.","1941-0506","","10.1109/TVCG.2011.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710907","Computational topology;scalar functions;Reeb graphs;level set topology;simplification;graph layout.","Level set;Topology;Manifolds;Layout;Algorithm design and analysis;Isosurfaces;Heuristic algorithms","computational geometry;graph theory;search problems;set theory","output sensitive Reeb graphs construction;scalar function;topology evolution;level sets;near optimal output sensitive algorithm;search procedure;visual scalar field analysis;surface segmentation;spatially aware transfer function design;interval volume visualization;interactive time varying data exploration","","17","","44","","10 Feb 2011","","","IEEE","IEEE Journals"
"ProtoSteer: Steering Deep Sequence Model with Prototypes","Y. Ming; P. Xu; F. Cheng; H. Qu; L. Ren",Hong Kong University of Science and Technology; Bosch Research North America; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Bosch Research North America,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","238","248","Recently we have witnessed growing adoption of deep sequence models (e.g. LSTMs) in many application domains, including predictive health care, natural language processing, and log analysis. However, the intricate working mechanism of these models confines their accessibility to the domain experts. Their black-box nature also makes it a challenging task to incorporate domain-specific knowledge of the experts into the model. In ProtoSteer (Prototype Steering), we tackle the challenge of directly involving the domain experts to steer a deep sequence model without relying on model developers as intermediaries. Our approach originates in case-based reasoning, which imitates the common human problem-solving process of consulting past experiences to solve new problems. We utilize ProSeNet (Prototype Sequence Network), which learns a small set of exemplar cases (i.e., prototypes) from historical data. In ProtoSteer they serve both as an efficient visual summary of the original data and explanations of model decisions. With ProtoSteer the domain experts can inspect, critique, and revise the prototypes interactively. The system then incorporates user-specified prototypes and incrementally updates the model. We conduct extensive case studies and expert interviews in application domains including sentiment analysis on texts and predictive diagnostics based on vehicle fault logs. The results demonstrate that involvements of domain users can help obtain more interpretable models with concise prototypes while retaining similar accuracy.","1941-0506","","10.1109/TVCG.2019.2934267","Hong Kong TRS(grant numbers:T41-709/17N); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827944","Sequence Data;Explainable Artificial Intelligence (XAI);Recurrent Neural Networks (RNNs);Prototype Learning","Prototypes;Data visualization;Data models;Machine learning;Computational modeling;Predictive models;Task analysis","case-based reasoning;data analysis;data visualisation","domain-specific knowledge;ProtoSteer;deep sequence model;human problem-solving process;model decisions;user-specified prototypes;application domains;domain users;interpretable models;natural language processing;prototype steering;case-based reasoning;ProSeNet;prototype sequence network;visual summary","Computer Graphics;Deep Learning;Humans;Models, Theoretical;User-Computer Interface","17","","51","IEEE","10 Sep 2019","","","IEEE","IEEE Journals"
"Registration based on projective reconstruction technique for augmented reality systems","M. L. Yuan; S. K. Ong; A. Y. C. Nee","Singapore-MIT Alliance, Nat. Univ. of Singapore, Singapore; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2005","2005","11","3","254","264","In AR systems, registration is one of the most difficult problems currently limiting their application. In this paper, we propose a simple registration method using projective reconstruction. This method consists of two steps: embedding and tracking. Embedding involves specifying four points to build the world coordinate system on which a virtual object will be superimposed. In tracking, a projective reconstruction technique is used to track these four specified points to compute the model view transformation for augmentation. This method is simple, as only four points need to be specified at the embedding stage and the virtual object can then be easily augmented onto a real scene from a video sequence. In addition, it can be extended to a scenario using the projective matrix that has been obtained from previous registration results using the same AR system. The proposed method has three advantages: 1) it is fast because the linear least square method can be used to estimate the related matrix in the algorithm and it is not necessary to calculate the fundamental matrix in the extended case. 2) A virtual object can still be superimposed on a related area even if some parts of the specified area are occluded during the whole process. 3) This method is robust because it remains effective even when not all the reference points are detected during the whole process, as long as at least six pairs of related reference points correspondences can be found. Some experiments have been conducted to validate the performance of the proposed method.","1941-0506","","10.1109/TVCG.2005.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407858","Index Terms- Augmented reality;registration;projective reconstruction;tracking.","Augmented reality;Magnetic sensors;Layout;Acoustic sensors;Cameras;Image reconstruction;Video sequences;Object detection;Application software;Computer vision","augmented reality;image registration;image reconstruction;image sequences;least squares approximations","image registration;projective reconstruction technique;augmented reality system;tracking;virtual object;model view transformation;real scene;video sequence;linear least square method;occlusion","Algorithms;Artificial Intelligence;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique;User-Computer Interface","17","1","25","","21 Mar 2005","","","IEEE","IEEE Journals"
"ScatterNet: A Deep Subjective Similarity Model for Visual Analysis of Scatterplots","Y. Ma; A. K. H. Tung; W. Wang; X. Gao; Z. Pan; W. Chen","State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; National University of Singapore, Singapore; National University of Singapore, Singapore; Hangzhou Normal University, Yuhang, China; Hangzhou Normal University, Yuhang, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2020","2020","26","3","1562","1576","Similarity measuring methods are widely adopted in a broad range of visualization applications. In this work, we address the challenge of representing human perception in the visual analysis of scatterplots by introducing a novel deep-learning-based approach, ScatterNet, captures perception-driven similarities of such plots. The approach exploits deep neural networks to extract semantic features of scatterplot images for similarity calculation. We create a large labeled dataset consisting of similar and dissimilar images of scatterplots to train the deep neural network. We conduct a set of evaluations including performance experiments and a user study to demonstrate the effectiveness and efficiency of our approach. The evaluations confirm that the learned features capture the human perception of scatterplot similarity effectively. We describe two scenarios to show how ScatterNet can be applied in visual analysis applications.","1941-0506","","10.1109/TVCG.2018.2875702","National 973 Program of China(grant numbers:2015CB352503); National Natural Science Foundation of China(grant numbers:61772456,61761136020); National Natural Science Foundation of China(grant numbers:61332017); National Key R&D Program of China(grant numbers:2017YFB1002803,2018YFB0904503); National Research Foundation Singapore; Singapore Ministry of Education Academic Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490694","Scatterplot;similarity measuring;deep learning;visualization;visual exploration","Visualization;Feature extraction;Measurement;Neural networks;Personal area networks;Visual perception;Computational modeling","data visualisation;learning (artificial intelligence);neural nets","deep subjective similarity model;similarity measuring methods;visualization applications;human perception;deep-learning-based approach;ScatterNet;perception-driven similarities;deep neural network;semantic features;scatterplot images;labeled dataset;similar images;dissimilar images;scatterplot similarity;visual analysis applications","","17","","62","IEEE","12 Oct 2018","","","IEEE","IEEE Journals"
"Segmentation of discrete vector fields","Hongyu Li; Wenbin Chen; I-Fan Shen","Dept. of Comput. Sci. & Eng., Fudan Univ., Shanghai, China; Dept. of Comput. Sci. & Eng., Fudan Univ., Shanghai, China; NA","IEEE Transactions on Visualization and Computer Graphics","20 Mar 2006","2006","12","3","289","300","In this paper, we propose an approach for 2D discrete vector field segmentation based on the Green function and normalized cut. The method is inspired by discrete Hodge decomposition such that a discrete vector field can be broken down into three simpler components, namely, curl-free, divergence-free, and harmonic components. We show that the Green function method (GFM) can be used to approximate the curl-free and the divergence-free components to achieve our goal of the vector field segmentation. The final segmentation curves that represent the boundaries of the influence region of singularities are obtained from the optimal vector field segmentations. These curves are composed of piecewise smooth contours or streamlines. Our method is applicable to both linear and nonlinear discrete vector fields. Experiments show that the segmentations obtained using our approach essentially agree with human perceptual judgement.","1941-0506","","10.1109/TVCG.2006.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608016","Hodge decomposition;Green Function Method;normalized cut;vector field segmentation;streamline;contour;approximation.","Vectors;Green function;Computational fluid dynamics;Shape measurement;Humans;Data visualization;Computational modeling;Merging;Principal component analysis;Clustering methods","computational geometry;curve fitting;data visualisation;graph theory;vectors","2D discrete vector field segmentation;normalized cut;discrete Hodge decomposition;Green function method;curl-free approximation;divergence-free components;piecewise smooth contours;harmonic components;streamlines","Algorithms;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Models, Theoretical;Rheology;Signal Processing, Computer-Assisted;User-Computer Interface","17","","20","IEEE","20 Mar 2006","","","IEEE","IEEE Journals"
"Situ: Identifying and Explaining Suspicious Behavior in Networks","J. R. Goodall; E. D. Ragan; C. A. Steed; J. W. Reed; G. D. Richardson; K. M. T. Huffer; R. A. Bridges; J. A. Laska",Oak Ridge National Laboratory; University of Florida; Oak Ridge National Laboratory; Oak Ridge National Laboratory; Oak Ridge National Laboratory; Oak Ridge National Laboratory; Oak Ridge National Laboratory; Oak Ridge National Laboratory,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","204","214","Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system's visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization's security operations center and present the results of expert reviews with professionals.","1941-0506","","10.1109/TVCG.2018.2865029","UT-Battelle, LLC(grant numbers:DE-AC05-000R22725); US Department of Energy; Department of Energy; Laboratory Directed Research and Development Program; Laboratory Directed Research and Development; Dept. of Homeland Security Science & Technology Directorate; HSARPA; Cyber Security Division; DARPA XAI program(grant numbers:N66001-17-2-4031); IARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440825","Network security;situational awareness;privacy and security;streaming data;machine learning;visualization","Data visualization;Network security;Machine learning;Anomaly detection;Visual analytics","computer network security;data visualisation;learning (artificial intelligence)","scalable tools;suspicious behavior;security systems;automated tool;visual analytics system;Situ platform;operational network setting;cyber security analysts;networked computing assets;anomaly detection methods;abnormal network activity;network operators;information visualization;anomalous events;IP addresses;machine learning","","17","","55","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Spatio-Temporal Manifold Learning for Human Motions via Long-Horizon Modeling","H. Wang; E. S. L. Ho; H. P. H. Shum; Z. Zhu","University of Leeds, Leeds, United Kingdom; Northumbria University, Newcastle Upon Tyne, United Kingdom; Northumbria University, Newcastle Upon Tyne, United Kingdom; Peking University, Haidian Qu, China","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","216","227","Data-driven modeling of human motions is ubiquitous in computer graphics and computer vision applications, such as synthesizing realistic motions or recognizing actions. Recent research has shown that such problems can be approached by learning a natural motion manifold using deep learning on a large amount data, to address the shortcomings of traditional data-driven approaches. However, previous deep learning methods can be sub-optimal for two reasons. First, the skeletal information has not been fully utilized for feature extraction. Unlike images, it is difficult to define spatial proximity in skeletal motions in the way that deep networks can be applied for feature extraction. Second, motion is time-series data with strong multi-modal temporal correlations between frames. On the one hand, a frame could be followed by several candidate frames leading to different motions; on the other hand, long-range dependencies exist where a number of frames in the beginning are correlated with a number of frames later. Ineffective temporal modeling would either under-estimate the multi-modality and variance, resulting in featureless mean motion or over-estimate them resulting in jittery motions, which is a major source of visual artifacts. In this paper, we propose a new deep network to tackle these challenges by creating a natural motion manifold that is versatile for many applications. The network has a new spatial component for feature extraction. It is also equipped with a new batch prediction model that predicts a large number of frames at once, such that long-term temporally-based objective functions can be employed to correctly learn the motion multi-modality and variances. With our system, long-duration motions can be predicted/synthesized using an open-loop setup where the motion retains the dynamics accurately. It can also be used for denoising corrupted motions and synthesizing new motions with given control signals. We demonstrate that our system can create superior results comparing to existing work in multiple applications.","1941-0506","","10.1109/TVCG.2019.2936810","Engineering and Physical Sciences Research Council(grant numbers:EP/R031193/1); Nvidia; Royal Society(grant numbers:IES\R2\181024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809754","Computer graphics;computer animation;character animation;deep learning","Manifolds;Deep learning;Skeleton;Three-dimensional displays;Feature extraction;Dynamics;Animation","computer graphics;computer vision;feature extraction;image motion analysis;learning (artificial intelligence);neural nets;time series","skeletal information;feature extraction;skeletal motions;deep network;time-series data;featureless mean motion;natural motion manifold;batch prediction model;motion multimodality;spatio-temporal manifold learning;human motions;long-horizon modeling;data-driven modeling;computer graphics;computer vision;corrupted motion denoising;open-loop setup;deep learning","Computer Graphics;Deep Learning;Humans;Image Processing, Computer-Assisted;Movement;Video Recording","17","","53","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"Stable Treemaps via Local Moves","M. Sondag; B. Speckmann; K. Verbeek",TU Eindhoven; TU Eindhoven; TU Eindhoven,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","729","738","Treemaps are a popular tool to visualize hierarchical data: items are represented by nested rectangles and the area of each rectangle corresponds to the data being visualized for this item. The visual quality of a treemap is commonly measured via the aspect ratio of the rectangles. If the data changes, then a second important quality criterion is the stability of the treemap: how much does the treemap change as the data changes. We present a novel stable treemapping algorithm that has very high visual quality. Whereas existing treemapping algorithms generally recompute the treemap every time the input changes, our algorithm changes the layout of the treemap using only local modifications. This approach not only gives us direct control over stability, but it also allows us to use a larger set of possible layouts, thus provably resulting in treemaps of higher visual quality compared to existing algorithms. We further prove that we can reach all possible treemap layouts using only our local modifications. Furthermore, we introduce a new measure for stability that better captures the relative positions of rectangles. We finally show via experiments on real-world data that our algorithm outperforms existing treemapping algorithms also in practice on either visual quality and/or stability. Our algorithm scores high on stability regardless of whether we use an existing stability measure or our new measure.","1941-0506","","10.1109/TVCG.2017.2745140","Netherlands Organisation for Scientific Research(grant numbers:639.023.208,639.021.541); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019841","Treemap;Stability;Local Moves","Layout;Visualization;Stability criteria;Space exploration;Position measurement;Binary trees","data visualisation;tree data structures","data changes;high visual quality;local modifications;rectangles;treemap change;visual quality;stable treemapping algorithm;treemap layouts;hierarchical data visualization","","17","","20","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Surface Mosaic Synthesis with Irregular Tiles","W. Hu; Z. Chen; H. Pan; Y. Yu; E. Grinspun; W. Wang","Department of Computer Science, The University of Hong Kong, Hong Kong; Department of Computer Science, Xiamen University, Xiamen, China; Department of Computer Science, The University of Hong Kong, Hong Kong; Department of Computer Science, The University of Hong Kong, Hong Kong; Department of Computer Science, Columbia University, New York, NY; Department of Computer Science, The University of Hong Kong, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","27 Jan 2016","2016","22","3","1302","1313","Mosaics are widely used for surface decoration to produce appealing visual effects. We present a method for synthesizing digital surface mosaics with irregularly shaped tiles, which are a type of tiles often used for mosaics design. Our method employs both continuous optimization and combinatorial optimization to improve tile arrangement. In the continuous optimization step, we iteratively partition the base surface into approximate Voronoi regions of the tiles and optimize the positions and orientations of the tiles to achieve a tight fit. Combination optimization performs tile permutation and replacement to further increase surface coverage and diversify tile selection. The alternative applications of these two optimization steps lead to rich combination of tiles and high surface coverage. We demonstrate the effectiveness of our solution with extensive experiments and comparisons.","1941-0506","","10.1109/TVCG.2015.2498620","National Natural Science Foundation of China(grant numbers:61472332); Fundamental Research Funds for the Central Universities(grant numbers:20720140520); GRF(grant numbers:17208214); Hong Kong Research Grant Council; NSFC(grant numbers:61272019,61572021,61332015); Shenzhen Science and Technology project(grant numbers:JCYJ20140903112959962); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321831","Simulated Mosaics;Irregular Packing;Polygon Containment;Surface Tessellation;Simulated mosaics;irregular packing;polygon containment;surface tessellation","Optimization;Layout;Partitioning algorithms;Containers;Visual effects","computational geometry;optimisation","irregular tiles;surface decoration;digital surface mosaics synthesis;irregularly shaped tiles;mosaics design;combinatorial optimization;tile arrangement;approximate Voronoi regions;tile permutation;tile replacement;surface coverage;tile selection","","17","","40","IEEE","6 Nov 2015","","","IEEE","IEEE Journals"
"The relation between visualization size, grouping, and user performance","C. C. Gramazio; K. B. Schloss; D. H. Laidlaw","Department of Computer Science, Brown University; Department of Cognitive, Linguistic, Psychological Sciences at Brown University; Department of Computer Science, Brown University","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1953","1962","In this paper we make the following contributions: (1) we describe how the grouping, quantity, and size of visual marks affects search time based on the results from two experiments; (2) we report how search performance relates to self-reported difficulty in finding the target for different display types; and (3) we present design guidelines based on our findings to facilitate the design of effective visualizations. Both Experiment 1 and 2 asked participants to search for a unique target in colored visualizations to test how the grouping, quantity, and size of marks affects user performance. In Experiment 1, the target square was embedded in a grid of squares and in Experiment 2 the target was a point in a scatterplot. Search performance was faster when colors were spatially grouped than when they were randomly arranged. The quantity of marks had little effect on search time for grouped displays (“pop-out”), but increasing the quantity of marks slowed reaction time for random displays. Regardless of color layout (grouped vs. random), response times were slowest for the smallest mark size and decreased as mark size increased to a point, after which response times plateaued. In addition to these two experiments we also include potential application areas, as well as results from a small case study where we report preliminary findings that size may affect how users infer how visualizations should be used. We conclude with a list of design guidelines that focus on how to best create visualizations based on grouping, quantity, and size of visual marks.","1941-0506","","10.1109/TVCG.2014.2346983","National Science Foundation Graduate Research Fellowship(grant numbers:DGE-1058262); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875989","information visualization;graphical perception;size;layout","Image color analysis;Visualization;Layout;Image color analysis;Time factors;Data visualization;Monitoring","data visualisation","visualization size;user performance;visual mark grouping;visual mark quantity;visual mark size;search time;search performance;display types;visualization design guidelines;colored visualizations;target square;square grid;spatially-grouped colors;mark quantity;pop-out;reaction time;random displays;grouped color layout;random color layout","Adult;Computer Graphics;Female;Humans;Informatics;Male;Reaction Time;Task Performance and Analysis;Young Adult","17","","51","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Topographic Visualization of Prefix Propagation in the Internet","P. F. Cortese; G. Di Battista; A. Moneta; M. Patrignani; M. Pizzonia","Dipt. di Informatica e Automazione, Rome Univ.; Dipt. di Informatica e Automazione, Rome Univ.; Dipt. di Informatica e Automazione, Rome Univ.; Dipt. di Informatica e Automazione, Rome Univ.; Dipt. di Informatica e Automazione, Rome Univ.","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","725","732","We propose a new metaphor for the visualization of prefixes propagation in the Internet. Such a metaphor is based on the concept of topographic map and allows to put in evidence the relative importance of the Internet Service Providers (ISPs) involved in the routing of the prefix. Based on the new metaphor we propose an algorithm for computing layouts and experiment with such algorithm on a test suite taken from the real Internet. The paper extends the visualization approach of the BGPlay service, which is an Internet routing monitoring tool widely used by ISP operators","1941-0506","","10.1109/TVCG.2006.185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015423","Interdomain Routing;Internet Visualization;Graph Drawing;Spring Embedder","Visualization;Web and internet services;Routing;IP networks;Testing;Monitoring;Springs;Local area networks;Displays;Real time systems","data visualisation;graph theory;Internet;telecommunication network routing","topographic visualization;prefix propagation;topographic map;Internet Service Providers;ISP;BGPlay service;Internet routing monitoring tool;graph drawing","","17","","37","","20 Nov 2006","","","IEEE","IEEE Journals"
"Visualization of Fibrous and Thread-like Data","Z. Melek; D. Mayerich; C. Yuksel; J. Keyser",Computer Science at Texas A&M University; Computer Science at Texas A&M University; Visualization Science at Texas A&M University; Computer Science at Texas A&M University,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1165","1172","Thread-like structures are becoming more common in modern volumetric data sets as our ability to image vascular and neural tissue at higher resolutions improves. The thread-like structures of neurons and micro-vessels pose a unique problem in visualization since they tend to be densely packed in small volumes of tissue. This makes it difficult for an observer to interpret useful patterns from the data or trace individual fibers. In this paper we describe several methods for dealing with large amounts of thread-like data, such as data sets collected using Knife-Edge Scanning Microscopy (KESM) and Serial Block-Face Scanning Electron Microscopy (SBF-SEM). These methods allow us to collect volumetric data from embedded samples of whole-brain tissue. The neuronal and microvascular data that we acquire consists of thin, branching structures extending over very large regions. Traditional visualization schemes are not sufficient to make sense of the large, dense, complex structures encountered. In this paper, we address three methods to allow a user to explore a fiber network effectively. We describe interactive techniques for rendering large sets of neurons using self-orienting surfaces implemented on the GPU. We also present techniques for rendering fiber networks in a way that provides useful information about flow and orientation. Third, a global illumination framework is used to create high-quality visualizations that emphasize the underlying fiber structure. Implementation details, performance, and advantages and disadvantages of each approach are discussed.","1941-0506","","10.1109/TVCG.2006.197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015478","neuron visualization;GPU acceleration;global illumination;orientation filtering","Data visualization;Scanning electron microscopy;Computer science;Neurons;Lighting;Data acquisition;Image segmentation;Rendering (computer graphics);Hardware","brain;medical image processing;neurophysiology;rendering (computer graphics);scanning electron microscopy","fibrous visualization;thread-like data;thread-like neuron structures;volumetric data sets;image vascular;neural tissue;knife-edge scanning microscopy;serial block-face scanning electron microscopy;whole-brain tissue;microvascular data;fiber network;interactive techniques;neuron rendering;self-orienting surfaces;fiber network rendering","Anatomy, Cross-Sectional;Computer Graphics;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Microscopy, Electron, Scanning;Nerve Net;Neurons;User-Computer Interface","17","1","17","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"A Semantic-Based Method for Visualizing Large Image Collections","X. Xie; X. Cai; J. Zhou; N. Cao; Y. Wu","Zhejiang University, Alibaba-Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Tongji University, Shanghai, China; Zhejiang University, Alibaba-Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","27 May 2019","2019","25","7","2362","2377","Interactive visualization of large image collections is important and useful in many applications, such as personal album management and user profiling on images. However, most prior studies focus on using low-level visual features of images, such as texture and color histogram, to create visualizations without considering the more important semantic information embedded in images. This paper proposes a novel visual analytic system to analyze images in a semantic-aware manner. The system mainly comprises two components: a semantic information extractor and a visual layout generator. The semantic information extractor employs an image captioning technique based on convolutional neural network (CNN) to produce descriptive captions for images, which can be transformed into semantic keywords. The layout generator employs a novel co-embedding model to project images and the associated semantic keywords to the same 2D space. Inspired by the galaxy metaphor, we further turn the projected 2D space to a galaxy visualization of images, in which semantic keywords and images are visually encoded as stars and planets. Our system naturally supports multi-scale visualization and navigation, in which users can immediately see a semantic overview of an image collection and drill down for detailed inspection of a certain group of images. Users can iteratively refine the visual layout by integrating their domain knowledge into the co-embedding process. Two task-based evaluations are conducted to demonstrate the effectiveness of our system.","1941-0506","","10.1109/TVCG.2018.2835485","National Key R&D Program of China(grant numbers:2018YFB1004302); NSFC(grant numbers:61761136020,61502416); NSFC-Zhejiang Joint Fund(grant numbers:U1609217); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); Zhejiang University; Microsoft Research Asia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358974","Image visualization;semantic layout;CNN;image captioning","Semantics;Visualization;Data visualization;Task analysis;Image analysis;Data mining;Layout","convolutional neural nets;data analysis;data visualisation;feature extraction;image classification;image colour analysis;image representation;image retrieval;semantic networks","image captioning technique;galaxy visualization;semantic overview;image collection;semantic-based method;interactive visualization;personal album management;user profiling;low-level visual features;semantic-aware manner;semantic information extractor;visual layout generator;semantic keywords;semantic information;visual analytic system;convolutional neural network;CNN;co-embedding process","","16","","54","IEEE","15 May 2018","","","IEEE","IEEE Journals"
"Augmented Virtual Teleportation for High-Fidelity Telecollaboration","T. Rhee; S. Thompson; D. Medeiros; R. dos Anjos; A. Chalmers",Victoria University of Wellington; Victoria University of Wellington; Victoria University of Wellington; Victoria University of Wellington; Victoria University of Wellington,"IEEE Transactions on Visualization and Computer Graphics","31 Mar 2020","2020","26","5","1923","1933","Telecollaboration involves the teleportation of a remote collaborator to another real-world environment where their partner is located. The fidelity of the environment plays an important role for allowing corresponding spatial references in remote collaboration. We present a novel asymmetric platform, Augmented Virtual Teleportation (AVT), which provides high-fidelity telepresence of a remote VR user (VR-Traveler) into a real-world collaboration space to interact with a local AR user (AR-Host). AVT uses a 360° video camera (360-camera) that captures and live-streams the omni-directional scenes over a network. The remote VR-Traveler watching the video in a VR headset experiences live presence and co-presence in the real-world collaboration space. The VR-Traveler's movements are captured and transmitted to a 3D avatar overlaid onto the 360-camera which can be seen in the AR-Host's display. The visual and audio cues for each collaborator are synchronized in the Mixed Reality Collaboration space (MRC-space), where they can interactively edit virtual objects and collaborate in the real environment using the real objects as a reference. High fidelity, real-time rendering of virtual objects and seamless blending into the real scene allows for unique mixed reality use-case scenarios. Our working prototype has been tested with a user study to evaluate spatial presence, co-presence, and user satisfaction during telecollaboration. Possible applications of AVT are identified and proposed to guide future usage.","1941-0506","","10.1109/TVCG.2020.2973065","TEC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998353","Telepresence;Collaboration;Real-time;Mixed Reality;360° Panoramic Video","Collaboration;Visualization;Avatars;Telepresence;Three-dimensional displays;Teleportation","augmented reality;avatars;groupware;rendering (computer graphics)","high-fidelity telecollaboration;spatial references;remote collaboration;AVT;high-fidelity telepresence;remote VR user;real-world collaboration space;local AR user;omni-directional scenes;remote VR-Traveler;VR headset experiences;real-time rendering;3D avatar;mixed reality use-case scenarios;mixed reality collaboration space;augmented virtual teleportation;spatial presence;virtual objects;MRC-space","","16","","74","IEEE","13 Feb 2020","","","IEEE","IEEE Journals"
"Drawing Euler Diagrams with Circles: The Theory of Piercings","G. Stapleton; L. Zhang; J. Howse; P. Rodgers","University of Brighton, Brighton; University of Kent, Kent; University of Brighton, Brighton; University of Kent, Kent","IEEE Transactions on Visualization and Computer Graphics","5 May 2011","2011","17","7","1020","1032","Euler diagrams are effective tools for visualizing set intersections. They have a large number of application areas ranging from statistical data analysis to software engineering. However, the automated generation of Euler diagrams has never been easy: given an abstract description of a required Euler diagram, it is computationally expensive to generate the diagram. Moreover, the generated diagrams represent sets by polygons, sometimes with quite irregular shapes that make the diagrams less comprehensible. In this paper, we address these two issues by developing the theory of piercings, where we define single piercing curves and double piercing curves. We prove that if a diagram can be built inductively by successively adding piercing curves under certain constraints, then it can be drawn with circles, which are more esthetically pleasing than arbitrary polygons. The theory of piercings is developed at the abstract level. In addition, we present a Java implementation that, given an inductively pierced abstract description, generates an Euler diagram consisting only of circles within polynomial time.","1941-0506","","10.1109/TVCG.2010.119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582085","Automated diagram drawing;Euler diagrams;diagrammatic reasoning;information visualization.","Software;Polynomials;Layout;Visualization;Measurement;Ontologies;Shape","computational geometry;data visualisation;Java;polynomials","Euler diagrams;circles;piercings theory;set intersection visualization;statistical data analysis;software engineering;single piercing curves;double piercing curves;arbitrary polygons;Java implementation;polynomial time","","16","","27","IEEE","23 Sep 2010","","","IEEE","IEEE Journals"
"FlowNet: A Deep Learning Framework for Clustering and Selection of Streamlines and Stream Surfaces","J. Han; J. Tao; C. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","IEEE Transactions on Visualization and Computer Graphics","27 Feb 2020","2020","26","4","1732","1744","For effective flow visualization, identifying representative flow lines or surfaces is an important problem which has been studied. However, no work can solve the problem for both lines and surfaces. In this paper, we present FlowNet, a single deep learning framework for clustering and selection of streamlines and stream surfaces. Given a collection of streamlines or stream surfaces generated from a flow field data set, our approach converts them into binary volumes and then employs an autoencoder to learn their respective latent feature descriptors. These descriptors are used to reconstruct binary volumes for error estimation and network training. Once converged, the feature descriptors can well represent flow lines or surfaces in the latent space. We perform dimensionality reduction of these feature descriptors and cluster the projection results accordingly. This leads to a visual interface for exploring the collection of flow lines or surfaces via clustering, filtering, and selection of representatives. Intuitive user interactions are provided for visual reasoning of the collection with ease. We validate and explain our deep learning framework from multiple perspectives, demonstrate the effectiveness of FlowNet using several flow field data sets of different characteristics, and compare our approach against state-of-the-art streamline and stream surface selection algorithms.","1941-0506","","10.1109/TVCG.2018.2880207","National Science Foundation(grant numbers:IIS-1455886,CNS-1629914,DUE-1833129); Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532319","Flow visualization;streamlines;stream surfaces;deep learning;autoencoder;feature descriptor;clustering;selection","Three-dimensional displays;Surface reconstruction;Feature extraction;Data visualization;Analytical models","computational fluid dynamics;data analysis;data visualisation;flow visualisation;learning (artificial intelligence)","FlowNet;stream surfaces;flow visualization;representative flow lines;deep learning framework;flow field data sets;surface selection algorithms","","16","","43","IEEE","11 Nov 2018","","","IEEE","IEEE Journals"
"Harnessing the Information Ecosystem with Wiki-based Visualization Dashboards","M. McKeon",IBM Research,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1081","1088","We describe the design and deployment of Dashiki, a public Website where users may collaboratively build visualization dashboards through a combination of a wiki-like syntax and interactive editors. Our goals are to extend existing research on social data analysis into presentation and organization of data from multiple sources, explore new metaphors for these activities, and participate more fully in the Web's information ecology by providing tighter integration with real-time data. To support these goals, our design includes novel and low-barrier mechanisms for editing and layout of dashboard pages and visualizations, connection to data sources, and coordinating interaction between visualizations. In addition to describing these technologies, we provide a preliminary report on the public launch of a prototype based on this design, including a description of the activities of our users derived from observation and interviews.","1941-0506","","10.1109/TVCG.2009.148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290715","visualization;web;social software;wikis;social data analysis;collaboration;dashboards;visual analytics.","Ecosystems;Data visualization;Pipelines;Data analysis;Environmental factors;Collaborative software;Application software;Feeds;Eyes;Web page design","data analysis;data visualisation;Internet;social networking (online)","Wiki-based visualization dashboards;Web information ecosystem;Dashiki;public Web site;wiki-like syntax;social data analysis;Web information ecology;dashboard pages;coordinating interaction","","16","1","26","","23 Oct 2009","","","IEEE","IEEE Journals"
"Interactive Mesh Cutting Using Constrained Random Walks","J. Zhang; J. Zheng; J. Cai","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore","IEEE Transactions on Visualization and Computer Graphics","10 Jan 2011","2011","17","3","357","367","This paper considers the problem of interactively finding the cutting contour to extract components from an existing mesh. First, we propose a constrained random walks algorithm that can add constraints to the random walks procedure and thus allows for a variety of intuitive user inputs. Second, we design an optimization process that uses the shortest graph path to derive a nice cut contour. Then a new mesh cutting algorithm is developed based on the constrained random walks plus the optimization process. Within the same computational framework, the new algorithm provides a novel user interface for interactive mesh cutting that supports three typical user inputs and also their combinations: 1) foreground/background seed inputs: the user draws strokes specifying seeds for “foreground” (i.e., the part to be cut out) and “background” (i.e., the rest); 2) soft constraint inputs: the user draws strokes on the mesh indicating the region which the cuts should be made nearby; and 3) hard constraint inputs: the marks which the cutting contour must pass. The algorithm uses feature sensitive metrics that are based on surface geometric properties and cognitive theory. The integration of the constrained random walks algorithm, the optimization process, the feature sensitive metrics, and the varieties of user inputs makes the algorithm intuitive, flexible, and effective as well. The experimental examples show that the proposed cutting method is fast, reliable, and capable of producing good results reflecting user intention and geometric attributes.","1941-0506","","10.1109/TVCG.2010.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453359","Computational geometry and object modeling;interaction techniques;geometric algorithms.","Shape;Humans;Constraint optimization;Partitioning algorithms;Process design;Design optimization;Computer interfaces;User interfaces;Geometry;Solid modeling","computational geometry;constraint handling;graph theory;mesh generation;optimisation","constrained random walks;optimization process;graph path;interactive mesh cutting;user interface;cognitive theory;surface geometric properties","Algorithms;Computer Graphics;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;User-Computer Interface","16","2","36","","22 Apr 2010","","","IEEE","IEEE Journals"
"Interactive Visual Profiling of Musicians","S. Jänicke; J. Focht; G. Scheuermann","Image and Signal Processing Group, Germany; Museum of Musical Instruments, Germany; Image and Signal Processing Group, Germany","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","200","209","Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians' attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology.","1941-0506","","10.1109/TVCG.2015.2467620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192680","visual analytics;profiling system;musicians database visualization;digital humanities;musicology;visual analytics;profiling system;musicians database visualization;digital humanities;musicology","Databases;Visual analytics;Data visualization;Music;Uncertainty;Social network services","data analysis;data visualisation;music","interactive visual profiling;musicians;musicologists;Bavarian Musicians Encyclopedia Online;visual analytics profiling system;collaborative digital humanities project","Computer Graphics;Databases, Factual;Female;History, 17th Century;History, 18th Century;History, 19th Century;History, 20th Century;Humans;Male;Music;Social Networking","16","","54","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Line Graph or Scatter Plot? Automatic Selection of Methods for Visualizing Trends in Time Series","Y. Wang; F. Han; L. Zhu; O. Deussen; B. Chen","Shandong University, Jinan, China; Shandong University, Jinan, China; Southeast University, Nanjing, China; SIAT Shenzhen, University of Konstanz, Konstanz, Germany; Shandong University, Jinan, China","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2017","2018","24","2","1141","1154","Line graphs are usually considered to be the best choice for visualizing time series data, whereas sometimes also scatter plots are used for showing main trends. So far there are no guidelines that indicate which of these visualization methods better display trends in time series for a given canvas. Assuming that the main information in a time series is its overall trend, we propose an algorithm that automatically picks the visualization method that reveals this trend best. This is achieved by measuring the visual consistency between the trend curve represented by a LOESS fit and the trend described by a scatter plot or a line graph. To measure the consistency between our algorithm and user choices, we performed an empirical study with a series of controlled experiments that show a large correspondence. In a factor analysis we furthermore demonstrate that various visual and data factors have effects on the preference for a certain type of visualization.","1941-0506","","10.1109/TVCG.2017.2653106","NSFC(grant numbers:U1501255); 973 program(grant numbers:2015CB352501); NSFC-ISF(grant numbers:61561146397); NSFC(grant numbers:11271350); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817898","Line graph;scatter plot;time series;trend","Market research;Time series analysis;Data visualization;Visualization;Bandwidth;Kernel;Estimation","data visualisation;time series","line graph;scatter plot;time series data;visualization method;visual consistency;trend curve;visual data factors;LOESS fit","","16","","49","IEEE","16 Jan 2017","","","IEEE","IEEE Journals"
"Lineage: Visualizing Multivariate Clinical Data in Genealogy Graphs","C. Nobre; N. Gehlenborg; H. Coon; A. Lex","University of Utah, Salt Lake City, UT; Harvard Medical School, Boston, MA; University of Utah, Salt Lake City, UT; University of Utah, Salt Lake City, UT","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2019","2019","25","3","1543","1558","The majority of diseases that are a significant challenge for public and individual heath are caused by a combination of hereditary and environmental factors. In this paper we introduce Lineage, a novel visual analysis tool designed to support domain experts who study such multifactorial diseases in the context of genealogies. Incorporating familial relationships between cases with other data can provide insights into shared genomic variants and shared environmental exposures that may be implicated in such diseases. We introduce a data and task abstraction, and argue that the problem of analyzing such diseases based on genealogical, clinical, and genetic data can be mapped to a multivariate graph visualization problem. The main contribution of our design study is a novel visual representation for tree-like, multivariate graphs, which we apply to genealogies and clinical data about the individuals in these families. We introduce data-driven aggregation methods to scale to multiple families. By designing the genealogy graph layout to align with a tabular view, we are able to incorporate extensive, multivariate attributes in the analysis of the genealogy without cluttering the graph. We validate our designs by conducting case studies with our domain collaborators.","1941-0506","","10.1109/TVCG.2018.2811488","National Institutes of Health(grant numbers:U01 CA198935,R00 HG007583,R01MH099134); DoD – Office of Economic Adjustment (OEA)(grant numbers:ST1605-16-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307265","Multivariate networks;biology visualization;genealogies;hereditary genetics;multifactorial diseases","Genetics;Diseases;Data visualization;Tools;Task analysis;Environmental factors;Sociology","biology computing;data visualisation;genetics;genomics;molecular biophysics","Lineage;multivariate clinical data;genealogy graphs;public heath;individual heath;hereditary factors;environmental factors;domain experts;multifactorial diseases;shared genomic variants;genealogical data;genetic data;multivariate graph visualization problem;genealogy graph layout;visual analysis tool;clinical data;visual representation;familial relationships","Algorithms;Computer Graphics;Databases, Genetic;Disease;Female;Genealogy and Heraldry;Genomics;Humans;Male;Pedigree","16","","76","IEEE","6 Mar 2018","","","IEEE","IEEE Journals"
"Parallel Computational Steering for HPC Applications Using HDF5 Files in Distributed Shared Memory","J. Biddiscombe; J. Soumagne; G. Oger; D. Guibert; J. Piccinali","Swiss National Supercomputing Centre, Manno; Swiss National Supercomputing Centre, Manno; INRIA Bordeaux Sud-Ouest, Talence; Ecole Centrale de Nantes, Nantes; Swiss National Supercomputing Centre, Manno","IEEE Transactions on Visualization and Computer Graphics","12 Apr 2012","2012","18","6","852","864","Interfacing a GUI driven visualization/analysis package to an HPC application enables a supercomputer to be used as an interactive instrument. We achieve this by replacing the IO layer in the HDF5 library with a custom driver which transfers data in parallel between simulation and analysis. Our implementation using ParaView as the interface, allows a flexible combination of parallel simulation, concurrent parallel analysis, and GUI client, either on the same or separate machines. Each MPI job may use different core counts or hardware configurations, allowing fine tuning of the amount of resources dedicated to each part of the workload. By making use of a distributed shared memory file, one may read data from the simulation, modify it using ParaView pipelines, write it back, to be reused by the simulation (or vice versa). This allows not only simple parameter changes, but complete remeshing of grids, or operations involving regeneration of field values over the entire domain. To avoid the problem of manually customizing the GUI for each application that is to be steered, we make use of XML templates that describe outputs from the simulation (and inputs back to it) to automatically generate GUI controls for manipulation of the simulation.","1941-0506","","10.1109/TVCG.2012.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152102","Parallel I/O;distributed/network graphics;software libraries.","Data models;Servers;Libraries;Graphical user interfaces;Analytical models;Computational modeling;Synchronization","application program interfaces;data analysis;data visualisation;device drivers;distributed shared memory systems;graphical user interfaces;interactive systems;mesh generation;parallel processing;pipeline processing;XML","parallel computational steering;HDF5 files;GUI driven visualization-analysis package;HPC application;supercomputer;interactive instrument;IO layer;HDF5 library;custom driver;concurrent parallel analysis;parallel simulation;GUI client;MPI job;hardware configurations;distributed shared memory file;ParaView pipelines;grid remeshing;XML templates","","16","","19","","14 Feb 2012","","","IEEE","IEEE Journals"
"PhotoRecomposer: Interactive Photo Recomposition by Cropping","Y. Liang; X. Wang; S. -H. Zhang; S. -M. Hu; S. Liu","Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2018","2018","24","10","2728","2742","We present a visual analysis method for interactively recomposing a large number of photos based on example photos with high-quality composition. The recomposition method is formulated as a matching problem between photos. The key to this formulation is a new metric for accurately measuring the composition distance between photos. We have also developed an earth-mover-distance-based online metric learning algorithm to support the interactive adjustment of the composition distance based on user preferences. To better convey the compositions of a large number of example photos, we have developed a multi-level, example photo layout method to balance multiple factors such as compactness, aspect ratio, composition distance, stability, and overlaps. By introducing an EulerSmooth-based straightening method, the composition of each photos is clearly displayed. The effectiveness and usefulness of the method has been demonstrated by the experimental results, user study, and case studies.","1941-0506","","10.1109/TVCG.2017.2764895","National Key Technology R&D Program(grant numbers:2016YFB1001402); Natural Science Foundation of China(grant numbers:61672308,61761136020,61521002,61373069); Beijing Higher Institution Engineering Research Center; Microsoft Research Fund; Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8078205","Photo recomposition;example-based learning;earth mover’s distance;metric learning;photo summarization","Visualization;Tools;Agriculture;Measurement;Layout;Photography;Algorithm design and analysis","image matching;image representation;learning (artificial intelligence);photography","interactive photo recomposition;visual analysis method;high-quality composition;composition distance;interactive adjustment;example photo layout method;earth-mover-distance-based online metric learning algorithm;PhotoRecomposer;matching problem;EulerSmooth-based straightening method","","16","","62","IEEE","23 Oct 2017","","","IEEE","IEEE Journals"
"Vision-an architecture for global illumination calculations","P. Slusallek; H. -. Seidel","Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany; Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","1","77","96","So far, the problem of global illumination calculation has almost exclusively been approached from an algorithmic point of view. We propose an architectural approach to global illumination. The proposed rendering architecture Vision is derived from a model of the physical rendering process, which is subsequently mapped onto an object-oriented hierarchy of classes. This design is powerful and flexible enough to support and exploit a large body of existing illumination algorithms for the simulation of various aspects of the underlying physical model. Additionally, the Vision architecture offers a platform for developing new algorithms and for combining them to create new rendering solutions. We discuss both abstract design as well as implementation issues. In particular, we give a detailed description of the global lighting subsystem and show how algorithms for path tracing, bidirectional estimators, irradiance caching, hierarchical radiosity, wavelet radiosity, and wavelet radiance have been implemented within Vision.<<ETX>></ETX>","1941-0506","","10.1109/2945.468387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468387","","Lighting;Layout;Object oriented modeling;Computer architecture;Rendering (computer graphics);Differential equations;Integral equations;Computer graphics;Algorithm design and analysis;Image generation","lighting;rendering (computer graphics);object-oriented methods;digital simulation;ray tracing;brightness;wavelet transforms","global illumination calculations;Vision architecture;rendering architecture;physical rendering process;object-oriented class hierarchy;illumination algorithms;simulation;abstract design;implementation issues;global lighting subsystem;path tracing;bidirectional estimators;irradiance caching;hierarchical radiosity;wavelet radiosity;wavelet radiance","","16","9","67","","6 Aug 2002","","","IEEE","IEEE Journals"
"Visual Trends Analysis in Time-Varying Ensembles","H. Obermaier; K. Bensema; K. I. Joy","Department of Computer Science, University of California, Davis, One Shields Avenue, Davis, CA; Department of Computer Science, University of California, Davis, One Shields Avenue, Davis, CA; Department of Computer Science, University of California, Davis, One Shields Avenue, Davis, CA","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2016","2016","22","10","2331","2342","Visualization and analysis techniques play a key role in the discovery of relevant features in ensemble data. Trends, in the form of persisting commonalities or differences in time-varying ensemble datasets, constitute one of the most expressive feature types in ensemble analysis. We develop a flow-graph representation as the core of a system designed for the visual analysis of trends in time-varying ensembles. In our interactive analysis framework, this graph is linked to a representation of ensemble parameter-space and the ensemble itself. This facilitates a detailed examination of trends and their correlations to properties of input-space. We demonstrate the utility of the proposed trends analysis framework in several benchmark data sets, highlighting its capability to support goal-driven design of time-varying simulations.","1941-0506","","10.1109/TVCG.2015.2507592","National Science Foundation(grant numbers:0916289,1018097); Office of ASCR; Office of Science; Department of Energy(grant numbers:DE-FC02-06ER25780,DE-FC02-12ER26072); SDAV; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352365","Ensemble visualization;trend visualization;data analysis","Data visualization;Market research;Analytical models;Visualization;Uncertainty;Computational modeling;Numerical models","data visualisation;graph theory","time-varying ensemble datasets;visual trend analysis;visualization techniques;ensemble analysis;flow-graph representation;ensemble parameter-space representation;time-varying simulations;goal-driven design","","16","","52","IEEE","10 Dec 2015","","","IEEE","IEEE Journals"
"Volume Splitting and Its Applications","S. Islam; D. Silver; M. Chen","Department of Computer Science, University of Wales Swansea, Singleton Park, Swansea SA2 8PP, UK; Department of Electrical and Computer Engineering, Rutgers, The State University of New Jersey, Piscataway, NJ 08855-0909; Department of Computer Science, University of Wales Swansea, Singleton Park, Swansea SA2 8PP, UK","IEEE Transactions on Visualization and Computer Graphics","22 Jan 2007","2007","13","2","193","203","Splitting a volumetric object is a useful operation in volume graphics and its applications, but is not widely supported by existing systems for volume-based modeling and rendering. In this paper, we present an investigation into two main algorithmic approaches, namely, explicit and implicit splitting, for modeling and rendering splitting actions. We consider a generalized notion based on scalar fields, which encompasses discrete specifications (e.g., volume data sets) as well as procedural specifications (e.g., hypertextures) of volumetric objects. We examine the correctness, effectiveness, efficiency, and deficiencies of each approach in specifying and controlling a spatial and temporal specification of splitting. We propose methods for implementing these approaches and for overcoming their deficiencies. We present a modeling tool for creating specifications of splitting functions, and describe the use of volume scene graphs for facilitating direct rendering of volume splitting. We demonstrate the use of these approaches with examples of volume visualization, medical illustration, volume animation, and special effects","1941-0506","","10.1109/TVCG.2007.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069230","Volume graphics;volume animation;volume visualization;medical illustration;spatial transfer function;constructive volume geometry;volumetric scene graph;volume splitting;fire effect;explosion effect.","Graphics;Rendering (computer graphics);Animation;Data visualization;Layout;Biomedical imaging;Explosions;Focusing;Surgery;Silver","computer animation;graph theory;image texture;rendering (computer graphics);solid modelling","volumetric object splitting;volume graphics;volume-based modeling;volume-based rendering;explicit splitting;implicit splitting;discrete specifications;procedural specifications;object hypertexture;spatial specification;temporal specification;volume scene graph;volume visualization;medical illustration;volume animation;special effects;spatial transfer function;constructive volume geometry;fire effect;explosion effect","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted","16","","30","","22 Jan 2007","","","IEEE","IEEE Journals"
"A Comparison of the Perceptual Benefits of Linear Perspective and Physically-Based Illumination for Display of Dense 3D Streamtubes","C. Weigle; D. Banks","UT/ORNL Joint Institiute for Computational Sciences, Department of Electrical Engineering and Computer Science, University of Tennessee; UT/ORNL Joint Institiute for Computational Sciences, Department of Electrical Engineering and Computer Science, University of Tennessee","IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1723","1730","Large datasets typically contain coarse features comprised of finer sub-features. Even if the shapes of the small structures are evident in a 3D display, the aggregate shapes they suggest may not be easily inferred. From previous studies in shape perception, the evidence has not been clear whether physically-based illumination confers any advantage over local illumination for understanding scenes that arise in visualization of large data sets that contain features at two distinct scales. In this paper we show that physically-based illumination can improve the perception for some static scenes of complex 3D geometry from flow fields. We perform human-subjects experiments to quantify the effect of physically-based illumination on participant performance for two tasks: selecting the closer of two streamtubes from a field of tubes, and identifying the shape of the domain of a flow field over different densities of tubes. We find that physically-based illumination influences participant performance as strongly as perspective projection, suggesting that physically-based illumination is indeed a strong cue to the layout of complex scenes. We also find that increasing the density of tubes for the shape identification task improved participant performance under physically-based illumination but not under the traditional hardware-accelerated illumination model.","1941-0506","","10.1109/TVCG.2008.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658196","Index Terms—;user study;volume completion;3D shape perception;physically-based illumination;global illumination;local illumination;multi-scale visualization;flow visualization;streamtubes;DT-MRI;white matter tractography","Lighting;Three dimensional displays;Shape;Layout;Data visualization;Humans;Visual system;Psychology;Aggregates;Geometry","computer vision;data visualisation;flow visualisation","linear perspective;physically-based illumination;dense 3D streamtubes;large data sets visualization;complex 3D geometry","","15","","28","","24 Oct 2008","","","IEEE","IEEE Journals"
"A Visual Analytics Framework for Identifying Topic Drivers in Media Events","Y. Lu; H. Wang; S. Landis; R. Maciejewski","Arizona State University, Tempe, AZ; Arizona State University, Tempe, AZ; University of Nevada, Las Vegas, NV; Arizona State University, Tempe, AZ","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2018","2018","24","9","2501","2515","Media data has been the subject of large scale analysis with applications of text mining being used to provide overviews of media themes and information flows. Such information extracted from media articles has also shown its contextual value of being integrated with other data, such as criminal records and stock market pricing. In this work, we explore linking textual media data with curated secondary textual data sources through user-guided semantic lexical matching for identifying relationships and data links. In this manner, critical information can be identified and used to annotate media timelines in order to provide a more detailed overview of events that may be driving media topics and frames. These linked events are further analyzed through an application of causality modeling to model temporal drivers between the data series. Such causal links are then annotated through automatic entity extraction which enables the analyst to explore persons, locations, and organizations that may be pertinent to the media topic of interest. To demonstrate the proposed framework, two media datasets and an armed conflict event dataset are explored.","1941-0506","","10.1109/TVCG.2017.2752166","US Department of Homeland Security's VACCINE Center(grant numbers:2009-ST-061-CI0001); US National Science Foundation(grant numbers:1350573,1639227); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8037991","Semantic similarity;media annotation;visual analytics;causality modeling;social media","Media;Semantics;Social network services;Visual analytics;Tools;Time series analysis","data analysis;data mining;data visualisation;text analysis","visual analytics framework;text mining;information flows;textual media data;curated secondary textual data sources;user-guided semantic lexical matching;causal links;automatic entity extraction;media datasets;armed conflict event dataset;media events topic drivers identification;media timeline annotation;data series temporal drivers","","15","","49","IEEE","14 Sep 2017","","","IEEE","IEEE Journals"
"An Evaluation of Semantically Grouped Word Cloud Designs","M. A. Hearst; E. Pedersen; L. Patil; E. Lee; P. Laskowski; S. Franconeri","UC Berkeley, Berkeley, CA, USA; UC Berkeley, Berkeley, CA, USA; UC Berkeley, Berkeley, CA, USA; Northwestern University, Evanston, IL, USA; UC Berkeley, Berkeley, CA, USA; Northwestern University, Evanston, IL, USA","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2020","2020","26","9","2748","2761","Word clouds continue to be a popular tool for summarizing textual information, despite their well-documented deficiencies for analytic tasks. Much of their popularity rests on their playful visual appeal. In this paper, we present the results of a series of controlled experiments that show that layouts in which words are arranged into semantically and visually distinct zones are more effective for understanding the underlying topics than standard word cloud layouts. White space separators and/or spatially grouped color coding led to significantly stronger understanding of the underlying topics compared to a standard Wordle layout, while simultaneously scoring higher on measures of aesthetic appeal. This work is an advance on prior research on semantic layouts for word clouds because that prior work has either not ensured that the different semantic groupings are visually or semantically distinct, or has not performed usability studies. An additional contribution of this work is the development of a dataset for a semantic category identification task that can be used for replication of these results or future evaluations of word cloud designs.","1941-0506","","10.1109/TVCG.2019.2904683","University of California; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8665933","Information visualization;word clouds;text analysis;data analytics;evaluation","Tag clouds;Layout;Task analysis;Semantics;White spaces;Tools;Color","cloud computing;data analysis;data visualisation;information retrieval;text analysis","semantic layouts;semantic category identification task;semantically grouped word cloud designs;textual information;visually distinct zones;standard word cloud layouts;white space separators;spatially grouped color coding;semantically distinct zones","","15","","41","IEEE","12 Mar 2019","","","IEEE","IEEE Journals"
"Attractive Flicker — Guiding Attention in Dynamic Narrative Visualizations","M. Waldner; M. Le Muzic; M. Bernhard; W. Purgathofer; I. Viola",Vienna University of Technology; Vienna University of Technology; Vienna University of Technology; Vienna University of Technology; Vienna University of Technology,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2456","2465","Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first “orientation stage” is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (“engagement stage”) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.","1941-0506","","10.1109/TVCG.2014.2346352","Vienna Science and Technology Fund; VRG 11¿010; EC Marie Curie Career Integration Grant(grant numbers:PCIGI3-GA-2013-618680); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876019","Visual attention;flicker;narrative visualization","Context awareness;Social network services;Image color analysis;Observers;Data visualization;Data models","brightness;data visualisation;human factors;visual perception","attention guidance;dynamic narrative visualizations;focus-plus-context techniques;visual guidance;visual prominence;context suppression;visual feature;large-dynamic scene;minimal visual deformation;subjective disturbance;visual attractor;visual field;Attractive Flicker technique;signal stages;orientation stage;short-intensive flicker stimulus;attention attraction;minimally-disturbing luminance oscillation;engagement stage;visual support;focus elements;attraction effectiveness;subjective annoyance;perceptual studies;signal parameters;perceptual statistics;molecular interactions","","15","","48","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Directable Weathering of Concave Rock Using Curvature Estimation","M. D. Jones; M. Farley; J. Butler; M. Beardall","Brigham Young University, Provo; Brigham Young University, Provo; Brigham Young University, Provo; Caselle Inc., Spanish Fork","IEEE Transactions on Visualization and Computer Graphics","13 Nov 2009","2010","16","1","81","94","We address the problem of directable weathering of exposed concave rock for use in computer-generated animation or games. Previous weathering models that admit concave surfaces are computationally inefficient and difficult to control. In nature, the spheroidal and cavernous weathering rates depend on the surface curvature. Spheroidal weathering is fastest in areas with large positive mean curvature and cavernous weathering is fastest in areas with large negative mean curvature. We simulate both processes using an approximation of mean curvature on a voxel grid. Both weathering rates are also influenced by rock durability. The user controls rock durability by editing a durability graph before and during weathering simulation. Simulations of rockfall and colluvium deposition further improve realism. The profile of the final weathered rock matches the shape of the durability graph up to the effects of weathering and colluvium deposition. We demonstrate the top-down directability and visual plausibility of the resulting model through a series of screenshots and rendered images. The results include the weathering of a cube into a sphere and of a sheltered inside corner into a cavern as predicted by the underlying geomorphological models.","1941-0506","","10.1109/TVCG.2009.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815233","Physically based modeling;modeling packages.","Animation;Computational modeling;Indium tin oxide;Shape;Packaging;Rendering (computer graphics);Predictive models;Production;Pipelines;Automobiles","computer animation;computer graphics;erosion;geophysics computing","concave rock directable weathering;curvature estimation;computer generated animation;spheroidal weathering;cavernous weathering;surface curvature;positive mean curvature weathering;negative mean curvature;mean curvature approximation;voxel grid;rock durability;weathering simulation;rockfall simulation;colluvium deposition;cube weathering;geomorphological model","Computer Graphics;Computer Simulation;Geology;Imaging, Three-Dimensional;Models, Theoretical;Soil;Weather","15","","40","IEEE","17 Apr 2009","","","IEEE","IEEE Journals"
"Efficient Rasterization for Outdoor Radio Wave Propagation","A. Schmitz; T. Rick; T. Karolski; T. Kuhlen; L. Kobbelt","RWTH-Aachen, Aachen; RWTH-Aachen, Aachen; RWTH-Aachen, Aachen; RWTH-Aachen, Aachen; RWTH Aachen University, Aachen","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2010","2011","17","2","159","170","Conventional beam tracing can be used for solving global illumination problems. It is an efficient algorithm and performs very well when implemented on the GPU. This allows us to apply the algorithm in a novel way to the problem of radio wave propagation. The simulation of radio waves is conceptually analogous to the problem of light transport. We use a custom, parallel rasterization pipeline for creation and evaluation of the beams. We implement a subset of a standard 3D rasterization pipeline entirely on the GPU, supporting 2D and 3D frame buffers for output. Our algorithm can provide a detailed description of complex radio channel characteristics like propagation losses and the spread of arriving signals over time (delay spread). Those are essential for the planning of communication systems required by mobile network operators. For validation, we compare our simulation results with measurements from a real-world network. Furthermore, we account for characteristics of different propagation environments and estimate the influence of unknown components like traffic or vegetation by adapting model parameters to measurements.","1941-0506","","10.1109/TVCG.2010.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492685","Ray tracing;rendering;electromagnetic propagation.","Electromagnetic propagation;Optical propagation;Pipelines;Computer graphics;Lighting;Electromagnetic measurements;Acoustic propagation;Propagation losses;Delay effects;Communication system traffic","mobile radio;radiowave propagation;ray tracing;telecommunication network planning","outdoor radiowave propagation;beam tracing;global illumination problems;GPU;radiowave simulation;light transport;parallel rasterization pipeline;beam evaluation;3D rasterization pipeline;3D frame buffers;2D frame buffers;radio channel characteristics;propagation losses;communication system planning;mobile network operators","","15","","37","","28 Jun 2010","","","IEEE","IEEE Journals"
"Filling Your Shelves: Synthesizing Diverse Style-Preserving Artifact Arrangements","L. Majerowicz; A. Shamir; A. Sheffer; H. H. Hoos","Efi Arazi School of Computer Science , The Interdisciplinary Center, POB 167, Herzliya, Israel; Efi Arazi School of Computer Science , The Interdisciplinary Center, POB 167, Herzliya, Israel; Computer Science, University of British Colombia, 201-2366 Main Mall, Vancouver, Canada; Computer Science, University of British Colombia, 201-2366 Main Mall, Vancouver, Canada","IEEE Transactions on Visualization and Computer Graphics","24 Sep 2014","2014","20","11","1507","1518","Our homes and workspaces are filled with collections of dozens of artifacts laid out on surfaces such as shelves, counters, and mantles. The content and layout of these arrangements reflect both context, e.g., kitchen or living room, and style, e.g., neat or messy. Manually assembling such arrangements in virtual scenes is highly time consuming, especially when one needs to generate multiple diverse arrangements for numerous support surfaces and living spaces. We present a data-driven method especially designed for artifact arrangement which automatically populates empty surfaces with diverse believable arrangements of artifacts in a given style. The input to our method is an annotated photograph or a 3D model of an exemplar arrangement, that reflects the desired context and style. Our method leverages this exemplar to generate diverse arrangements reflecting the exemplar style for arbitrary furniture setups and layout dimensions. To simultaneously achieve scalability, diversity and style preservation, we define a valid solution space of arrangements that reflect the input style. We obtain solutions within this space using barrier functions and stochastic optimization.","1941-0506","","10.1109/TVCG.2013.245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6636298","Procedural modeling;object layout;data-driven modeling","Surface treatment;Three-dimensional displays;Scalability","optimisation;solid modelling;stochastic programming","stochastic optimization;barrier functions;style preservation;layout dimensions;arbitrary furniture setups;exemplar arrangement;3D model;annotated photograph;data-driven method;virtual scenes;diverse style-preserving artifact arrangement synthesis","","15","2","22","IEEE","18 Oct 2013","","","IEEE","IEEE Journals"
"Node-Link or Adjacency Matrices: Old Question, New Insights","M. Okoe; R. Jianu; S. Kobourov","Florida International University, Miami, FL, USA; City, University of London, London, United Kingdom; University of Arizona, Tucson, AZ, USA","IEEE Transactions on Visualization and Computer Graphics","4 Sep 2019","2019","25","10","2940","2952","Visualizing network data is applicable in domains such as biology, engineering, and social sciences. We report the results of a study comparing the effectiveness of the two primary techniques for showing network data: node-link diagrams and adjacency matrices. Specifically, an evaluation with a large number of online participants revealed statistically significant differences between the two visualizations. Our work adds to existing research in several ways. First, we explore a broad spectrum of network tasks, many of which had not been previously evaluated. Second, our study uses two large datasets, typical of many real-life networks not explored by previous studies. Third, we leverage crowdsourcing to evaluate many tasks with many participants. This paper is an expanded journal version of a Graph Drawing (GD'17) conference paper. We evaluated a second dataset, added a qualitative feedback section, and expanded the procedure, results, discussion, and limitations sections.","1941-0506","","10.1109/TVCG.2018.2865940","NSF(grant numbers:CCF-1740858,CCF-1712119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438968","Evaluation;user study;graphs;networks;node-link;adjacency matrices","Task analysis;Data visualization;Visualization;Taxonomy;Encoding;Layout;Airports","data visualisation;graph theory;matrix algebra;network theory (graphs);statistical analysis","node-link diagrams;adjacency matrices;network data visualization;crowdsourcing;qualitative feedback section;graph drawing","Adult;Aged;Computer Graphics;Crowdsourcing;Data Visualization;Female;Humans;Male;Middle Aged;Task Performance and Analysis;Young Adult","15","","65","IEEE","17 Aug 2018","","","IEEE","IEEE Journals"
"<italic>PowerSet</italic>: A Comprehensive Visualization of Set Intersections","B. Alsallakh; L. Ren",BOSCH Research; BOSCH Research,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","361","370","When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques.","1941-0506","","10.1109/TVCG.2016.2598496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536208","Set visualization;treemaps;interaction;scalability","Data visualization;Silicon;Visualization;Bars;Layout;Scalability;Data analysis","data visualisation;trees (mathematics)","PowerSet;visualization;set intersections;data volume;element attributes;set-based analysis;intersections relations;treemaps;nonempty intersections;fine-grained analysis;querying;filtering;set memberships;data exploration","","15","","47","IEEE","8 Aug 2016","","","IEEE","IEEE Journals"
"Proxy Graph: Visual Quality Metrics of Big Graph Sampling","Q. H. Nguyen; S. Hong; P. Eades; A. Meidiana","School of Information Technologies, University of Sydney, Camperdown, NSW, Australia; School of Information Technologies, University of Sydney, Camperdown, NSW, Australia; School of Information Technologies, University of Sydney, Camperdown, NSW, Australia; School of Information Technologies, University of Sydney, Camperdown, NSW, Australia","IEEE Transactions on Visualization and Computer Graphics","28 Apr 2017","2017","23","6","1600","1611","Data sampling has been extensively studied for large scale graph mining. Many analyses and tasks become more efficient when performed on graph samples of much smaller size. The use of proxy objects is common in software engineering for analysis and interaction with heavy objects or systems. In this paper, we coin the term 'proxy graph' and empirically investigate how well a proxy graph visualization can represent a big graph. Our investigation focuses on proxy graphs obtained by sampling; this is one of the most common proxy approaches. Despite the plethora of data sampling studies, this is the first evaluation of sampling in the context of graph visualization. For an objective evaluation, we propose a new family of quality metrics for visual quality of proxy graphs. Our experiments cover popular sampling techniques. Our experimental results lead to guidelines for using sampling-based proxy graphs in visualization.","1941-0506","","10.1109/TVCG.2017.2674999","Australian Research Council(grant numbers:DP160104148); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7864456","Graph visualization;graph sampling;proxy graph;quality metrics","Visualization;Measurement;Sampling methods;Data visualization;Software engineering","Big Data;graph theory;sampling methods","visual quality metrics;big-graph sampling;empirical analysis;proxy graph visualization;data sampling;graph visualization;objective evaluation;sampling-based proxy graphs","","15","","26","IEEE","24 Feb 2017","","","IEEE","IEEE Journals"
"RACBVHs: Random-Accessible Compressed Bounding Volume Hierarchies","T. -J. Kim; B. Moon; D. Kim; S. -E. Yoon","Korea Advanced Institute of Science and Technology, Daejeon; Korea Advanced Institute of Science and Technology, Daejeon; Korea Advanced Institute of Science and Technology, Daejeon; Korea Advanced Institute of Science and Technology, Daejeon","IEEE Transactions on Visualization and Computer Graphics","15 Jan 2010","2010","16","2","273","286","We present a novel compressed bounding volume hierarchy (BVH) representation, random-accessible compressed bounding volume hierarchies (RACBVHs), for various applications requiring random access on BVHs of massive models. Our RACBVH representation is compact and transparently supports random access on the compressed BVHs without decompressing the whole BVH. To support random access on our compressed BVHs, we decompose a BVH into a set of clusters. Each cluster contains consecutive bounding volume (BV) nodes in the original layout of the BVH. Also, each cluster is compressed separately from other clusters and serves as an access point to the RACBVH representation. We provide the general BVH access API to transparently access our RACBVH representation. At runtime, our decompression framework is guaranteed to provide correct BV nodes without decompressing the whole BVH. Also, our method is extended to support parallel random access that can utilize the multicore CPU architecture. Our method can achieve up to a 12:1 compression ratio, and more importantly, can decompress 4.2 M BV nodes ({=}135 {\rm MB}) per second by using a single CPU-core. To highlight the benefits of our approach, we apply our method to two different applications: ray tracing and collision detection. We can improve the runtime performance by more than a factor of 4 as compared to using the uncompressed original data. This improvement is a result of the fast decompression performance and reduced data access time by selectively fetching and decompressing small regions of the compressed BVHs requested by applications.","1941-0506","","10.1109/TVCG.2009.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5128906","Hierarchy and BVH compression;random access;cache-coherent layouts;ray tracing;collision detection.","Runtime;Ray tracing;Moon;Multicore processing;Layout;Graphics;Motion detection;Performance evaluation;Testing;Cache storage","application program interfaces;collision avoidance;data compression;knowledge representation;pattern clustering;ray tracing","random-accessible compressed bounding volume hierarchies;parallel random access;bounding volume nodes;RACBVH representation;API;multicore CPU architecture;ray tracing;collision detection;data access time;cluster","Algorithms;Computer Graphics;Computer Simulation;Data Compression;Imaging, Three-Dimensional;Models, Theoretical","15","3","60","","26 Jun 2009","","","IEEE","IEEE Journals"
"ReconViguRation: Reconfiguring Physical Keyboards in Virtual Reality","D. Schneider; A. Otte; T. Gesslein; P. Gagel; B. Kuth; M. S. Damlakhi; O. Dietz; E. Ofek; M. Pahud; P. O. Kristensson; J. Müller; J. Grubert",Coburg University of Applied Sciences and Arts; Coburg University of Applied Sciences and Arts; Coburg University of Applied Sciences and Arts; Coburg University of Applied Sciences and Arts; Coburg University of Applied Sciences and Arts; Coburg University of Applied Sciences and Arts; Coburg University of Applied Sciences and Arts; Mircosoft Research; Mircosoft Research; University of Cambridge; University of Bayreuth; Coburg University of Applied Sciences and Arts,"IEEE Transactions on Visualization and Computer Graphics","8 Oct 2019","2019","25","11","3190","3201","Physical keyboards are common peripherals for personal computers and are efficient standard text entry devices. Recent research has investigated how physical keyboards can be used in immersive head-mounted display-based Virtual Reality (VR). So far, the physical layout of keyboards has typically been transplanted into VR for replicating typing experiences in a standard desktop environment. In this paper, we explore how to fully leverage the immersiveness of VR to change the input and output characteristics of physical keyboard interaction within a VR environment. This allows individual physical keys to be reconfigured to the same or different actions and visual output to be distributed in various ways across the VR representation of the keyboard. We explore a set of input and output mappings for reconfiguring the virtual presentation of physical keyboards and probe the resulting design space by specifically designing, implementing and evaluating nine VR-relevant applications: emojis, languages and special characters, application shortcuts, virtual text processing macros, a window manager, a photo browser, a whack-a-mole game, secure password entry and a virtual touch bar. We investigate the feasibility of the applications in a user study with 20 participants and find that, among other things, they are usable in VR. We discuss the limitations and possibilities of remapping the input and output characteristics of physical keyboards in VR based on empirical findings and analysis and suggest future research directions in this area.","1941-0506","","10.1109/TVCG.2019.2932239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794572","Virtual Reality;Text Entry;Physical Keyboards","Keyboards;Visualization;Virtual reality;Sensors;Tracking;Password;Task analysis","helmet mounted displays;keyboards;virtual reality","efficient standard text entry devices;physical keyboard interaction;VR environment;standard text entry devices;immersive head-mounted display-based virtual reality;standard desktop environment;VR representation;virtual text processing macros;window manager;photo browser;whack-a-mole game;secure password entry;virtual touch bar;emojis;languages;ReconViguRation;input-output mappings","","15","","86","IEEE","12 Aug 2019","","","IEEE","IEEE Journals"
"Scalable Data Servers for Large Multivariate Volume Visualization","M. Glatter; J. Huang; J. Gao; C. Mollenhour",The University of Tennessee; The University of Tennessee; The University of Tennessee; Oak Ridge National Lab,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1291","1298","Volumetric datasets with multiple variables on each voxel over multiple time steps are often complex, especially when considering the exponentially large attribute space formed by the variables in combination with the spatial and temporal dimensions. It is intuitive, practical, and thus often desirable, to interactively select a subset of the data from within that high-dimensional value space for efficient visualization. This approach is straightforward to implement if the dataset is small enough to be stored entirely in-core. However, to handle datasets sized at hundreds of gigabytes and beyond, this simplistic approach becomes infeasible and thus, more sophisticated solutions are needed. In this work, we developed a system that supports efficient visualization of an arbitrary subset, selected by range-queries, of a large multivariate time-varying dataset. By employing specialized data structures and schemes of data distribution, our system can leverage a large number of networked computers as parallel data servers, and guarantees a near optimal load-balance. We demonstrate our system of scalable data servers using two large time-varying simulation datasets.","1941-0506","","10.1109/TVCG.2006.175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015494","Parallel and distributed volume visualization;large data set visualization;multi-variate visualization;volume visualization.","Data visualization;Computational modeling;Network servers;Time varying systems;Computer networks;Concurrent computing;Astrophysics;Parallel processing;Data processing;Pipelines","data visualisation;file servers;spatial data structures","scalable data servers;multivariate volume visualization;multivariate time-varying dataset;spatial data structures;parallel data servers","Clinical Trials, Phase III as Topic;Data Interpretation, Statistical;Drug Industry;Humans;Research Design","15","","25","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"Stereoscopic view-dependent visualization of terrain height fields","U. Gudukbay; T. Yilmaz","Dept. of Comput. Eng., Bilkent Univ., Ankara, Turkey; Dept. of Comput. Eng., Bilkent Univ., Ankara, Turkey","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2002","2002","8","4","330","345","Visualization of large geometric environments has always been an important problem of computer graphics. We present a framework for the stereoscopic view-dependent visualization of large scale terrain models. We use a quadtree based multiresolution representation for the terrain data. This structure is queried to obtain the view-dependent approximations of the terrain model at different levels of detail. In order not to lose depth information, which is crucial for the stereoscopic visualization, we make use of a different simplification criterion, namely, distance-based angular error threshold. We also present an algorithm for the construction of stereo pairs in order to speed up the view-dependent stereoscopic visualization. The approach we use is the simultaneous generation of the triangles for two stereo images using a single draw-list so that the view frustum culling and vertex activation is done only once for each frame. The cracking problem is solved using the dependency information stored for each vertex. We eliminate the popping artifacts that can occur while switching between different resolutions of the data using morphing. We implemented the proposed algorithms on personal computers and graphics workstations. Performance experiments show that the second eye image can be produced approximately 45 percent faster than drawing the two images separately and a smooth stereoscopic visualization can be achieved at interactive frame rates using continuous multiresolution representation of height fields.","1941-0506","","10.1109/TVCG.2002.1044519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044519","","Data visualization;Computer graphics;Workstations;Computer Society;Large-scale systems;Microcomputers;Image resolution;Rendering (computer graphics);Geometry;Layout","data visualisation;geophysics computing;quadtrees;stereo image processing;image morphing;software performance evaluation;rendering (computer graphics)","stereoscopic view-dependent visualization;terrain height field visualization;large geometric environments;computer graphics;large scale terrain models;quadtree based multiresolution representation;simplification criterion;distance-based angular error threshold;view frustum culling;vertex activation;cracking problem;image morphing;multiresolution rendering;personal computers;graphics workstations;performance experiments;interactive frame rates;continuous multiresolution representation","","15","3","16","","10 Dec 2002","","","IEEE","IEEE Journals"
"Stylized and abstract painterly rendering system using a multiscale segmented sphere hierarchy","Ming-Te Chi; Tong-Yee Lee","Dept. of Comput. Sci. & Eng., Nat. Cheng Kung Univ., Tainan, Taiwan; Dept. of Comput. Sci. & Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","IEEE Transactions on Visualization and Computer Graphics","21 Nov 2005","2006","12","1","61","72","This paper presents a novel system framework for interactive, three-dimensional, stylized, abstract painterly rendering. In this framework, the input models are first represented using 3D point sets and then this point-based representation is used to build a multiresolution bounding sphere hierarchy. From the leaf to root nodes, spheres of various sizes are rendered into multiple-size strokes on the canvas. The proposed sphere hierarchy is developed using multiscale region segmentation. This segmentation task assembles spheres with similar attribute regularities into a meaningful region hierarchy. These attributes include colors, positions, and curvatures. This hierarchy is very useful in the following respects: 1) it ensures the screen-space stroke density, 2) controls different input model abstractions, 3) maintains region structures such as the edges/boundaries at different scales, and 4) renders models interactively. By choosing suitable abstractions, brush stroke, and lighting parameters, we can interactively generate various painterly styles. We also propose a novel scheme that reduces the popping effect in animation sequences. Many different stylized images can be generated using the proposed framework.","1941-0506","","10.1109/TVCG.2006.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542000","Painterly rendering;bounding sphere hierarchy;multiscale region segmentation;stylization and abstraction;stroke-based rendering.","Rendering (computer graphics);Image generation;Image segmentation;Animation;Assembly;Power generation;Painting;Ink;Layout;Coherence","rendering (computer graphics);computer animation;image segmentation;interactive systems;solid modelling","stylized painterly rendering system;abstract painterly rendering system;multiscale segmented sphere hierarchy;point-based representation;screen-space stroke density;model abstraction;animation sequences","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Paintings;Pattern Recognition, Automated;User-Computer Interface","15","","36","IEEE","21 Nov 2005","","","IEEE","IEEE Journals"
"TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data","A. Rind; T. Lammarsch; W. Aigner; B. Alsallakh; S. Miksch","Vienna University of Technology, Institute of Software Technology & Interactive Systems; Vienna University of Technology, Institute of Software Technology & Interactive Systems; Vienna University of Technology, Institute of Software Technology & Interactive Systems; Vienna University of Technology, Institute of Software Technology & Interactive Systems; Vienna University of Technology, Institute of Software Technology & Interactive Systems","IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2247","2256","Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.","1941-0506","","10.1109/TVCG.2013.206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634096","Visual analytics;Data models;Data structures;Data visualization;Time-domain analysis;temporal data;Visual Analytics;information visualization;toolkits;software infrastructure;time","Visual analytics;Data models;Data structures;Data visualization;Time-domain analysis","data models;data visualisation;software libraries;time-domain analysis","TimeBench;data model;software library;time-oriented data;medical insights;electronic health records;network traffic;flat numerical data type;time domain complexity;calendar granularity;visual analytics designs;temporal foundations;application code;foundational data structures;foundational data algorithms;long-term developer study","Algorithms;Computer Graphics;Decision Making;Decision Support Techniques;Pattern Recognition, Automated;Software;User-Computer Interface","15","","52","","16 Oct 2013","","","IEEE","IEEE Journals"
"Towards Robust Topology of Sparsely Sampled Data","C. Correa; P. Lindstrom",Lawrence Livermore National Lab; Lawrence Livermore National Lab,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","1852","1861","Sparse, irregular sampling is becoming a necessity for reconstructing large and high-dimensional signals. However, the analysis of this type of data remains a challenge. One issue is the robust selection of neighborhoods − a crucial part of analytic tools such as topological decomposition, clustering and gradient estimation. When extracting the topology of sparsely sampled data, common neighborhood strategies such as k-nearest neighbors may lead to inaccurate results, either due to missing neighborhood connections, which introduce false extrema, or due to spurious connections, which conceal true extrema. Other neighborhoods, such as the Delaunay triangulation, are costly to compute and store even in relatively low dimensions. In this paper, we address these issues. We present two new types of neighborhood graphs: a variation on and a generalization of empty region graphs, which considerably improve the robustness of neighborhood-based analysis tools, such as topological decomposition. Our findings suggest that these neighborhood graphs lead to more accurate topological representations of low- and high- dimensional data sets at relatively low cost, both in terms of storage and computation time. We describe the implications of our work in the analysis and visualization of scalar functions, and provide general strategies for computing and applying our neighborhood graphs towards robust data analysis.","1941-0506","","10.1109/TVCG.2011.245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064948","Neighborhood graphs;topology;sparsely sampled data.","Topology;Robustness;Data mining;Noise measurement","data analysis;data visualisation;gradient methods;graph theory;mesh generation;pattern clustering;sampling methods;set theory","sparsely sampled data;sparse irregular sampling;high dimensional signal;topological decomposition;topological clustering;gradient estimation;neighborhood strategy;k-nearest neighbor;neighborhood connection;spurious connection;Delaunay triangulation;empty region graph;neighborhood-based analysis tool;topological decomposition;neighborhood graph;high dimensional data set;low dimensional data set;scalar function visualization;robust data analysis","","15","","54","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Tugging Graphs Faster: Efficiently Modifying Path-Preserving Hierarchies for Browsing Paths","D. Archambault; T. Munzner; D. Auber","INRIA Bordeaux Sud-Ouest, Talence; University of British Columbia, Vancouver; LaBRI, University of Bordeaux I, Talence","IEEE Transactions on Visualization and Computer Graphics","10 Jan 2011","2011","17","3","276","289","Many graph visualization systems use graph hierarchies to organize a large input graph into logical components. These approaches detect features globally in the data and place these features inside levels of a hierarchy. However, this feature detection is a global process and does not consider nodes of the graph near a feature of interest. TugGraph is a system for exploring paths and proximity around nodes and subgraphs in a graph. The approach modifies a pre-existing hierarchy in order to see how a node or subgraph of interest extends out into the larger graph. It is guaranteed to create path-preserving hierarchies, so that the abstraction shown is meaningful with respect to the underlying structure of the graph. The system works well on graphs of hundreds of thousands of nodes and millions of edges. TugGraph is able to present views of this proximal information in the context of the entire graph in seconds, and does not require a layout of the full graph as input.","1941-0506","","10.1109/TVCG.2010.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453362","Graph visualization;proximity;graph hierarchies.","Network servers;Web server;Computer networks;IP networks;Books;Computer Society;Data visualization;Computer vision;Systems engineering and theory;Internet","data visualisation;edge detection;feature extraction;graph theory;online front-ends","graph visualization systems;feature detection;TugGraph;subgraphs;browsing paths;path preserving hierarchy","Algorithms;Computer Graphics;Information Storage and Retrieval;Software;User-Computer Interface","15","","28","","22 Apr 2010","","","IEEE","IEEE Journals"
"Using Dashboard Networks to Visualize Multiple Patient Histories: A Design Study on Post-Operative Prostate Cancer","J. Bernard; D. Sessler; J. Kohlhammer; R. A. Ruddle","TU Darmstadt, Darmstadt, Germany; TU Darmstadt, Darmstadt, Germany; TU Darmstadt, Darmstadt, Germany; University of Leeds, Leeds, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2019","2019","25","3","1615","1628","In this design study, we present a visualization technique that segments patients' histories instead of treating them as raw event sequences, aggregates the segments using criteria such as the whole history or treatment combinations, and then visualizes the aggregated segments as static dashboards that are arranged in a dashboard network to show longitudinal changes. The static dashboards were developed in nine iterations, to show 15 important attributes from the patients' histories. The final design was evaluated with five non-experts, five visualization experts and four medical experts, who successfully used it to gain an overview of a 2,000 patient dataset, and to make observations about longitudinal changes and differences between two cohorts. The research represents a step-change in the detail of large-scale data that may be successfully visualized using dashboards, and provides guidance about how the approach may be generalized.","1941-0506","","10.1109/TVCG.2018.2803829","American Friends of the Alexander von Humboldt Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283817","Information visualization;visual analytics;multivariate data visualization;electronic health care records;medical data analysis;prostate cancer disease;design study;user study;evaluation;static dashboard;dashboard network","Data visualization;History;Prostate cancer;Visualization;Task analysis;Tools;Medical diagnostic imaging","cancer;data visualisation;medical computing;patient treatment","dashboard network;multiple patient histories;post-operative prostate cancer;visualization technique;static dashboards","Computer Graphics;Electronic Health Records;Humans;Male;Medical Informatics;Prostatic Neoplasms;User-Computer Interface","15","","49","IEEE","8 Feb 2018","","","IEEE","IEEE Journals"
"Visualization of multidimensional shape and texture features in laser range data using complex-valued Gabor wavelets","M. H. Gross; R. Koch","Inst. for Inf. Syst., Swiss Federal Inst. of Technol., Zurich, Switzerland; Inst. for Inf. Syst., Swiss Federal Inst. of Technol., Zurich, Switzerland","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","1","44","59","The paper describes a new method for visualization and analysis of multivariate laser range data using complex valued non orthogonal Gabor wavelets (D. Gabor, 1946), principal component analysis and a topological mapping network. The initial data set that provides both shape and texture information is encoded in terms of both amplitude and phase of a complex valued 2D image function. A set of carefully designed oriented Gabor filters performs a decomposition of the data and allows for retrieving local shape and texture features. The feature vector obtained from this method is multidimensional and in order to evaluate similar data features, further subspace methods to transform the data onto visualizable attributes, such as R, G, B, have to be determined. For this purpose, a feature based visualization pipeline is proposed consisting of principal component analysis, normalization and a topological mapping network. This process finally renders a R,G,B subspace representation of the multidimensional feature vector. Our method is primarily applied to the visual analysis of features in human faces but is not restricted to that.<<ETX>></ETX>","1941-0506","","10.1109/2945.468389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468389","","Multidimensional systems;Shape;Data visualization;Principal component analysis;Wavelet analysis;Gabor filters;Information retrieval;Pipelines;Humans;Face","data visualisation;laser ranging;wavelet transforms;image texture;feature extraction;face recognition","multidimensional shape visualization;texture features;complex valued non orthogonal Gabor wavelets;complex-valued Gabor wavelets;multivariate laser range data;principal component analysis;topological mapping network;initial data set;complex valued 2D image function;Gabor filters;subspace methods;feature based visualization pipeline;multidimensional feature vector;human faces;feature extraction","","15","","63","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Visualizing Social Photos on a Hasse Diagram for Eliciting Relations and Indexing New Photos","M. Crampes; J. de Oliveira-Kumar; S. Ranwez; J. Villerd",LGI2P/EMA Research Center; UNSW; LGI2P/EMA Research Center; LGI2P/EMA Research Center,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","985","992","Social photos, which are taken during family events or parties, represent individuals or groups of people. We show in this paper how a Hasse diagram is an efficient visualization strategy for eliciting different groups and navigating through them. However, we do not limit this strategy to these traditional uses. Instead we show how it can also be used for assisting in indexing new photos. Indexing consists of identifying the event and people in photos. It is an integral phase that takes place before searching and sharing. In our method we use existing indexed photos to index new photos. This is performed through a manual drag and drop procedure followed by a content fusion process that we call 'propagation'. At the core of this process is the necessity to organize and visualize the photos that will be used for indexing in a manner that is easily recognizable and accessible by the user. In this respect we make use of an object Galois sub-hierarchy and display it using a Hasse diagram. The need for an incremental display that maintains the user's mental map also leads us to propose a novel way of building the Hasse diagram. To validate the approach, we present some tests conducted with a sample of users that confirm the interest of this organization, visualization and indexation approach. Finally, we conclude by considering scalability, the possibility to extract social networks and automatically create personalised albums.","1941-0506","","10.1109/TVCG.2009.201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290703","Information visualization;Hasse Diagram;indexation;social photos;formal concept analysis;Galois sub-hierarchy.","Visualization;Indexing;Navigation;Displays;Testing;Digital cameras;Tagging;Facebook;Scalability;Social network services","data analysis;data visualisation;Galois fields;human computer interaction;indexing;social networking (online)","social photos;Hasse diagram;eliciting relations;indexing new photos;visualization strategy;content fusion process;object Galois sub-hierarchy;information visualization;formal concept analysis","","15","1","26","","23 Oct 2009","","","IEEE","IEEE Journals"
"Wavelet-Based Visual Analysis of Dynamic Networks","A. D. Col; P. Valdivia; F. Petronetto; F. Dias; C. T. Silva; L. G. Nonato","University of São Paulo, São Carlos, São Paulo, Brazil; University of São Paulo, São Carlos, São Paulo, Brazil; Federal University of Espirito Santo, Vitória, ES, Brazil; New York University, New York, NY; New York University, New York, NY; University of São Paulo, São Carlos, São Paulo, Brazil","IEEE Transactions on Visualization and Computer Graphics","29 Jun 2018","2018","24","8","2456","2469","Dynamic networks naturally appear in a multitude of applications from different fields. Analyzing and exploring dynamic networks in order to understand and detect patterns and phenomena is challenging, fostering the development of new methodologies, particularly in the field of visual analytics. In this work, we propose a novel visual analytics methodology for dynamic networks, which relies on the spectral graph wavelet theory. We enable the automatic analysis of a signal defined on the nodes of the network, making viable the robust detection of network properties. Specifically, we use a fast approximation of a graph wavelet transform to derive a set of wavelet coefficients, which are then used to identify activity patterns on large networks, including their temporal recurrence. The coefficients naturally encode the spatial and temporal variations of the signal, leading to an efficient and meaningful representation. This methodology allows for the exploration of the structural evolution of the network and their patterns overtime. The effectiveness of our approach is demonstrated using usage scenarios and comparisons involving real dynamic networks.","1941-0506","","10.1109/TVCG.2017.2746080","São Paulo Research Foundation (FAPESP)(grant numbers:2011/22749-8,2013/14089-3,2014/12815-1,2015/03330-7,2016/04391-2); CAPES (Brazilian government agency for postgraduate studies); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017630","Dynamic networks;spectral graph wavelets;visual analytics","Wavelet analysis;Visual analytics;Wavelet transforms;Data visualization;Tools;Network topology","data visualisation;graph theory;network theory (graphs);wavelet transforms","spectral graph wavelet theory;network properties;wavelet-based visual analysis;dynamic networks;visual analytics methodology","","15","","43","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"A technique for rendering complex portals","N. Lowe; A. Datta","Sch. of Comput. Sci. & Software Eng., Western Australia Univ., Australia; Sch. of Comput. Sci. & Software Eng., Western Australia Univ., Australia","IEEE Transactions on Visualization and Computer Graphics","17 Jan 2005","2005","11","1","81","90","We identify a general paradigm for portal-based rendering and present an image-space algorithm for rendering complex portals. Our general paradigm is an abstraction of portal-based rendering that is independent of scene geometry. It provides a framework for flexible and dynamic scene composition by connecting cells with transformative portals. Our rendering algorithm maintains a visible volume in image-space and uses fragment culling to discard fragments outside of this volume. We discuss our implementation in OpenGL and present results that show it provides correct rendering of complex portals at interactive rates on current hardware. We believe that our work is useful in many applications that require a means of creating dynamic and meaningful visual connections between different sets of data.","1941-0506","","10.1109/TVCG.2005.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359733","Index Terms- Portal-based rendering;fragment-culling;dual-depth-buffer;scene composition;complex portals.","Portals;Rendering (computer graphics);Layout;Engines;Joining processes;Windows;Runtime;Geometry;Hardware;Mirrors","rendering (computer graphics);computational geometry;interactive systems;image segmentation;portals","portal-based rendering;image-space algorithm;scene geometry;transformative portal;OpenGL implementation;visual connection","Algorithms;Computer Graphics;Computer Simulation;Environment;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Online Systems;Pattern Recognition, Automated;Signal Processing, Computer-Assisted;Subtraction Technique;User-Computer Interface","14","","21","IEEE","17 Jan 2005","","","IEEE","IEEE Journals"
"DGaze: CNN-Based Gaze Prediction in Dynamic Scenes","Z. Hu; S. Li; C. Zhang; K. Yi; G. Wang; D. Manocha","Peking University, China; Peking University, China; Peking University, China; Peking University, China; Peking University, China; University of Maryland, USA","IEEE Transactions on Visualization and Computer Graphics","31 Mar 2020","2020","26","5","1902","1911","We conduct novel analyses of users' gaze behaviors in dynamic virtual scenes and, based on our analyses, we present a novel CNN-based model called DGaze for gaze prediction in HMD-based applications. We first collect 43 users' eye tracking data in 5 dynamic scenes under free-viewing conditions. Next, we perform statistical analysis of our data and observe that dynamic object positions, head rotation velocities, and salient regions are correlated with users' gaze positions. Based on our analysis, we present a CNN-based model (DGaze) that combines object position sequence, head velocity sequence, and saliency features to predict users' gaze positions. Our model can be applied to predict not only realtime gaze positions but also gaze positions in the near future and can achieve better performance than prior method. In terms of realtime prediction, DGaze achieves a 22.0% improvement over prior method in dynamic scenes and obtains an improvement of 9.5% in static scenes, based on using the angular distance as the evaluation metric. We also propose a variant of our model called DGaze_ET that can be used to predict future gaze positions with higher precision by combining accurate past gaze data gathered using an eye tracker. We further analyze our CNN architecture and verify the effectiveness of each component in our model. We apply DGaze to gaze-contingent rendering and a game, and also present the evaluation results from a user study.","1941-0506","","10.1109/TVCG.2020.2973473","National Key R&D Program of China(grant numbers:2017YFB1002700); National Natural Science Foundation of China(grant numbers:61632003,61661146002,61631001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998375","Gaze prediction;convolutional neural network;eye tracking;dynamic scene;gaze-contingent rendering;virtual reality","Predictive models;Gaze tracking;Solid modeling;Head;Analytical models;Data models;Rendering (computer graphics)","convolutional neural nets;feature extraction;gaze tracking;helmet mounted displays;human computer interaction;rendering (computer graphics);statistical analysis;virtual reality","dynamic virtual scenes;HMD-based applications;dynamic object positions;head rotation velocities;object position sequence;head velocity sequence;realtime gaze positions;DGaze_ET;CNN architecture;gaze-contingent rendering;CNN-based gaze prediction model;users eye tracking data;statistical analysis;helmet mounted displays","Adolescent;Adult;Computer Graphics;Eye-Tracking Technology;Female;Fixation, Ocular;Humans;Male;Neural Networks, Computer;Software;Task Performance and Analysis;Young Adult","14","","46","IEEE","13 Feb 2020","","","IEEE","IEEE Journals"
"Data Through Others' Eyes: The Impact of Visualizing Others' Expectations on Visualization Interpretation","Y. Kim; K. Reinecke; J. Hullman",University of Washington; University of Washington; University of Washington,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","760","769","In addition to visualizing input data, interactive visualizations have the potential to be social artifacts that reveal other people's perspectives on the data. However, how such social information embedded in a visualization impacts a viewer's interpretation of the data remains unknown. Inspired by recent interactive visualizations that display people's expectations of data against the data, we conducted a controlled experiment to evaluate the effect of showing social information in the form of other people's expectations on people's ability to recall the data, the degree to which they adjust their expectations to align with the data, and their trust in the accuracy of the data. We found that social information that exhibits a high degree of consensus lead participants to recall the data more accurately relative to participants who were exposed to the data alone. Additionally, participants trusted the accuracy of the data less and were more likely to maintain their initial expectations when other people's expectations aligned with their own initial expectations but not with the data. We conclude by characterizing the design space for visualizing others' expectations alongside data.","1941-0506","","10.1109/TVCG.2017.2745240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019830","Social influence;Social visualization;Data interpretation","Data visualization;Uncertainty;Collaboration;Social network services;Market research;Focusing;Data analysis","data visualisation;human computer interaction;social networking (online)","social artifacts;social information;input data visualization;interactive visualizations;consensus degree","Computer Graphics;Crowdsourcing;Data Visualization;Databases, Factual;Humans;Mental Recall;Motivation;Social Perception;Trust","14","","40","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Distributed Seams for Gigapixel Panoramas","S. Philip; B. Summa; J. Tierny; P. Bremer; V. Pascucci","Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT; Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT; CNRS - LIP6 UPMC Sorbonne Universites, LTCI Telecom ParisTech, Paris, France; Lawrence Livermore National Laboratory, Livermore, CA; Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2015","2015","21","3","350","362","Gigapixel panoramas are an increasingly popular digital image application. They are often created as a mosaic of many smaller images. The mosaic acquisition can take many hours causing the individual images to differ in exposure and lighting conditions. A blending operation is often necessary to give the appearance of a seamless image. The blending quality depends on the magnitude of discontinuity along the image boundaries. Often, new boundaries, or seams, are first computed that minimize this transition. Current techniques based on multi-labeling Graph Cuts are too slow and memory intensive for gigapixel sized panoramas. In this paper, we present a parallel, out-of-core seam computing technique that is fast, has small memory footprint, and is capable of running efficiently on different types of parallel systems. Its maximum memory usage is configurable, in the form of a cache, which can improve performance by reducing redundant disk I/O and computations. It shows near-perfect scaling on symmetric multiprocessing systems and good scaling on clusters and distributed shared memory systems. Our technique improves the time required to compute seams for gigapixel imagery from many hours (or even days) to just a few minutes, while still producing boundaries with energy that is on-par with Graph Cuts.","1941-0506","","10.1109/TVCG.2014.2366128","NSF(grant numbers:OCI-0906379); NSF(grant numbers:OCI-0904631); DOE/NEUP(grant numbers:120341); DOE/MAPD(grant numbers:DESC000192); DOE/LLNL(grant numbers:B597476); DOE/Codesign(grant numbers:P01180734); DOE/SciDAC(grant numbers:DESC0007446); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6940309","Panorama;Seams;Gigapixel;Parallel;Scalable;Out-Of-Core;MPI;Panorama;seams;gigapixel;parallel;scalable;out-of-core;MPI","Image edge detection;Weaving;Labeling;Memory management;Lighting;Image resolution;Robots","image processing;parallel processing","digital photography;distributed shared memory systems;clusters;symmetric multiprocessing systems;memory footprint;parallel out-of-core seam computing technique;digital image application;gigapixel panoramas;distributed seams","","14","","29","IEEE","30 Oct 2014","","","IEEE","IEEE Journals"
"Efficiently Computing Exact Geodesic Loops within Finite Steps","S. -Q. Xin; Y. He; C. -W. Fu","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore","IEEE Transactions on Visualization and Computer Graphics","12 Apr 2012","2012","18","6","879","889","Closed geodesics, or geodesic loops, are crucial to the study of differential topology and differential geometry. Although the existence and properties of closed geodesics on smooth surfaces have been widely studied in mathematics community, relatively little progress has been made on how to compute them on polygonal surfaces. Most existing algorithms simply consider the mesh as a graph and so the resultant loops are restricted only on mesh edges, which are far from the actual geodesics. This paper is the first to prove the existence and uniqueness of geodesic loop restricted on a closed face sequence; it contributes also with an efficient algorithm to iteratively evolve an initial closed path on a given mesh into an exact geodesic loop within finite steps. Our proposed algorithm takes only an O(k) space complexity and an O(mk) time complexity (experimentally), where m is the number of vertices in the region bounded by the initial loop and the resultant geodesic loop, and k is the average number of edges in the edge sequences that the evolving loop passes through. In contrast to the existing geodesic curvature flow methods which compute an approximate geodesic loop within a predefined threshold, our method is exact and can apply directly to triangular meshes without needing to solve any differential equation with a numerical solver; it can run at interactive speed, e.g., in the order of milliseconds, for a mesh with around 50K vertices, and hence, significantly outperforms existing algorithms. Actually, our algorithm could run at interactive speed even for larger meshes. Besides the complexity of the input mesh, the geometric shape could also affect the number of evolving steps, i.e., the performance. We motivate our algorithm with an interactive shape segmentation example shown later in the paper.","1941-0506","","10.1109/TVCG.2011.119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928345","Discrete geodesic;geodesic loop;triangular mesh.","Face;Shape;Approximation algorithms;Image edge detection;Complexity theory;Measurement;Approximation methods","computational complexity;computational geometry;differential geometry;image segmentation;mesh generation","differential topology;differential geometry;mathematics community;polygonal surfaces;closed face sequence;closed path;exact geodesic loop;finite steps;space complexity;time complexity;edge sequences;geodesic curvature flow method;triangular mesh edge;interactive speed;geometric shape;interactive shape segmentation","","14","","38","IEEE","23 Jun 2011","","","IEEE","IEEE Journals"
"Exploring the Possibilities of Embedding Heterogeneous Data Attributes in Familiar Visualizations","M. H. Loorak; C. Perin; C. Collins; S. Carpendale","Department of Computer Science, University of Calgary; Department of Computer Science, University of Calgary; University of Ontario; Department of Computer Science, University of Calgary","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","581","590","Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering.","1941-0506","","10.1109/TVCG.2016.2598586","NSERC; AITF; SMART Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536142","Multi-dimensional data;Hybrid visualization","Data visualization;Layout;Visualization;Space exploration;Context;Joining processes;Encoding","data structures;data visualisation;query languages;query processing","heterogeneous embedded data attribute;HEDA;familiar visualization;data representation;design space;data query;attribute reordering","","14","","54","IEEE","8 Aug 2016","","","IEEE","IEEE Journals"
"Information Olfactation: Harnessing Scent to Convey Data","B. Patnaik; A. Batch; N. Elmqvist","University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","726","736","Olfactory feedback for analytical tasks is a virtually unexplored area in spite of the advantages it offers for information recall, feature identification, and location detection. Here we introduce the concept of <italic>information olfactation</italic> as the fragrant sibling of information visualization, and discuss how scent can be used to convey data. Building on a review of the human olfactory system and mirroring common visualization practice, we propose olfactory marks, the substrate in which they exist, and their olfactory channels that are available to designers. To exemplify this idea, we present <sc>vi</sc>S<sc>cent</sc>: A six-scent stereo olfactory display capable of conveying olfactory glyphs of varying temperature and direction, as well as a corresponding software system that integrates the display with a traditional visualization display. Finally, we present three applications that make use of the viScent system: A 2D graph visualization, a 2D line and point chart, and an immersive analytics graph visualization in 3D virtual reality. We close the paper with a review of possible extensions of viScent and applications of information olfactation for general visualization beyond the examples in this paper.","1941-0506","","10.1109/TVCG.2018.2865237","National Science Foundation(grant numbers:IIS-1539534); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444077","Olfaction;smell;scent;olfactory display;immersive analytics;immersion","Olfactory;Data visualization;Visualization;Task analysis;Two dimensional displays;Neurons;Virtual reality","chemioception;data visualisation;virtual reality","information olfactation;olfactory feedback;information recall;feature identification;location detection;information visualization;human olfactory system;olfactory marks;olfactory channels;six-scent stereo olfactory display;olfactory glyphs;viScent system;2D graph visualization;immersive analytics graph visualization;software system;visualization display;3D virtual reality","","14","","104","IEEE","22 Aug 2018","","","IEEE","IEEE Journals"
"Inviwo — A Visualization System with Usage Abstraction Levels","D. Jönsson; P. Steneteg; E. Sundén; R. Englund; S. Kottravel; M. Falk; A. Ynnerman; I. Hotz; T. Ropinski","Linköing University, Linköing, Sweden; Linköing University, Linköing, Sweden; Linköing University, Linköing, Sweden; Linköing University, Linköing, Sweden; Linköing University, Linköing, Sweden; Linköing University, Linköing, Sweden; Linköing University, Linköing, Sweden; Linköing University, Linköing, Sweden; Ulm University, Ulm, Germany","IEEE Transactions on Visualization and Computer Graphics","30 Sep 2020","2020","26","11","3241","3254","The complexity of today's visualization applications demands specific visualization systems tailored for the development of these applications. Frequently, such systems utilize levels of abstraction to improve the application development process, for instance by providing a data flow network editor. Unfortunately, these abstractions result in several issues, which need to be circumvented through an abstraction-centered system design. Often, a high level of abstraction hides low level details, which makes it difficult to directly access the underlying computing platform, which would be important to achieve an optimal performance. Therefore, we propose a layer structure developed for modern and sustainable visualization systems allowing developers to interact with all contained abstraction levels. We refer to this interaction capabilities as usage abstraction levels, since we target application developers with various levels of experience. We formulate the requirements for such a system, derive the desired architecture, and present how the concepts have been exemplary realized within the Inviwo visualization system. Furthermore, we address several specific challenges that arise during the realization of such a layered architecture, such as communication between different computing platforms, performance centered encapsulation, as well as layer-independent development by supporting cross layer documentation and debugging capabilities.","1941-0506","","10.1109/TVCG.2019.2920639","Swedish e-Science Research Centre; Deutsche Forschungsgemeinschaft(grant numbers:RO 3408/3-1); Excellence Center at Linköping and Lund in Information Technology; Knut och Alice Wallenbergs Stiftelse(grant numbers:2013-0076); Swedish research council(grant numbers:2015-05462); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8730513","Visualization systems;data visualization;visual analytics;data analysis;computer graphics;image processing","Data visualization;Visualization;Pipelines;Debugging;Interoperability;Documentation;Games","data visualisation;program debugging;software architecture","usage abstraction levels;specific visualization systems;application development process;data flow network editor;abstraction-centered system design;modern visualization systems;sustainable visualization systems;contained abstraction levels;application developers;Inviwo visualization system;layer-independent development;cross layer documentation","","14","","55","IEEE","4 Jun 2019","","","IEEE","IEEE Journals"
"Juniper: A Tree+Table Approach to Multivariate Graph Visualization","C. Nobre; M. Streit; A. Lex","University of Utah; Johannes Kepler University, Linz; University of Utah","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","544","554","Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree-table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.","1941-0506","","10.1109/TVCG.2018.2865149","NIH(grant numbers:U01 CA198935); NSF(grant numbers:IIS 1751238); DoD(grant numbers:ST1605-16-01); Austrian Science Fund(grant numbers:FWF P27975-NBL); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454344","Multivariate graphs;networks;tree-based graph visualization;adjacency matrix;spanning trees;visualization","Task analysis;Data visualization;Layout;Topology;Visualization;Network topology;Encoding","data visualisation;matrix algebra;trees (mathematics)","Juniper;tree-table multivariate graph visualization technique;spanning tree;interaction techniques;multivariate networks;subgraphs;bipartite network;multitype network;hybrid node-link matrix technique;citation metrics;adjacency matrix technique","","14","","52","IEEE","3 Sep 2018","","","IEEE","IEEE Journals"
"Marker Optimization for Facial Motion Acquisition and Deformation","B. H. Le; M. Zhu; Z. Deng","University of Houston, Houston; Nanjing University of Science and Technology, Nanjing; University of Houston, Houston","IEEE Transactions on Visualization and Computer Graphics","11 Sep 2013","2013","19","11","1859","1871","A long-standing problem in marker-based facial motion capture is what are the optimal facial mocap marker layouts. Despite its wide range of potential applications, this problem has not yet been systematically explored to date. This paper describes an approach to compute optimized marker layouts for facial motion acquisition as optimization of characteristic control points from a set of high-resolution, ground-truth facial mesh sequences. Specifically, the thin-shell linear deformation model is imposed onto the example pose reconstruction process via optional hard constraints such as symmetry and multiresolution constraints. Through our experiments and comparisons, we validate the effectiveness, robustness, and accuracy of our approach. Besides guiding minimal yet effective placement of facial mocap markers, we also describe and demonstrate its two selected applications: marker-based facial mesh skinning and multiresolution facial performance capture.","1941-0506","","10.1109/TVCG.2013.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6517176","Facial animation;facial deformation;motion capture;marker optimization;thin-shell deformation","Layout;Face;Deformable models;Optimization;Trajectory;Facial animation","computer animation;image motion analysis;image reconstruction;image resolution;image sequences;mesh generation;optimisation","facial motion acquisition;facial motion deformation;marker-based facial motion capture;optimal facial mocap marker layouts;characteristic control point optimization;high-resolution ground-truth facial mesh animation sequences;thin-shell linear deformation model;pose reconstruction process;hard constraints;symmetry constraints;multiresolution constraints;marker-based facial mesh skinning;multiresolution facial performance capture","Algorithms;Computer Graphics;Face;Humans;Image Processing, Computer-Assisted;Reproducibility of Results","14","","41","","17 May 2013","","","IEEE","IEEE Journals"
"Skeleton-Based Scagnostics","J. Matute; A. C. Telea; L. Linsen","Institute of Computer Science, Westfälische Wilhelms-Universität Münster, Germany; Johann Bernoulli Institute for Mathematics and Computer Science, University of Groningen, Groningen, The Netherlands; Institute of Computer Science, Westfälische Wilhelms-Universität Münster, Germany","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","542","552","Scatterplot matrices (SPLOMs) are widely used for exploring multidimensional data. Scatterplot diagnostics (scagnostics) approaches measure characteristics of scatterplots to automatically find potentially interesting plots, thereby making SPLOMs more scalable with the dimension count. While statistical measures such as regression lines can capture orientation, and graph-theoretic scagnostics measures can capture shape, there is no scatterplot characterization measure that uses both descriptors. Based on well-known results in shape analysis, we propose a scagnostics approach that captures both scatterplot shape and orientation using skeletons (or medial axes). Our representation can handle complex spatial distributions, helps discovery of principal trends in a multiscale way, scales visually well with the number of samples, is robust to noise, and is automatic and fast to compute. We define skeleton-based similarity metrics for the visual exploration and analysis of SPLOMs. We perform a user study to measure the human perception of scatterplot similarity and compare the outcome to our results as well as to graph-based scagnostics and other visual quality metrics. Our skeleton-based metrics outperform previously defined measures both in terms of closeness to perceptually-based similarity and computation time efficiency.","1941-0506","","10.1109/TVCG.2017.2744339","Deutsche Forschungsgemeinschaft(grant numbers:699379); European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017649","Multidimensional Data (primary keyword);High-Dimensional Data","Shape;Two dimensional displays;Visualization;Shape measurement;Skeleton;Correlation","data visualisation;graph theory;matrix algebra;statistical analysis","human perception;complex spatial distributions;medial axes;scatterplot shape;shape analysis;scatterplot characterization measure;graph-theoretic scagnostics measures;regression lines;statistical measures;scatterplot diagnostics;multidimensional data;scatterplot matrices;visual quality metrics;scatterplot similarity;SPLOMs;visual exploration;skeleton-based similarity metrics","","14","","65","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"The Curse of Knowledge in Visual Data Communication","C. Xiong; L. Van Weelden; S. Franconeri","Northwestern University, Evanston, IL, USA; Utrecht University, Utrecht, Netherlands; Northwestern University, Evanston, IL, USA","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2020","2020","26","10","3051","3062","A viewer can extract many potential patterns from any set of visualized data values. But that means that two people can see different patterns in the same visualization, potentially leading to miscommunication. Here, we show that when people are primed to see one pattern in the data as visually salient, they believe that naïve viewers will experience the same visual salience. Participants were told one of multiple backstories about political events that affected public polling data, before viewing a graph that depicted those data. One pattern in the data was particularly visually salient to them given the backstory that they heard. They then predicted what naïve viewers would most visually salient on the visualization. They were strongly influenced by their own knowledge, despite explicit instructions to ignore it, predicting that others would find the same patterns to be most visually salient. This result reflects a psychological phenomenon known as the curse of knowledge, where an expert struggles to re-create the state of mind of a novice. The present findings show that the curse of knowledge also plagues the visual perception of data, explaining why people can fail to connect with audiences when they communicate patterns in data.","1941-0506","","10.1109/TVCG.2019.2917689","Northwestern Cognitive Science Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718533","Cognitive biases;data communication;expertise;information visualization;perception and cognition","Data visualization;Visualization;Psychology;Decision making;Data communication;Data mining;Cognition","data communication;data visualisation;feature extraction;psychology;visual perception","visual perception;visual data communication;potential patterns;visualized data values;naïve viewers;visual salience;multiple backstories;political events;public polling data;backstory;psychological phenomenon;knowledge curse","","14","","47","IEEE","20 May 2019","","","IEEE","IEEE Journals"
"VideoPlus: a method for capturing the structure and appearance of immersive environments","C. J. Taylor","Dept. of Comput. & Inf. Sci., Pennsylvania Univ., Philadelphia, PA, USA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2002","8","2","171","182","This paper presents a simple approach to capturing the appearance and structure of immersive scenes based on the imagery acquired with an omnidirectional video camera. The scheme proceeds by combining techniques from structure-from-motion with ideas from image-based rendering. An interactive photogrammetric modeling scheme is used to recover the locations of a set of salient features in the scene (points and lines) from image measurements in a small set of keyframe images. The estimates obtained from this process are then used as a basis for estimating the position and orientation of the camera at every frame in the video clip. By augmenting the video sequence with pose information, we provide the end-user with the ability to index the video sequence spatially as opposed to temporally. This allows the user to explore the immersive scene by interactively selecting the desired viewpoint and viewing direction.","1941-0506","","10.1109/2945.998669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998669","","Layout;Cameras;Video sequences;Rendering (computer graphics)","virtual reality;image reconstruction;computer vision;video signal processing;image sequences;rendering (computer graphics);image motion analysis;video cameras","VideoPlus;immersive environment structure;immersive environment appearance;scene capture;imagery acquisition;omnidirectional video camera;structure from motion;image-based rendering;interactive photogrammetric modeling scheme;feature location recovery;image measurements;keyframe images;camera position estimation;camera orientation estimation;pose estimation;video frames;video clip;video sequence spatial indexing;interactive viewpoint selection;viewing direction;image reconstruction","","14","15","24","","7 Aug 2002","","","IEEE","IEEE Journals"
"Visual Integration of Quantitative Proteomic Data, Pathways, and Protein Interactions","R. Jianu; K. Yu; L. Cao; V. Nguyen; A. R. Salomon; D. H. Laidlaw","Brown University, Providence; Brown University, Providence; Brown University, Providence; Brown University, Providence; Brown University, Providence; Brown University, Providence","IEEE Transactions on Visualization and Computer Graphics","18 May 2010","2010","16","4","609","620","We introduce several novel visualization and interaction paradigms for visual analysis of published protein-protein interaction networks, canonical signaling pathway models, and quantitative proteomic data. We evaluate them anecdotally with domain scientists to demonstrate their ability to accelerate the proteomic analysis process. Our results suggest that structuring protein interaction networks around canonical signaling pathway models, exploring pathways globally and locally at the same time, and driving the analysis primarily by the experimental data, all accelerate the understanding of protein pathways. Concrete proteomic discoveries within T-cells, mast cells, and the insulin signaling pathway validate the findings. The aim of the paper is to introduce novel protein network visualization paradigms and anecdotally assess the opportunity of incorporating them into established proteomic applications. We also make available a prototype implementation of our methods, to be used and evaluated by the proteomic community.","1941-0506","","10.1109/TVCG.2009.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5262942","Biological (genome or protein) databases;data and knowledge visualization;graphs and networks;interactive data exploration and discovery;visualization techniques and methodologies.","Proteomics;Proteins;Data visualization;Signal analysis;Acceleration;Concrete;Prototypes;Genomics;Bioinformatics;Data mining","biology computing;data visualisation;proteins;proteomics","visual integration;quantitative proteomic data;visual analysis;protein-protein interaction networks;canonical signaling pathway models;proteomic analysis process;protein network visualization paradigms","Computer Graphics;Computer Simulation;Database Management Systems;Databases, Protein;Information Storage and Retrieval;Models, Biological;Protein Interaction Mapping;Proteome;Signal Transduction;Systems Integration;User-Computer Interface","14","","24","","25 Sep 2009","","","IEEE","IEEE Journals"
"Vulnus: Visual Vulnerability Analysis for Network Security","M. Angelini; G. Blasilli; T. Catarci; S. Lenti; G. Santucci",University of Rome “La Sapienza”; University of Rome “La Sapienza”; University of Rome “La Sapienza”; University of Rome “La Sapienza”; University of Rome “La Sapienza”,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","183","192","Vulnerabilities represent one of the main weaknesses of IT systems and the availability of consolidated official data, like CVE (Common Vulnerabilities and Exposures), allows for using them to compute the paths an attacker is likely to follow. However, even if patches are available, business constraints or lack of resources create obstacles to their straightforward application. As a consequence, the security manager of a network needs to deal with a large number of vulnerabilities, making decisions on how to cope with them. This paper presents VULNUS (VULNerabilities visUal aSsessment), a visual analytics solution for dynamically inspecting the vulnerabilities spread on networks, allowing for a quick understanding of the network status and visually classifying nodes according to their vulnerabilities. Moreover, VULNUS computes the approximated optimal sequence of patches able to eliminate all the attack paths and allows for exploring sub-optimal patching strategies, simulating the effect of removing one or more vulnerabilities. VULNUS has been evaluated by domain experts using a lab-test experiment, investigating the effectiveness and efficiency of the proposed solution.","1941-0506","","10.1109/TVCG.2018.2865028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8443131","Visual Analytics;Network security;Vulnerability analysis;CVE;CVSS;Attack Graph;Vulnerability triage and management","Security;Bars;Measurement;Visual analytics;Organizations","computer network security;data visualisation;Internet","business constraints;visual analytics solution;network status;visually classifying nodes;VULNUS;visual vulnerability analysis;network security;consolidated official data;vulnerabilities visual assessment;lab-test experiment","","14","","46","IEEE","21 Aug 2018","","","IEEE","IEEE Journals"
"A Space-Filling Visualization Technique for Multivariate Small-World Graphs","P. C. Wong; H. Foote; P. Mackey; G. Chin; Z. Huang; J. Thomas","Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland; Pacific Northwest National Laboratory, Richland","IEEE Transactions on Visualization and Computer Graphics","15 Mar 2012","2012","18","5","797","809","We introduce an information visualization technique, known as GreenCurve, for large multivariate sparse graphs that exhibit small-world properties. Our fractal-based design approach uses spatial cues to approximate the node connections and thus eliminates the links between the nodes in the visualization. The paper describes a robust algorithm to order the neighboring nodes of a large sparse graph by solving the Fiedler vector of its graph Laplacian, and then fold the graph nodes into a space-filling fractal curve based on the Fiedler vector. The result is a highly compact visualization that gives a succinct overview of the graph with guaranteed visibility of every graph node. GreenCurve is designed with the power grid infrastructure in mind. It is intended for use in conjunction with other visualization techniques to support electric power grid operations. The research and development of GreenCurve was conducted in collaboration with domain experts who understand the challenges and possibilities intrinsic to the power grid infrastructure. The paper reports a case study on applying GreenCurve to a power grid problem and presents a usability study to evaluate the design claims that we set forth.","1941-0506","","10.1109/TVCG.2011.99","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887326","Data and knowledge visualization;information visualization;visualization techniques and methodologies.","Data visualization;Laplace equations;Power grids;Layout;Fractals;Sparse matrices;Partitioning algorithms","curve fitting;data visualisation;graph theory;power engineering computing;power grids;vectors","space-filling visualization technique;multivariate small-world graphs;GreenCurve technique;multivariate sparse graph;small-world property;fractal-based design approach;spatial cue;node connection;visualization node;Fiedler vector;Laplacian graph;space-filling fractal curve;power grid infrastructure;electric power grid operation;domain expert;power grid problem;usability study","","13","1","39","","16 Jun 2011","","","IEEE","IEEE Journals"
"Adaptive extraction of time-varying isosurfaces","B. Gregorski; J. Senecal; M. A. Duchaineau; K. I. Joy","Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA; Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA; Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA; NA","IEEE Transactions on Visualization and Computer Graphics","13 Sep 2004","2004","10","6","683","694","We present an algorithm for adaptively extracting and rendering isosurfaces from compressed time-varying volume data sets. Tetrahedral meshes defined by longest edge bisection are used to create a multiresolution representation of the volume in the spatial domain that is adapted overtime to approximate the time-varying volume. The reextraction of the isosurface at each time step is accelerated with the vertex programming capabilities of modern graphics hardware. A data layout scheme which follows the access pattern indicated by mesh refinement is used to access the volume in a spatially and temporally coherent manner. This data layout scheme allows our algorithm to be used for out-of-core visualization.","1941-0506","","10.1109/TVCG.2004.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333666","Index Terms- Isosurfaces;multiresolution techniques;large isosurface visualization;time-varying isosurfaces;time-varying visualization;out-of-core visualization.","Isosurfaces;Data visualization;Data mining;Spatial resolution;Layout;Runtime;Acceleration;Graphics;Hardware;Clustering algorithms","rendering (computer graphics);data visualisation;mesh generation;feature extraction;very large databases;computer graphic equipment;computational geometry;surface fitting","time-varying isosurfaces;time-varying volume data sets;tetrahedral meshes;spatial domain;vertex programming;graphics hardware;data layout scheme;mesh refinement;out-of-core visualization;multiresolution techniques;isosurface visualization","","13","","24","","13 Sep 2004","","","IEEE","IEEE Journals"
"AirVis: Visual Analytics of Air Pollution Propagation","Z. Deng; D. Weng; J. Chen; R. Liu; Z. Wang; J. Bao; Y. Zheng; Y. Wu","State Key Lab of CAD & CG, Zhejiang University; State Key Lab of CAD & CG, Zhejiang University; State Key Lab of CAD & CG, Zhejiang University; State Key Lab of CAD & CG, Zhejiang University; Research Center for Air Pollution and Health, Zhejiang University; JD Intelligent City Research, Beijing, China; JD Intelligent City Research, Beijing, China; State Key Lab of CAD & CG, Zhejiang University","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","800","810","Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.","1941-0506","","10.1109/TVCG.2019.2934670","National Key R and D Program of China(grant numbers:2018YFB1004300); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:U1609217); NSFC(grant numbers:61761136020); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); 100 Talents Program of Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807233","Air pollution propagation;pattern mining;graph visualization","Air pollution;Data visualization;Data mining;Atmospheric modeling;Transportation;Spatiotemporal phenomena","air pollution;data analysis;data mining;data visualisation;environmental science computing;feature extraction;graph theory","visual analytics system;air pollution propagation;air pollutants;data mining;uncertain pollutant transportation;uncertain spatiotemporal propagation process;public health problem;AirVis;graph visualizations;propagation pattern extraction;pattern presentation scalability;pattern mining;minimum description length principle","Air Pollution;Cities;Computer Graphics;Data Mining;Environmental Monitoring","13","","81","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"An Evaluation of Graphical Context as a Means for Ameliorating the Effects of Registration Error","C. M. Robertson; B. MacIntyre; B. N. Walker","Georgia Institute of Technology, Atlanta; Georgia Institute of Technology, Atlanta; Georgia Institute of Technology, Atlanta","IEEE Transactions on Visualization and Computer Graphics","20 Jan 2009","2009","15","2","179","192","An ongoing research problem in Augmented Reality (AR) is to improve tracking and display technology in order to minimize registration errors. However, perfect registration is not always necessary for users to understand the intent of an augmentation. This paper describes the results of an experiment to evaluate the effects of registration error in a Lego block placement task and the effectiveness of graphical context at ameliorating these effects. Three types of registration error were compared: no error, fixed error and random error. These three errors were evaluated with no context present and some graphical context present. The results of this experiment indicated that adding graphical context to a scene in which some registration error is present can allow a person to effectively operate in such an environment, in this case completing the Lego block placement task with a reduced number of errors made and in a shorter amount of time.","1941-0506","","10.1109/TVCG.2008.100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4604662","Augmented Reality;augmented environments;Communicative Intent;human-computer interaction;Augmented Reality;augmented environments;Communicative Intent;human-computer interaction","Displays;Graphics;Layout;Visualization;Back;Augmented reality;Virtual reality;Workstations;Computer errors;Adaptive systems","","","Adult;Analysis of Variance;Computer Graphics;Humans;Imaging, Three-Dimensional;Male;Middle Aged;Multivariate Analysis;Pilot Projects;User-Computer Interface;Visual Perception","13","3","9","","22 Aug 2008","","","IEEE","IEEE Journals"
"Analyzing Eye-Tracking Information in Visualization and Data Space: From Where on the Screen to What on the Screen","S. S. Alam; R. Jianu","School of Computing and Information Sciences, Florida International University, Miami, FL; School of Computing and Information Sciences, Florida International University, Miami, FL","IEEE Transactions on Visualization and Computer Graphics","3 Apr 2017","2017","23","5","1492","1505","Eye-tracking data is currently analyzed in the image space that gaze-coordinates were recorded in, generally with the help of overlays such as heatmaps or scanpaths, or with the help of manually defined areas of interest (AOI). Such analyses, which focus predominantly on where on the screen users are looking, require significant manual input and are not feasible for studies involving many subjects, long sessions, and heavily interactive visual stimuli. Alternatively, we show that it is feasible to collect and analyze eye-tracking information in data space. Specifically, the visual layout of visualizations with open source code that can be instrumented is known at rendering time, and thus can be used to relate gaze-coordinates to visualization and data objects that users view, in real time. We demonstrate the effectiveness of this approach by showing that data collected using this methodology from nine users working with an interactive visualization, was well aligned with the tasks that those users were asked to solve, and similar to annotation data produced by five human coders. Moreover, we introduce an algorithm that, given our instrumented visualization, could translate gaze-coordinates into viewed objects with greater accuracy than simply binning gazes into dynamically defined AOIs. Finally, we discuss the challenges, opportunities, and benefits of analyzing eye-tracking in visualization and data space.","1941-0506","","10.1109/TVCG.2016.2535340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420740","Eye-tracking;area of interest analysis;usability analysis;evaluation","Data visualization;Visualization;Instruments;Layout;Rendering (computer graphics);Real-time systems;Computers","data visualisation;gaze tracking;interactive systems","eye-tracking information analysis;data space visualization;eye tracking data;image space;screen users;interactive visual stimuli;data space;visual layout;rendering time;interactive visualization;annotation data;human coders;instrumented visualization;translate gaze-coordinates","","13","","42","IEEE","26 Feb 2016","","","IEEE","IEEE Journals"
"Analyzing Visibility Configurations","C. Dachsbacher","Karlsruhe Institute of Technology, Karlsruhe","IEEE Transactions on Visualization and Computer Graphics","17 Feb 2011","2011","17","4","475","486","Many algorithms, such as level of detail rendering and occlusion culling methods, make decisions based on the degree of visibility of an object, but do not analyze the distribution, or structure, of the visible and occluded regions across surfaces. We present an efficient method to classify different visibility configurations and show how this can be used on top of existing methods based on visibility determination. We adapt co-occurrence matrices for visibility analysis and generalize them to operate on clusters of triangular surfaces instead of pixels. We employ machine learning techniques to reliably classify the thus extracted feature vectors. Our method allows perceptually motivated level of detail methods for real-time rendering applications by detecting configurations with expected visual masking. We exemplify the versatility of our method with an analysis of area light visibility configurations in ray tracing and an area-to-area visibility analysis suitable for hierarchical radiosity refinement. Initial results demonstrate the robustness, simplicity, and performance of our method in synthetic scenes, as well as real applications.","1941-0506","","10.1109/TVCG.2010.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473225","Real-time rendering;visibility;GPUs;artificial intelligence.","Ray tracing;Layout;Algorithm design and analysis;Robustness;Computational modeling;Machine learning;Feature extraction;Artificial intelligence;Solids;Clustering algorithms","data analysis;learning (artificial intelligence);matrix algebra;pattern classification;rendering (computer graphics)","visibility configuration classification;detail rendering method;occlusion culling method;visibility degree;visibility determination;co-occurrence matrices;visibility analysis;machine learning techniques;visual masking;hierarchical radiosity refinement;ray tracing","","13","3","43","","27 May 2010","","","IEEE","IEEE Journals"
"Coloring 3D Printed Surfaces by Thermoforming","Y. Zhang; Y. Tong; K. Zhou","State Key Lab of CAD&CG, Zhejiang University, Mengminwei Building, Zijingang Campus, Hangzhou, Zhejiang, China; Computer Science and Engineering Department, Michigan State University, 428 S. Shaw Lane, Room 3115, MI; State Key Lab of CAD&CG, Zhejiang University, Mengminwei Building, Zijingang Campus, Hangzhou, Zhejiang, China","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2017","2017","23","8","1924","1935","Decorating the surfaces of 3D printed objects with color textures is still not readily available in most consumer-level or even high-end 3D printers. Existing techniques such as hydrographics color transfer suffer from the issues of air pockets in concave regions and discoloration in overly stretched regions. We propose a novel thermoforming-based coloring technique to alleviate these problems as well as to simplify the overall procedure. Thermoforming is a widely used technique in industry for plastic thin shell product manufacturing by pressing heated plastic sheets onto molds using atmospheric pressure. We attach on the transparent plastic sheet a precomputed color pattern decal prior to heating, and adhere it to 3D printed models treated as the molds in thermoforming. The 3D models are thus decorated with the desired color texture, as well as a thin, polished protective cover. The precomputation involves a physical simulation of the thermoforming process to compute the correct color pattern on the plastic sheet, and the vent hole layout on the 3D model for air pocket elimination. We demonstrate the effectiveness and accuracy of our computational model and our prototype thermoforming surface coloring system through physical experiments.","1941-0506","","10.1109/TVCG.2016.2598570","NSF of China(grant numbers:61272305); National Program for Special Support of Eminent Professionals of China, and Lenovo’s Program for Young Scientists; State Key Lab of CAD&CG for his stay at Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536161","3D printing;thermoforming;thermoplastic sheet simulation;texture mapping","Solid modeling;Atmospheric modeling;Computational modeling;Three-dimensional displays;Thermoforming;Plastics;Color","heat treatment;plastic products;polishing;pressing;production engineering computing;solid modelling;thermoforming;three-dimensional printing","3D printed surfaces;thermoforming-based coloring technique;plastic thin shell product manufacturing;plastic sheets pressing;atmospheric pressure;3D printed models;protective cover polishing","","13","","45","IEEE","8 Aug 2016","","","IEEE","IEEE Journals"
"Counting cases in substitope algorithms","D. C. Banks; S. A. Linton; P. K. Stockmeyer","Dept. of Comput. Sci., Florida State Univ., Tallahassee, FL, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","18 May 2004","2004","10","4","371","384","We describe how to count the cases that arise in a family of visualization techniques, including marching cubes, sweeping simplices, contour meshing, interval volumes, and separating surfaces. Counting the cases is the first step toward developing a generic visualization algorithm to produce substitopes (geometric substitutions of polytopes). We demonstrate the method using ""GAP,"" a software system for computational group theory. The case-counts are organized into a table that provides a taxonomy of members of the family; numbers in the table are derived from actual lists of cases, which are computed by our methods. The calculations confirm previously reported case-counts for four dimensions that are too large to check by hand and predict the number of cases that will arise in substitope algorithms that have not yet been invented. We show how Polya theory produces a closed-form upper bound on the case counts.","1941-0506","","10.1109/TVCG.2004.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298795","Isosurface;level set;group action;orbit;geometric substitution;Marching Cubes;separating surface;Polya counting;substitope.","Computer aided software engineering;Level set;Data visualization;Software systems;Taxonomy;Upper bound;Isosurfaces;Mirrors;Pattern matching","data visualisation;group theory;graph colouring;computational geometry","case counting;substitope algorithms;Marching Cubes visualization;Sweeping Simplices visualization;contour meshing visualization;interval volumes visualization;separating surfaces visualization;GAP software system;computational group theory;Polya counting theory;geometric substitution;graph colouring","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional","13","","39","","18 May 2004","","","IEEE","IEEE Journals"
"Detecting Symmetry in Scalar Fields Using Augmented Extremum Graphs","D. M. Thomas; V. Natarajan",Indian Institute of Science; Indian Institute of Science,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2663","2672","Visualizing symmetric patterns in the data often helps the domain scientists make important observations and gain insights about the underlying experiment. Detecting symmetry in scalar fields is a nascent area of research and existing methods that detect symmetry are either not robust in the presence of noise or computationally costly. We propose a data structure called the augmented extremum graph and use it to design a novel symmetry detection method based on robust estimation of distances. The augmented extremum graph captures both topological and geometric information of the scalar field and enables robust and computationally efficient detection of symmetry. We apply the proposed method to detect symmetries in cryo-electron microscopy datasets and the experiments demonstrate that the algorithm is capable of detecting symmetry even in the presence of significant noise. We describe novel applications that use the detected symmetry to enhance visualization of scalar field data and facilitate their exploration.","1941-0506","","10.1109/TVCG.2013.148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634095","Computer graphics;Robustness;Geometry;Histograms;Symmetric matrices;Feature extraction;data exploration;Scalar field visualization;extremum graph;Morse decomposition;symmetry detection","Computer graphics;Robustness;Geometry;Histograms;Symmetric matrices;Feature extraction","computational geometry;data visualisation;graph theory","cryo-electron microscopy dataset;geometric information;topological informaton;robust distance estimation;data structure;symmetric pattern;augmented extremum graph;scalar field data visualization;symmetry detection","Algorithms;Computer Graphics;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;User-Computer Interface","13","","44","","16 Oct 2013","","","IEEE","IEEE Journals"
"Developing and Evaluating Quilts for the Depiction of Large Layered Graphs","J. Bae; B. Watson",North Carolina State University; North Carolina State University,"IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","2268","2275","Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).","1941-0506","","10.1109/TVCG.2011.187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064992","Graph drawing;layered graphs;matrix based depiction;node-link diagram.","Time measurement;Atmospheric measurements;Particle measurements;Analysis of variance;Graphics","flowcharting;graphs;matrix algebra","quilts;layered graph depiction;flow charts;matrix depiction;skip link depiction;color-only depiction;text-only depiction;node-link diagrams;matrix diagrams","","13","","16","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Dynamic Influence Networks for Rule-Based Models","A. G. Forbes; A. Burks; K. Lee; X. Li; P. Boutillier; J. Krivine; W. Fontana","University of California, Santa Cruz; University of Illinois, Chicago; University of Illinois, Chicago; University of Illinois, Chicago; Harvard Medical School; Université Paris Diderot; Harvard Medical School","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","184","194","We introduce the Dynamic Influence Network (DIN), a novel visual analytics technique for representing and analyzing rule-based models of protein-protein interaction networks. Rule-based modeling has proved instrumental in developing biological models that are concise, comprehensible, easily extensible, and that mitigate the combinatorial complexity of multi-state and multi-component biological molecules. Our technique visualizes the dynamics of these rules as they evolve over time. Using the data produced by KaSim, an open source stochastic simulator of rule-based models written in the Kappa language, DINs provide a node-link diagram that represents the influence that each rule has on the other rules. That is, rather than representing individual biological components or types, we instead represent the rules about them (as nodes) and the current influence of these rules (as links). Using our interactive DIN-Viz software tool, researchers are able to query this dynamic network to find meaningful patterns about biological processes, and to identify salient aspects of complex rule-based models. To evaluate the effectiveness of our approach, we investigate a simulation of a circadian clock model that illustrates the oscillatory behavior of the KaiC protein phosphorylation cycle.","1941-0506","","10.1109/TVCG.2017.2745280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017593","Dynamic networks;biological data visualization;rule-based modeling;protein-protein interaction networks","Biological system modeling;Data visualization;Analytical models;Proteins;Computational modeling;Data models","biochemistry;biology computing;data analysis;data visualisation;molecular biophysics;physiological models;proteins;stochastic processes","node-link diagram;individual biological components;interactive DIN-Viz software tool;dynamic network;biological processes;circadian clock model;KaiC protein phosphorylation cycle;Dynamic Influence networks;Dynamic Influence Network;novel visual analytics technique;protein-protein interaction networks;biological models;open source stochastic simulator","","13","","67","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Dynamic interactions in physically realistic collaborative virtual environments","P. Jorissen; M. Wijnants; M. Lamotte","Expertise Centre for Digital Media, Hasselt Univ., Diepenbeek, Belgium; Expertise Centre for Digital Media, Hasselt Univ., Diepenbeek, Belgium; Expertise Centre for Digital Media, Hasselt Univ., Diepenbeek, Belgium","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","649","660","This work describes our efforts in creating a general object interaction framework for dynamic collaborative virtual environments. Furthermore, we increase the realism of the interactive world by using a rigid body simulator to calculate all actor and object movements. The main idea behind our interactive platform is to construct a virtual world using only objects that contain their own interaction information. As a result, the object interactions are application independent and only a single scheme is required to handle all interactions in the virtual world. In order to have more dynamic interactions, we also created a new and efficient way for human users to dynamically interact within virtual worlds through their avatar. In particular, we show how inverse kinematics can be used to increase the interaction possibilities and realism in collaborative virtual environments. This results in a higher feeling of presence for connected users and allows for easy, on-the-fly creation of new interactions. For the distribution of both the interactive objects and the dynamic avatar interactions, we keep the network load as low as possible. To demonstrate the effectiveness of our techniques, we incorporate them into an existing CVE framework.","1941-0506","","10.1109/TVCG.2005.100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512016","Index Terms- Artificial;augmented;and virtual realities;computer-supported cooperative work;synchronous interaction;animation;simulation.","Collaboration;Animation;Virtual environment;Collaborative work;Avatars;Computational modeling;Computer simulation;Application software;Humans;Kinematics","augmented reality;groupware;avatars;motion estimation;computer animation;graphical user interfaces","physically realistic collaborative virtual environment;rigid body simulator;object movement;inverse kinematics;realism;dynamic avatar interaction;augmented virtual reality;computer-supported cooperative work;synchronous interaction;computer animation","Computer Simulation;Computer Systems;Cybernetics;Data Display;Environment;Humans;Imaging, Three-Dimensional;Man-Machine Systems;Models, Biological;Online Systems;Touch;User-Computer Interface","13","9","39","","26 Sep 2005","","","IEEE","IEEE Journals"
"Dynamic scene occlusion culling","O. Sudarsky; C. Gotsman","Dept. of Comput. Sci., Israel Inst. of Technol., Haifa, Israel; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1999","5","1","13","29","Large, complex 3D scenes are best rendered in an output-sensitive way, i.e., in time largely independent of the entire scene model's complexity. Occlusion culling is one of the key techniques for output-sensitive rendering. We generalize existing occlusion culling algorithms, intended for static scenes, to handle dynamic scenes having numerous moving objects. The data structure used by an occlusion culling method is updated to reflect the objects' possible positions. To avoid updating the structure for every dynamic object at each frame, a temporal bounding volume (TBV) is created for each occluded dynamic object, using some known constraints on the object's motion. The TBV is inserted into the structure instead of the object. Subsequently, the object is ignored as long as the TBV is occluded and guaranteed to contain the object. The generalized algorithms' rendering time is linearly affected only by the scene's visible parts, not by hidden parts or by occluded dynamic objects. Our techniques also save communications in distributed graphic systems, e.g., multiuser virtual environments, by eliminating update messages for hidden dynamic objects. We demonstrate the adaptation of two occlusion culling algorithms to dynamic scenes: hierarchical Z-buffering and BSP tree projection.","1941-0506","","10.1109/2945.764866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=764866","","Layout;Rendering (computer graphics);Hardware;Virtual environment;Tree graphs;Computer graphics;Robots;Data structures;Heuristic algorithms;Animation","rendering (computer graphics);computer animation;data structures;virtual reality","dynamic scene occlusion culling;complex 3D scenes;output-sensitive rendering;static scenes;dynamic scenes;moving objects;data structure;temporal bounding volume;distributed graphic systems;update messages;hidden dynamic objects;hierarchical Z-buffering;BSP tree projection;multiuser virtual environments","","13","1","48","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Functional Decomposition for Bundled Simplification of Trail Sets","C. Hurter; S. Puechmorel; F. Nicol; A. Telea",ENAC; ENAC; ENAC; University of Groningen,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","500","510","Bundling visually aggregates curves to reduce clutter and help finding important patterns in trail-sets or graph drawings. We propose a new approach to bundling based on functional decomposition of the underling dataset. We recover the functional nature of the curves by representing them as linear combinations of piecewise-polynomial basis functions with associated expansion coefficients. Next, we express all curves in a given cluster in terms of a centroid curve and a complementary term, via a set of so-called principal component functions. Based on the above, we propose a two-fold contribution: First, we use cluster centroids to design a new bundling method for 2D and 3D curve-sets. Secondly, we deform the cluster centroids and generate new curves along them, which enables us to modify the underlying data in a statistically-controlled way via its simplified (bundled) view. We demonstrate our method by applications on real-world 2D and 3D datasets for graph bundling, trajectory analysis, and vector field and tensor field visualization.","1941-0506","","10.1109/TVCG.2017.2744338","Agence Nationale de la Recherche(grant numbers:ANR-14-CE24-0006-01); SESAR Research and Innovation Action Horizon 2020; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017623","path visualization;trajectory visualization;edge bundles;functional decomposition;path generation;streamlines","Shape;Data models;Two dimensional displays;Three-dimensional displays;Data visualization;Splines (mathematics);Clutter","computational geometry;data visualisation;graph theory;pattern clustering;polynomials;principal component analysis;tensors;vectors","trail sets;principal component functions;trajectory analysis;vector field visualization;tensor field visualization;graph bundling;3D curve-sets;bundling method;cluster centroids;complementary term;centroid curve;associated expansion coefficients;piecewise-polynomial basis functions;linear combinations;graph drawings;aggregates curves;bundled simplification;functional decomposition","","13","","74","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"GraphProtector: A Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms","X. Wang; W. Chen; J. -K. Chou; C. Bryan; H. Guan; W. Chen; R. Pan; K. -L. Ma","Zhejiang University; Zhejiang University; University of California, Davis; University of California, Davis; Zhejiang UniversityAlibaba Group; Zhejiang University; Zhejiang University; University of California, Davis","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","193","203","Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph's structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques-along with evaluating how applying the strategies will affect the utility of the anonymized results-remains a significant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphPro tector, we report several case studies and feedback collected from interviews with expert users in various scenarios.","1941-0506","","10.1109/TVCG.2018.2865021","National 973 Program of China(grant numbers:2015CB352503); National Natural Science Foundation of China(grant numbers:61772456,61761136020); Alibaba-Zhejiang University Joint Institute of Frontier Technologies; U.S. National Science Foundation(grant numbers:IIS-1320229,IIS-1741536); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440807","Graph privacy;k-anonymity;structural features;privacy preservation","Privacy;Data privacy;Data visualization;Pipelines;Visualization;Task analysis;Measurement","data privacy;data visualisation;graph theory;social networking (online)","visual interface;graph algorithms;social networks;privacy exposure;ostensibly anonymous individuals;sanitization strategies;hypothesized tactics;GraphProtector;privacy preservation pipeline;privacy protection schemes;anonymization schemes","","13","","57","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Illusion of Causality in Visualized Data","C. Xiong; J. Shapiro; J. Hullman; S. Franconeri","Northwestern University; Northwestern University, Kellogg School of Management; Northwestern University; Northwestern University","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","853","862","Students who eat breakfast more frequently tend to have a higher grade point average. From this data, many people might confidently state that a before-school breakfast program would lead to higher grades. This is a reasoning error, because correlation does not necessarily indicate causation - X and Y can be correlated without one directly causing the other. While this error is pervasive, its prevalence might be amplified or mitigated by the way that the data is presented to a viewer. Across three crowdsourced experiments, we examined whether how simple data relations are presented would mitigate this reasoning error. The first experiment tested examples similar to the breakfast-GPA relation, varying in the plausibility of the causal link. We asked participants to rate their level of agreement that the relation was correlated, which they rated appropriately as high. However, participants also expressed high agreement with a causal interpretation of the data. Levels of support for the causal interpretation were not equally strong across visualization types: causality ratings were highest for text descriptions and bar graphs, but weaker for scatter plots. But is this effect driven by bar graphs aggregating data into two groups or by the visual encoding type? We isolated data aggregation versus visual encoding type and examined their individual effect on perceived causality. Overall, different visualization designs afford different cognitive reasoning affordances across the same data. High levels of data aggregation by graphs tend to be associated with higher perceived causality in data. Participants perceived line and dot visual encodings as more causal than bar encodings. Our results demonstrate how some visualization designs trigger stronger causal links while choosing others can help mitigate unwarranted perceptions of causality.","1941-0506","","10.1109/TVCG.2019.2934399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805448","Information Visualization;Correlation and Causation;Visualization Design;Reasoning Affordance","Correlation;Data visualization;Bars;Task analysis;Visualization;Cognition;Encoding","causality;cognition;data visualisation;educational computing;educational institutions;graph theory","causal interpretation;visualization types;causality ratings;bar graphs;data aggregation;bar encodings;data visualization;grade point average;before-school breakfast program;crowdsourced experiments;text descriptions","","13","","50","IEEE","19 Aug 2019","","","IEEE","IEEE Journals"
"Interactive Approximate Rendering of Reflections, Refractions, and Caustics","W. Hu; K. Qin","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing; Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2007","13","1","46","57","Reflections, refractions, and caustics are very important for rendering global illumination images. Although many methods can be applied to generate these effects, the rendering performance is not satisfactory for interactive applications. In this paper, complex ray-object intersections are simplified so that the intersections can be computed on a GPU, and an iterative computing scheme based on the depth buffers is used for correcting the approximate results caused by the simplification. As a result, reflections and refractions of environment maps and nearby geometry can be rendered on a GPU interactively without preprocessing. We can even achieve interactive recursive reflections and refractions by using an object-impostor technique. Moreover, caustic effects caused by reflections and refractions can be rendered by placing the eye at the light. Rendered results prove that our method is sufficiently efficient to render plausible images interactively for many interactive applications","1941-0506","","10.1109/TVCG.2007.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015397","Interactive rendering;reflection;refraction;caustics;GPU.","Optical refraction;Rendering (computer graphics);Optical reflection;Layout;Lighting;Computer graphics;Ray tracing;Geometry;Costs;Hardware","computational geometry;image texture;iterative methods;ray tracing;realistic images;rendering (computer graphics)","interactive approximate rendering;image caustics;global illumination image rendering;complex ray-object intersections;GPU;iterative computing scheme;interactive recursive reflections;interactive recursive refractions;object-impostor technique","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Lighting;Refractometry;User-Computer Interface","13","","26","","20 Nov 2006","","","IEEE","IEEE Journals"
"Interactive, Internet Delivery of Visualization via Structured Prerendered Multiresolution Imagery","J. Chen; I. Yoon; W. Bethel","Yahoo Inc., Sunnyvale; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Jan 2008","2008","14","2","302","312","We present a novel approach for latency-tolerant delivery of visualization and rendering results where client-side frame rate display performance is independent of source dataset size, image size, visualization technique or rendering complexity. Our approach delivers pre-rendered, multiresolution images to a remote user as they navigate through different viewpoints, visualization or rendering parameters. We employ demand-driven tiled, multiresolution image streaming and prefetching to efficiently utilize available bandwidth while providing the maximum resolution user can perceive from a given viewpoint. Since image data is the only input to our system, our approach is generally applicable to all visualization and graphics rendering applications capable of generating image files in an ordered fashion. In our implementation, a normal web server provides on-demand images to a remote custom client application, which uses client-pull to obtain and cache only those images required to fulfill the interaction needs. The main contributions of this work are: (1) an architecture for latency-tolerant, remote delivery of precomputed imagery suitable for use with any visualization or rendering application capable of producing images in an ordered fashion; (2) a performance study showing the impact of diverse network environments and different tunable system parameters on end-to-end system performance in terms of deliverable frames per second.","1941-0506","","10.1109/TVCG.2007.70428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359497","Visualization systems and software;Evolving Internet applications;Distributed/network graphics;Visualization systems and software;Evolving Internet applications;Distributed/network graphics","Internet;Image resolution;Data visualization;Rendering (computer graphics);Displays;Navigation;Streaming media;Prefetching;Bandwidth;Graphics","data visualisation;image coding;image resolution;interactive systems;Internet;rendering (computer graphics)","interactive Internet delivery;data visualization;structured prerendered multiresolution imagery;latency-tolerant remote delivery;graphics rendering application;demand-driven tiled multiresolution image streaming;remote custom client application","","13","6","36","IEEE","21 Jan 2008","","","IEEE","IEEE Journals"
"Multi-Patch Collaborative Point Cloud Denoising via Low-Rank Recovery with Graph Constraint","H. Chen; M. Wei; Y. Sun; X. Xie; J. Wang","Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China","IEEE Transactions on Visualization and Computer Graphics","30 Sep 2020","2020","26","11","3255","3270","Point cloud is the primary source from 3D scanners and depth cameras. It usually contains more raw geometric features, as well as higher levels of noise than the reconstructed mesh. Although many mesh denoising methods have proven to be effective in noise removal, they hardly work well on noisy point clouds. We propose a new multi-patch collaborative method for point cloud denoising, which is solved as a low-rank matrix recovery problem. Unlike the traditional single-patch based denoising approaches, our approach is inspired by the geometric statistics which indicate that a number of surface patches sharing approximate geometric properties always exist within a 3D model. Based on this observation, we define a rotation-invariant height-map patch (HMP) for each point by robust Bi-PCA encoding bilaterally filtered normal information, and group its non-local similar patches together. Within each group, all patches are geometrically similar, while suffering from noise. We pack the height maps of each group into an HMP matrix, whose initial rank is high, but can be significantly reduced. We design an improved low-rank recovery model, by imposing a graph constraint to filter noise. Experiments on synthetic and raw datasets demonstrate that our method outperforms state-of-the-art methods in both noise removal and feature preservation.","1941-0506","","10.1109/TVCG.2019.2920817","National Natural Science Foundation of China(grant numbers:61772267,61502137); Fundamental Research Funds for the Central Universities(grant numbers:NE2014402,NE2016004); NUAA Fundamental Research Funds(grant numbers:NS2015053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8730533","Point cloud denoising;low-rank matrix recovery;height-map patch;self-similarity","Three-dimensional displays;Noise reduction;Collaboration;Solid modeling;Cameras;Surface reconstruction;Image reconstruction","filtering theory;image denoising;image reconstruction;matrix algebra;mesh generation;principal component analysis","approximate geometric properties;rotation-invariant height-map patch;bilaterally filtered normal information;nonlocal similar patches;HMP matrix;initial rank;low-rank recovery model;graph constraint;noise removal;depth cameras;raw geometric features;reconstructed mesh;mesh denoising methods;noisy point clouds;multipatch collaborative method;point cloud denoising;low-rank matrix recovery problem;geometric statistics;surface patches;multipatch collaborative point cloud denoising;robust Bi-PCA encoding","","13","","63","IEEE","4 Jun 2019","","","IEEE","IEEE Journals"
"Perturbation methods for interactive specular reflections","M. Chen; J. Arvo","Dept. of Comput. Sci., California Inst. of Technol., Pasadena, CA, USA; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2000","6","3","253","264","We describe an approach for interactively approximating specular reflections in arbitrary curved surfaces. The technique is applicable to any smooth implicitly defined reflecting surface that is equipped with a ray intersection procedure; it is also extremely efficient as it employs local perturbations to interpolate point samples analytically. After ray tracing a sparse set of reflection paths with respect to a given vantage point and static reflecting surfaces, the algorithm rapidly approximates reflections of arbitrary points in 3-space by expressing them as perturbations of nearby points with known reflections. The reflection of each new point is approximated to second-order accuracy by applying a closed-form perturbation formula to one or more nearby reflection paths. This formula is derived from the Taylor expansion of a reflection path and is based on first and second-order path derivatives. After preprocessing, the approach is fast enough to compute reflections of tessellated diffuse objects in arbitrary curved surfaces at interactive rates using standard graphics hardware. The resulting images are nearly indistinguishable from ray traced images that take several orders of magnitude longer to generate.","1941-0506","","10.1109/2945.879786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=879786","","Perturbation methods;Optical reflection;Ray tracing;Graphics;Hardware;Lighting;Computational modeling;Radiometry;Acceleration;Layout","ray tracing;reflection;perturbation techniques;interactive systems;computer graphic equipment","perturbation methods;interactive specular reflections;interactive approximation;arbitrary curved surfaces;smooth implicitly defined reflecting surface;ray intersection procedure;local perturbations;point samples;ray tracing;sparse set;reflection paths;vantage point;static reflecting surfaces;arbitrary points;3-space;second-order accuracy;closed-form perturbation formula;nearby reflection paths;Taylor expansion;reflection path;second-order path derivatives;preprocessing;tessellated diffuse objects;interactive rates;standard graphics hardware;ray traced images","","13","","26","","6 Aug 2002","","","IEEE","IEEE Journals"
"Real-Time Volume-Based Ambient Occlusion","G. Papaioannou; M. L. Menexi; C. Papadopoulos","Athens University of Economics and Business, Athens; Athens University of Economics and Business, Athens; Athens University of Economics and Business, Athens","IEEE Transactions on Visualization and Computer Graphics","8 Jul 2010","2010","16","5","752","762","Real-time rendering can benefit from global illumination methods to make the 3D environments look more convincing and lifelike. On the other hand, the conventional global illumination algorithms for the estimation of the diffuse surface interreflection make heavy usage of intra- and interobject visibility calculations, so they are time-consuming, and using them in real-time graphics applications can be prohibitive for complex scenes. Modern illumination approximations, such as ambient occlusion variants, use precalculated or frame-dependent data to reduce the problem to a local shading one. This paper presents a fast real-time method for visibility sampling using volumetric data in order to produce accurate inter- and intraobject ambient occlusion. The proposed volume sampling technique disassociates surface representation data from the visibility calculations, and therefore, makes the method suitable for both primitive-order or screen-order rendering, such as deferred rendering. The sampling mechanism can be used in any application that performs visibility queries or ray marching.","1941-0506","","10.1109/TVCG.2010.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383355","Shading;shadowing;raytracing;volume visualization;visibility;ambient occlusion;ray marching.","Sampling methods;Lighting;Layout;Optical attenuators;Animation;Geometry;Buffer storage;Graphics;Shadow mapping;Data visualization","hidden feature removal;lighting;ray tracing;rendering (computer graphics);sampling methods","real-time volume-based ambient occlusion;real-time rendering;global illumination methods;diffuse surface interreflection estimation;intravisibility calculations;interobject visibility calculations;illumination approximations;visibility sampling;volume sampling technique;primitive-order rendering;screen-order rendering;visibility queries;ray marching;raytracing","","13","","34","","15 Jan 2010","","","IEEE","IEEE Journals"
"Ribbon networks for modeling navigable paths of autonomous agents in virtual environments","P. Willemsen; J. K. Kearney; H. Wang","Dept. of Comput. Sci., Minnesota Univ., Duluth, MN, USA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","20 Mar 2006","2006","12","3","331","342","This paper presents the environment description framework (EOF) for modeling complex networks of intersecting roads and pathways in virtual environments. EOF represents information about the layout of streets and sidewalks, the rules that govern behavior on roads and walkways, and the locations of agents with respect to navigable structures. The framework serves as the substrate on which behavior programs for autonomous vehicles and pedestrians are built. Pathways are modeled as ribbons in space. The ribbon structure provides a natural coordinate frame for defining the local geometry of navigable surfaces. EOF includes a powerful runtime interface supported by robust and efficient code for locating objects on the ribbon network, for mapping between Cartesian and ribbon coordinates, and for determining behavioral constraints imposed by the environment.","1941-0506","","10.1109/TVCG.2006.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608020","Virtual reality;visual;model development;artificial;augmented;and virtual realities;specialized application language.","Autonomous agents;Intelligent networks;Virtual environment;Remotely operated vehicles;Shape;Road vehicles;Geometry;Robustness;Animation;Complex networks","computational geometry;computer animation;software agents;virtual reality","ribbon networks;navigable path modeling;autonomous agents;virtual environment;environment description framework;local geometry;Cartesian coordinates;behavioral constraints;behavior program","Algorithms;Computer Graphics;Computer Simulation;Ecosystem;Image Interpretation, Computer-Assisted;Models, Theoretical;Transportation;User-Computer Interface","13","2","33","IEEE","20 Mar 2006","","","IEEE","IEEE Journals"
"RingText: Dwell-free and hands-free Text Entry for Mobile Head-Mounted Displays using Head Motions","W. Xu; H. -N. Liang; Y. Zhao; T. Zhang; D. Yu; D. Monteiro","Xi'an Jiaotong-Liverpool University, Suzhou, China; Xi'an Jiaotong-Liverpool University, Suzhou, China; Xi'an Jiaotong-Liverpool University, Suzhou, China; Xi'an Jiaotong-Liverpool University, Suzhou, China; Xi'an Jiaotong-Liverpool University, Suzhou, China; Xi'an Jiaotong-Liverpool University, Suzhou, China","IEEE Transactions on Visualization and Computer Graphics","27 Mar 2019","2019","25","5","1991","2001","In this paper, we present a case for text entry using a circular keyboard layout for mobile head-mounted displays (HMDs) that is dwell-free and does not require users to hold a dedicated input device for letter selection. To support the case, we have implemented RingText whose design is based on a circular layout with two concentric circles. The outer circle is subdivided into regions containing letters. Selection is made by using a virtual cursor controlled by the user's head movements-entering a letter region triggers a selection and moving back into the inner circle resets the selection. The design of RingText follows an iterative process, where we initially conduct one first study to investigate the optimal number of letters per region, inner circle size, and alphabet starting location. We then optimize its design by selecting the most suitable features from the first study: one letter per region, narrowing the trigger area to lower error rates, and creating candidate regions that incorporate two suggested words to appear next to the current letter region (close to the cursor) using a dynamic (rather than fixed) approach. Our second study compares text entry performance of RingText with four other hands-free techniques and the results show that RingText outperforms them. Finally, we run a third study lasting four consecutive days with 10 participants (5 novice users and 5 expert users) doing two daily sessions and the results show that RingText is quite efficient and yields a low error rate. At the end of the eighth session, the novice users can achieve a text entry speed of 11.30 WPM after 60 minutes of training while the expert (more experienced) users can reach an average text entry speed of 13.24 WPM after 90 minutes of training.","1941-0506","","10.1109/TVCG.2019.2898736","XJTLU(grant numbers:KSF-A-03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642443","Virtual Reality;text entry;circular keyboard layout;mobile head-worn/mounted displays;dwell-free input","Layout;Keyboards;Error analysis;Training;Head-mounted displays;Resists;Dynamics","feature selection;helmet mounted displays;keyboards;mobile computing;text analysis;virtual reality","RingText;hands-free text entry;mobile head-mounted displays;head motions;dwell-free text entry;mobile HMD;virtual cursor;feature selection;virtual reality","Adolescent;Adult;Female;Head Movements;Humans;Male;Smart Glasses;Text Messaging;Virtual Reality;Young Adult","13","","47","IEEE","14 Feb 2019","","","IEEE","IEEE Journals"
"Smashing Peacocks Further: Drawing Quasi-Trees from Biconnected Components","D. Archambault; T. Munzner; D. Auber",University of British Columbia; University of British Columbia; Universite de Bordeaux,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","813","820","Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality.","1941-0506","","10.1109/TVCG.2006.177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015434","Graph and Network Visualization;Quasi-Tree","Tree graphs;Proteins;Peer to peer computing;Bioinformatics;Application software;Computer networks;Skeleton;Engineering drawings;IP networks;Tomography","","","","13","","23","","20 Nov 2006","","","IEEE","IEEE Journals"
"UnTangle Map: Visual Analysis of Probabilistic Multi-Label Data","N. Cao; Y. -R. Lin; D. Gotz","Graph Computing, IBM T.J. Watson Research Center, Yorktown Heights, NY; School of Information Sciences, University of Pittsburgh, PA; School of Information and Library Science, University of North Carolina Chapel Hill School, Mannign Hall, Chapel Hill, NC","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2015","2016","22","2","1149","1163","Data with multiple probabilistic labels are common in many situations. For example, a movie may be associated with multiple genres with different levels of confidence. Despite their ubiquity, the problem of visualizing probabilistic labels has not been adequately addressed. Existing approaches often either discard the probabilistic information, or map the data to a low-dimensional subspace where their associations with original labels are obscured. In this paper, we propose a novel visual technique, UnTangle Map, for visualizing probabilistic multi-labels. In our proposed visualization, data items are placed inside a web of connected triangles, with labels assigned to the triangle vertices such that nearby labels are more relevant to each other. The positions of the data items are determined based on the probabilistic associations between items and labels. UnTangle Map provides both (a) an automatic label placement algorithm, and (b) adaptive interactions that allow users to control the label positioning for different information needs. Our work makes a unique contribution by providing an effective way to investigate the relationship between data items and their probabilistic labels, as well as the relationships among labels. Our user study suggests that the visualization effectively helps users discover emergent patterns and compare the nuances of probabilistic information in the data labels.","1941-0506","","10.1109/TVCG.2015.2424878","US Defense Advanced Research Projects Agency; Social Media in Strategic Communication program(grant numbers:W911NF-12-C-0028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091015","Visualization;Multidimensional Visualization;Probability Vector;Visualization;multidimensional visualization;probability vector","Data visualization;Probabilistic logic;Visualization;Layout;Distributed databases;Motion pictures;Data models","data visualisation;probability","UnTangle Map;visual analysis;data mapping;low-dimensional subspace;visual technique;probabilistic multilabel data visualization;data items;triangle vertices;automatic label placement algorithm;adaptive interactions;label positioning control","","13","","52","IEEE","21 Apr 2015","","","IEEE","IEEE Journals"
"Video-Based Crowd Synthesis","M. Flagg; J. M. Rehg","Georgia Institute of Technology, Atlanta; Georgia Institute of Technology , Atlanta","IEEE Transactions on Visualization and Computer Graphics","11 Sep 2013","2013","19","11","1935","1947","As a controllable medium, video-realistic crowds are important for creating the illusion of a populated reality in special effects, games, and architectural visualization. While recent progress in simulation and motion captured-based techniques for crowd synthesis has focused on natural macroscale behavior, this paper addresses the complementary problem of synthesizing crowds with realistic microscale behavior and appearance. Example-based synthesis methods such as video textures are an appealing alternative to conventional model-based methods, but current techniques are unable to represent and satisfy constraints between video sprites and the scene. This paper describes how to synthesize crowds by segmenting pedestrians from input videos of natural crowds and optimally placing them into an output video while satisfying environmental constraints imposed by the scene. We introduce crowd tubes, a representation of video objects designed to compose a crowd of video billboards while avoiding collisions between static and dynamic obstacles. The approach consists of representing crowd tube samples and constraint violations with a conflict graph. The maximal independent set yields a dense constraint-satisyfing crowd composition. We present a prototype system for the capture, analysis, synthesis, and control of video-based crowds. Several results demonstrate the system's ability to generate videos of crowds which exhibit a variety of natural behaviors.","1941-0506","","10.1109/TVCG.2012.317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365628","Crowd synthesis;video-based rendering;video object layout;crowd constraint optimization","Electron tubes;Trajectory;Layout;Computational modeling;Collision avoidance;Shape;Rendering (computer graphics)","image representation;image segmentation;set theory;video signal processing","video-based crowd synthesis;video-realistic crowd;motion captured-based technique;example-based synthesis method;pedestrian segmentation;scene environmental constraint;video billboard;crowd tube;video object representation;conflict graph;maximal independent set;dense constraint-satisyfing crowd composition","Computer Graphics;Computer Simulation;Crowding;Humans;Image Processing, Computer-Assisted;Video Recording","13","","36","","30 Nov 2012","","","IEEE","IEEE Journals"
"View Management of Projected Labels on Nonplanar and Textured Surfaces","D. Iwai; T. Yabiki; K. Sato","Osaka University, Toyonaka; Osaka University, Toyonaka; Osaka University, Toyonaka","IEEE Transactions on Visualization and Computer Graphics","12 Jun 2013","2013","19","8","1415","1424","This paper presents a new label layout technique for projection-based augmented reality (AR) that determines the placement of each label directly projected onto an associated physical object with a surface that is normally inappropriate for projection (i.e., nonplanar and textured). Central to our technique is a new legibility estimation method that evaluates how easily people can read projected characters from arbitrary viewpoints. The estimation method relies on the results of a psychophysical study that we conducted to investigate the legibility of projected characters on various types of surfaces that deform their shapes, decrease their contrasts, or cast shadows on them. Our technique computes a label layout by minimizing the energy function using a genetic algorithm (GA). The terms in the function quantitatively evaluate different aspects of the layout quality. Conventional label layout solvers evaluate anchor regions and leader lines. In addition to these evaluations, we design our energy function to deal with the following unique factors, which are inherent in projection-based AR applications: the estimated legibility value and the disconnection of the projected leader line. The results of our subjective experiment showed that the proposed technique could significantly improve the projected label layout.","1941-0506","","10.1109/TVCG.2012.321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381407","Projection-based augmented reality;view management;label layout;projected character's legibility","Layout;Surface texture;Shape;Estimation;Computational modeling;Image color analysis;Gaussian noise","augmented reality;genetic algorithms;image texture;minimisation","nonplanar surfaces;textured surfaces;label layout technique;projection-based augmented reality;label placement determines;legibility estimation method;psychophysical study;projected character legibility;shape deformation;energy function minimization;genetic algorithm;GA;layout quality;anchor region evaluation;leader lines;projection-based AR applications;projected label layout improvement","","13","","20","","13 Dec 2012","","","IEEE","IEEE Journals"
"Visualization of Barrier Tree Sequences","C. Heine; G. Scheuermann; C. Flamm; I. L. Hofacker; P. F. Stadler","Dept. of Comput. Sci., Leipzig Univ.; Dept. of Comput. Sci., Leipzig Univ.; Dept. of Comput. Sci., Leipzig Univ.; NA; NA","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","781","788","Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation","1941-0506","","10.1109/TVCG.2006.196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015430","Graph drawing;dynamic graph;RNA folding;energy landscape;fitness landscape;barrier tree","Visualization;RNA;Computer science;Animation;Tree graphs;Biomedical signal processing;Bioinformatics;Joining processes;Heuristic algorithms;US Department of Transportation","biology computing;computer animation;data visualisation;macromolecules;molecular biophysics;organic compounds;sequences;trees (mathematics)","barrier tree sequence visualization;RNA molecule spatial structures;RNA folding landscape visualization;barrier tree animation;tolerance algorithm;dynamic supergraph layout problem;graph drawing","Base Sequence;Computer Graphics;Computer Simulation;Models, Chemical;Models, Molecular;Molecular Sequence Data;Nucleic Acid Conformation;RNA;RNA;Sequence Analysis, RNA;User-Computer Interface","13","1","25","","20 Nov 2006","","","IEEE","IEEE Journals"
"Adaptive Disentanglement Based on Local Clustering in Small-World Network Visualization","A. Nocaj; M. Ortmann; U. Brandes","Department of Computer and Information Science, University of Konstanz; Department of Computer and Information Science, University of Konstanz; Department of Computer and Information Science, University of Konstanz","IEEE Transactions on Visualization and Computer Graphics","28 Apr 2016","2016","22","6","1662","1671","Small-world networks have characteristically low pairwise shortest-path distances, causing distance-based layout methods to generate hairball drawings. Recent approaches thus aim at finding a sparser representation of the graph to amplify variations in pairwise distances. Since the effect of sparsification on the layout is difficult to describe analytically, the incorporated filtering parameters of these approaches typically have to be selected manually and individually for each input instance. We here propose the use of graph invariants to determine suitable parameters automatically. This allows us to perform adaptive filtering to obtain drawings in which the cluster structure is most prominent. The approach is based on an empirical relationship between input and output characteristics that is derived from real and synthetic networks. Experimental evaluation shows the effectiveness of our approach and suggests that it can be used by default to increase the robustness of force-directed layout methods.","1941-0506","","10.1109/TVCG.2016.2534559","German Research Foundation(grant numbers:Br 2158/11-1); SFB/Transregio(grant numbers:161); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422137","Automatic Parameter Selection;Adaptive Edge Filtering;Graph Simplification;Force-directed Layout;Small-World Networks;Network Visualization;Automatic parameter selection;adaptive edge filtering;graph simplification;force-directed layout;small-world networks;network visualization","Layout;Visualization;Measurement;Adaptive systems;Filtering;Standards;Heuristic algorithms","adaptive filters;pattern clustering;small-world networks","synthetic networks;real networks;cluster structure;adaptive filtering;filtering parameters;pairwise distances;sparser representation;hairball drawings;distance-based layout methods;small-world network visualization;local clustering;adaptive disentanglement","","12","","35","IEEE","29 Feb 2016","","","IEEE","IEEE Journals"
"ColorMap<sup>ND</sup>: A Data-Driven Approach and Tool for Mapping Multivariate Data to Color","S. Cheng; W. Xu; K. Mueller","Computer Science Department, Stony Brook University, Stony Brook, NY; Computer Science Department, Stony Brook University, Stony Brook, NY; Computer Science Department, Stony Brook University, Stony Brook, NY","IEEE Transactions on Visualization and Computer Graphics","1 Jan 2019","2019","25","2","1361","1377","A wide variety of color schemes have been devised for mapping scalar data to color. We address the challenge of color-mapping multivariate data. While a number of methods can map low-dimensional data to color, for example, using bilinear or barycentric interpolation for two or three variables, these methods do not scale to higher data dimensions. Likewise, schemes that take a more artistic approach through color mixing and the like also face limits when it comes to the number of variables they can encode. Our approach does not have these limitations. It is data driven in that it determines a proper and consistent color map from first embedding the data samples into a circular interactive multivariate color mapping display (ICD) and then fusing this display with a convex (CIE HCL) color space. The variables (data attributes) are arranged in terms of their similarity and mapped to the ICD's boundary to control the embedding. Using this layout, the color of a multivariate data sample is then obtained via modified generalized barycentric coordinate interpolation of the map. The system we devised has facilities for contrast and feature enhancement, supports both regular and irregular grids, can deal with multi-field as well as multispectral data, and can produce heat maps, choropleth maps, and diagrams such as scatterplots.","1941-0506","","10.1109/TVCG.2018.2808489","NSF(grant numbers:IIS 1527200); MSIP, Korea; Brookhaven National Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302605","Multivariate data;color mapping;color space;high dimensional data;pseudo coloring","Image color analysis;Interpolation;Data visualization;Tools;Aerospace electronics;Principal component analysis;Hyperspectral imaging","data visualisation;image colour analysis;interpolation","data attributes;convex color space;circular interactive multivariate color mapping display;data samples;consistent color map;color mixing;artistic approach;map low-dimensional data;color-mapping multivariate data;mapping scalar data;color schemes;data-driven approach;choropleth maps;heat maps;multispectral data;multivariate data sample","","12","","40","IEEE","26 Feb 2018","","","IEEE","IEEE Journals"
"Combining Recurrent Neural Networks and Adversarial Training for Human Motion Synthesis and Control","Z. Wang; J. Chai; S. Xia","Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy Of Sciences, Beijing, China; Texas A&M University, Uvalde, TX, USA; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy Of Sciences, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","14","28","This paper introduces a new generative deep learning network for human motion synthesis and control. Our key idea is to combine recurrent neural networks (RNNs) and adversarial training for human motion modeling. We first describe an efficient method for training an RNN model from prerecorded motion data. We implement RNNs with long short-term memory (LSTM) cells because they are capable of addressing the nonlinear dynamics and long term temporal dependencies present in human motions. Next, we train a refiner network using an adversarial loss, similar to generative adversarial networks (GANs), such that refined motion sequences are indistinguishable from real mocap data using a discriminative network. The resulting model is appealing for motion synthesis and control because it is compact, contact-aware, and can generate an infinite number of naturally looking motions with infinite lengths. Our experiments show that motions generated by our deep learning model are always highly realistic and comparable to high-quality motion capture data. We demonstrate the power and effectiveness of our models by exploring a variety of applications, ranging from random motion synthesis, online/offline motion control, and motion filtering. We show the superiority of our generative model by comparison against baseline models.","1941-0506","","10.1109/TVCG.2019.2938520","National Natural Science Foundation of China(grant numbers:61772499); Natural Science Foundation of Beijing Municipality(grant numbers:L182052); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826012","Deep learning;adversarial training;human motion modeling;synthesis and control","Hidden Markov models;Data models;Training;Generators;Mathematical model;Recurrent neural networks;Animation","image motion analysis;learning (artificial intelligence);motion control;recurrent neural nets","adversarial training;RNN model;prerecorded motion data;long short-term memory cells;long term temporal dependencies;adversarial loss;generative adversarial networks;refined motion sequences;discriminative network;high-quality motion capture data;motion filtering;recurrent neural networks;human motion synthesis;generative deep learning network","Computer Graphics;Deep Learning;Female;Humans;Image Processing, Computer-Assisted;Male;Models, Biological;Movement;Neural Networks, Computer","12","","41","IEEE","5 Sep 2019","","","IEEE","IEEE Journals"
"Distributed Shared Memory for Roaming Large Volumes","L. Castanie; C. Mion; X. Cavin; B. Levy","ALICE Group, INRIA, Lorraine; ALICE Group, INRIA, Lorraine; ALICE Group, INRIA, Lorraine; ALICE Group, INRIA, Lorraine","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","1299","1306","We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming","1941-0506","","10.1109/TVCG.2006.135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015495","Large volumes;volume roaming;out-of-core;hierarchical caching;distributed shared memory;hardware-accelerated volume visualization;graphics hardware;parallel rendering;graphics cluster.","Rendering (computer graphics);Probes;Graphics;Data visualization;Clustering algorithms;Real time systems;Aggregates;Ethernet networks;Network interfaces;Acceleration","cache storage;distributed shared memory systems;paged storage;rendering (computer graphics);workstation clusters","distributed shared memory;cluster-based volume rendering system;distributed graphics processing;pipelined sort-last rendering algorithm;data caching;gigabit Ethernet network interface;optimal volume roaming","Clinical Trials, Phase II as Topic;Clinical Trials, Phase III as Topic;Data Interpretation, Statistical;Humans;Probability;Sample Size","12","3","38","","20 Nov 2006","","","IEEE","IEEE Journals"
"Graphiti: Interactive Specification of Attribute-Based Edges for Network Modeling and Visualization","A. Srinivasan; H. Park; A. Endert; R. C. Basole",Georgia Institute of Technology; The Ohio State University; Georgia Institute of Technology; Georgia Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","226","235","Network visualizations, often in the form of node-link diagrams, are an effective means to understand relationships between entities, discover entities with interesting characteristics, and to identify clusters. While several existing tools allow users to visualize pre-defined networks, creating these networks from raw data remains a challenging task, often requiring users to program custom scripts or write complex SQL commands. Some existing tools also allow users to both visualize and model networks. Interaction techniques adopted by these tools often assume users know the exact conditions for defining edges in the resulting networks. This assumption may not always hold true, however. In cases where users do not know much about attributes in the dataset or when there are several attributes to choose from, users may not know which attributes they could use to formulate linking conditions. We propose an alternate interaction technique to model networks that allows users to demonstrate to the system a subset of nodes and links they wish to see in the resulting network. The system, in response, recommends conditions that can be used to model networks based on the specified nodes and links. In this paper, we show how such a demonstration-based interaction technique can be used to model networks by employing it in a prototype tool, Graphiti. Through multiple usage scenarios, we show how Graphiti not only allows users to model networks from a tabular dataset but also facilitates updating a pre-defined network with additional edge types.","1941-0506","","10.1109/TVCG.2017.2744843","Tennenbaum Institute; Georgia Tech; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019835","Network modeling;visual analytics;user interaction","Tools;Data visualization;Joining processes;Data models;Prototypes;Image color analysis;Computational modeling","data visualisation;formal specification;graphical user interfaces;human computer interaction;interactive systems;SQL","predefined networks;cluster identification;custom scripts programming;attribute-based edges;interactive specification;tabular dataset;Graphiti;demonstration-based interaction technique;complex SQL commands;resulting network;model networks;node-link diagrams;network visualizations;network modeling","","12","","49","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Hardware Accelerated Segmentation of Complex Volumetric Filament Networks","D. Mayerich; J. Keyser","Texas A&M University, College Station; Texas A&M University, College Station","IEEE Transactions on Visualization and Computer Graphics","12 May 2009","2009","15","4","670","681","We present a framework for segmenting and storing filament networks from scalar volume data. Filament networks are encountered more and more commonly in biomedical imaging due to advances in high-throughput microscopy. These data sets are characterized by a complex volumetric network of thin filaments embedded in a scalar volume field. High-throughput microscopy volumes are also difficult to manage since they can require several terabytes of storage, even though the total volume of the embedded structure is much smaller. Filaments in microscopy data sets are difficult to segment because their diameter is often near the sampling resolution of the microscope, yet these networks can span large regions of the data set. We describe a novel method to trace filaments through scalar volume data sets that is robust to both noisy and undersampled data. We use graphics hardware to accelerate the tracing algorithm, making it more useful for large data sets. After the initial network is traced, we use an efficient encoding scheme to store volumetric data pertaining to the network.","1941-0506","","10.1109/TVCG.2008.196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4695828","Microscopy;vessel;neuron;segmentation;tracking.;Pixel classification;Edge and feature detection;Applications","Hardware;Acceleration;Image segmentation;Microscopy;Biomedical imaging;Computed tomography;Sampling methods;Graphics;Optical imaging;Magnetic resonance imaging","computer graphics;image segmentation;medical image processing;microscopy;ray tracing","hardware accelerated segmentation;complex volumetric filament networks;biomedical imaging;high-throughput microscopy volumes;graphics hardware;tracing algorithm","Algorithms;Animals;Brain;Computer Graphics;Computer Simulation;Database Management Systems;Fibrin;Image Interpretation, Computer-Assisted;Image Processing, Computer-Assisted;Information Storage and Retrieval;Mice;Microscopy;Neurons;Spinal Cord","12","","26","","9 Dec 2008","","","IEEE","IEEE Journals"
"Mining Graphs for Understanding Time-Varying Volumetric Data","Y. Gu; C. Wang; T. Peterka; R. Jacob; S. H. Kim","Department Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Division of Mathematics and Computer Science, Argonne National Laboratory, Argonne, IL; Division of Mathematics and Computer Science, Argonne National Laboratory, Argonne, IL; Department of Mechanical and Aerospace Engineering, The Ohio State University, Columbus, OH","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","965","974","A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.","1941-0506","","10.1109/TVCG.2015.2468031","National Science Foundation(grant numbers:IIS-1456763,IIS-1455886); U.S. Department of Energy(grant numbers:DE-FC02-06ER25777); U.S. Department of Energy(grant numbers:DE-AC02-06CH11357); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194853","Time-varying data visualization;graph simplification;community detection;visual recommendation;Time-varying data visualization;graph simplification;community detection;visual recommendation","Data visualization;Visualization;Connectors;Fans;Data mining;Feature extraction;Layout","data analysis;data mining;data visualisation;graph theory","graph mining;data understanding;time-varying volumetric data analysis;data visualization;data relationship extraction;low-dimensional abstract graph view;visual understanding;data complexity;cognition overhead;interaction cost;automatic meaningful feature extraction;graph-based representation;graph analysis technique;graph simplification;community detection;visual recommendation","","12","","28","IEEE","13 Aug 2015","","","IEEE","IEEE Journals"
"Perceptual-Aware Sketch Simplification Based on Integrated VGG Layers","X. Xu; M. Xie; P. Miao; W. Qu; W. Xiao; H. Zhang; X. Liu; T. -T. Wong","School of Computer Science and Engineering, South China University of Technology, Guangdong, China; Chinese University of Hong Kong, China; School of Computer Science and Engineering, South China University of Technology, Guangdong, China; School of Computer Science and Engineering, South China University of Technology, Guangdong, China; School of Computer Science and Engineering, South China University of Technology, Guangdong, China; School of Computer Science and Engineering, South China University of Technology, Guangdong, China; School of Computing and Information Sciences, Caritas Institute of Higher Education, China; Chinese University of Hong Kong, China","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","178","189","Deep learning has been recently demonstrated as an effective tool for raster-based sketch simplification. Nevertheless, it remains challenging to simplify extremely rough sketches. We found that a simplification network trained with a simple loss, such as pixel loss or discriminator loss, may fail to retain the semantically meaningful details when simplifying a very sketchy and complicated drawing. In this paper, we show that, with a well-designed multi-layer perceptual loss, we are able to obtain aesthetic and neat simplification results preserving semantically important global structures as well as fine details without blurriness and excessive emphasis on local structures. To do so, we design a multi-layer discriminator by fusing all VGG feature layers to differentiate sketches and clean lines. The weights used in layer fusing are automatically learned via an intelligent adjustment mechanism. Furthermore, to evaluate our method, we compare our method to state-of-the-art methods through multiple experiments, including visual comparison and intensive user study.","1941-0506","","10.1109/TVCG.2019.2930512","National Natural Science Foundation of China(grant numbers:61772206,U1611461,61472145); Guangdong R&D key project of China(grant numbers:2018B010107003); Guangdong High-level personnel program(grant numbers:2016TQ03X319); Guangdong NSF(grant numbers:2017A030311027); Guangzhou key project in industrial technology(grant numbers:201802010027); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771128","Convolutional neural network;perceptual awareness;sketch simplification","Feature extraction;Semantics;Task analysis;Generative adversarial networks;Visualization;Lighting;Image segmentation","art;feature extraction;image fusion;learning (artificial intelligence);multilayer perceptrons;visual perception","visual comparison;VGG feature layer fusion;multilayer discriminator;local structures;semantically important global structures;multilayer perceptual loss;discriminator loss;pixel loss;simplification network;extremely rough sketches;raster-based sketch simplification;deep learning;integrated VGG layers;perceptual-aware sketch simplification","","12","","31","IEEE","24 Jul 2019","","","IEEE","IEEE Journals"
"Persistence Atlas for Critical Point Variability in Ensembles","G. Favelier; N. Faraj; B. Summa; J. Tierny",Sorbonne UniversitéCNRS (LIP6); Tulane University; Tulane University; Sorbonne UniversitéCNRS (LIP6),"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","1152","1162","This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes.","1941-0506","","10.1109/TVCG.2018.2864432","BPI(grant numbers:P112017-2661376/DOS0021427); NSF(grant numbers:CRII 1657020); NSF/NIH(grant numbers:QuBBD 1664848); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457259","Topological data analysis;scalar data;ensemble data","Market research;Data visualization;Layout;Probability density function;Extraterrestrial measurements;Uncertainty;Robustness","data visualisation;pattern clustering;probability;trees (mathematics)","critical points;critical point layouts;mandatory critical point;critical point variability;Persistence Atlas;lightweight VTK-based C++ implementation","","12","","87","IEEE","11 Sep 2018","","","IEEE","IEEE Journals"
"Saliency-Aware Texture Smoothing","L. Zhu; X. Hu; C. Fu; J. Qin; P. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","28 May 2020","2020","26","7","2471","2484","Texture smoothing aims to smooth out textures in images, while retaining the prominent structures. This paper presents a saliency-aware approach to the problem with two key contributions. First, we design a deep saliency network with guided non-local blocks (GNLBs) for learning long-range pixel dependencies by taking the predicted saliency map at former layer as the guidance image to help suppress the non-saliency regions in the shallow layer. The GNLB computes the saliency response at a position by a weighted sum of features at all positions, and enables us to produce results that outperform existing deep saliency models. Second, we formulate a joint optimization framework to take saliency information when iteratively separating textures from structures: on the texture layer, we smooth out structures with the help of the saliency information and migrate structures from the texture to structure layer, while on the structure layer, we adopt another deep model to detect edges and simultaneous sparse coding to push textures back to the texture layer. We tested our method on a rich variety of images and compared it with several state-of-the-art methods. Both visual and quantitative comparison results show that our method better preserves structures while removing the texture components.","1941-0506","","10.1109/TVCG.2018.2889055","Shenzhen Science and Technology Program(grant numbers:JCYJ20170413162617606); Shenzhen Key Laboratory(grant numbers:ZDSYS- 201605101739178); Research Grants Council of the Hong Kong Special Administrative Region(grant numbers:CUHK 14225616); Innovation and Technology Fund of Hong Kong(grant numbers:ITS/026/17); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585158","Texture smoothing;saliency detection;guided non-local block;deep learning","Smoothing methods;Image edge detection;Saliency detection;Optimization;Data models;Visualization;Semantics","edge detection;feature extraction;image coding;image texture;learning (artificial intelligence);object detection;optimisation","predicted saliency map;long-range pixel dependencies;guided nonlocal blocks;deep saliency network;key contributions;saliency-aware approach;saliency-aware texture smoothing;texture components;deep model;structure layer;migrate structures;texture layer;saliency information;deep saliency models;saliency response;shallow layer;nonsaliency regions;guidance image","","12","","68","IEEE","21 Dec 2018","","","IEEE","IEEE Journals"
"Support Substructures: Support-Induced Part-Level Structural Representation","S. -S. Huang; H. Fu; L. -Y. Wei; S. -M. Hu","Department of Computer Science and Technology, Tsinghua University, Beijing, China; School of Creative Media, City University of Hong Kong, Hong Kong; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","29 Jun 2016","2016","22","8","2024","2036","In this work we explore a support-induced structural organization of object parts. We introduce the concept of support substructures, which are special subsets of object parts with support and stability. A bottom-up approach is proposed to identify such substructures in a support relation graph. We apply the derived high-level substructures to part-based shape reshuffling between models, resulting in nontrivial functionally plausible model variations that are difficult to achieve with symmetry-induced substructures by the state-of-the-art methods. We also show how to automatically or interactively turn a single input model to new functionally plausible shapes by structure rearrangement and synthesis, enabled by support substructures. To the best of our knowledge no single existing method has been designed for all these applications.","1941-0506","","10.1109/TVCG.2015.2473845","National Basic Research Project of China(grant numbers:2011CB302203); Natural Science Foundation of China(grant numbers:61120106007); Beijing Higher Institution Engineering Research Center; Tsinghua University; HKSAR(grant numbers:113513,11204014,11300615); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226860","Support substructure;shape synthesis;3D modeling;stability","Shape;Stability analysis;Three-dimensional displays;Solid modeling;Periodic structures;Adaptation models;Ports (Computers)","image representation","support substructures;support-induced part-level structural representation;object parts support-induced structural organization;bottom-up approach;support relation graph;high-level substructures;part-based shape reshuffling;nontrivial functionally plausible model variations;symmetry-induced substructures;functionally plausible shapes;structure rearrangement;structure synthesis","","12","","30","IEEE","27 Aug 2015","","","IEEE","IEEE Journals"
"Temporal Radiance Caching","P. Gautron; K. Bouatouch; S. Pattanaik",NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","19 Mar 2007","2007","13","5","891","901","We present a novel method for fast, high quality computation of glossy global illumination in animated environments. Building on the irradiance caching and radiance caching algorithms, our method leverages temporal coherence by sparse temporal sampling and interpolation of the indirect lighting. In our approach, part of the global illumination solution computed in previous frames is reused in the current frame. Our reusing scheme adapts to the change of incoming radiance by updating the indirect lighting only where there is a significant change. By reusing data in several frames, our method removes the flickering artifacts and yields a significant speedup compared to classical computation in which a new cache is computed for every frame. We also define temporal gradients for smooth temporal interpolation. A key aspect of our method is the absence of any additional complex data structure, making the implementation into any existing renderer based on irradiance and radiance caching straightforward. We describe the implementation of our method using graphics hardware for improved performance.","1941-0506","","10.1109/TVCG.2007.1061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4135667","Global illumination;animation;temporal coherence;graphics processors","Lighting;Animation;Interpolation;Computational efficiency;Layout;Computer graphics;Sampling methods;Data structures;Rendering (computer graphics);Hardware","blood vessels;endoscopes;image colour analysis;medical image processing;rendering (computer graphics)","curved planar reformation;CPR projection method;curved tubular structure;blood vessel;spine;volume rendering;gray-scale contextual information;color information;virtual endoscopy;image processing","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Lighting;Reproducibility of Results;Sensitivity and Specificity;Video Recording","12","","31","IEEE","19 Mar 2007","","","IEEE","IEEE Journals"
"Touch? Speech? or Touch and Speech? Investigating Multimodal Interaction for Visual Network Exploration and Analysis","A. Saktheeswaran; A. Srinivasan; J. Stasko","Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA","IEEE Transactions on Visualization and Computer Graphics","30 Apr 2020","2020","26","6","2168","2179","Interaction plays a vital role during visual network exploration as users need to engage with both elements in the view (e.g., nodes, links) and interface controls (e.g., sliders, dropdown menus). Particularly as the size and complexity of a network grow, interactive displays supporting multimodal input (e.g., touch, speech, pen, gaze) exhibit the potential to facilitate fluid interaction during visual network exploration and analysis. While multimodal interaction with network visualization seems like a promising idea, many open questions remain. For instance, do users actually prefer multimodal input over unimodal input, and if so, why? Does it enable them to interact more naturally, or does having multiple modes of input confuse users? To answer such questions, we conducted a qualitative user study in the context of a network visualization tool, comparing speech- and touch-based unimodal interfaces to a multimodal interface combining the two. Our results confirm that participants strongly prefer multimodal input over unimodal input attributing their preference to: 1) the freedom of expression, 2) the complementary nature of speech and touch, and 3) integrated interactions afforded by the combination of the two modalities. We also describe the interaction patterns participants employed to perform common network visualization operations and highlight themes for future multimodal network visualization systems to consider.","1941-0506","","10.1109/TVCG.2020.2970512","National Science Foundation(grant numbers:IIS-1717111); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977320","Multimodal interaction;network visualizations;natural language interfaces","Visualization;Encoding;Tools;Data visualization;Speech recognition;Natural languages;Task analysis","data visualisation;graphical user interfaces;mobile handsets","visual network exploration;interactive displays;multimodal input;network visualization tool;multimodal interface;interaction patterns participants;multimodal network visualization systems;network visualization operations","Adolescent;Adult;Aged;Computer Graphics;Data Visualization;Female;Humans;Male;Middle Aged;Speech;Touch;User-Computer Interface;Young Adult","12","","70","IEEE","31 Jan 2020","","","IEEE","IEEE Journals"
"Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System","R. Shadoan; C. Weaver",Akashic Labs LLC; School of Computer Science and the Center for Spatial Analysis at University of Oklahoma,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2070","2079","Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.","1941-0506","","10.1109/TVCG.2013.220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634154","Visual analytics;Data analysis;Data visualization;Marine vehicles;Semantics;Database languages;digital humanities;Graph search;graph query language;multidimensional data;attribute relationship graphs;multivariate data analysis;higher-order conjunctive queries;visual query language","Visual analytics;Data analysis;Data visualization;Marine vehicles;Semantics;Database languages","data analysis;data visualisation;query processing","visual analysis;higher-order conjunctive relationships;multidimensional data analysis;hypergraph query system;visual exploration;binary conjunctive relationships;attribute relationship graph;visual querying systems;conjunctive interdimensional relationships;conjunctive intradimensional relationships;query specification;digital humanities;query expressiveness;cross-filtering","Algorithms;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Theoretical;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface","12","","30","","16 Oct 2013","","","IEEE","IEEE Journals"
"iStoryline: Effective Convergence to Hand-drawn Storylines","T. Tang; S. Rubab; J. Lai; W. Cui; L. Yu; Y. Wu","State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies; State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies; State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies; Microsoft Research; Bernoulli Institute, University of Groningen, Netherlands; State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","769","778","Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes 1) how artists utilize narrative elements and 2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations.","1941-0506","","10.1109/TVCG.2018.2864899","National Key R&D Program of China(grant numbers:2018YFB1004300); NSFC(grant numbers:61761136020,61502416,61502132); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:U1609217); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); 100 Talents Program of Zhejiang University; Microsoft Research Asia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440828","Hand-drawn illustrations;automatic layout;design space;interactions;optimization","Visualization;Layout;Tools;Motion pictures;Optimization methods;Guidelines","data visualisation;interactive systems;optimisation","hand-drawn storyline;storyline visualization techniques;optimization goals;narrative contexts;iStoryline;user interactions;authoring tool;high-level user interactions;optimization algorithms","","12","","44","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"A Graph-Based Interface for VisualAnalytics of 3D Streamlines and Pathlines","J. Ma; C. Wang; C. -K. Shene; J. Jiang","Department of Computer Science , Michigan Technological University, 1400 Townsend Drive, Houghton; Department of Computer Science , Michigan Technological University, 1400 Townsend Drive, Houghton; Department of Computer Science , Michigan Technological University, 1400 Townsend Drive, Houghton; Department of Biomedical Engineering , Michigan Technological University, 1400 Townsend Drive, Houghton","IEEE Transactions on Visualization and Computer Graphics","1 Jul 2014","2014","20","8","1127","1140","Visual exploration of large and complex 3D steady and unsteady flow fields is critically important in many areas of science and engineering. In this paper, we introduce FlowGraph, a novel compound graph representation that organizes field line clusters and spatiotemporal regions hierarchically for occlusion-free and controllable visual exploration. It works with any seeding strategy as long as the domain is well covered and important flow features are captured. By transforming a flow field to a graph representation, we enable observation and exploration of the relationships among field line clusters, spatiotemporal regions and their interconnection in the transformed space. FlowGraph not only provides a visual mapping that abstracts field line clusters and spatiotemporal regions in various levels of detail, but also serves as a navigation tool that guides flow field exploration and understanding. Through brushing and linking in conjunction with the standard field line view, we demonstrate the effectiveness of FlowGraph with several visual exploration and comparison tasks that cannot be well accomplished using the field line view alone. We also perform an empirical expert evaluation to confirm the usefulness of this graph-based technique.","1941-0506","","10.1109/TVCG.2013.236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613495","Flow visualization;streamlines;pathlines;graph representation;visual interface;visual analytics","Layout;Three-dimensional displays;Visualization;Spatiotemporal phenomena;Data visualization;Vectors;Context","computational geometry;data visualisation;graph theory;graphical user interfaces","graph-based interface;visual analytics;3D streamlines;3D pathlines;visual exploration;large-complex 3D steady flow field;large-complex 3D unsteady flow field;FlowGraph;compound graph representation;field line cluster organization;hierarchical spatiotemporal regions;hierarchical field line cluster organization;seeding strategy;visual mapping;navigation tool;empirical expert evaluation;spatiotemporal regions","","11","","30","IEEE","27 Sep 2013","","","IEEE","IEEE Journals"
"A Multi-Level Cache Model for Run-Time Optimization of Remote Visualization","R. Sisneros; C. Jones; J. Huang; J. Gao; B. -H. Park; N. Samatova","Univ. of Tennessee, Knoxville; NA; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","23 Jul 2007","2007","13","5","991","1003","Remote visualization is an enabling technology aiming to resolve the barrier of physical distance. Although many researchers have developed innovative algorithms for remote visualization, previous work has focused little on systematically investigating optimal configurations of remote visualization architectures. In this paper, we study caching and prefetching, an important aspect of such architecture design, in order to optimize the fetch time in a remote visualization system. Unlike a processor cache or Web cache, caching for remote visualization is unique and complex. Through actual experimentation and numerical simulation, we have discovered ways to systematically evaluate and search for optimal configurations of remote visualization caches under various scenarios, such as different network speeds, sizes of data for user requests, prefetch schemes, cache depletion schemes, etc. We have also designed a practical infrastructure software to adaptively optimize the caching architecture of general remote visualization systems, when a different application is started or the network condition varies. The lower bound of achievable latency discovered with our approach can aid the design of remote visualization algorithms and the selection of suitable network layouts for a remote visualization system.","1941-0506","","10.1109/TVCG.2007.1046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4276079","Remote visualization;distributed visualization;performance analysis;caching","Runtime;Delay;Data visualization;Numerical simulation;Prefetching;Design optimization;Application software;Switches;Computer architecture;Algorithm design and analysis","cache storage;data visualisation","distributed visualization;Web cache;prefetching;caching;remote visualization;runtime optimization;multilevel cache model","Algorithms;Computer Communication Networks;Computer Graphics;Computer Simulation;Computer Systems;Data Compression;Image Enhancement;Image Interpretation, Computer-Assisted;Models, Theoretical;Numerical Analysis, Computer-Assisted;Signal Processing, Computer-Assisted;Time Factors;User-Computer Interface","11","","21","","23 Jul 2007","","","IEEE","IEEE Journals"
"A practical approach to spectral volume rendering","S. Bergner; T. Moller; M. Tory; M. S. Drew","Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada; NA; NA","IEEE Transactions on Visualization and Computer Graphics","31 Jan 2005","2005","11","2","207","216","To make a spectral representation of color practicable for volume rendering, a new low-dimensional subspace method is used to act as the carrier of spectral information. With that model, spectral light material interaction can be integrated into existing volume rendering methods at almost no penalty. In addition, slow rendering methods can profit from the new technique of postillumination-generating spectral images in real-time for arbitrary light spectra under a fixed viewpoint. Thus, the capability of spectral rendering to create distinct impressions of a scene under different lighting conditions is established as a method of real-time interaction. Although we use an achromatic opacity in our rendering, we show how spectral rendering permits different data set features to be emphasized or hidden as long as they have not been entirely obscured. The use of postillumination is an order of magnitude faster than changing the transfer function and repeating the projection step. To put the user in control of the spectral visualization, we devise a new widget, a ""light-dial"", for interactively changing the illumination and include a usability study of this new light space exploration tool. Applied to spectral transfer functions, different lights bring out or hide specific qualities of the data. In conjunction with postillumination, this provides a new means for preparing data for visualization and forms a new degree of freedom for guided exploration of volumetric data sets","1941-0506","","10.1109/TVCG.2005.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1388231","Index Terms- Volume rendering;real-time spectral computer graphics.","Rendering (computer graphics);Transfer functions;Layout;Data visualization;Lighting control;Usability;Space exploration;Computer graphics;Composite materials;Visual effects","data visualisation;image colour analysis;image representation;real-time systems;rendering (computer graphics);spectral analysis","spectral volume rendering;spectral color representation;spectral light material interaction;postillumination-generating spectral images;real-time system;achromatic opacity;rendering;transfer function;spectral visualization","Algorithms;Color;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Online Systems;Pattern Recognition, Automated;Photometry;Software;User-Computer Interface","11","","23","","31 Jan 2005","","","IEEE","IEEE Journals"
"ARC: Alignment-based Redirection Controller for Redirected Walking in Complex Environments","N. L. Williams; A. Bera; D. Manocha","University of Maryland, College Park, USA; University of Maryland, College Park, USA; University of Maryland, College Park, USA","IEEE Transactions on Visualization and Computer Graphics","15 Apr 2021","2021","27","5","2535","2544","We present a novel redirected walking controller based on alignment that allows the user to explore large and complex virtual environments, while minimizing the number of collisions with obstacles in the physical environment. Our alignment-based redirection controller, ARC, steers the user such that their proximity to obstacles in the physical environment matches the proximity to obstacles in the virtual environment as closely as possible. To quantify a controller's performance in complex environments, we introduce a new metric, Complexity Ratio (CR), to measure the relative environment complexity and characterize the difference in navigational complexity between the physical and virtual environments. Through extensive simulation-based experiments, we show that ARC significantly outperforms current state-of-the-art controllers in its ability to steer the user on a collision-free path. We also show through quantitative and qualitative measures of performance that our controller is robust in complex environments with many obstacles. Our method is applicable to arbitrary environments and operates without any user input or parameter tweaking, aside from the layout of the environments. We have implemented our algorithm on the Oculus Quest head-mounted display and evaluated its performance in environments with varying complexity. Our project website is available at https://ganuna.umd.edu/arc/.","1941-0506","","10.1109/TVCG.2021.3067781","ARO(grant numbers:W911NF1910069,W911NF1910315); Intel; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382909","Virtual Reality;Locomotion;Redirected Walking;Redirection Controllers;Steering Algorithms;Alignment","Complexity theory;Legged locomotion;Trajectory;Virtual environments;Measurement;Prediction algorithms;Navigation","collision avoidance;helmet mounted displays;virtual reality","ARC;complex environments;arbitrary environments;Oculus Quest head-mounted display;performance evaluation;qualitative measure;quantitative measure;obstacle collision;extensive simulation-based experiments;physical environments;navigational complexity;relative environment complexity;complexity ratio;virtual environment;physical environment;complex virtual environments;redirected walking controller;alignment-based redirection controller","","11","","43","IEEE","22 Mar 2021","","","IEEE","IEEE Journals"
"An Exploratory Framework for Cyclone Identification and Tracking","A. A. Valsangkar; J. M. Monteiro; V. Narayanan; I. Hotz; V. Natarajan","Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Department of Meteorology, Stockholm University, Stockholm, Sweden; Computer Science Department, Carnegie Mellon University, Pittsburgh, PA; Department of Science and Technology, Linkoping University, Linkoping, Sweden; Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2019","2019","25","3","1460","1473","Analyzing depressions plays an important role in meteorology, especially in the study of cyclones. In particular, the study of the temporal evolution of cyclones requires a robust depression tracking framework. To cope with this demand we propose a pipeline for the exploration of cyclones and their temporal evolution. This entails a generic framework for their identification and tracking. The fact that depressions and cyclones are not well-defined objects and their shape and size characteristics change over time makes this task especially challenging. Our method combines the robustness of topological approaches and the detailed tracking information from optical flow analysis. At first cyclones are identified within each time step based on well-established topological concepts. Then candidate tracks are computed from an optical flow field. These tracks are clustered within a moving time window to distill dominant coherent cyclone movements, which are then forwarded to a final tracking step. In contrast to previous methods our method requires only a few intuitive parameters. An integration into an exploratory framework helps in the study of cyclone movement by identifying smooth, representative tracks. Multiple case studies demonstrate the effectiveness of the method in tracking cyclones, both in the northern and southern hemisphere.","1941-0506","","10.1109/TVCG.2018.2810068","Department of Science and Technology, India(grant numbers:DST/SJF/ETA-02/2015-16); Indian Institute of Science(grant numbers:JATP/RG/PROJ/2015/16); Swedish e-Science Research Center (SeRC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8303701","Cyclone;scalar field;time-varying data;track graph;spatio-temporal clustering;tracking","Cyclones;Tracking;Meteorology;Object tracking;Image sequences;Storms","atmospheric movements;image sequences;object tracking;storms;topology","candidate tracks;dominant coherent cyclone movements;final tracking step;exploratory framework;cyclone movement;smooth tracks;cyclone identification;temporal evolution;robust depression tracking framework;generic framework;detailed tracking information;depression analysis","","11","","29","IEEE","27 Feb 2018","","","IEEE","IEEE Journals"
"An attempt for coloring multichannel MR imaging data","S. Muraki; T. Nakai; Y. Kita; K. Tsuda","Nat. Inst. of Adv. Ind. Sci. & Technol., Tsukuba, Japan; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2001","7","3","265","274","This is an elementary research into assigning color values to voxels of multi-channel magnetic resonance imaging (MRI) volume data. The MRI volume data sets obtained under different scanning conditions are transformed into components by independent component analysis (ICA), which enhances the physical characteristics of the tissue. The transfer functions for generating color values from the independent components are obtained by using a radial basis function network, a kind of neural net, by training the network with sample data chosen from the Visible Human female data set (VHF). The resultant color volume data sets correspond well with the full-color cross-sections of the Visible Human data sets.","1941-0506","","10.1109/2945.942694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=942694","","Magnetic resonance imaging;Transfer functions;Independent component analysis;Humans;Surgery;Biomedical imaging;Medical diagnostic imaging;Radial basis function networks;Endoscopes;Medical simulation","image colour analysis;transfer function matrices;radial basis function networks;learning by example;biomedical MRI;medical image processing","multi-channel magnetic resonance imaging data;voxel colour value assignment;MRI volume data sets;scanning conditions;independent component analysis;tissue physical characteristics;image enhancement;transfer functions;radial basis function network;neural net training;Visible Human female data set;full-colour cross-sections","","11","1","27","IEEE","7 Aug 2002","","","IEEE","IEEE Journals"
"Analyzing Dynamic Hypergraphs with Parallel Aggregated Ordered Hypergraph Visualization","P. Valdivia; P. Buono; C. Plaisant; N. Dufournaud; J. -D. Fekete","Inria, Saclay, France; University of Bari, Italy; University of Maryland, USA; École des Hautes Études en Sciences Sociales, Paris, France; Inria, Saclay, France","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","1","13","Parallel Aggregated Ordered Hypergraph(PAOH) is a novel technique to visualize dynamic hypergraphs. Hypergraphs are a generalization of graphs where edges can connect several vertices. Hypergraphs can be used to model networks of business partners or co-authorship networks with multiple authors per article. A dynamic hypergraph evolves over discrete time slots. PAOH represents vertices as parallel horizontal bars and hyperedges as vertical lines, using dots to depict the connections to one or more vertices. We describe a prototype implementation of Parallel Aggregated Ordered Hypergraph, report on a usability study with 9 participants analyzing publication data, and summarize the improvements made. Two case studies and several examples are provided. We believe that PAOH is the first technique to provide a highly readable representation of dynamic hypergraphs. It is easy to learn and well suited for medium size dynamic hypergraphs (50-500 vertices) such as those commonly generated by digital humanities projects-our driving application domain.","1941-0506","","10.1109/TVCG.2019.2933196","CHIST-ERA(grant numbers:20CH21_174081); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789484","dynamic graph;interaction;case study;dynamic hypergraph;digital humanities;usability ","Visualization;Contracts;Motion pictures;Usability;Topology;Computational modeling","data analysis;data visualisation;graph theory;network theory (graphs)","business partner networks;co-authorship networks;publication data analysis;dots;PAOH visualization;dynamic hypergraph visualization;parallel aggregated ordered hypergraph visualization;dynamic hypergraph analysis;hyperedges;parallel horizontal bars","","11","","50","IEEE","6 Aug 2019","","","IEEE","IEEE Journals"
"Chromium Renderserver: Scalable and Open Remote Rendering Infrastructure","B. Paul; S. Ahern; W. Bethel; E. Brugger; R. Cook; J. Daniel; K. Lewis; J. Owen; D. Southard","Tungsten Graphics, Inc., Steamboat Springs; NA; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2008","2008","14","3","627","639","Chromium Renderserver (CRRS) is software infrastruc-ture that provides the ability for one or more users to run and view image output from unmodified, interactive OpenGL and X11 applications on a remote, parallel computational platform equipped with graphics hardware accelerators via industry-standard Layer 7 network proto-cols and client viewers. The new contributions of this work include a solution to the problem of synchronizing X11 and OpenGL command streams, remote delivery of parallel hardware accelerated rendering, and a performance anal-ysis of several different optimizations that are generally applicable to a variety of rendering architectures. CRRS is fully operational, Open Source software. imagery and sending it to a remote viewer.","1941-0506","","10.1109/TVCG.2007.70631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4459319","remote visualization;remote rendering;parallel rendering;virtual network computer;collaborative visualization;distance visualization;remote visualization;remote rendering;parallel rendering;virtual network computer;collaborative visualization;distance visualization","Chromium;Rendering (computer graphics);Application software;Computer networks;Concurrent computing;Graphics;Hardware;Computer industry;Protocols;Streaming media","parallel processing;public domain software;rendering (computer graphics);software architecture","chromium renderserver;open remote rendering infrastructure;scalable remote rendering infrastructure;software infrastructure;interactive OpenGL;remote parallel computational platform;graphics hardware accelerators;industry-standard layer-7 network protocols;client viewers;rendering architectures;open source software","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Internet;Signal Processing, Computer-Assisted;Software","11","9","21","IEEE","3 Mar 2008","","","IEEE","IEEE Journals"
"Data streaming in telepresence environments","E. Lamboray; S. Wurmlin; M. Gross","Cyfex AG, Zurich, Switzerland; NA; NA","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","637","648","In this paper, we discuss data transmission in telepresence environments for collaborative virtual reality applications. We analyze data streams in the context of networked virtual environments and classify them according to their traffic characteristics. Special emphasis is put on geometry-enhanced (3D) video. We review architectures for real-time 3D video pipelines and derive theoretical bounds on the minimal system latency as a function of the transmission and processing delays. Furthermore, we discuss bandwidth issues of differential update coding for 3D video. In our telepresence system - the blue-c - we use a point-based 3D video technology which allows for differentially encoded 3D representations of human users. While we discuss the considerations which lead to the design of our three-stage 3D video pipeline, we also elucidate some critical implementation details regarding decoupling of acquisition, processing and rendering frame rates, and audio/video synchronization. Finally, we demonstrate the communication and networking features of the blue-c system in its full deployment. We show how the system can possibly be controlled to face processing or networking bottlenecks by adapting the multiple system components like audio, application data, and 3D video.","1941-0506","","10.1109/TVCG.2005.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512015","Index Terms- Computer conferencing;teleconferencing;and videoconferencing;distributed/network graphics;three-dimensional graphics and realism.","Streaming media;Pipelines;Delay;Data communication;Collaboration;Virtual reality;Data analysis;Virtual environment;Telecommunication traffic;Real time systems","video coding;teleconferencing;virtual reality;real-time systems;image representation;synchronisation;rendering (computer graphics);face recognition;groupware;video streaming","data streaming;telepresence environment;data transmission;collaborative virtual reality application;geometry-enhanced 3D video;real-time 3D video pipeline;minimal system latency;delays;3D video coding;telepresence system;3D graphics representation;audio video synchronization;face processing;computer conferencing;teleconferencing;videoconferencing;distributed network graphics","Computer Communication Networks;Computer Simulation;Computer Systems;Data Display;Environment;Humans;Imaging, Three-Dimensional;Information Storage and Retrieval;Online Systems;Signal Processing, Computer-Assisted;User-Computer Interface;Video Recording","11","","19","","26 Sep 2005","","","IEEE","IEEE Journals"
"Dealing with Multiple Requirements in Geometric Arrangements","E. Gomez-Nieto; W. Casaca; D. Motta; I. Hartmann; G. Taubin; L. G. Nonato","Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil; Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil; Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil; Universidade Estadual de Rio de Janeiro, Rio de Janeiro, Brazil; Brown University, School of Engineering, Providence; Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil","IEEE Transactions on Visualization and Computer Graphics","27 Jan 2016","2016","22","3","1223","1235","Existing algorithms for building layouts from geometric primitives are typically designed to cope with requirements such as orthogonal alignment, overlap removal, optimal area usage, hierarchical organization, among others. However, most techniques are able to tackle just a few of those requirements simultaneously, impairing their use and flexibility. In this work we propose a novel methodology for building layouts from geometric primitives that concurrently addresses a wider range of requirements. Relying on multidimensional projection and mixed integer optimization, our approach arranges geometric objects in the visual space so as to generate well structured layouts that preserve the semantic relation among objects while still making an efficient use of display area. Moreover, scalability is handled through a hierarchical representation scheme combined with navigation tools. A comprehensive set of quantitative comparisons against existing geometry-based layouts and applications on text, image, and video data set visualization prove the effectiveness of our approach.","1941-0506","","10.1109/TVCG.2015.2489660","FAPESP(grant numbers:#2011/22749-8,#2013/00191-0,#2014/16857-0); CNPq(grant numbers:#302643/2013-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296669","Overlap Removal;Similarity Preserving;Structured Layouts;Area Optimization;Overlap removal;similarity preserving;structured layouts;area optimization","Layout;Visualization;Optimization;Data visualization;Semantics;Scalability;Buildings","computational geometry;integer programming","geometric arrangements;geometric primitives;multidimensional projection;mixed integer optimization;visual space;hierarchical representation scheme;navigation tools;geometry-based structured layouts","","11","","44","IEEE","12 Oct 2015","","","IEEE","IEEE Journals"
"DeepOrganNet: On-the-Fly Reconstruction and Visualization of 3D / 4D Lung Models from Single-View Projections by Deep Deformation Network","Y. Wang; Z. Zhong; J. Hua","Department of Computer Science, Wayne State University, Detroit, MI; Department of Computer Science, Wayne State University, Detroit, MI; Department of Computer Science, Wayne State University, Detroit, MI","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","960","970","This paper introduces a deep neural network based method, i.e., DeepOrganNet, to generate and visualize fully high-fidelity 3D / 4D organ geometric models from single-view medical images with complicated background in real time. Traditional 3D / 4D medical image reconstruction requires near hundreds of projections, which cost insufferable computational time and deliver undesirable high imaging / radiation dose to human subjects. Moreover, it always needs further notorious processes to segment or extract the accurate 3D organ models subsequently. The computational time and imaging dose can be reduced by decreasing the number of projections, but the reconstructed image quality is degraded accordingly. To our knowledge, there is no method directly and explicitly reconstructing multiple 3D organ meshes from a single 2D medical grayscale image on the fly. Given single-view 2D medical images, e.g., 3D / 4D-CT projections or X-ray images, our end-to-end DeepOrganNet framework can efficiently and effectively reconstruct 3D / 4D lung models with a variety of geometric shapes by learning the smooth deformation fields from multiple templates based on a trivariate tensor-product deformation technique, leveraging an informative latent descriptor extracted from input 2D images. The proposed method can guarantee to generate high-quality and high-fidelity manifold meshes for 3D / 4D lung models; while, all current deep learning based approaches on the shape reconstruction from a single image cannot. The major contributions of this work are to accurately reconstruct the 3D organ shapes from 2D single-view projection, significantly improve the procedure time to allow on-the-fly visualization, and dramatically reduce the imaging dose for human subjects. Experimental results are evaluated and compared with the traditional reconstruction method and the state-of-the-art in deep learning, by using extensive 3D and 4D examples, including both synthetic phantom and real patient datasets. The efficiency of the proposed method shows that it only needs several milliseconds to generate organ meshes with 10K vertices, which has great potential to be used in real-time image guided radiation therapy (IGRT).","1941-0506","","10.1109/TVCG.2019.2934369","NSF(grant numbers:IIS-1816511,CNS-1647200,OAC-1657364,OAC-1845962,OAC-1910469); Wayne State University Subaward(grant numbers:4207299A,CNS-1821962,NIH 1R56AG060822-01A1,NIH 1R44HL145826-01A1,ZJNSF LZ16F020002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809843","Deep deformation network;organ meshes;3D / 4D shapes;2D projections;single-view","Three-dimensional displays;Image reconstruction;Shape;Strain;Solid modeling;Biomedical imaging;Two dimensional displays","computer graphics;computerised tomography;image reconstruction;image resolution;image segmentation;learning (artificial intelligence);lung;medical image processing;phantoms;radiation therapy","accurate 3D organ models;imaging dose;reconstructed image quality;organ meshes;single 2D medical grayscale image;4D-CT projections;X-ray images;end-to-end DeepOrganNet framework;input 2D images;shape reconstruction;single image;3D organ shapes;2D single-view projection;traditional reconstruction method;real-time image;single-view projections;deep deformation network;deep neural network based method;single-view medical images;insufferable computational time;temperature 10.0 K","Algorithms;Cone-Beam Computed Tomography;Deep Learning;Humans;Imaging, Three-Dimensional;Lung;Lung Neoplasms;Neural Networks, Computer;Phantoms, Imaging","11","","54","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"Detecting 3D Points of Interest Using Multiple Features and Stacked Auto-encoder","Z. Shu; S. Xin; X. Xu; L. Liu; L. Kavan","School of Computer and Data Engineering, Ningbo Institute of Technology, Zhejiang University, Ningbo, PR China; School of Computer Science and Technology, ShanDong University, Jinan, PR China; School of Information Science and Engineering, Ningbo University, Ningbo, PR China; Graphics & Geometric Computing Laboratory, School of Mathematical Sciences, University of Science and Technology of China, Anhui, PR China; School of Computing, University of Utah, Salt Lake City, UT, USA","IEEE Transactions on Visualization and Computer Graphics","1 Jul 2019","2019","25","8","2583","2596","Considering the fact that points of interest on 3D shapes can be discriminated from a geometric perspective, it is reasonable to map the geometric signature of a point p to a probability value encoding to what degree p is a point of interest, especially for a specific class of 3D shapes. Based on the observation, we propose a three-phase algorithm for learning and predicting points of interest on 3D shapes by using multiple feature descriptors. Our algorithm requires two separate deep neural networks (stacked auto-encoders) to accomplish the task. During the first phase, we predict the membership of the given 3D shape according to a set of geometric descriptors using a deep neural network. After that, we train the other deep neural network to predict a probability distribution defined on the surface representing the possibility of a point being a point of interest. Finally, we use a manifold clustering technique to extract a set of points of interest as the output. Experimental results show superior detection performance of the proposed method over the previous state-of-the-art approaches.","1941-0506","","10.1109/TVCG.2018.2848628","National Natural Science Foundation of China(grant numbers:11226328,61672482,11626253,61772016,61572022); National Science Foundation(grant numbers:IIS-1617172,IIS-1622360); Natural Science Foundation of Zhejiang Province(grant numbers:LY17F020018); Ningbo Leader and Top-notch Talent Training Project; Fundamental Research Funds of Shandong University; Zhejiang University(grant numbers:A1702); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388294","3D shapes;point of interest;multiple features;stacked auto-encoder","Shape;Three-dimensional displays;Neural networks;Feature extraction;Prediction algorithms;Solid modeling;Task analysis","feature extraction;learning (artificial intelligence);neural nets;pattern clustering;probability;solid modelling","multiple features;auto-encoder;geometric signature;probability value;three-phase algorithm;multiple feature descriptors;stacked auto-encoders;geometric descriptors;deep neural network;deep neural networks;3D points of interest detection;predicting points learning;manifold clustering technique","","11","","72","IEEE","19 Jun 2018","","","IEEE","IEEE Journals"
"Drawing Road Networks with Mental Maps","S. Lin; C. Lin; Y. Hu; T. Lee","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Geomatics, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan","IEEE Transactions on Visualization and Computer Graphics","24 Jul 2014","2014","20","9","1241","1252","Tourist and destination maps are thematic maps designed to represent specific themes in maps. The road network topologies in these maps are generally more important than the geometric accuracy of roads. A road network warping method is proposed to facilitate map generation and improve theme representation in maps. The basic idea is deforming a road network to meet a user-specified mental map while an optimization process is performed to propagate distortions originating from road network warping. To generate a map, the proposed method includes algorithms for estimating road significance and for deforming a road network according to various geometric and aesthetic constraints. The proposed method can produce an iconic mark of a theme from a road network and meet a user-specified mental map. Therefore, the resulting map can serve as a tourist or destination map that not only provides visual aids for route planning and navigation tasks, but also visually emphasizes the presentation of a theme in a map for the purpose of advertising. In the experiments, the demonstrations of map generations show that our method enables map generation systems to generate deformed tourist and destination maps efficiently.","1941-0506","","10.1109/TVCG.2014.2312010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774478","Map generation;mesh warping;information visualization","Roads;Shape;Optimization;Navigation;Visualization;Network topology;Distortion measurement","advertising;cartography;optimisation","road network drawing;mental maps;tourist maps;destination maps;thematic maps;road network topologies;road network warping method;map generation;optimization process;geometric constraints;aesthetic constraints;route planning;navigation tasks;advertising","","11","","31","IEEE","17 Mar 2014","","","IEEE","IEEE Journals"
"Error and complexity of random walk Monte Carlo radiosity","M. Sbert","Departament d'Inf. i Matematica Aplicada, Girona Univ., Spain","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1997","3","1","23","38","The author studies the error and complexity of the discrete random walk Monte Carlo technique for radiosity, using both the shooting and gathering methods. The author shows that the shooting method exhibits a lower complexity than the gathering one, and under some constraints, it has a linear complexity. This is an improvement over a previous result that pointed to an O(n log n) complexity. The author gives and compares three unbiased estimators for each method, and obtains closed forms and bounds for their variances. The author also bounds the expected value of the mean square error (MSE). Some of the results obtained are also shown to be valid for the nondiscrete gathering case. The author also gives bounds for the variances and MSE for the infinite path length estimators; these bounds might be useful in the study of biased estimators resulting from cutting off the infinite path.","1941-0506","","10.1109/2945.582339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=582339","","Monte Carlo methods;Integral equations;Computer errors;Mean square error methods;Layout;Computer Society;Area measurement;Noise measurement;Costs","Monte Carlo methods;brightness;computational complexity;random processes;rendering (computer graphics);error analysis","random walk Monte Carlo radiosity;error;complexity;discrete random walk Monte Carlo technique;shooting method;gathering method;unbiased estimators;closed forms;variance bounds;mean square error;nondiscrete gathering case;infinite path length estimators;rendering","","11","","20","","6 Aug 2002","","","IEEE","IEEE Journals"
"Graph Drawing by Stochastic Gradient Descent","J. X. Zheng; S. Pawar; D. F. M. Goodman","Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom; Department of Life Sciences, Imperial College London, Ascot, United Kingdom; Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2019","2019","25","9","2738","2748","A popular method of force-directed graph drawing is multidimensional scaling using graph-theoretic distances as input. We present an algorithm to minimize its energy function, known as stress, by using stochastic gradient descent (SGD) to move a single pair of vertices at a time. Our results show that SGD can reach lower stress levels faster and more consistently than majorization, without needing help from a good initialization. We then show how the unique properties of SGD make it easier to produce constrained layouts than previous approaches. We also show how SGD can be directly applied within the sparse stress approximation of Ortmann et al. [1], making the algorithm scalable up to large graphs.","1941-0506","","10.1109/TVCG.2018.2859997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419285","Graph drawing;multidimensional scaling;constraints;relaxation;stochastic gradient descent","Stress;Layout;Schedules;Annealing;Mathematical model;Standards;Approximation algorithms","directed graphs;gradient methods;minimisation;stochastic processes","force-directed graph drawing;multidimensional scaling;graph-theoretic distances;stochastic gradient descent;SGD;sparse stress approximation;energy function minimization;stress levels","","11","","34","IEEE","25 Jul 2018","","","IEEE","IEEE Journals"
"Hand Motion Prediction for Distributed Virtual Environments","A. Chan; R. Lau; L. Li","Durham Univ., Durham; Durham Univ., Durham; Durham Univ., Durham","IEEE Transactions on Visualization and Computer Graphics","19 Nov 2007","2008","14","1","146","159","We use our hands to manipulate objects in our daily life. The hand is capable of accomplishing diverse tasks such as pointing, gripping, twisting, and tearing. However, there is not much work that considers using the hand as input in distributed virtual environments (DVEs), in particular, over the Internet. The main reasons are that the Internet suffers from high network latency, which affects interaction, and the hand has many degrees of freedom, which adds additional challenges to synchronizing the collaboration. In this paper, we propose a prediction method specifically designed for human hand motion to address the network latency problem in DVEs. Through a thorough analysis of finger motion, we have identified various finger motion constraints, and we propose a constraint-based motion prediction method for hand motion. To reduce the average prediction error under high network latency, for example, over the Internet, we further propose a revised dead-reckoning scheme here. Our performance results show that the proposed prediction method produces a lower prediction error than some popular methods, and the revised dead-reckoning scheme produces a lower average prediction error than the traditional dead-reckoning scheme, particularly at high network latency.","1941-0506","","10.1109/TVCG.2007.1056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359479","Motion Prediction;hand motion prediction;hand interaction;network latency;Motion Prediction;hand motion prediction;hand interaction;network latency","Virtual environment;Delay;Motion analysis;Prediction methods;IP networks;Fingers;Internet;Collaborative work;Design methodology;Humans","groupware;Internet;virtual reality","human hand motion prediction;distributed virtual environment;Internet suffering;network latency problem;finger motion analysis;constraint-based motion prediction method;collaborative design","Computer Graphics;Computer Simulation;Hand;Hand;Humans;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Internet;Models, Biological;Movement;User-Computer Interface","11","1","35","","19 Nov 2007","","","IEEE","IEEE Journals"
"Interactive Exploration of Data Traffic with Hierarchical Network Maps","F. Mansmann; S. Vinnik","Department of Computer and Information Science, University of Konstanz, Germany; Department of Computer and Information Science, University of Konstanz, Germany","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1440","1449","Network communication has become indispensable in business, education, and government. With the pervasive role of the Internet as a means of sharing information across networks, its misuse for destructive purposes, such as spreading malicious code, compromising remote hosts, or damaging data through unauthorized access, has grown immensely in the recent years. The classical way of monitoring the operation of large network systems is by analyzing the system logs for detecting anomalies. In this work, we introduce Hierarchical Network Map, an interactive visualization technique for gaining a deeper insight into network flow behavior by means of user-driven visual exploration. Our approach is meant as an enhancement to conventional analysis methods based on statistics or machine learning. We use multidimensional modeling combined with position and display awareness to view source and target data of the hosts in a hierarchical fashion with the ability to interactively change the level of aggregation or apply filtering. The interdisciplinary approach integrating data warehouse technology, information visualization, and decision support, brings about the benefit of efficiently collecting the input data and aggregating over very large data sets, visualizing the results, and providing interactivity to facilitate analytical reasoning.","1941-0506","","10.1109/TVCG.2006.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703365","Data and knowledge visualization;information visualization;visual analytics;network security.","Telecommunication traffic;Data visualization;Business communication;Government;IP networks;Remote monitoring;Statistical analysis;Machine learning;Multidimensional systems;Displays","data visualisation;data warehouses;inference mechanisms;Internet;IP networks;learning (artificial intelligence);security of data;telecommunication security;telecommunication traffic","Data and knowledge visualization;information visualization;visual analytics;network security.","Algorithms;Computer Communication Networks;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Signal Processing, Computer-Assisted;User-Computer Interface","11","2","19","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"Interactive Indirect Illumination Using Adaptive Multiresolution Splatting","G. Nichols; C. Wyman","University of Iowa, Iowa City; University of Iowa, Iowa City","IEEE Transactions on Visualization and Computer Graphics","8 Jul 2010","2010","16","5","729","741","Global illumination provides a visual richness not achievable with the direct illumination models used by most interactive applications. To generate global effects, numerous approximations attempt to reduce global illumination costs to levels feasible in interactive contexts. One such approximation, reflective shadow maps, samples a shadow map to identify secondary light sources whose contributions are splatted into eye space. This splatting introduces significant overdraw that is usually reduced by artificially shrinking each splat's radius of influence. This paper introduces a new multiresolution approach for interactively splatting indirect illumination. Instead of reducing GPU fill rate by reducing splat size, we reduce fill rate by rendering splats into a multiresolution buffer. This takes advantage of the low-frequency nature of diffuse and glossy indirect lighting, allowing rendering of indirect contributions at low resolution where lighting changes slowly and at high-resolution near discontinuities. Because this multiresolution rendering occurs on a per-splat basis, we can significantly reduce fill rate without arbitrarily clipping splat contributions below a given threshold-those regions simply are rendered at a coarse resolution.","1941-0506","","10.1109/TVCG.2009.97","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5226625","Global illumination;interactive rendering;reflective shadow maps;multiresolution splatting.","Lighting;Costs;Layout;Rendering (computer graphics);Light sources;Integral equations;Computer graphics;Optical reflection;Hemorrhaging;Geometry","light sources;rendering (computer graphics)","interactive indirect illumination;adaptive multiresolution splatting;direct illumination models;reflective shadow maps;secondary light sources;GPU fill rate;splat rendering;multiresolution buffer rendering","","11","1","40","","28 Aug 2009","","","IEEE","IEEE Journals"
"Interactive Quadrangulation with Reeb Atlases and Connectivity Textures","J. Tierny; J. Daniels II; L. G. Nonato; V. Pascucci; C. T. Silva","CNRS at Telecom ParisTech, Paris; NYU-Poly, New York City; ICMC, Universidade de São Paulo, São Carlos; University of Utah, Salt Lake City; NYU-Poly, New York City","IEEE Transactions on Visualization and Computer Graphics","9 Aug 2012","2012","18","10","1650","1663","Creating high-quality quad meshes from triangulated surfaces is a highly nontrivial task that necessitates consideration of various application specific metrics of quality. In our work, we follow the premise that automatic reconstruction techniques may not generate outputs meeting all the subjective quality expectations of the user. Instead, we put the user at the center of the process by providing a flexible, interactive approach to quadrangulation design. By combining scalar field topology and combinatorial connectivity techniques, we present a new framework, following a coarse to fine design philosophy, which allows for explicit control of the subjective quality criteria on the output quad mesh, at interactive rates. Our quadrangulation framework uses the new notion of Reeb atlas editing, to define with a small amount of interactions a coarse quadrangulation of the model, capturing the main features of the shape, with user prescribed extraordinary vertices and alignment. Fine grain tuning is easily achieved with the notion of connectivity texturing, which allows for additional extraordinary vertices specification and explicit feature alignment, to capture the high-frequency geometries. Experiments demonstrate the interactivity and flexibility of our approach, as well as its ability to generate quad meshes of arbitrary resolution with high-quality statistics, while meeting the user's own subjective requirements.","1941-0506","","10.1109/TVCG.2011.270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060817","Quadrangulation;Reeb graph;connectivity operators.","Topology;Mesh generation;Harmonic analysis;Level set;Linear systems;Electronic mail","","","","11","","47","","25 Oct 2011","","","IEEE","IEEE Journals"
"JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure","M. Labschütz; S. Bruckner; M. E. Gröller; M. Hadwiger; P. Rautek",KAUST; University of Bergen; TU Wien and VrVis Research Center; KAUST; KAUST,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","1025","1034","Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.","1941-0506","","10.1109/TVCG.2015.2467331","King Abdullah University of Science and Technology (KAUST) Visual Computing Center, and the ViMaL(grant numbers:P21695); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192686","Data Transformation and Representation;GPUs and Multi-core Architectures;Volume Rendering;Data Transformation and Representation;GPUs and Multi-core Architectures;Volume Rendering","Octrees;Graphics processing units;Arrays;Memory management;Optimization;Layout","data structures;graphics processing units;just-in-time;optimisation","memory usage;traversal overhead;optimization criteria;data access patterns;memory budget;GPU memory;just-in-time compiled sparse GPU volume data structure;JiTTree","","11","","30","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"<italic>KnowledgePearls</italic>: Provenance-Based Visualization Retrieval","H. Stitz; S. Gratzl; H. Piringer; T. Zichner; M. Streit","Johannes Kepler University, Linz, Austria; Johannes Kepler University, Linz, Austria; VRVis Research Center, Austria; Boehringer Ingelheim RCV GmbH & Co KG, Austria; Johannes Kepler University, Linz, Austria","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","120","130","Storing analytical provenance generates a knowledge base with a large potential for recalling previous results and guiding users in future analyses. However, without extensive manual creation of meta information and annotations by the users, search and retrieval of analysis states can become tedious. We present KnowledgePearls, a solution for efficient retrieval of analysis states that are structured as provenance graphs containing automatically recorded user interactions and visualizations. As a core component, we describe a visual interface for querying and exploring analysis states based on their similarity to a partial definition of a requested analysis state. Depending on the use case, this definition may be provided explicitly by the user by formulating a search query or inferred from given reference states. We explain our approach using the example of efficient retrieval of demographic analyses by Hans Rosling and discuss our implementation for a fast look-up of previous states. Our approach is independent of the underlying visualization framework. We discuss the applicability for visualizations which are based on the declarative grammar Vega and we use a Vega-based implementation of Gapminder as guiding example. We additionally present a biomedical case study to illustrate how KnowledgePearls facilitates the exploration process by recalling states from earlier analyses.","1941-0506","","10.1109/TVCG.2018.2865024","Boehringer Ingelheim Regional Center Vienna; Austrian Science Fund(grant numbers:FWF P27975-NBL); State of Upper Austria(grant numbers:FFG 851460); COMET – Competence Centers for Excellent Technologies(grant numbers:854174); BMVIT; BMWFW; Styria; Styrian Business Promotion Agency – SFG; Vienna Business Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440831","Visualization provenance;interaction provenance;retrieval","Data visualization;Visualization;Indexes;History;Database languages;Knowledge based systems;Grammar","data analysis;data visualisation;grammars;graph theory;knowledge based systems;query processing","meta information;KnowledgePearls;provenance graphs;automatically recorded user interactions;core component;visual interface;search query;demographic analyses;Vega-based implementation;provenance-based visualization retrieval;analytical provenance;knowledge base;analysis state;reference states;visualization framework;manual creation;meta annotations;declarative grammar Vega","","11","","47","CCBY","20 Aug 2018","","","IEEE","IEEE Journals"
"MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data","S. Jang; N. Elmqvist; K. Ramani","Purdue University, West Lafayette, IN, USA; University of Maryland, College Park, MD, USA; Purdue University, West Lafayette, IN, USA","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","21","30","Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.","1941-0506","","10.1109/TVCG.2015.2468292","Division of Civil, Mechanical and Manufacturing Innovation(grant numbers:1235232); CPS(grant numbers:1329979); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194831","Human motion visualization;interactive clustering;motion tracking data;expert reviews;user study;Human motion visualization;interactive clustering;motion tracking data;expert reviews;user study","Data visualization;Tracking;Pattern analysis;Visualization;Context;Layout;Three-dimensional displays","data visualisation;gesture recognition;human computer interaction;interactive systems;object tracking;pattern clustering;pose estimation;trees (mathematics)","MotionFlow;visual abstraction;sequential pattern aggregation;human motion tracking data;human motion pattern analysis;visual analytics system;interactive flow visualization;motion sequence;static pose;tree diagram;pose similarity;representative pose state;partition-based clustering process;unstructured motion data organization;pattern groups;data subset exploration;gesture-based interaction design","Cluster Analysis;Computer Graphics;Humans;Image Processing, Computer-Assisted;Movement;Pattern Recognition, Automated;Video Recording","11","3","46","IEEE","13 Aug 2015","","","IEEE","IEEE Journals"
"Mélange: Space Folding for Visual Exploration","N. Elmqvist; Y. Riche; N. Henry-Riche; J. -D. Fekete","Purdue University, West Lafayette; Independant Researcher, Seattle; Microsoft Research, Redmond; INRIA Saclay, INRIA/LRI, Paris","IEEE Transactions on Visualization and Computer Graphics","11 Mar 2010","2010","16","3","468","483","Navigating in large geometric spaces—such as maps, social networks, or long documents—typically requires a sequence of pan and zoom actions. However, this strategy is often ineffective and cumbersome, especially when trying to study and compare several distant objects. We propose a new distortion technique that folds the intervening space to guarantee visibility of multiple focus regions. The folds themselves show contextual information and support unfolding and paging interactions. We conducted a study comparing the space-folding technique to existing approaches and found that participants performed significantly better with the new technique. We also describe how to implement this distortion technique and give an in-depth case study on how to apply it to the visualization of large-scale 1D time-series data.","1941-0506","","10.1109/TVCG.2009.86","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5184829","Interaction;visualization;navigation;exploration;folding;split screen;space distortion;focus+context.","Navigation;Costs;Europe;Airports;Land transportation;Social network services;Collaboration;Feedback;Data visualization;Graphics","data visualisation;geophysical prospecting;interactive systems;navigation;time series","geometric space;maps;social networks;space folding technique;visual exploration;distortion technique;unfolding interaction;paging interaction;large scale 1D time series data;navigation","Algorithms;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Theoretical;User-Computer Interface","11","1","41","IEEE","31 Jul 2009","","","IEEE","IEEE Journals"
"Planar Visualization of Treelike Structures","J. Marino; A. Kaufman","Computer Science Department, Stony Brook University; Computer Science Department, Stony Brook University","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","906","915","We present a novel method to create planar visualizations of treelike structures (e.g., blood vessels and airway trees) where the shape of the object is well preserved, allowing for easy recognition by users familiar with the structures. Based on the extracted skeleton within the treelike object, a radial planar embedding is first obtained such that there are no self-intersections of the skeleton which would have resulted in occlusions in the final view. An optimization procedure which adjusts the angular positions of the skeleton nodes is then used to reconstruct the shape as closely as possible to the original, according to a specified view plane, which thus preserves the global geometric context of the object. Using this shape recovered embedded skeleton, the object surface is then flattened to the plane without occlusions using harmonic mapping. The boundary of the mesh is adjusted during the flattening step to account for regions where the mesh is stretched over concavities. This parameterized surface can then be used either as a map for guidance during endoluminal navigation or directly for interrogation and decision making. Depth cues are provided with a grayscale border to aid in shape understanding. Examples are presented using bronchial trees, cranial and lower limb blood vessels, and upper aorta datasets, and the results are evaluated quantitatively and with a user study.","1941-0506","","10.1109/TVCG.2015.2467413","NSF(grant numbers:CNS-0959979,IIP-1069147,CNS-1302246); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192698","Geometry-based techniques;view-dependent visualization;medical visualization;planar embedding;Geometry-based techniques;view-dependent visualization;medical visualization;planar embedding","Skeleton;Shape;Three-dimensional displays;Layout;Visualization;Blood vessels;Context","blood vessels;cardiovascular system;data visualisation;image thinning;lung;medical computing;shape recognition;trees (mathematics)","planar visualization;treelike structure;airway trees;object shape;skeleton extraction;treelike object;radial planar embedding;optimization procedure;skeleton node angular position;shape reconstruction;object global geometric context preservation;shape recovered embedded skeleton;object surface flattening;occlusions;harmonic mapping;mesh boundary;mesh stretching;surface parameterization;endoluminal navigation;decision making;depth cue;grayscale border;shape understanding;upper aorta dataset;lower limb blood vessels;cranial blood vessels;bronchial trees","Algorithms;Aorta;Bronchi;Computer Graphics;Humans;Imaging, Three-Dimensional;Pattern Recognition, Automated;Visible Human Projects","11","1","41","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Stroscope: Multi-Scale Visualization of Irregularly Measured Time-Series Data","M. Cho; B. Kim; H. -J. Bae; J. Seo","Department of Computer Science and Engineering, Seoul National University, Seoul, Korea; Department of Radiology, Seoul National University Bundang Hospital, Seongnam-si, Korea; Department of Neurology, Seoul National University Bundang Hospital, Seongnam, Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, Korea","IEEE Transactions on Visualization and Computer Graphics","17 Mar 2014","2014","20","5","808","821","For irregularly measured time-series data, the measurement frequency or interval is as crucial information as measurements are. A well-known time-series visualization such as the line graph is good at showing an overall temporal pattern of change; however, it is not so effective in revealing the measurement frequency/interval while likely giving illusory confidence in values between measurements. In contrast, the bar graph is more effective in showing the frequency/interval, but less effective in showing an overall pattern than the line graph. We integrate the line graph and bar graph in a unified visualization model, called a ripple graph, to take the benefits of both of them with enhanced graphical integrity. Based on the ripple graph, we implemented an interactive time-series data visualization tool, called Stroscope, which facilitates multi-scale visualizations by providing users with a graphical widget to interactively control the integrated visualization model. We evaluated the visualization model (i.e., the ripple graph) through a controlled user study and Stroscope through long-term case studies with neurologists exploring large blood pressure measurement data of stroke patients. Results from our evaluations demonstrate that the ripple graph outperforms existing time-series visualizations, and that Stroscope has the efficacy and potential as an effective visual analysis tool for (irregularly) measured time-series data.","1941-0506","","10.1109/TVCG.2013.2297933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702502","Irregularly measured time-series data;frequency-aware visualization;uncertainty visualization;long-term case study","Data visualization;Frequency measurement;Bars;Blood pressure;Visualization;Time measurement;Market research","blood pressure measurement;data analysis;data visualisation;graph theory;interactive systems;medical administrative data processing;time series","Stroscope;multiscale visualization;irregularly measured time-series data;measurement frequency;measurement interval;bar graph;line graph;unified visualization model;ripple graph;graphical integrity;interactive time-series data visualization tool;graphical widget;integrated visualization model;blood pressure measurement data;stroke patients;visual analysis tool","","11","","39","IEEE","9 Jan 2014","","","IEEE","IEEE Journals"
"The Subspace Voyager: Exploring High-Dimensional Data along a Continuum of Salient 3D Subspaces","B. Wang; K. Mueller","Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY; Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2017","2018","24","2","1204","1222","Analyzing high-dimensional data and finding hidden patterns is a difficult problem and has attracted numerous research efforts. Automated methods can be useful to some extent but bringing the data analyst into the loop via interactive visual tools can help the discovery process tremendously. An inherent problem in this effort is that humans lack the mental capacity to truly understand spaces exceeding three spatial dimensions. To keep within this limitation, we describe a framework that decomposes a high-dimensional data space into a continuum of generalized 3D subspaces. Analysts can then explore these 3D subspaces individually via the familiar trackball interface while using additional facilities to smoothly transition to adjacent subspaces for expanded space comprehension. Since the number of such subspaces suffers from combinatorial explosion, we provide a set of data-driven subspace selection and navigation tools which can guide users to interesting subspaces and views. A subspace trail map allows users to manage the explored subspaces, keep their bearings, and return to interesting subspaces and views. Both trackball and trail map are each embedded into a word cloud of attribute labels which aid in navigation. We demonstrate our system via several use cases in a diverse set of application areas-cluster analysis and refinement, information discovery, and supervised training of classifiers. We also report on a user study that evaluates the usability of the various interactions our system provides.","1941-0506","","10.1109/TVCG.2017.2672987","NSF(grant numbers:IIS 1527200,IIS 1117132); MSIP (Ministry of Science, ICT and Future Planning); NIPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7862917","High-dimensional data;subspace navigation;trackball;PCA;ant colony optimization1","Three-dimensional displays;Visualization;Space exploration;Two dimensional displays;Navigation;Cognition;Layout","data analysis;data mining;data visualisation;learning (artificial intelligence);pattern classification;pattern clustering","visualization;supervised classifier training;information discovery;cluster analysis;salient 3D subspace continuum;high-dimensional data analysis;interactive visual tools;data analyst;subspace voyager;subspace trail map;data-driven subspace selection;expanded space comprehension","","11","","53","IEEE","23 Feb 2017","","","IEEE","IEEE Journals"
"Toward a Design Space for Mitigating Cognitive Bias in Vis","E. Wall; J. Stasko; A. Endert",Georgia Tech; Georgia Tech; Georgia Tech,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","111","115","The use of cognitive heuristics often leads to fast and effective decisions. However, they can also systematically and predictably lead to errors known as cognitive biases. Strategies for minimizing or mitigating these biases, however, remain largely non-technological (e.g., training courses). The growing use of visual analytic (VA) tools for analysis and decision making enables a new class of bias mitigation strategies. In this work, we explore the ways in which the design of visualizations (vis) may be used to mitigate cognitive biases. We derive a design space comprised of 8 dimensions that can be manipulated to impact a user's cognitive and analytic processes and describe them through an example hiring scenario. This design space can be used to guide and inform future vis systems that may integrate cognitive processes more closely.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933611","Index Terms: Human-centered computing;Human Computer Interaction (HCI);Human-centered computing;Visualization","Decision making;Visualization;Training;Tools;Data visualization;Data analysis;Task analysis","behavioural sciences computing;cognition;data analysis;data visualisation;decision making","design space;cognitive heuristics;cognitive biases;visual analytic tools;decision making;bias mitigation strategies;cognitive processes","","11","","44","","19 Dec 2019","","","IEEE","IEEE Conferences"
"vLOD: high-fidelity walkthrough of large virtual environments","J. Chhugani; B. Purnomo; Shankar Krishnan; J. Cohen; S. Venkatasubramanian; D. S. Johnson; Subodh Kumar","Johns Hopkins Univ., Baltimore, MD, USA; Johns Hopkins Univ., Baltimore, MD, USA; NA; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","17 Jan 2005","2005","11","1","35","47","We present visibility computation and data organization algorithms that enable high-fidelity walkthroughs of large 3D geometric data sets. A novel feature of our walkthrough system is that it performs work proportional only to the required detail in visible geometry at the rendering time. To accomplish this, we use a precomputation phase that efficiently generates per cell vLOD: the geometry visible from a view-region at the right level of detail. We encode changes between neighboring cells' vLODs, which are not required to be memory resident. At the rendering time, we incrementally construct the vLOD for the current view-cell and render it. We have a small CPU and memory requirement for rendering and are able to display models with tens of millions of polygons at interactive frame rates with less than one pixel screen-space deviation and accurate visibility.","1941-0506","","10.1109/TVCG.2005.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359730","Index Terms- Interactive walkthrough;levels of detail;visibility computation;compression.","Geometry;Displays;Hardware;Graphics;Military computing;Computational modeling;Solid modeling;Layout;Virtual environment;Computer Society","computational geometry;rendering (computer graphics);data visualisation;three-dimensional displays;data compression;virtual reality;solid modelling;storage management","visibility computation;data organization algorithms;high-fidelity walkthroughs;3D geometric data sets;level of detail;vLOD;rendering;screen-space deviation","Algorithms;Computer Graphics;Computer Simulation;Database Management Systems;Databases, Factual;Environment;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Metamorphosis, Biological;Online Systems;Pattern Recognition, Automated;Signal Processing, Computer-Assisted;Subtraction Technique;User-Computer Interface","11","14","47","IEEE","17 Jan 2005","","","IEEE","IEEE Journals"
"Breadth-first ray tracing utilizing uniform spatial subdivision","K. Nakamaru; Y. Ohno","Fac. of Sci. & Technol., Keio Univ., Yokohama, Japan; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1997","3","4","316","328","Breadth-first ray tracing is based on the idea of exchanging the roles of rays and objects. For scenes with a large number of objects, it may be profitable to form a set of rays and compare each object in turn against this set. By doing so, thrashing, due to disk access, can be minimized. We present ways to combine breadth-first methods with traditional efficient algorithms, along with new schemes to minimize accessing objects stored on disk. Experimental analysis, including comparisons with depth-first ray tracing, shows that large databases can be handled efficiently with this approach.","1941-0506","","10.1109/2945.646235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=646235","","Ray tracing;Layout;Electrical capacitance tomography;Spatial databases;Robustness;Acceleration;Concrete;Computer Society;Costs;Hardware","tree searching;ray tracing;very large databases;visual databases;rendering (computer graphics)","breadth first ray tracing;uniform spatial subdivision;scenes;thrashing;disk access;object access;experimental analysis;depth first ray tracing;large databases","","10","7","23","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Effective Visualization of Short Routes","P. Degener; R. Schnabel; C. Schwartz; R. Klein",University of Bonn; University of Bonn; University of Bonn; University of Bonn,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1452","1458","In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.","1941-0506","","10.1109/TVCG.2008.124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658162","Index Terms—;Maps;Route visualization;Space deformation","Visualization;Navigation;Rendering (computer graphics);Image generation;Humans;Layout;Shape;Psychology;Computer graphics","cartography;data visualisation;realistic images;rendering (computer graphics);solid modelling","warped rendering;3D model;short route visualization;realistic image;map depiction","","10","","32","","24 Oct 2008","","","IEEE","IEEE Journals"
"GLO-STIX: Graph-Level Operations for Specifying Techniques and Interactive eXploration","C. D. Stolper; M. Kahng; Z. Lin; F. Foerster; A. Goel; J. Stasko; D. H. Chau","College of Computing, Georgia Institute of Technology; College of Computing, Georgia Institute of Technology; College of Computing, Georgia Institute of Technology; College of Computing, Georgia Institute of Technology; College of Computing, Georgia Institute of Technology; College of Computing, Georgia Institute of Technology; College of Computing, Georgia Institute of Technology","IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2320","2328","The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs.","1941-0506","","10.1109/TVCG.2014.2346444","National Science Foundation(grant numbers:IIS-1320537); National Science Foundation Graduate Research Fellowship Program(grant numbers:DGE-1148903); U.S. Army Research Office (ARO); Defense Advanced Research Projects Agency (DARPA)(grant numbers:W911NF-II-C-0088); XDATA program sponsored by the Air Force Research Laboratory (AFRL); DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875969","Graph-level operations;graph visualization;visualization technique specification;graph analysis;information visualization","Graph theory;Data visualization;Interactive systems;Semantics;Aggregates","data visualisation;graph theory;graphs","graph-level operations;interactive exploration;visual graph analysis application;network visualization technique specification;canonical graph visualization techniques;GLO-STIX prototype system","","10","","30","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"GPU-Based Ray-Casting of Spherical Functions Applied to High Angular Resolution Diffusion Imaging","M. van Almsick; T. H. J. M. Peeters; V. Prckovska; A. Vilanova; B. ter Haar Romeny","Eindhoven University of Technology, Eindhoven; Eindhoven University of Technology, Eindhoven; Eindhoven University of Technology, Eindhoven; Eindhoven University of Technology, Eindhoven; Eindhoven University of Technology, Eindhoven","IEEE Transactions on Visualization and Computer Graphics","14 Mar 2011","2011","17","5","612","625","Any sufficiently smooth, positive, real-valued function \psi : S^2 \rightarrow {\hbox{\rlap{I}\kern 2.0pt{\hbox{R}}}}^+ on a sphere S^2 can be expanded by a Laplace expansion into a sum of spherical harmonics. Given the Laplace expansion coefficients, we provide a CPU and GPU-based algorithm that renders the radial graph of \psi in a fast and efficient way by ray-casting the glyph of \psi in the fragment shader of a GPU. The proposed rendering algorithm has proven highly useful in the visualization of high angular resolution diffusion imaging (HARDI) data. Our implementation of the rendering algorithm can display simultaneously thousands of glyphs depicting the local diffusivity of water. The rendering is fast enough to allow for interactive manipulation of large HARDI data sets.","1941-0506","","10.1109/TVCG.2010.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453363","Computer graphics;viewing algorithms;three-dimensional graphics and realism;computer applications;life and medical sciences.","Image resolution;High-resolution imaging;Diffusion tensor imaging;Rendering (computer graphics);Computer graphics;Magnetic resonance imaging;Data visualization;Probability density function;Computer displays;Computer applications","computational geometry;computer graphic equipment;coprocessors;rendering (computer graphics)","GPU based ray casting;spherical functions;high angular resolution diffusion imaging;Laplace expansion;CPU based algorithm;GPU based algorithm;fragment shader;glyph ray casting;rendering algorithm;HARDI data sets","","10","","28","IEEE","22 Apr 2010","","","IEEE","IEEE Journals"
"Hierarchical Photon Mapping","B. Spencer; M. W. Jones","Swansea University, Swansea; University of Wales, Swansea","IEEE Transactions on Visualization and Computer Graphics","17 Nov 2008","2009","15","1","49","61","Photon mapping is an efficient method for producing high-quality, photorealistic images with full global illumination. In this paper we present a more accurate and efficient approach to final gathering using the photon map based upon hierarchical evaluation of the photons over each surface. We use the footprint of each gather ray to calculate the irradiance estimate area rather than deriving it from the local photon density. We then describe an efficient method for computing the irradiance from the photon map given an arbitrary estimate area. Finally, we demonstrate how the technique may be used to reduce variance and increase efficiency when sampling diffuse and glossy-specular BRDFs.","1941-0506","","10.1109/TVCG.2008.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4509430","Three-Dimensional Graphics and Realism;Raytracing;Three-Dimensional Graphics and Realism;Raytracing","Kernel;Lighting;Optical computing;Optical propagation;Ray tracing;Layout;Sampling methods;Graphics;Hardware","lighting;ray tracing","hierarchical photon mapping;photorealistic images;full global illumination;ray tracing;density estimation","Algorithms;Computer Simulation;Image Interpretation, Computer-Assisted;Light;Lighting;Models, Statistical;Photometry;Photons;Scattering, Radiation","10","4","31","","2 May 2008","","","IEEE","IEEE Journals"
"Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics","S. Oeltze; W. Freiler; R. Hillert; H. Doleisch; B. Preim; W. Schubert","Universität Magdeburg; SimVis GmbH, Vienna; University of Magdeburg; SimVis GmbH, Vienna; University of Magdeburg; University of Magdeburg","IEEE Transactions on Visualization and Computer Graphics","3 Nov 2011","2011","17","12","1882","1891","In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.","1941-0506","","10.1109/TVCG.2011.217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064951","Visual Analytics;Fluorescence Microscopy;Toponomics;Protein Interaction;Graph Visualization.","Microscopy;Fluorescence;Graphics;Three dimensional displays;Biological information theory;Image color analysis","biological tissues;biology computing;data visualisation;drugs;graph theory;interactive systems;proteins;toxicology","interactive analysis;graph-based visual analysis;high-dimensional fluorescence microscopy data;multi-parameter fluorescence microscopy data;toponomics;function protein pattern;cells;toxicology;drug development;patient-drug-interaction;advanced imaging technique;robot-driven multi-parameter fluorescence microscopy;protein clusters;interactive visual analysis;focus+context visualization;reagent bindings;graph visualization;glyphs;lymphocytes;prostate tissue","Computer Graphics;Data Interpretation, Statistical;Humans;Imaging, Three-Dimensional;Lymphocytes;Male;Microscopy, Fluorescence;Neoplasm Proteins;Prostatic Neoplasms;Proteomics","10","","38","IEEE","3 Nov 2011","","","IEEE","IEEE Journals"
"Laws of Attraction: From Perceptual Forces to Conceptual Similarity","C. Ziemkiewicz; R. Kosara",UNC Charlotte; UNC Charlotte,"IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1009","1016","Many of the pressing questions in information visualization deal with how exactly a user reads a collection of visual marks as information about relationships between entities. Previous research has suggested that people see parts of a visualization as objects, and may metaphorically interpret apparent physical relationships between these objects as suggestive of data relationships. We explored this hypothesis in detail in a series of user experiments. Inspired by the concept of implied dynamics in psychology, we first studied whether perceived gravity acting on a mark in a scatterplot can lead to errors in a participant's recall of the mark's position. The results of this study suggested that such position errors exist, but may be more strongly influenced by attraction between marks. We hypothesized that such apparent attraction may be influenced by elements used to suggest relationship between objects, such as connecting lines, grouping elements, and visual similarity. We further studied what visual elements are most likely to cause this attraction effect, and whether the elements that best predicted attraction errors were also those which suggested conceptual relationships most strongly. Our findings show a correlation between attraction errors and intuitions about relatedness, pointing towards a possible mechanism by which the perception of visual marks becomes an interpretation of data relationships.","1941-0506","","10.1109/TVCG.2010.174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613438","Perceptual cognition;visualization models;laboratory studies;cognition theory","Visualization;Gravity;Image color analysis;Layout;Joining processes;Data visualization;Dynamics","data visualisation;psychology;visual perception","laws of attraction;perceptual forces;conceptual similarity;information visualization;visual marks;data relationships;psychology;grouping elements;visual similarity;attraction effect;attraction errors","","10","","17","","28 Oct 2010","","","IEEE","IEEE Journals"
"Low-Cost Telepresence for Collaborative Virtual Environments","S. -m. Rhee; R. Ziegler; J. Park; M. Naef; M. Gross; M. -h. Kim","Visual Computing and Virtual Reality Laboratory, Department of Computer Science and Engineering, Ewha Womans University, 405-1, Ewha-SK Telecom Bldg., 11-1, Daehyun-dong, Seodaemun-gu, 120-750, Seoul, Korea; Computer Graphics Laboratory, Department of Computer Science, ETH Zurich, ETH Zentrum, IFW D 27.1, Haldeneggsteig 4, CH-8092, Zurich, Switzerland; Visual Computing and Virtual Reality Laboratory, Department of Computer Science and Engineering, Ewha Womans University, 405-1, Ewha-SK Telecom Bldg., 11-1, Daehyun-dong, Seodaemun-gu, 120-750, Seoul, Korea; Glasgow School of Art, Digital Design Studio, House for an Art Lover, 10 Dumbreck Road, Glasgow G41 5BW UK; Computer Graphics Laboratory, Department of Computer Science, ETH Zurich, ETH Zentrum, IFW D 27.1, Haldeneggsteig 4, CH-8092, Zurich, Switzerland; Visual Computing and Virtual Reality Laboratory, Department of Computer Science and Engineering/Center for Computer Graphics and Virtual Reality, Ewha Womans University, 400, Ewha-SK Telecom Bldg., 11-1, Daehyun-dong, Seodaemun-gu, 120-750, Seoul, Korea","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2007","13","1","156","166","We present a novel low-cost method for visual communication and telepresence in a CAVEtrade-like environment, relying on 2D stereo-based video avatars. The system combines a selection of proven efficient algorithms and approximations in a unique way, resulting in a convincing stereoscopic real-time representation of a remote user acquired in a spatially immersive display. The system was designed to extend existing projection systems with acquisition capabilities requiring minimal hardware modifications and cost. The system uses infrared-based image segmentation to enable concurrent acquisition and projection in an immersive environment without a static background. The system consists of two color cameras and two additional b/w cameras used for segmentation in the near-IR spectrum. There is no need for special optics as the mask and color image are merged using image-warping based on a depth estimation. The resulting stereo image stream is compressed, streamed across a network, and displayed as a frame-sequential stereo texture on a billboard in the remote virtual environment","1941-0506","","10.1109/TVCG.2007.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015406","Remote systems;segmentation;stereo;virtual reality;teleconferencing.","Collaboration;Virtual environment;Image segmentation;Cameras;Streaming media;Visual communication;Avatars;Real time systems;Displays;Hardware","avatars;groupware;image segmentation;image texture;stereo image processing","low-cost telepresence;collaborative virtual environments;visual communication;CAVE-like environment;2D stereo-based video avatars;infrared-based image segmentation;concurrent acquisition;concurrent projection;immersive environment;stereo image stream compression;frame-sequential stereo texture","Algorithms;Computer Graphics;Cooperative Behavior;Environment;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Dissemination;Information Storage and Retrieval;Reproducibility of Results;Sensitivity and Specificity;Telecommunications;User-Computer Interface","10","","27","","20 Nov 2006","","","IEEE","IEEE Journals"
"PIWI: Visually Exploring Graphs Based on Their Community Structure","J. Yang; Y. Liu; X. Zhang; X. Yuan; Y. Zhao; S. Barlowe; S. Liu","University of North Carolina at Charlotte, Charlotte; University of North Carolina at Charlotte, Charlotte; Peking University, Beijing; Peking University, Beijing; Kent State University, Kent; University of North Carolina Charlotte, Charlotte; Microsoft Research Asia, Beijing","IEEE Transactions on Visualization and Computer Graphics","5 Apr 2013","2013","19","6","1034","1047","Community structure is an important characteristic of many real networks, which shows high concentrations of edges within special groups of vertices and low concentrations between these groups. Community related graph analysis, such as discovering relationships among communities, identifying attribute-structure relationships, and selecting a large number of vertices with desired structural features and attributes, are common tasks in knowledge discovery in such networks. The clutter and the lack of interactivity often hinder efforts to apply traditional graph visualization techniques in these tasks. In this paper, we propose PIWI, a novel graph visual analytics approach to these tasks. Instead of using Node-Link Diagrams (NLDs), PIWI provides coordinated, uncluttered visualizations, and novel interactions based on graph community structure. The novel features, applicability, and limitations of this new technique have been discussed in detail. A set of case studies and preliminary user studies have been conducted with real graphs containing thousands of vertices, which provide supportive evidence about the usefulness of PIWI in community related tasks.","1941-0506","","10.1109/TVCG.2012.172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269876","Information visualization;visual analytics;graph visualization;community structure","Communities;Tag clouds;Visual analytics;Data visualization;Color;Measurement","data analysis;data mining;data visualisation;graph theory","PIWI approach;visually exploring graph;community structure;community related graph analysis;community relationship;attribute-structure relationship;knowledge discovery;graph visualization technique;graph visual analytics approach;node-link diagram;NLD;graph edge;graph vertex","","10","","39","","16 Aug 2012","","","IEEE","IEEE Journals"
"Point-Based Visualization for Large Hierarchies","H. -J. Schulz; S. Hadlak; H. Schumann","University of Rostock, Rostock; University of Rostock, Rostock; University of Rostock, Rostock","IEEE Transactions on Visualization and Computer Graphics","14 Mar 2011","2011","17","5","598","611","Space-filling layout techniques for tree representations are frequently used when the available screen space is small or the data set is large. In this paper, we propose an efficient approach to space-filling tree representations that uses mechanisms from the point-based rendering paradigm. We present helpful interaction techniques and visual cues that tie in with our layout. Additionally, we relate this new layout approach to common layout mechanisms and evaluate the new layout along the lines of a numerical evaluation using the measures of the Ink-Paper Ratio and overplotted%, and in a preliminary user study. The flexibility of the general approach is illustrated by several enhancements of the basic layout, as well as its usage within the context of two software frameworks from different application fields.","1941-0506","","10.1109/TVCG.2010.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5644519","Tree visualization;space-filling layout;point-based rendering.","Layout;Image color analysis;Pixel;Data visualization;Three dimensional displays;Web sites;Rendering (computer graphics)","data visualisation;rendering (computer graphics)","point-based visualization;space-filling layout technique;space-filling tree representation;point-based rendering paradigm;visual cues;numerical evaluation;ink-paper ratio;software framework","","10","","29","IEEE","29 Nov 2010","","","IEEE","IEEE Journals"
"Recovering Functional Mechanical Assemblies from Raw Scans","M. Lin; T. Shao; Y. Zheng; N. J. Mitra; K. Zhou","State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; ShanghaiTech University, Shanghai Shi, China; University College London, London, United Kingdom; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2018","2018","24","3","1354","1367","This paper presents a method to reconstruct a functional mechanical assembly from raw scans. Given multiple input scans of a mechanical assembly, our method first extracts the functional mechanical parts using a motion-guided, patch-based hierarchical registration and labeling algorithm. The extracted functional parts are then parameterized from the segments and their internal mechanical relations are encoded by a graph. We use a joint optimization to solve for the best geometry, placement, and orientation of each part, to obtain a final workable mechanical assembly. We demonstrated our algorithm on various types of mechanical assemblies with diverse settings and validated our output using physical fabrication.","1941-0506","","10.1109/TVCG.2017.2662238","Microsoft Research Asia; NSF of China(grant numbers:61402402,61572429,U1609215); the Fundamental Research Funds for the Central Universities; the China Young 1000 Talents Program; The ERC Starting Grant SmartGeometry(grant numbers:StG-2013335373); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7839260","3D scanning;mechanical assembly;functionality;mechanical constraints;motion","Geometry;Shape;Gears;Motion segmentation;Parametric statistics;Fabrication;Three-dimensional displays","assembling;CAD;feature extraction;geometry;image registration;image segmentation;mechanical engineering computing;optimisation","raw scans;functional mechanical parts;hierarchical registration;labeling algorithm;internal mechanical relations;functional mechanical assembly recovery;multiple input scans;workable mechanical assembly;functional part extraction;graph encoding;joint optimization;geometry;physical fabrication","","10","","36","IEEE","1 Feb 2017","","","IEEE","IEEE Journals"
"Relation-Aware Volume Exploration Pipeline","M. Chan; H. Qu; K. Chung; W. Mak; Y. Wu",The Hong Kong University of Science and Technolgoy; The Hong Kong University of Science and Technolgoy; The Hong Kong University of Science and Technolgoy; The Hong Kong University of Science and Technolgoy; The Hong Kong University of Science and Technolgoy,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1683","1690","Volume exploration is an important issue in scientific visualization. Research on volume exploration has been focused on revealing hidden structures in volumetric data. While the information of individual structures or features is useful in practice, spatial relations between structures are also important in many applications and can provide further insights into the data. In this paper, we systematically study the extraction, representation,exploration, and visualization of spatial relations in volumetric data and propose a novel relation-aware visualization pipeline for volume exploration. In our pipeline, various relations in the volume are first defined and measured using region connection calculus (RCC) and then represented using a graph interface called relation graph. With RCC and the relation graph, relation query and interactive exploration can be conducted in a comprehensive and intuitive way. The visualization process is further assisted with relation-revealing viewpoint selection and color and opacity enhancement. We also introduce a quality assessment scheme which evaluates the perception of spatial relations in the rendered images. Experiments on various datasets demonstrate the practical use of our system in exploratory visualization.","1941-0506","","10.1109/TVCG.2008.159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658191","Index Terms—;Exploratory Visualization;Relation-Based Visualization;Visualization Pipeline.","Pipelines;Rendering (computer graphics);Data visualization;Data mining;Volume measurement;Calculus;Color;Quality assessment;Data acquisition;Analytical models","data visualisation;graph theory;rendering (computer graphics)","relation-aware volume exploration pipeline;scientific visualization;volumetric data;region connection calculus;graph interface;relation graph;rendered images","","10","","28","","24 Oct 2008","","","IEEE","IEEE Journals"
"Solving the Fluid Pressure Poisson Equation Using Multigrid—Evaluation and Improvements","C. Dick; M. Rogowsky; R. Westermann","Computer Graphics and Visualization Group, Technische Universität München, Germany; Computer Graphics and Visualization Group, Technische Universität München, Germany; Computer Graphics and Visualization Group, Technische Universität München, Germany","IEEE Transactions on Visualization and Computer Graphics","20 Sep 2016","2016","22","11","2480","2492","In many numerical simulations of fluids governed by the incompressible Navier-Stokes equations, the pressure Poisson equation needs to be solved to enforce mass conservation. Multigrid solvers show excellent convergence in simple scenarios, yet they can converge slowly in domains where physically separated regions are combined at coarser scales. Moreover, existing multigrid solvers are tailored to specific discretizations of the pressure Poisson equation, and they cannot easily be adapted to other discretizations. In this paper we analyze the convergence properties of existing multigrid solvers for the pressure Poisson equation in different simulation domains, and we show how to further improve the multigrid convergence rate by using a graph-based extension to determine the coarse grid hierarchy. The proposed multigrid solver is generic in that it can be applied to different kinds of discretizations of the pressure Poisson equation, by using solely the specification of the simulation domain and pre-assembled computational stencils. We analyze the proposed solver in combination with finite difference and finite volume discretizations of the pressure Poisson equation. Our evaluations show that, despite the common assumption, multigrid schemes can exploit their potential even in the most complicated simulation scenarios, yet this behavior is obtained at the price of higher memory consumption.","1941-0506","","10.1109/TVCG.2015.2511734","European Union; ERC(grant numbers:291372); Safer-Vis—Uncertainty Visualization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364293","Fluid simulation;multigrid;convergence analysis","Mathematical model;Convergence;Computational modeling;Multigrid methods;Interpolation;Poisson equations;Topology","computational fluid dynamics;convergence of numerical methods;finite difference methods;finite volume methods;flow simulation;graph theory;Navier-Stokes equations;Poisson equation","fluid pressure Poisson equation;numerical simulations;incompressible Navier-Stokes equations;mass conservation;simulation domains;multigrid convergence rate improvement;graph-based extension;coarse grid hierarchy;generic multigrid solver;preassembled computational stencils;finite difference discretizations;finite volume discretizations","","10","","27","IEEE","23 Dec 2015","","","IEEE","IEEE Journals"
"Surface and contour-preserving origamic architecture paper pop-ups","S. N. Le; S. Leow; T. Le-Nguyen; C. Ruiz; K. Low","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore","IEEE Transactions on Visualization and Computer Graphics","19 Dec 2013","2014","20","2","276","288","Origamic architecture (OA) is a form of papercraft that involves cutting and folding a single sheet of paper to produce a 3D pop-up, and is commonly used to depict architectural structures. Because of the strict geometric and physical constraints, OA design requires considerable skill and effort. In this paper, we present a method to automatically generate an OA design that closely depicts an input 3D model. Our algorithm is guided by a novel set of geometric conditions to guarantee the foldability and stability of the generated pop-ups. The generality of the conditions allows our algorithm to generate valid pop-up structures that are previously not accounted for by other algorithms. Our method takes a novel image-domain approach to convert the input model to an OA design. It performs surface segmentation of the input model in the image domain, and carefully represents each surface with a set of parallel patches. Patches are then modified to make the entire structure foldable and stable. Visual and quantitative comparisons of results have shown our algorithm to be significantly better than the existing methods in the preservation of contours, surfaces, and volume. The designs have also been shown to more closely resemble those created by real artists.","1941-0506","","10.1109/TVCG.2013.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574851","computer art;papercraft;paper architecture;surface segmentation;shape abstraction;pop-up foldability;pop-up stability","Algorithm design and analysis;Solid modeling;Stability analysis;Shape;Computer architecture;Layout;Computational modeling","image segmentation;solid modelling","parallel patches;surface segmentation;image-domain approach;pop-up structures;geometric conditions;input 3D model;OA design;architectural structures;3D pop-up;papercraft;contour-preserving origamic architecture paper pop-ups","","10","","39","","5 Aug 2013","","","IEEE","IEEE Journals"
"TORNADO: omnistereo video imaging with rotating optics","K. Tanaka; S. Tachi","Graduate Sch. of Inf. Sci. & Technol., Tokyo Univ., Japan; Graduate Sch. of Inf. Sci. & Technol., Tokyo Univ., Japan","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","614","625","One of the key techniques for vision-based communication is omnidirectional stereo (omnistereo) imaging, in which stereoscopic images for an arbitrary horizontal direction are captured and presented according to the viewing direction of the observer. Although omnistereo models have been surveyed in several studies, few omnistereo sensors have actually been implemented. In this paper, a practical method for capturing omnistereo video sequences using rotating optics is proposed and evaluated. The rotating optics system consists of prism sheets, circular or linear polarizing films, and a hyperboloidal mirror. This system has two different modes of operation with regard to the separation of images for the left and right eyes. In the high-speed shutter mode, images are separated using postimage processing, while, in the low-speed shutter mode, the image separation is completed by optics. By capturing actual images, we confirmed the effectiveness of the methods.","1941-0506","","10.1109/TVCG.2005.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512013","Index Terms- Virtual reality;3D/stereo scene analysis;image processing;computer vision.","Tornadoes;Optical imaging;Optical films;Cameras;High speed optical techniques;Optical sensors;Image reconstruction;Layout;Photography;Stereo vision","computer vision;stereo image processing;solid modelling;image sequences;image sensors;eye;video signal processing","TORNADO;omnistereo video imaging;vision-based communication;omnidirectional stereo imaging;stereoscopic image;arbitrary horizontal direction;omnistereo sensor;omnistereo video sequence;rotating optics system;prism sheets;linear polarizing film;hyperboloidal mirror;image separation;eye;high-speed shutter mode;postimage processing;low-speed shutter mode;virtual reality;3D stereo scene analysis;image processing;computer vision","Computer Simulation;Computer Systems;Data Display;Environment;Equipment Design;Equipment Failure Analysis;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Online Systems;Optics;Photogrammetry;Photogrammetry;User-Computer Interface;Video Recording;Video Recording","10","2","20","","26 Sep 2005","","","IEEE","IEEE Journals"
"Tabletop Computed Lighting for Practical Digital Photography","A. Mohan; R. Bailey; J. Waite; J. Tumblin; C. Grimm; B. Bodenheimer","Department of Electrical Engineering and Computer Science, Northwestern University, 3.320 Ford Design Center, 2133 Sheridan Road, Evanston, IL 60208; Department of Computer Science and Engineering, Washington University in St. Louis, Campus Box 1045, One Brookings Drive, St. Louis, MO 63130; Department of Electrical Engineering and Computer Science, Vanderbilt University, VU Station B #351679, 2301 Vanderbilt Place, Nashville, TN 37235; Department of Electrical Engineering and Computer Science, Northwestern University, 3.320 Ford Design Center, 2133 Sheridan Road, Evanston, IL 60208; Department of Computer Science and Engineering, Washington University in St. Louis, Campus Box 1045, One Brookings Drive, St. Louis, MO 63130; Department of Electrical Engineering and Computer Science, Vanderbilt University, VU Station B #351679, 2301 Vanderbilt Place, Nashville, TN 37235","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","652","662","We apply simplified image-based lighting methods to reduce the equipment, cost, time, and specialized skills required for high-quality photographic lighting of desktop-sized static objects such as museum artifacts. We place the object and a computer-steered moving-head spotlight inside a simple foam-core enclosure and use a camera to record photos as the light scans the box interior. Optimization, guided by interactive user sketching, selects a small set of these photos whose weighted sum best matches the user-defined target sketch. Unlike previous image-based relighting efforts, our method requires only a single area light source, yet it can achieve high-resolution light positioning to avoid multiple sharp shadows. A reduced version uses only a handheld light and may be suitable for battery-powered field photography equipment that fits into a backpack.","1941-0506","","10.1109/TVCG.2007.1008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293010","Image-based lighting;enclosure lighting;handheld lighting;controllable lighting;digital photography.","Digital photography;Light sources;Cameras;Layout;Shape;Lifting equipment;Costs;Digital control;Lighting control;Clamps","digital photography;light sources;lighting","tabletop computed lighting;digital photography;image-based lighting methods;high-quality photographic lighting;desktop-sized static objects;museum artifacts;interactive user sketching;user-defined target sketch;high-resolution light positioning;multiple sharp shadows;handheld light;battery-powered field photography equipment","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Lighting;Photography;Signal Processing, Computer-Assisted;User-Computer Interface","10","4","28","","20 Aug 2007","","","IEEE","IEEE Journals"
"Three-dimensional interfaces for querying by example in content-based image retrieval","J. Assfalg; A. Del Bimbo; P. Pala","Dipt. di Sistemi e Informatica, Universita di Firenze, Italy; Dipt. di Sistemi e Informatica, Universita di Firenze, Italy; Dipt. di Sistemi e Informatica, Universita di Firenze, Italy","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2002","2002","8","4","305","318","Image databases are widely exploited in a number of different contexts, ranging from history of art, through medicine, to education. Existing querying paradigms are based either on the usage of textual strings, for high-level semantic queries or on 2D visual examples for the expression of perceptual queries. Semantic queries require manual annotation of the database images. Instead, perceptual queries only require that image analysis is performed on the database images in order to extract salient perceptual features that are matched with those of the example. However, usage of 2D examples is generally inadequate as effective authoring of query images, attaining a realistic reproduction of complex scenes, needs manual editing and sketching ability. Investigation of new querying paradigms is therefore an important-yet still marginally investigated-factor for the success of content-based image retrieval. In this paper, a novel querying paradigm is presented which is based on usage of 3D interfaces exploiting navigation and editing of 3D virtual environments. Query images are obtained by taking a snapshot of the framed environment and by using the snapshot as an example to retrieve similar database images. A comparative analysis is carried out between the usage of 3D and 2D interfaces and their related query paradigms. This analysis develops on a user test on retrieval efficiency and effectiveness, as well as on an evaluation of users' satisfaction.","1941-0506","","10.1109/TVCG.2002.1044517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044517","","Image databases;Spatial databases;Visual databases;Image retrieval;History;Art;Biomedical imaging;Image analysis;Feature extraction;Layout","image retrieval;content-based retrieval;user interfaces;visual databases;multimedia databases","3D user interfaces;content-based image retrieval;querying by example;image databases;perceptual queries;image analysis;perceptual features;3D virtual environment editing;3D virtual environment navigation;framed environment;snapshot;2D user interfaces;retrieval efficiency;retrieval effectiveness;user satisfaction","","10","","35","","10 Dec 2002","","","IEEE","IEEE Journals"
"Towards Automated Infographic Design: Deep Learning-based Auto-Extraction of Extensible Timeline","Z. Chen; Y. Wang; Q. Wang; Y. Wang; H. Qu",Hong Kong University of Science and Technology; Microsoft Research; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","917","926","Designers need to consider not only perceptual effectiveness but also visual styles when creating an infographic. This process can be difficult and time consuming for professional designers, not to mention non-expert users, leading to the demand for automated infographics design. As a first step, we focus on timeline infographics, which have been widely used for centuries. We contribute an end-to-end approach that automatically extracts an extensible timeline template from a bitmap image. Our approach adopts a deconstruction and reconstruction paradigm. At the deconstruction stage, we propose a multi-task deep neural network that simultaneously parses two kinds of information from a bitmap timeline: 1) the global information, i.e., the representation, scale, layout, and orientation of the timeline, and 2) the local information, i.e., the location, category, and pixels of each visual element on the timeline. At the reconstruction stage, we propose a pipeline with three techniques, i.e., Non-Maximum Merging, Redundancy Recover, and DL GrabCut, to extract an extensible template from the infographic, by utilizing the deconstruction results. To evaluate the effectiveness of our approach, we synthesize a timeline dataset (4296 images) and collect a real-world timeline dataset (393 images) from the Internet. We first report quantitative evaluation results of our approach over the two datasets. Then, we present examples of automatically extracted templates and timelines automatically generated based on these templates to qualitatively demonstrate the performance. The results confirm that our approach can effectively extract extensible templates from real-world timeline infographics.","1941-0506","","10.1109/TVCG.2019.2934810","MSRA(grant numbers:MRA19EG02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807266","Automated Infographic Design;Deep Learning-based Approach;Timeline Infographics;Multi-task Model","Visualization;Data visualization;Data mining;Image reconstruction;Pipelines;Image coding;Object detection","computer graphics;data visualisation;feature extraction;image segmentation;Internet;learning (artificial intelligence);neural nets","automatically extracted templates;extensible template;real-world timeline infographics;deep learning-based auto-extraction;perceptual effectiveness;visual styles;nonexpert users;automated infographics design;end-to-end approach;extensible timeline template;bitmap image;reconstruction paradigm;deconstruction stage;multitask deep neural network;bitmap timeline;global information;local information;visual element;reconstruction stage;NonMaximum Merging;real-world timeline dataset;automated infographic design","","10","","56","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"WORDGRAPH: Keyword-in-Context Visualization for NETSPEAK's Wildcard Search","P. Riehmann; H. Gruendl; M. Potthast; M. Trenkmann; B. Stein; B. Froehlich","Bauhaus-Universität Weimar, Weimar; Bauhaus-Universität Weimar, Weimar; Bauhaus-Universität Weimar, Weimar; Bauhaus-Universität Weimar, Weimar; Bauhaus-Universität Weimar, Weimar; Bauhaus-Universität Weimar, Weimar","IEEE Transactions on Visualization and Computer Graphics","12 Jul 2012","2012","18","9","1411","1423","The WORDGRAPH helps writers in visually choosing phrases while writing a text. It checks for the commonness of phrases and allows for the retrieval of alternatives by means of wildcard queries. To support such queries, we implement a scalable retrieval engine, which returns high-quality results within milliseconds using a probabilistic retrieval strategy. The results are displayed as WORDGRAPH visualization or as a textual list. The graphical interface provides an effective means for interactive exploration of search results using filter techniques, query expansion, and navigation. Our observations indicate that, of three investigated retrieval tasks, the textual interface is sufficient for the phrase verification task, wherein both interfaces support context-sensitive word choice, and the WORDGRAPH best supports the exploration of a phrase's context or the underlying corpus. Our user study confirms these observations and shows that WORDGRAPH is generally the preferred interface over the textual result list for queries containing multiple wildcards.","1941-0506","","10.1109/TVCG.2012.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175895","Information visualization;visual queries;text visualization;information retrieval;Web n-grams;wildcard search.","Visualization;Google;Navigation;Engines;Layout;Indexes","data visualisation;information retrieval;probability","WORDGRAPH;keyword-in-context visualization;NETSPEAK wildcard search;visually choosing phrases;wildcard queries;scalable retrieval engine;probabilistic retrieval strategy;graphical interface;interactive exploration;filter techniques;query expansion;query navigation;phrase context;underlying corpus","","10","","27","","3 Apr 2012","","","IEEE","IEEE Journals"
"A Deep Generative Model for Graph Layout","O. -H. Kwon; K. -L. Ma","University of California, Davis; University of California, Davis","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","665","675","Different layouts can characterize different aspects of the same graph. Finding a “good” layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.","1941-0506","","10.1109/TVCG.2019.2934396","U.S. National Science Foundation(grant numbers:IIS-1741536); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805452","Graph;network;visualization;layout;machine learning;deep learning;neural network;generative model;autoencoder","Layout;Training;Visualization;Task analysis;Data visualization;Machine learning;Data models","data visualisation;graph theory;learning (artificial intelligence);mathematics computing;neural nets","graph visualization;diverse layouts;deep generative model;encoder-decoder architecture;two-dimensional latent space;graph layouts;machine learning model","","9","","87","IEEE","19 Aug 2019","","","IEEE","IEEE Journals"
"Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures","D. Cashman; A. Perer; R. Chang; H. Strobelt","Tufts University, USA; Carnegie Mellon University, USA; Tufts University, USA; MIT IBM Watson AI Lab, USA","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","863","873","The performance of deep learning models is dependent on the precise configuration of many layers and parameters. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.","1941-0506","","10.1109/TVCG.2019.2934261","Defense Advanced Research Projects Agency(grant numbers:FA8750-17-2-0107); NSF(grant numbers:CAREER IIS-1452977); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827593","visual analytics;neural networks;parameter space exploration","Neural networks;Computer architecture;Tools;Training;Visual analytics;Machine learning","data analysis;data visualisation;learning (artificial intelligence);neural net architecture","graphical interface;rapid exploration of model architectures and parameters;visual analytics tool;neural network architectures;deep learning model builders;REMAP","","9","","73","IEEE","9 Sep 2019","","","IEEE","IEEE Journals"
"Compressing Color Data for Voxelized Surface Geometry","D. Dolonius; E. Sintorn; V. Kämpe; U. Assarsson","Gothenburg, Sweden; Gothenburg, Sweden; Gothenburg, Sweden; Gothenburg, Sweden","IEEE Transactions on Visualization and Computer Graphics","28 Dec 2018","2019","25","2","1270","1282","We explore the problem of decoupling color information from geometry in large scenes of voxelized surfaces and of compressing the array of colors without introducing disturbing artifacts. In this extension of our I3D paper with the same title [1] , we first present a novel method for connecting each node in a sparse voxel DAG to its corresponding colors in a separate 1D array of colors, with very little additional information stored to the DAG. Then, we show that by mapping the 1D array of colors onto a 2D image using a space-filling curve, we can achieve high compression rates and good quality using conventional, modern, hardware-accelerated texture compression formats such as ASTC or BC7. We additionally explore whether this method can be used to compress voxel colors for off-line storage and network transmission using conventional off-line compression formats such as JPG and JPG2K. For real-time decompression, we suggest a novel variable bitrate block encoding that consistently outperforms previous work, often achieving two times the compression at equal quality.","1941-0506","","10.1109/TVCG.2017.2741480","Vetenskapsrådet(grant numbers:2014-4559); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8013133","Voxel;sparse voxel octree;directed acyclic graph;space filling curve;color compression;ASTC;BC;JPEG;PNG","Image color analysis;Image coding;Geometry;Indexes;Octrees;Arrays;Two dimensional displays","computational geometry;correlation methods;data compression;image coding;image colour analysis;image texture","hardware-accelerated texture compression formats;off-line compression formats;voxel colors;high compression rates;sparse voxel DAG;voxelized surfaces;color information;voxelized surface geometry;color data","","9","","26","IEEE","18 Aug 2017","","","IEEE","IEEE Journals"
"Decomposition and Simplification of Multivariate Data using Pareto Sets","L. Huettenberger; C. Heine; C. Garth",TU Kaiserslautern; ETH Zurich; TU Kaiserslautern,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","2684","2693","Topological and structural analysis of multivariate data is aimed at improving the understanding and usage of such data through identification of intrinsic features and structural relationships among multiple variables. We present two novel methods for simplifying so-called Pareto sets that describe such structural relationships. Such simplification is a precondition for meaningful visualization of structurally rich or noisy data. As a framework for simplification operations, we introduce a decomposition of the data domain into regions of equivalent structural behavior and the reachability graph that describes global connectivity of Pareto extrema. Simplification is then performed as a sequence of edge collapses in this graph; to determine a suitable sequence of such operations, we describe and utilize a comparison measure that reflects the changes to the data that each operation represents. We demonstrate and evaluate our methods on synthetic and real-world examples.","1941-0506","","10.1109/TVCG.2014.2346447","DFG International Research Training Group 1131 ¿Visualization of Large and Unstructured Data Sets¿; Marie Curie Actions within the EU FP7 Programme(grant numbers:#304099); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875963","Multivariate Topology;Pareto Set;Simplification;Decomposition;Multivariate Topology;Pareto Set;Simplification;Decomposition","Data visualization;Jacobian matrices;Image edge detection;Image color analysis;Pareto analysis","data analysis;data visualisation;reachability analysis;set theory","multivariate data decomposition;multivariate data simplification;Pareto set;multivariate data analysis;topological analysis;structural analysis;structural relationship;data visualization;simplification operation;reachability graph;Pareto extrema;comparison measure","","9","","22","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"<italic>DeepDrawing</italic>: A Deep Learning Approach to Graph Drawing","Y. Wang; Z. Jin; Q. Wang; W. Cui; T. Ma; H. Qu",Hong Kong University of Science and Technology (HKUST); Hong Kong University of Science and Technology (HKUST); Hong Kong University of Science and Technology (HKUST); Microsoft Research Asia; IBM T. J. Watson Research Center; Hong Kong University of Science and Technology (HKUST),"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","676","686","Node-link diagrams are widely used to facilitate network explorations. However, when using a graph drawing technique to visualize networks, users often need to tune different algorithm-specific parameters iteratively by comparing the corresponding drawing results in order to achieve a desired visual effect. This trial and error process is often tedious and time-consuming, especially for non-expert users. Inspired by the powerful data modelling and prediction capabilities of deep learning techniques, we explore the possibility of applying deep learning techniques to graph drawing. Specifically, we propose using a graph-LSTM-based approach to directly map network structures to graph drawings. Given a set of layout examples as the training dataset, we train the proposed graph-LSTM-based model to capture their layout characteristics. Then, the trained model is used to generate graph drawings in a similar style for new networks. We evaluated the proposed approach on two special types of layouts (i.e., grid layouts and star layouts) and two general types of layouts (i.e., ForceAtlas2 and PivotMDS) in both qualitative and quantitative ways. The results provide support for the effectiveness of our approach. We also conducted a time cost assessment on the drawings of small graphs with 20 to 50 nodes. We further report the lessons we learned and discuss the limitations and future work.","1941-0506","","10.1109/TVCG.2019.2934798","MSRA(grant numbers:MRA19EG02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807275","Graph Drawing;Deep Learning;LSTM;Procrustes Analysis","Deep learning;Layout;Neural networks;Training;Convolution;Data models;Visualization","data visualisation;drawing (mechanical);graph theory;learning (artificial intelligence);recurrent neural nets","graph drawings;grid layouts;star layouts;node-link diagrams;network explorations;data modelling;deep learning;graph-LSTM-based approach;DeepDrawing;ForceAtlas2 layout;PivotMDS layout","","9","","82","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Design and Evaluation of Data Annotation Workflows for CAVE-like Virtual Environments","S. Pick; B. Weyers; B. Hentschel; T. W. Kuhlen","Visual Computing Institute at RWTH Aachen University, Germany; Visual Computing Institute at RWTH Aachen University, Germany; Visual Computing Institute at RWTH Aachen University, Germany; Visual Computing Institute at RWTH Aachen University, Germany","IEEE Transactions on Visualization and Computer Graphics","14 Mar 2016","2016","22","4","1452","1461","Data annotation finds increasing use in Virtual Reality applications with the goal to support the data analysis process, such as architectural reviews. In this context, a variety of different annotation systems for application to immersive virtual environments have been presented. While many interesting interaction designs for the data annotation workflow have emerged from them, important details and evaluations are often omitted. In particular, we observe that the process of handling metadata to interactively create and manage complex annotations is often not covered in detail. In this paper, we strive to improve this situation by focusing on the design of data annotation workflows and their evaluation. We propose a workflow design that facilitates the most important annotation operations, i.e., annotation creation, review, and modification. Our workflow design is easily extensible in terms of supported annotation and metadata types as well as interaction techniques, which makes it suitable for a variety of application scenarios. To evaluate it, we have conducted a user study in a CAVE-like virtual environment in which we compared our design to two alternatives in terms of a realistic annotation creation task. Our design obtained good results in terms of task performance and user experience.","1941-0506","","10.1109/TVCG.2016.2518086","German Research Foundation DFG; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383336","Virtual reality;data annotation;interaction design;user study;Virtual reality;data annotation;interaction design;user study","Metadata;Three-dimensional displays;Visualization;Virtual environments;Context;Layout;Data analysis","data analysis;human computer interaction;meta data;virtual reality","virtual environment;virtual reality application;data analysis process;data annotation system;metadata handling process;data annotation workflow design;interaction technique","","9","","39","IEEE","14 Jan 2016","","","IEEE","IEEE Journals"
"Disentangled Human Body Embedding Based on Deep Hierarchical Neural Network","B. Jiang; J. Zhang; J. Cai; J. Zheng","School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China; School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China; Faculty of IT, Monash University, Clayton, VIC, Australia; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore","IEEE Transactions on Visualization and Computer Graphics","30 Jun 2020","2020","26","8","2560","2575","Human bodies exhibit various shapes for different identities or poses, but the body shape has certain similarities in structure and thus can be embedded in a low-dimensional space. This article presents an autoencoder-like network architecture to learn disentangled shape and pose embedding specifically for the 3D human body. This is inspired by recent progress of deformation-based latent representation learning. To improve the reconstruction accuracy, we propose a hierarchical reconstruction pipeline for the disentangling process and construct a large dataset of human body models with consistent connectivity for the learning of the neural network. Our learned embedding can not only achieve superior reconstruction accuracy but also provide great flexibility in 3D human body generation via interpolation, bilinear interpolation, and latent space sampling. The results from extensive experiments demonstrate the powerfulness of our learned 3D human body embedding in various applications.","1941-0506","","10.1109/TVCG.2020.2988476","National Natural Science Foundation of China(grant numbers:61672481); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2018495); NTU Data Science and Artificial Intelligence Research Center (DSAIR)(grant numbers:M4082285); MoE Tier-2(grant numbers:2016-T2-2-065,2017-T2-1-076); National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072593","3D body shape;3D human articulated body model;variational autoencoder;deformation representation;hierarchical structure","Shape;Strain;Three-dimensional displays;Biological system modeling;Computational modeling;Solid modeling;Face","image reconstruction;image representation;image sampling;interpolation;learning (artificial intelligence);neural net architecture;shape recognition;solid modelling","deep hierarchical neural network;body shape;low-dimensional space;autoencoder-like network architecture;disentangled shape;deformation-based latent representation learning;hierarchical reconstruction pipeline;3D human body generation;latent space sampling;disentangled human body embedding;pose embedding;bilinear interpolation;interpolation","Algorithms;Computer Graphics;Female;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Male;Neural Networks, Computer;Posture","9","","58","IEEE","20 Apr 2020","","","IEEE","IEEE Journals"
"Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data","H. Guo; C. L. Phillips; T. Peterka; D. Karpeyev; A. Glatz","Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA; Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA; Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA; Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA; Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","827","836","We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible.","1941-0506","","10.1109/TVCG.2015.2466838","U.S. Department of Energy, Office of Science(grant numbers:DE-AC02-06CH11357); U.S. Department of Energy, Office of Advanced Scientific Computing Research, Scientific Discovery; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192679","Superconductor;Vortex extraction;Feature tracking;Unstructured grid;Superconductor;Vortex extraction;Feature tracking;Unstructured grid","Three-dimensional displays;Data visualization;Superconducting transmission lines;Feature extraction;Data mining;Superconducting magnets;Magnetic domains","data visualisation;electronic engineering computing;magnetic flux;type II superconductors;vortices","macroscale superconductor behavior;vortex dynamics;2D event diagrams;3D visualization;data discretization;time-varying discrete dataset;type-II superconductors;complex-valued order parameter field;Ginzburg-Landau theory;3D complex-valued superconductor simulation data;vortex visualization;vortex tracking;vortex extraction;magnetic flux vortices","","9","","39","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Functional Workspace Optimization via Learning Personal Preferences from Virtual Experiences","W. Liang; J. Liu; Y. Lang; B. Ning; L. -F. Yu",Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Fashion Technology; George Mason University,"IEEE Transactions on Visualization and Computer Graphics","27 Mar 2019","2019","25","5","1836","1845","The functionality of a workspace is one of the most important considerations in both virtual world design and interior design. To offer appropriate functionality to the user, designers usually take some general rules into account, e.g., general workflow and average stature of users, which are summarized from the population statistics. Yet, such general rules cannot reflect the personal preferences of a single individual, which vary from person to person. In this paper, we intend to optimize a functional workspace according to the personal preferences of the specific individual who will use it. We come up with an approach to learn the individual's personal preferences from his activities while using a virtual version of the workspace via virtual reality devices. Then, we construct a cost function, which incorporates personal preferences, spatial constraints, pose assessments, and visual field. At last, the cost function is optimized to achieve an optimal layout. To evaluate the approach, we experimented with different settings. The results of the user study show that the workspaces updated in this way better fit the users.","1941-0506","","10.1109/TVCG.2019.2898721","National Natural Science Foundation of China(grant numbers:61876020); National Science Foundation(grant numbers:1565978); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642445","Affordance;Human-centered Design;Virtual Environments;Workspace Design;Remodeling","Layout;Task analysis;Cost function;Visualization;Software;Three-dimensional displays","ergonomics;learning (artificial intelligence);virtual reality","functional workspace optimization;virtual experiences;virtual world design;interior design;cost function;personal preference learning","Algorithms;Computer Graphics;Computer Simulation;Ergonomics;Humans;Interior Design and Furnishings;Posture;Task Performance and Analysis;User-Computer Interface;Virtual Reality;Workplace","9","","52","IEEE","14 Feb 2019","","","IEEE","IEEE Journals"
"Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks","B. Yu; H. Doraiswamy; X. Chen; E. Miraldi; M. L. Arrieta-Ortiz; C. Hafemeister; A. Madar; R. Bonneau; C. T. Silva",NYU Polytechnic School of Engineering; NYU Polytechnic School of Engineering; NYU Center for Genomics and Systems Biology; NYU Center for Genomics and Systems Biology; NYU Center for Genomics and Systems Biology; NYU Center for Genomics and Systems Biology; Cornell University; NYU Center for Genomics and Systems Biology; NYU Polytechnic School of Engineering,"IEEE Transactions on Visualization and Computer Graphics","6 Nov 2014","2014","20","12","1903","1912","Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).","1941-0506","","10.1109/TVCG.2014.2346753","IBM Faculty Award, the NYU School of Engineering, DOE, NSF(grant numbers:CNS-1229185,IOS-1126971); NIH(grant numbers:PN2-EY016586,IU54CA143907-01,EY016586-06); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876028","Web-based visualization;gene regulatory network","Data visualization;Genomics;Bioinformatics;Browsers;Gene expression;Data models;Biological system modeling;Computational modeling","bioinformatics;cellular biophysics;genetics;genomics;graphical user interfaces;interactive systems;query processing;RNA","Genotet;interactive Web-based visual exploration framework;transcriptional regulatory network elucidation;TRN elucidation;transcription factors;gene promoter regions;gene enhancer regions;target gene expression patterns;genomic technologies;computational biology;multiple large regulatory network models;directed networks;data corpus;gene-annotation corpus;TF-target gene relationship validation;co-regulation patterns;cell process coordination;cell state;cell environment;regulatory network model validation;primary data visualization coordination;directed weighted gene regulatory networks;network models;primary data;coordinated queries;expression data exploration coordination;expression data visualization coordination;RNA- seq;microarray;gene-binding data;ChIP-seq;specialized data structures;multiple coordinated views;querying model;interactive analysis;mouse immune system;cellular functions;bacteria model;genome;data-completeness","Animals;Computational Biology;Computer Graphics;Databases, Genetic;Gene Regulatory Networks;Internet;Mice;Transcription Factors;User-Computer Interface","9","","32","IEEE","6 Nov 2014","","","IEEE","IEEE Journals"
"Interest Driven Navigation in Visualization","C. G. Healey; B. M. Dennis","North Carolina State University, Raleigh; Massachusetts Institute of Technology, Lexington","IEEE Transactions on Visualization and Computer Graphics","9 Aug 2012","2012","18","10","1744","1756","This paper describes a new method to explore and discover within a large data set. We apply techniques from preference elicitation to automatically identify data elements that are of potential interest to the viewer. These ""elements of interest (EOI)” are bundled into spatially local clusters, and connected together to form a graph. The graph is used to build camera paths that allow viewers to ""tour” areas of interest (AOI) within their data. It is also visualized to provide wayfinding cues. Our preference model uses Bayesian classification to tag elements in a data set as interesting or not interesting to the viewer. The model responds in real time, updating the elements of interest based on a viewer's actions. This allows us to track a viewer's interests as they change during exploration and analysis. Viewers can also interact directly with interest rules the preference model defines. We demonstrate our theoretical results by visualizing historical climatology data collected at locations throughout the world.","1941-0506","","10.1109/TVCG.2012.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6133283","Bayesian network;classification;navigation;preferences;visualization.","Data visualization;Bayesian methods;Navigation;Data models;Cameras;Context awareness","","","","9","","41","","17 Jan 2012","","","IEEE","IEEE Journals"
"NPU-Based Image Compositing in a Distributed Visualization System","D. Pugmire; L. Monroe; C. Connor Davenport; A. DuBois; D. DuBois; S. Poole","Los Alamos National Laboratory, MS T080, Los Alamos, NM 87545; Los Alamos National Laboratory, MS T080, Los Alamos, NM 87545; Los Alamos National Laboratory, MS B255, Los Alamos, NM 87545; Los Alamos National Laboratory, MS B255, Los Alamos, NM 87545; Los Alamos National Laboratory, MS B255, Los Alamos, NM 87545; Oak Ridge National Laboratory, PO Box 2008 MS6164, Oak Ridge, TN 37831","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","798","809","This paper describes the first use of a Network Processing Unit (NPU) to perform hardware-based image composition in a distributed rendering system. The image composition step is a notorious bottleneck in a clustered rendering system. Furthermore, image compositing algorithms do not necessarily scale as data size and number of nodes increase. Previous researchers have addressed the composition problem via software and/or custom-built hardware. We used the heterogeneous multicore computation architecture of the Intel IXP28XX NPU, a fully programmable commercial off-the-shelf (COTS) technology, to perform the image composition step. With this design, we have attained a nearly four-times performance increase over traditional software-based compositing methods, achieving sustained compositing rates of 22-28 fps on a 1,024 \times 1,024 image. This system is fully scalable with a negligible penalty in frame rate, is entirely COTS, and is flexible with regard to operating system, rendering software, graphics cards, and node architecture. The NPU-based compositor has the additional advantage of being a modular compositing component that is eminently suitable for integration into existing distributed software visualization packages.","1941-0506","","10.1109/TVCG.2007.1026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293022","Hardware-assisted image compositing;high-performance computing;image compositing;Network Processing Unit;parallel rendering;PC clusters;visualization;volume rendering.","Rendering (computer graphics);Computer architecture;Data visualization;Clustering algorithms;Hardware;Multicore processing;Operating systems;Software systems;Graphics;Software packages","computer graphic equipment;data visualisation;distributed processing;image processing;rendering (computer graphics);software packages","distributed visualization system;network processing unit;hardware-based image composition;distributed rendering system;clustered rendering system;Intel IXP28XX NPU;commercial off-the-shelf technology;operating system;rendering software;graphics cards;node architecture;distributed software visualization packages","Algorithms;Computer Communication Networks;Computer Graphics;Equipment Design;Equipment Failure Analysis;Image Enhancement;Image Enhancement;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Signal Processing, Computer-Assisted","9","","34","USGov","20 Aug 2007","","","IEEE","IEEE Journals"
"OoDAnalyzer: Interactive Analysis of Out-of-Distribution Samples","C. Chen; J. Yuan; Y. Lu; Y. Liu; H. Su; S. Yuan; S. Liu","Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China; Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China; BloombergL.P, New York, NY, USA; Microsoft Research Asia, Haidian, Beijing, China; Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China; First Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","27 May 2021","2021","27","7","3335","3349","One major cause of performance degradation in predictive models is that the test samples are not well covered by the training data. Such not well-represented samples are called OoD samples. In this article, we propose OoDAnalyzer, a visual analysis approach for interactively identifying OoD samples and explaining them in context. Our approach integrates an ensemble OoD detection method and a grid-based visualization. The detection method is improved from deep ensembles by combining more features with algorithms in the same family. To better analyze and understand the OoD samples in context, we have developed a novel <i>k</i>NN-based grid layout algorithm motivated by Hall's theorem. The algorithm approximates the optimal layout and has O(<i>k</i>N<sup>2</sup>)O(<i>k</i>N<sup>2</sup>) time complexity, faster than the grid layout algorithm with overall best performance but O(N<sup>3</sup>)O(N<sup>3</sup>) time complexity. Quantitative evaluation and case studies were performed on several datasets to demonstrate the effectiveness and usefulness of OoDAnalyzer.","1941-0506","","10.1109/TVCG.2020.2973258","National Key Research and Development Program of China(grant numbers:2018YFB1004300); National Natural Science Foundation of China(grant numbers:61936002,61761136020,61672308); Tsinghua University; National Key Research and Development Program of China(grant numbers:2017YFA0700904); NSFC Projects(grant numbers:61620106010,61621136008); JP Morgan Faculty Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994105","Out-of-Distribution detection;grid layout;interactive visualization","Training;Layout;Visualization;Dogs;Feature extraction;Approximation algorithms;Cats","computational complexity;data analysis;data visualisation;graph theory;interactive systems;optimisation","OoDAnalyzer;out-of-distribution samples;OoD samples;visual analysis approach;ensemble OoD detection method;grid-based visualization;NN-based grid;grid layout algorithm","","9","","67","IEEE","11 Feb 2020","","","IEEE","IEEE Journals"
"PieceStack: Toward Better Understanding of Stacked Graphs","T. Wu; Y. Wu; C. Shi; H. Qu; W. Cui","Hong Kong University of Science and Technology, Hong Kong; State Key Lab of CAD & CG, Zhejiang University, Zhejiang, China; IBM T.J, Watson Research Center, NY; Hong Kong University of Science and Technology, Hong Kong; Microsoft Research","IEEE Transactions on Visualization and Computer Graphics","28 Apr 2016","2016","22","6","1640","1651","Stacked graphs have been widely adopted in various fields, because they are capable of hierarchically visualizing a set of temporal sequences as well as their aggregation. However, because of visual illusion issues, connections between overly-detailed individual layers and overly-generalized aggregation are intercepted. Consequently, information in this area has yet to be fully excavated. Thus, we present PieceStack in this paper, to reveal the relevance of stacked graphs in understanding intrinsic details of their displayed shapes. This new visual analytic design interprets the ways through which aggregations are generated with individual layers by interactively splitting and re-constructing the stacked graphs. A clustering algorithm is designed to partition stacked graphs into sub-aggregated pieces based on trend similarities of layers. We then visualize the pieces with augmented encoding to help analysts decompose and explore the graphs with respect to their interests. Case studies and a user study are conducted to demonstrate the usefulness of our technique in understanding the formation of stacked graphs.","1941-0506","","10.1109/TVCG.2016.2534518","National 973 Program of China(grant numbers:2015CB352503); NSFC(grant numbers:61502416); RGC; GRF(grant numbers:618313); Microsoft Research Asia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419266","Statistical graphics;Time series visualization;Stacked graphs;Statistical graphics;time series visualization;stacked graphs","Shape;Visualization;Market research;Time series analysis;Clustering algorithms;Algorithm design and analysis;Trajectory","graph theory;pattern clustering","PieceStack;stacked graphs;temporal sequences;visual illusion issues;overly-detailed individual layers;overly-generalized aggregation;visual analytic design;clustering algorithm;augmented encoding","","9","","36","IEEE","24 Feb 2016","","","IEEE","IEEE Journals"
"RIVA: a versatile parallel rendering system for interactive scientific visualization","P. P. Li; W. H. Duquette; D. W. Curkendall","Autom. & Scheduling Technol. Group, Jet Propulsion Lab., Pasadena, CA, USA; Autom. & Scheduling Technol. Group, Jet Propulsion Lab., Pasadena, CA, USA; Autom. & Scheduling Technol. Group, Jet Propulsion Lab., Pasadena, CA, USA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1996","2","3","186","201","JPL's Remote Interactive Visualization and Analysis System (RIVA) is described in detail. The RIVA system integrates workstation graphics, massively parallel computing technology, and gigabit communication networks to provide a flexible interactive environment for scientific data perusal, analysis, and visualization, RIVA's kernel is a highly scalable parallel perspective renderer tailored especially for the demands of large datasets beyond the sensible reach of workstations. Early experience with using RIVA to interactively explore and process multivariate, multiresolution datasets is reported; several examples using data from a variety of remote sensing instruments are discussed in detail and the results shown. Particular attention is placed on describing the algorithmic details of RIVA's parallel renderer kernel, with emphasis on the key aspects of achieving the algorithm's overall scalability. The paper summarizes the performance achieved for machine sizes up to more than 500 nodes and for initial input image/terrain bases in the 2 Gbyte range.","1941-0506","","10.1109/2945.537303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=537303","","Rendering (computer graphics);Data visualization;Workstations;Kernel;Graphics;Parallel processing;Communications technology;Communication networks;Data analysis;Remote sensing","rendering (computer graphics);data visualisation;parallel programming","RIVA;parallel rendering system;interactive scientific visualization;workstation graphics;massively parallel computing;gigabit communication network;perspective renderer","","9","8","14","","6 Aug 2002","","","IEEE","IEEE Journals"
"Sociotechnical Considerations for Accessible Visualization Design","A. Lundgard; C. Lee; A. Satyanarayan",MIT CSAIL; MIT HASTS; MIT CSAIL,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","16","20","Accessibility-the process of designing for people with disabilities (PWD)-is an important but under-explored challenge in the visualization research community. Without careful attention, and if PWD are not included as equal participants throughout the process, there is a danger of perpetuating a vision-first approach to accessible design that marginalizes the lived experience of disability (e.g., by creating overly simplistic ""sensory translations"" that map visual to non-visual modalities in a one-to-one fashion). In this paper, we present a set of sociotechnical considerations for research in accessible visualization design, drawing on literature in disability studies, tactile information systems, and participatory methods. We identify that using state-of-the-art technologies may introduce more barriers to access than they remove, and that expectations of research novelty may not produce outcomes well-aligned with the needs of disability communities. Instead, to promote a more inclusive design process, we emphasize the importance of clearly communicating goals, following existing accessibility guidelines, and treating PWD as equal participants who are compensated for their specialized skills. To illustrate how these considerations can be applied in practice, we discuss a case study of an inclusive design workshop held in collaboration with the Perkins School for the Blind.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933762","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933762","Human-centered computing;Visualization;Visualization design and evaluation methods;Accessibility;Accessibility technologies","Biological system modeling;Visualization;Guidelines;Data visualization;Medical diagnostic imaging;Human computer interaction","data visualisation;handicapped aids;human computer interaction;user interfaces","PWD;visualization research community;nonvisual modalities;sociotechnical considerations;accessible visualization design;disability communities;inclusive design workshop;people with disabilities","","9","","44","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Temporal Treemaps: Static Visualization of Evolving Trees","W. Köpp; T. Weinkauf","KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","534","543","We consider temporally evolving trees with changing topology and data: tree nodes may persist for a time range, merge or split, and the associated data may change. Essentially, one can think of this as a time series of trees with a node correspondence per hierarchy level between consecutive time steps. Existing visualization approaches for such data include animated 2D treemaps, where the dynamically changing layout makes it difficult to observe the data in its entirety. We present a method to visualize this dynamic data in a static, nested, and space-filling visualization. This is based on two major contributions: First, the layout constitutes a graph drawing problem. We approach it for the entire time span at once using a combination of a heuristic and simulated annealing. Second, we propose a rendering that emphasizes the hierarchy through an adaption of the classic cushion treemaps. We showcase the wide range of applicability using data from feature tracking in time-dependent scalar fields, evolution of file system hierarchies, and world population.","1941-0506","","10.1109/TVCG.2018.2865265","SSF; SeRC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8443124","Treemaps;Temporal trees","Layout;Data visualization;Rendering (computer graphics);Time series analysis;Topology;Regression tree analysis;Two dimensional displays","computer animation;data visualisation;tree data structures;trees (mathematics)","file system hierarchies;temporal treemaps;changing topology;tree nodes;associated data;time series;node correspondence;hierarchy level;consecutive time steps;visualization approaches;dynamic data;static space-filling visualization;graph drawing problem;classic cushion treemaps;time-dependent scalar fields;nested space-filling visualization;feature tracking","","9","","40","IEEE","21 Aug 2018","","","IEEE","IEEE Journals"
"Towards Zero-Waste Furniture Design","B. Koo; J. Hergel; S. Lefebvre; N. J. Mitra","University College London, London, United Kingdom; INRIA Nancy, Villers-lés-Nancy, France; INRIA Nancy, Villers-lés-Nancy, France; University College London, London, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","30 Oct 2017","2017","23","12","2627","2640","In traditional design, shapes are first conceived, and then fabricated. While this decoupling simplifies the design process, it can result in unwanted material wastage, especially where off-cut pieces are hard to reuse. In absence of explicit feedback on material usage, the designer remains helpless to effectively adapt the design - even when design variabilities exist. We investigate waste minimizing furniture design wherein based on the current design, the user is presented with design variations that result in less wastage of materials. Technically, we dynamically analyze material space layout to determine which parts to change and how , while maintaining original design intent specified in the form of design constraints. We evaluate the approach on various design scenarios, and demonstrate effective material usage that is difficult, if not impossible, to achieve without computational support.","1941-0506","","10.1109/TVCG.2016.2633519","ERC(grant numbers:StG-2012- 307877,StG-2013-335373); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7762730","","Shape analysis;Solid modeling;Three-dimensional displays;Algorithm design and analysis;Fabrication;Two dimensional displays","CAD;design engineering;feedback;furniture;furniture industry;industrial waste;optimisation;product design;recycling","design constraints;design scenarios;traditional design;design process;unwanted material wastage;off-cut pieces;explicit feedback;design variabilities;waste minimizing furniture design;current design;design variations;material space layout;material usage;zero-waste furniture design","","9","","35","IEEE","1 Dec 2016","","","IEEE","IEEE Journals"
"Visual Genealogy of Deep Neural Networks","Q. Wang; J. Yuan; S. Chen; H. Su; H. Qu; S. Liu","Hong Kong University of Science and Technology, Kowloon, Hong Kong; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Hong Kong University of Science and Technology, Kowloon, Hong Kong; Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","30 Sep 2020","2020","26","11","3340","3352","A comprehensive and comprehensible summary of existing deep neural networks (DNNs) helps practitioners understand the behaviour and evolution of DNNs, offers insights for architecture optimization, and sheds light on the working mechanisms of DNNs. However, this summary is hard to obtain because of the complexity and diversity of DNN architectures. To address this issue, we develop DNN Genealogy, an interactive visualization tool, to offer a visual summary of representative DNNs and their evolutionary relationships. DNN Genealogy enables users to learn DNNs from multiple aspects, including architecture, performance, and evolutionary relationships. Central to this tool is a systematic analysis and visualization of 66 representative DNNs based on our analysis of 140 papers. A directed acyclic graph is used to illustrate the evolutionary relationships among these DNNs and highlight the representative DNNs. A focus + context visualization is developed to orient users during their exploration. A set of network glyphs is used in the graph to facilitate the understanding and comparing of DNNs in the context of the evolution. Case studies demonstrate that DNN Genealogy provides helpful guidance in understanding, applying, and optimizing DNNs. DNN Genealogy is extensible and will continue to be updated to reflect future advances in DNNs.","1941-0506","","10.1109/TVCG.2019.2921323","National Key R&D Program of China(grant numbers:2018YFB1004300); National Natural Science Foundation of China(grant numbers:61761136020,61672308); HK TRS(grant numbers:T41-709/17N); HK RGC(grant numbers:GRF 16213317); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732351","Interactive visual summary;information visualization;educational tool;deep neural networks","Visualization;Computer architecture;Tools;Neural networks;Interviews;Task analysis;Deep learning","data visualisation;directed graphs;learning (artificial intelligence);neural net architecture","deep neural networks;comprehensive summary;architecture optimization;DNN architectures;DNN Genealogy;interactive visualization tool;visual summary;evolutionary relationships;representative DNNs;context visualization;visual genealogy","","9","","69","IEEE","6 Jun 2019","","","IEEE","IEEE Journals"
"Visualization of Graph Products","S. Jänicke; C. Heine; M. Hellmuth; P. F. Stadler; G. Scheuermann","Institute for Computer Science, University of Leipzig, Germany; Institute for Computer Science, University of Leipzig, Germany; Institute for Computer Science, University of Leipzig, Germany; Institute for Computer Science, University of Leipzig, Germany; Institute for Computer Science, University of Leipzig, Germany","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2010","2010","16","6","1082","1089","Graphs are a versatile structure and abstraction for binary relationships between objects. To gain insight into such relationships, their corresponding graph can be visualized. In the past, many classes of graphs have been defined, e.g. trees, planar graphs, directed acyclic graphs, and visualization algorithms were proposed for these classes. Although many graphs may only be classified as ""general"" graphs, they can contain substructures that belong to a certain class. Archambault proposed the TopoLayout framework: rather than draw any arbitrary graph using one method, split the graph into components that are homogeneous with respect to one graph class and then draw each component with an algorithm best suited for this class. Graph products constitute a class that arises frequently in graph theory, but for which no visualization algorithm has been proposed until now. In this paper, we present an algorithm for drawing graph products and the aesthetic criterion graph product's drawings are subject to. We show that the popular High-Dimensional Embedder approach applied to cartesian products already respects this aestetic criterion, but has disadvantages. We also present how our method is integrated as a new component into the TopoLayout framework. Our implementation is used for further research of graph products in a biological context.","1941-0506","","10.1109/TVCG.2010.217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613446","Graph drawing;graph products;TopoLayout.","Layout;Visualization;Image edge detection;Springs;Complexity theory;Signal processing algorithms;Shape","data visualisation;graph theory","graph products visualization;versatile structure;binary relationships;trees;planar graphs;directed acyclic graphs;visualization algorithms;Archambault;TopoLayout framework;graph class;graph theory;high-dimensional embedder;Cartesian products","","9","","35","IEEE","28 Oct 2010","","","IEEE","IEEE Journals"
"Visualizing and Interacting with Kernelized Data","A. Barbosa; F. V. Paulovich; A. Paiva; S. Goldenstein; F. Petronetto; L. G. Nonato","Instituto de Computação e Matemática Computacional, Universidade de São Paulo, São Carlos-SP; Instituto de Computação e Matemática Computacional, Universidade de São Paulo, São Carlos-SP; Instituto de Computação e Matemática Computacional, Universidade de São Paulo, São Carlos-SP; Instituto de Computação, Universidade Estadual de Campinas, Campinas-SP; Departamento de Matemática, Universidade Federal do Espírito Santo, Vitória-ES; Instituto de Computação e Matemática Computacional, Universidade de São Paulo, São Carlos-SP","IEEE Transactions on Visualization and Computer Graphics","27 Jan 2016","2016","22","3","1314","1325","Kernel-based methods have experienced a substantial progress in the last years, tuning out an essential mechanism for data classification, clustering and pattern recognition. The effectiveness of kernel-based techniques, though, depends largely on the capability of the underlying kernel to properly embed data in the feature space associated to the kernel. However, visualizing how a kernel embeds the data in a feature space is not so straightforward, as the embedding map and the feature space are implicitly defined by the kernel. In this work, we present a novel technique to visualize the action of a kernel, that is, how the kernel embeds data into a high-dimensional feature space. The proposed methodology relies on a solid mathematical formulation to map kernelized data onto a visual space. Our approach is faster and more accurate than most existing methods while still allowing interactive manipulation of the projection layout, a game-changing trait that other kernel-based projection techniques do not have.","1941-0506","","10.1109/TVCG.2015.2464797","FAPESP(grant numbers:#2011/22749–8,#2013/19760–5,#2014/09546–9); CNPq(grant numbers:#302643/2013–3); CAPES; Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7180398","Multidimensional Projection;Visualization;Kernel Methods;Multidimensional projection;visualization;kernel methods","Kernel;Visualization;Data visualization;Layout;Force;Stress;Eigenvalues and eigenfunctions","data visualisation;pattern classification;pattern clustering","kernel-based projection techniques;game-changing trait;projection layout;interactive manipulation;visual space;solid mathematical formulation;high-dimensional feature space;embedding map;kernel-based techniques;pattern recognition;clustering;data classification;kernel-based methods;kernelized data","","9","","43","IEEE","5 Aug 2015","","","IEEE","IEEE Journals"
"A Data-Driven Approach for Furniture and Indoor Scene Colorization","J. Zhu; Y. Guo; H. Ma","National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2018","2018","24","9","2473","2486","We present a data-driven approach that colorizes 3D furniture models and indoor scenes by leveraging indoor images on the internet. Our approach is able to colorize the furniture automatically according to an example image. The core is to learn image-guided mesh segmentation to segment the model into different parts according to the image object. Given an indoor scene, the system supports colorization-by-example, and has the ability to recommend the colorization scheme that is consistent with a user-desired color theme. The latter is realized by formulating the problem as a Markov random field model that imposes user input as an additional constraint. Our system is able to imitate the colorization results for those scenes containing the same type of objects, but with spatially varied patterns. We contribute to the community a hierarchically organized image-model database with correspondences between each image and the corresponding model at the part-level. Our experiments and a user study show that our system produces perceptually convincing results comparable to those generated by interior designers.","1941-0506","","10.1109/TVCG.2017.2753255","National Natural Science Foundation of China(grant numbers:61373059,61672279,61772257); Natural Science Foundation of Jiangsu Province(grant numbers:BK20150016); Fundamental Research Funds for the Central Universities(grant numbers:14380034/4-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8039524","Colorization;interior design;data-driven approach;mesh segmentation","Image color analysis;Three-dimensional displays;Image segmentation;Solid modeling;Databases;Layout;Computational modeling","computer graphics;furniture;image colour analysis;image segmentation;Markov processes;mesh generation;visual databases","example image;image-guided mesh segmentation;image object;colorization-by-example;colorization scheme;user-desired color theme;Markov random field model;colorization results;hierarchically organized image-model database;data-driven approach;furniture;indoor scene colorization;indoor images;interior designers","","8","","43","IEEE","18 Sep 2017","","","IEEE","IEEE Journals"
"A Structural Average of Labeled Merge Trees for Uncertainty Visualization","L. Yan; Y. Wang; E. Munch; E. Gasparovic; B. Wang",University of Utah; Ohio State University; Michigan State University; Union College; University of Utah,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","832","842","Physical phenomena in science and engineering are frequently modeled using scalar fields. In scalar field topology, graph-based topological descriptors such as merge trees, contour trees, and Reeb graphs are commonly used to characterize topological changes in the (sub)level sets of scalar fields. One of the biggest challenges and opportunities to advance topology-based visualization is to understand and incorporate uncertainty into such topological descriptors to effectively reason about their underlying data. In this paper, we study a structural average of a set of labeled merge trees and use it to encode uncertainty in data. Specifically, we compute a 1-center tree that minimizes its maximum distance to any other tree in the set under a well-defined metric called the interleaving distance. We provide heuristic strategies that compute structural averages of merge trees whose labels do not fully agree. We further provide an interactive visualization system that resembles a numerical calculator that takes as input a set of merge trees and outputs a tree as their structural average. We also highlight structural similarities between the input and the average and incorporate uncertainty information for visual exploration. We develop a novel measure of uncertainty, referred to as consistency, via a metric-space view of the input trees. Finally, we demonstrate an application of our framework through merge trees that arise from ensembles of scalar fields. Our work is the first to employ interleaving distances and consistency to study a global, mathematically rigorous, structural average of merge trees in the context of uncertainty visualization.","1941-0506","","10.1109/TVCG.2019.2934242","NSF(grant numbers:CCF-1740761,CCF-1907591,CMMI-1562012,DBI-1661375,IIS-1513616,RI-1815697,DMS-1547357); NIH(grant numbers:R01EB022899,1R01EB022876); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794553","Topological data analysis;uncertainty visualization;merge trees","Uncertainty;Data visualization;Vegetation;Topology;Visualization;Measurement uncertainty","computational geometry;data analysis;data visualisation;interactive systems;trees (mathematics)","structural average;labeled merge trees;uncertainty visualization;scalar field topology;graph-based topological descriptors;topology-based visualization;1-center tree;interleaving distance;interactive visualization system;topological data analysis;topological data visualization","","8","","81","IEEE","12 Aug 2019","","","IEEE","IEEE Journals"
"A Visual Analytics Framework for Spatiotemporal Trade Network Analysis","H. Wang; Y. Lu; S. T. Shutters; M. Steptoe; F. Wang; S. Landis; R. Maciejewski",Arizona State University; Arizona State University; Arizona State University; Arizona State University; GE Global Research; University of Nevada; Arizona State University,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","331","341","Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.","1941-0506","","10.1109/TVCG.2018.2864844","U.S. Department of Homeland Security(grant numbers:2017-ST-061-QA0001); National Science Foundation(grant numbers:1350573,1639227); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440040","Global trade network;anomaly detection;visual analytics","Data visualization;Visual analytics;Correlation;Anomaly detection;Time series analysis;Spatiotemporal phenomena","data analysis;data visualisation;economics;financial data processing;globalisation;international trade;time series","regional instability measures;international global trade;visual analytics framework;spatiotemporal trade network analysis;economic globalization;supply chains;supply shocks;network-induced vulnerability;political science;environmental studies;global trade networks;multivariate nature;spatiotemporal nature;network structure;exploratory data analysis;multiview framework;network analytics;spatiotemporal visualization methods;visual encoding techniques;trade goods","","8","","82","IEEE","19 Aug 2018","","","IEEE","IEEE Journals"
"Biased Average Position Estimates in Line and Bar Graphs: Underestimation, Overestimation, and Perceptual Pull","C. Xiong; C. R. Ceja; C. J. H. Ludwig; S. Franconeri",Northwestern University; Northwestern University; University of Bristol; Northwestern University,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","301","310","In visual depictions of data, position (i.e., the vertical height of a line or a bar) is believed to be the most precise way to encode information compared to other encodings (e.g., hue). Not only are other encodings less precise than position, but they can also be prone to systematic biases (e.g., color category boundaries can distort perceived differences between hues). By comparison, position's high level of precision may seem to protect it from such biases. In contrast, across three empirical studies, we show that while position may be a precise form of data encoding, it can also produce systematic biases in how values are visually encoded, at least for reports of average position across a short delay. In displays with a single line or a single set of bars, reports of average positions were significantly biased, such that line positions were underestimated and bar positions were overestimated. In displays with multiple data series (i.e., multiple lines and/or sets of bars), this systematic bias still persisted. We also observed an effect of “perceptual pull”, where the average position estimate for each series was `pulled' toward the other. These findings suggest that, although position may still be the most precise form of visual data encoding, it can also be systematically biased.","1941-0506","","10.1109/TVCG.2019.2934400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805427","Perceptual biases;perception and cognition;cue combination;bar graphs;line graphs;position estimation","Bars;Data visualization;Visualization;Encoding;Systematics;Image color analysis;Task analysis","data visualisation;estimation theory;graph theory;image colour analysis","multiple data series;systematic bias;perceptual pull;visual data encoding;bar graphs;overestimation;color category boundaries;line positions;bar positions;biased average position estimation","","8","","34","IEEE","19 Aug 2019","","","IEEE","IEEE Journals"
"Binary Mesh Partitioning for Cache-Efficient Visualization","M. Tchiboukdjian; V. Danjean; B. Raffin","CNRS and CEA/DAM, DIF, ENSIGMAG-Antenne de Montbonnot, Montbonnot Saint Martin; Grenoble Universités and LIG, ENSIGMAG-Antenne de Montbonnot, Montbonnot Saint Martin; INRIA and LIG, ENSIGMAG-Antenne de Montbonnot, Montbonnot Saint Martin","IEEE Transactions on Visualization and Computer Graphics","8 Jul 2010","2010","16","5","815","828","One important bottleneck when visualizing large data sets is the data transfer between processor and memory. Cacheaware (CA) and cache-oblivious (CO) algorithms take into consideration the memory hierarchy to design cache efficient algorithms. CO approaches have the advantage to adapt to unknown and varying memory hierarchies. Recent CA and CO algorithms developed for 3D mesh layouts significantly improve performance of previous approaches, but they lack of theoretical performance guarantees. We present in this paper a O(N log N) algorithm to compute a CO layout for unstructured but well shaped meshes. We prove that a coherent traversal of a JV-size mesh in dimension d induces less than N/B + O(N/M<sup>1/d</sup>) cache-misses where B and M are the block size and the cache size, respectively. Experiments show that our layout computation is faster and significantly less memory consuming than the best known CO algorithm. Performance is comparable to this algorithm for classical visualization algorithm access patterns, or better when the BSP tree produced while computing the layout is used as an acceleration data structure adjusted to the layout. We also show that cache oblivious approaches lead to significant performance increases on recent GPU architectures.","1941-0506","","10.1109/TVCG.2010.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383356","Cache-aware;cache-oblivious;mesh layouts;data locality;unstructured mesh;isosurface extraction.","Partitioning algorithms;Data visualization;Data structures;Data mining;Filling;Algorithm design and analysis;Acceleration;Tree data structures;Computer architecture;Isosurfaces","cache storage;data visualisation;mesh generation","binary mesh partitioning;cache efficient visualization;data transfer;cacheaware algorithms;cache oblivious algorithms;3D mesh layouts;data structure acceleration;GPU architectures","","8","","32","","15 Jan 2010","","","IEEE","IEEE Journals"
"Compressed Facade Displacement Maps","S. Ali; J. Ye; A. Razdan; P. Wonka","AMD, Santa Clara; Arizona State University, Tempe; Arizona State University, Tempe; Arizona State University, Tempe","IEEE Transactions on Visualization and Computer Graphics","20 Jan 2009","2009","15","2","262","273","We describe an approach to render massive urban models. To prevent a memory transfer bottleneck we propose to render the models from a compressed representation directly. Our solution is based on rendering crude building outlines as polygons and generating details by ray-tracing displacement maps in the fragment shader. We demonstrate how to compress a displacement map so that a decompression algorithm can selectively and quickly access individual entries in a fragment shader. Our prototype implementation shows how a massive urban model can be compressed by a factor of 85 and outperform a basic geometry-based renderer by a factor of 50 to 80 in rendering speed.","1941-0506","","10.1109/TVCG.2008.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4585376","Display algorithms;Raytracing;Displacement Mapping;GPU Raytracing;Display algorithms;Raytracing;Displacement Mapping;GPU Raytracing","Data structures;Acceleration;Urban planning;Ray tracing;Rendering (computer graphics);Compression algorithms;Prototypes;Layout;Graphics;Libraries","architectural CAD;computational geometry;data compression;engineering graphics;ray tracing;rendering (computer graphics);solid modelling;storage management","compressed facade displacement map;massive urban model rendering;memory transfer bottleneck;polygon rendering;ray tracing;fragment shader;decompression algorithm;geometry-based rendering","","8","6","53","","1 Aug 2008","","","IEEE","IEEE Journals"
"CourtTime: Generating Actionable Insights into Tennis Matches Using Visual Analytics","T. Polk; D. Jäckle; J. Häußler; J. Yang",University of Konstanz; University of Konstanz; University of Konstanz; University of North Carolina,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","397","406","Tennis players and coaches of all proficiency levels seek to understand and improve their play. Summary statistics alone are inadequate to provide the insights players need to improve their games. Spatio-temporal data capturing player and ball movements is likely to provide the actionable insights needed to identify player strengths, weaknesses, and strategies. To fully utilize this spatio-temporal data, we need to integrate it with domain-relevant context meta-data. In this paper, we propose CourtTime, a novel approach to perform data-driven visual analysis of individual tennis matches. Our visual approach introduces a novel visual metaphor, namely 1-D Space-Time Charts that enable the analysis of single points at a glance based on small multiples. We also employ user-driven sorting and clustering techniques and a layout technique that aligns the last few shots in a point to facilitate shot pattern discovery. We discuss the usefulness of CourtTime via an extensive case study and report on feedback from an amateur tennis player and three tennis coaches.","1941-0506","","10.1109/TVCG.2019.2934243","DFG(grant numbers:422037984); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795584","Visual analytics;tennis analysis;sports analytics;spatio-temporal analysis","Sports;Visual analytics;Spatial databases;Games;Data visualization;Tracking","data analysis;data visualisation;pattern clustering;sport;statistics","visual metaphor;1-D Space-Time Charts;CourtTime;amateur tennis player;tennis coaches;actionable insights;visual analytics;tennis players;summary statistics;spatio-temporal data;data-driven visual analysis;tennis matches;visual approach;user-driven sorting;clustering techniques","","8","","40","IEEE","13 Aug 2019","","","IEEE","IEEE Journals"
"Drawing Large Graphs by Multilevel Maxent-Stress Optimization","H. Meyerhenke; M. Nöllenburg; C. Schulz","Institute of Theoretical Informatics, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Algorithms and Complexity Group, TU Wien, Vienna, Wien, Austria; Department of Computer Science, University of Vienna, Wien, Austria","IEEE Transactions on Visualization and Computer Graphics","27 Mar 2018","2018","24","5","1814","1827","Drawing large graphs appropriately is an important step for the visual analysis of data from real-world networks. Here we present a novel multilevel algorithm to compute a graph layout with respect to the maxent-stress metric proposed by Gansner et al. (2013) that combines layout stress and entropy. As opposed to previous work, we do not solve the resulting linear systems of the maxent-stress metric with a typical numerical solver. Instead we use a simple local iterative scheme within a multilevel approach. To accelerate local optimization, we approximate long-range forces and use shared-memory parallelism. Our experiments validate the high potential of our approach, which is particularly appealing for dynamic graphs. In comparison to the previously best maxent-stress optimizer, which is sequential, our parallel implementation is on average 30 times faster already for static graphs (and still faster if executed on a single thread) while producing a comparable solution quality.","1941-0506","","10.1109/TVCG.2017.2689016","DFG; DFG(grant numbers:ME 3619/3-1,SA 933/10-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889042","Graph layout;algorithm engineering;multilevel algorithm","Layout;Stress;Computational modeling;Approximation algorithms;Linear systems;Force;Optimization","approximation theory;data analysis;data visualisation;entropy;graph theory;iterative methods;optimisation;parallel processing;shared memory systems","multilevel maxent-stress optimization;real-world networks;graph layout;layout stress;entropy;multilevel approach;local optimization;shared-memory parallelism;dynamic graphs;multilevel algorithm;local iterative scheme;long-range forces approximation;graphs drawing;visual analysis","","8","","44","IEEE","29 Mar 2017","","","IEEE","IEEE Journals"
"Efficient Space Skipping and Adaptive Sampling of Unstructured Volumes Using Hardware Accelerated Ray Tracing","N. Morrical; W. Usher; I. Wald; V. Pascucci","University of Utah,SCI Institute; University of Utah,SCI Institute; NVIDIA; University of Utah,SCI Institute","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","256","260","Sample based ray marching is an effective method for direct volume rendering of unstructured meshes. However, sampling such meshes remains expensive, and strategies to reduce the number of samples taken have received relatively little attention. In this paper, we introduce a method for rendering unstructured meshes using a combination of a coarse spatial acceleration structure and hardware-accelerated ray tracing. Our approach enables efficient empty space skipping and adaptive sampling of unstructured meshes, and outperforms a reference ray marcher by up to 7×.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933539","Volume rendering;space skipping;adaptive sampling","Hardware;Acceleration;Ray tracing;Rendering (computer graphics);Geometry;Transfer functions;Graphics processing units","mesh generation;ray tracing;rendering (computer graphics)","adaptive sampling;unstructured volumes;hardware accelerated ray tracing;sample based ray marching;direct volume rendering;unstructured meshes;coarse spatial acceleration structure;reference ray marcher;space skipping","","8","","35","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data","R. Krueger; J. Beyer; W. -D. Jang; N. W. Kim; A. Sokolov; P. K. Sorger; H. Pfister","School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Laboratory of Systems Pharmacology, Harvard Medical School, Boston, MA, USA; Laboratory of Systems Pharmacology, Harvard Medical School, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","227","237","Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 109 or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.","1941-0506","","10.1109/TVCG.2019.2934547","NCI(grant numbers:U54-CA225088); King Abdullah University of Science and Technology; OSR(grant numbers:OSR-2015-CCF-2533-0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827951","Clustering;Classification;Visual Analysis;Multiplex Tissue Imaging;Digital Pathology;Cancer Systems Biology","Cancer;Tools;Visualization;Rendering (computer graphics);Biomedical imaging;Multiplexing","biomedical optical imaging;cancer;cellular biophysics;data analysis;data visualisation;diseases;feature extraction;fluorescence;genetics;image classification;image segmentation;learning (artificial intelligence);medical image processing;neural nets;pattern clustering;tumours","unsupervised learning;supervised learning;hierarchical phenotype analysis;multichannel image data;scalable visual analytics application;single-cell phenotypes;high-dimensional multichannel microscopy images;human tumors;cutting edge;digital histology;highly multiplexed tissue images;comprising 109 pixels;more pixels;individual cells;manual analysis;automated approaches;human tissue biology;cell types;analytical provenance;immune cells;aggregate patterns;phenotype subsets;hierarchical approach;analysis steps;phenotype trees;resulting hierarchical structures;high-dimensional feature;Facetto assists;classification process;cancer biology","Cluster Analysis;Humans;Image Interpretation, Computer-Assisted;Machine Learning;Neoplasms;Neural Networks, Computer;Phenotype;Software;Systems Biology","8","","70","IEEE","10 Sep 2019","","","IEEE","IEEE Journals"
"Facial Expression Retargeting From Human to Avatar Made Easy","J. Zhang; K. Chen; J. Zheng","School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China; School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1274","1287","Facial expression retargeting from humans to virtual characters is a useful technique in computer graphics and animation. Traditional methods use markers or blendshapes to construct a mapping between the human and avatar faces. However, these approaches require a tedious 3D modeling process, and the performance relies on the modelers’ experience. In this article, we propose a brand-new solution to this cross-domain expression transfer problem via nonlinear expression embedding and expression domain translation. We first build low-dimensional latent spaces for the human and avatar facial expressions with variational autoencoder. Then we construct correspondences between the two latent spaces guided by geometric and perceptual constraints. Specifically, we design geometric correspondences to reflect geometric matching and utilize a triplet data structure to express users’ perceptual preference of avatar expressions. A user-friendly method is proposed to automatically generate triplets for a system allowing users to easily and efficiently annotate the correspondences. Using both geometric and perceptual correspondences, we trained a network for expression domain translation from human to avatar. Extensive experimental results and user studies demonstrate that even nonprofessional users can apply our method to generate high-quality facial expression retargeting results with less time and effort.","1941-0506","","10.1109/TVCG.2020.3013876","National Natural Science Foundation of China(grant numbers:61672481); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2018495); Zhejiang Lab(grant numbers:2019NB0AB03); Data Science and Artificial Intelligence Research Centre, Nanyang Technological University(grant numbers:04INS000518C130); Ministry of Education - Singapore(grant numbers:MoE 2017-T2-1- 076); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157962","Facial expression retargeting;variational autoencoder;deformation transfer;cross domain translation;triplet","Avatars;Three-dimensional displays;Strain;Animation;Shape;Solid modeling;Machine learning","avatars;computer animation;data structures;face recognition;learning (artificial intelligence);video signal processing","expression domain translation;low-dimensional latent spaces;human expressions;avatar facial expressions;geometric constraints;perceptual constraints;design geometric correspondences;users;avatar expressions;user-friendly method;perceptual correspondences;high-quality facial expression;facial expression retargeting;avatar made easy;human faces;avatar faces;tedious 3D modeling process;modelers;cross-domain expression transfer problem;nonlinear expression embedding","Computer Graphics;Facial Expression;Humans;User-Computer Interface","8","","52","IEEE","4 Aug 2020","","","IEEE","IEEE Journals"
"Hi-Trees and Their Layout","K. Marriott; P. Sbarski; T. van Gelder; D. Prager; A. Bulka","Monash University, Clayton; 1/42 Elizabeth Str, Bentleigh East; Austhink Consulting, Melbourne; Austhink Software, Victoria; Magian Design Studio, Wyndham Vale","IEEE Transactions on Visualization and Computer Graphics","10 Jan 2011","2011","17","3","290","304","We introduce hi-trees, a new visual representation for hierarchical data in which, depending on the kind of parent node, the child relationship is represented using either containment or links. We give a drawing convention for hi-trees based on the standard layered drawing convention for rooted trees, then show how to extend standard bottom-up tree layout algorithms to draw hi-trees in this convention. We also explore a number of other more compact layout styles for layout of larger hi-trees and give algorithms for computing these. Finally, we describe two applications of hi-trees: argument mapping and business decision support.","1941-0506","","10.1109/TVCG.2010.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432168","Tree layout;hi-tree;argument mapping;decision support;information visualization.","Standards development;Data visualization;Electronic mail;Compaction;Decision making;Economic indicators","tree data structures;trees (mathematics)","hi-trees;hierarchical data visual representation;standard layered drawing convention;rooted trees;standard bottom-up tree layout algorithms;argument mapping;business decision support","Algorithms;Computational Biology;Decision Trees","8","","24","","18 Mar 2010","","","IEEE","IEEE Journals"
"Learning Discriminative 3D Shape Representations by View Discerning Networks","B. Leng; C. Zhang; X. Zhou; C. Xu; K. Xu","School of Computer Science & Engineering, Beihang University, Beijing, P.R. China; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; School of Engineering and Applied Science, Washington University in St. Louis, St. Louis, Missouri, MO, USA; School of Computer Science & Engineering, Beihang University, Beijing, P.R. China; School of Computer, National University of Defense Technology, Changsha, P.R. China","IEEE Transactions on Visualization and Computer Graphics","2 Sep 2019","2019","25","10","2896","2909","In view-based 3D shape recognition, extracting discriminative visual representation of 3D shapes from projected images is considered the core problem. Projections with low discriminative ability can adversely influence the final 3D shape representation. Especially under the real situations with background clutter and object occlusion, the adverse effect is even more severe. To resolve this problem, we propose a novel deep neural network, View Discerning Network, which learns to judge the quality of views and adjust their contributions to the representation of shapes. In this network, a Score Generation Unit is devised to evaluate the quality of each projected image with score vectors. These score vectors are used to weight the image features and the weighted features perform much better than original features in 3D shape recognition task. In particular, we introduce two structures of Score Generation Unit, Channel-wise Score Unit and Part-wise Score Unit, to assess the quality of feature maps from different perspectives. Our network aggregates features and scores in an end-to-end framework, so that final shape descriptors are directly obtained from its output. Our experiments on ModelNet and ShapeNet Core55 show that View Discerning Network outperforms the state-of-the-arts in terms of the retrieval task, with excellent robustness against background clutter and object occlusion.","1941-0506","","10.1109/TVCG.2018.2865317","National Natural Science Foundation of China(grant numbers:61472023,61532003,61572507,61622212); Beijing Municipal Natural Science Foundation(grant numbers:4182034); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439008","View-based 3D shape recognition;convolutional neural network;image quality judgment","Shape;Three-dimensional displays;Feature extraction;Task analysis;Computational modeling;Clutter;Solid modeling","clutter;feature extraction;image representation;learning (artificial intelligence);neural nets;shape recognition","final 3D shape representation;discriminative visual representation;view-based 3D shape recognition;View Discerning networks;discriminative 3D shape representations;background clutter;final shape descriptors;network aggregates features;Part-wise Score Unit;Channel-wise Score Unit;3D shape recognition task;weighted features;image features;score vectors;projected image;Score Generation Unit;View Discerning Network;deep neural network;object occlusion","","8","","46","IEEE","17 Aug 2018","","","IEEE","IEEE Journals"
"Mesh-Guided Optimized Retexturing for Image and Video","Y. Guo; H. Sun; Q. Peng; Z. Jiang","Nanjing Univ., Nanjing; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","21 Jan 2008","2008","14","2","426","439","This paper presents a novel approach for replacing textures of specified regions in the input image and video using stretch-based mesh optimization. The retexturing results have the similar distortion and shading effect conforming to the unknown underlying geometry and lighting conditions. For replacing textures in a single image, two important steps are developed: The stretch-based mesh parameterization incorporating the recovered normal information is deduced to imitate perspective distortion of the region of interest; the Poisson-based refinement process is exploited to account for texture distortion at fine scale. The luminance of the input image is preserved through color transfer in YCbCr color space. Our approach is independent of the replaced textures. Once the input image is processed, any new textures can be applied to efficiently generate the retexturing results. For video retexturing, we propose key-frame-based texture replacement extended and generalized from the image retexturing. Our approach repeatedly propagates the replacement results of key frames to the rest of the frames. We develop the local motion optimization scheme to deal with the inaccuracies and errors of robust optical flow when tracking moving objects. Visibility shifting and texture drifting are effectively alleviated using graphcut segmentation algorithm and the global optimization to smooth trajectories of the tracked points over temporal domain. Our experimental results showed that the proposed approach can generate visually pleasing results for retextured images and video.","1941-0506","","10.1109/TVCG.2007.70438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359506","Picture/Image Generation;Color;shading;shadowing;and texture;Image Processing and Computer Vision;Picture/Image Generation;Color;shading;shadowing;and texture;Image Processing and Computer Vision","Geometry;Surface texture;Image segmentation;Visual effects;Light sources;Data mining;Sun;Mesh generation;Optical propagation;Robustness","graph theory;image colour analysis;image motion analysis;image segmentation;image texture;stochastic processes;video signal processing","mesh-guided optimized retexturing;image textures;video textures;stretch-based mesh optimization;shading effect;underlying geometry;Poisson-based refinement process;color transfer;YCbCr color space;key-frame-based texture replacement;local motion optimization scheme;robust optical flow;moving objects tracking;graphcut segmentation algorithm;smooth trajectories","","8","7","43","","21 Jan 2008","","","IEEE","IEEE Journals"
"Nonuniform Timeslicing of Dynamic Graphs Based on Visual Complexity","Y. Wang; D. Archambault; H. Haleem; T. Moeller; Y. Wu; H. Qu",HKUST; Swansea University; HKUST; University of Vienna; Visa Research; HKUST,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Uniform timeslicing of dynamic graphs has been used due to its convenience and uniformity across the time dimension. However, uniform timeslicing does not take the data set into account, which can generate cluttered timeslices with edge bursts and empty times-lices with few interactions. The graph mining filed has explored nonuniform timeslicing methods specifically designed to preserve graph features for mining tasks. In this paper, we propose a nonuniform timeslicing approach for dynamic graph visualization. Our goal is to create timeslices of equal visual complexity. To this end, we adapt histogram equalization to create timeslices with a similar number of events, balancing the visual complexity across timeslices and conveying more important details of timeslices with bursting edges. A case study has been conducted, in comparison with uniform timeslicing, to demonstrate the effectiveness of our approach.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933748","Human-centered computing;Visualization;Visu-alization techniques;Graph Visualization","Visualization;Complexity theory;Histograms;Heuristic algorithms;Data mining;Data visualization;Animation","computational complexity;data mining;data visualisation;graph theory","graph mining;nonuniform timeslicing methods;dynamic graph visualization;equal visual complexity","","8","","36","","19 Dec 2019","","","IEEE","IEEE Conferences"
"PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning","T. Tang; R. Li; X. Wu; S. Liu; J. Knittel; S. Koch; T. Ertl; L. Yu; P. Ren; Y. Wu",Zhejiang Lab and State Key Lab of CAD&CGZhejiang University; Zhejiang Lab and State Key Lab of CAD&CGZhejiang University; Zhejiang Lab and State Key Lab of CAD&CGZhejiang University; Zhejiang Lab and State Key Lab of CAD&CGZhejiang University; VIS/VISUSUniversity of Stuttgart; VIS/VISUSUniversity of Stuttgart; VIS/VISUSUniversity of Stuttgart; Department of Computer Science and Software EngineeringXi 'an Jiaotong-Liverpool University.; Alibaba Group; Zhejiang Lab and State Key Lab of CAD&CGZhejiang University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","294","303","Storyline visualizations are an effective means to present the evolution of plots and reveal the scenic interactions among characters. However, the design of storyline visualizations is a difficult task as users need to balance between aesthetic goals and narrative constraints. Despite that the optimization-based methods have been improved significantly in terms of producing aesthetic and legible layouts, the existing (semi-) automatic methods are still limited regarding 1) efficient exploration of the storyline design space and 2) flexible customization of storyline layouts. In this work, we propose a reinforcement learning framework to train an AI agent that assists users in exploring the design space efficiently and generating well-optimized storylines. Based on the framework, we introduce PlotThread, an authoring tool that integrates a set of flexible interactions to support easy customization of storyline visualizations. To seamlessly integrate the AI agent into the authoring process, we employ a mixed-initiative approach where both the agent and designers work on the same canvas to boost the collaborative design of storylines. We evaluate the reinforcement learning model through qualitative and quantitative experiments and demonstrate the usage of PlotThread using a collection of use cases.","1941-0506","","10.1109/TVCG.2020.3030467","Joint Sino-German program of NSFC(grant numbers:61761136020); National Key R&D Program of China(grant numbers:2018YFB1004300); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:U1609217); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); Microsoft Research Asia; XJTLU Research Development Funding(grant numbers:RDF-19-02-11); German Science Foundation (DFG)(grant numbers:392087235); Sino-German program of NSFC(grant numbers:(61761136020)); National Key R&D Program of China(grant numbers:(2018YFB 1004300)); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:(U1609217)); Zhejiang Provincial Natural Science Foundation(grant numbers:(LR18F020001)); Talents Program of Zhejiang University. This project was also partially funded by Microsoft Research Asia. Lingyun Yu is supported by XJTLU Research Development Funding RDF-19-02-11. Parts of this work were funded by German Science Foundation (DFG) as part of the project 'VAOST’(grant numbers:(392087235)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222335","Storyline visualization;reinforcement learning;mixed-initiative design","Layout;Visualization;Reinforcement learning;Collaboration;Task analysis;Optimization","data visualisation;learning (artificial intelligence);neural nets;optimisation","reinforcement learning model;PlotThread;storyline visualizations;optimization-based methods;aesthetic layouts;legible layouts;storyline design space;storyline layouts;AI agent;well-optimized storylines;mixed-initiative approach","","8","","50","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams","A. Cohé; B. Liutkus; G. Bailly; J. Eagan; E. Lecolinet",Télécom ParisTech; Télécom ParisTech; CNRS LTCI & Télécom ParisTech; Télécom ParisTech; Télécom ParisTech,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","330","338","System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology.","1941-0506","","10.1109/TVCG.2015.2467035","French ANR/Investissement d’ Avenir “Cluster Connexion.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192681","Fisheye;vector-scaling;content-aware;network schematics;interactive zoom;navigation;information visualization;Fisheye;vector-scaling;content-aware;network schematics;interactive zoom;navigation;information visualization","Lenses;Distortion;Navigation;Visualization;Context;Layout;Shape","data visualisation;distortion;lenses;topology;vectors","SchemeLens;content-aware vector-based fisheye technique;large systems diagrams navigation;system schematics;electrical systems;hydraulic systems;large documents navigation;focus region;diagram readability;topology-aware fisheye technique;vector-based scaling;components distortion;layout distortion;topology structure;topology orthogonality;topology alignment;user intention;network diagram;information visualization","","8","","33","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Scribble-Based 3D Shape Segmentation via Weakly-Supervised Learning","Z. Shu; X. Shen; S. Xin; Q. Chang; J. Feng; L. Kavan; L. Liu","School of Computer and Data Engineering, Ningbo Institute of Technology, Zhejiang University, Ningbo, PR China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, PR China; School of Computer Science and Technology, ShanDong University, Jinan, PR China; School of Computer and Data Engineering, Ningbo Institute of Technology, Zhejiang University, Ningbo, PR China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, PR China; School of Computing, University of Utah, Salt Lake City, USA; Graphics & Geometric Computing Laboratory, School of Mathematical Sciences, University of Science and Technology of China, Anhui, PR China","IEEE Transactions on Visualization and Computer Graphics","2 Jul 2020","2020","26","8","2671","2682","Shape segmentation is a fundamental problem in shape analysis. Previous research shows that prior knowledge helps to improve the segmentation accuracy and quality. However, completely labeling each 3D shape in a large training data set requires a heavy manual workload. In this paper, we propose a novel weakly-supervised algorithm for segmenting 3D shapes using deep learning. Our method jointly propagates information from scribbles to unlabeled faces and learns deep neural network parameters. Therefore, it does not rely on completely labeled training shapes and only needs a really simple and convenient scribble-based partially labeling process, instead of the extremely time-consuming and tedious fully labeling processes. Various experimental results demonstrate the proposed method's superior segmentation performance over the previous unsupervised approaches and comparable segmentation performance to the state-of-the-art fully supervised methods.","1941-0506","","10.1109/TVCG.2019.2892076","National Natural Science Foundation of China(grant numbers:61872321,61672482,11626253,61732015,61772016,61572022); National Science Foundation(grant numbers:IIS-1617172,IIS-1622360); Natural Science Foundation of Zhejiang Province(grant numbers:LY17F020018); Natural Science Foundation of Ningbo(grant numbers:2018A610161); Ningbo Leader and Top-notch Talent Training Project(grant numbers:NBLJ201801010); intelligent big data engineering application for life and health(grant numbers:2016C11024); Fundamental Research Funds of Shandong University; Open Project Program of the State Key Lab of CAD & CG(grant numbers:A1702); Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607113","3D shapes;segmentation;scribble;weakly-supervised;deep learning","Shape;Three-dimensional displays;Training;Labeling;Training data;Solid modeling;Deep learning","image segmentation;neural nets;shape recognition;stereo image processing;supervised learning","shape analysis;deep learning;deep neural network;scribble-based 3D shape segmentation;scribble-based partially labeling process;weakly-supervised learning","","8","","40","IEEE","10 Jan 2019","","","IEEE","IEEE Journals"
"TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization","J. Han; C. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","205","215","We present TSR-TVD, a novel deep learning framework that generates temporal super-resolution (TSR) of time-varying data (TVD) using adversarial learning. TSR-TVD is the first work that applies the recurrent generative network (RGN), a combination of the recurrent neural network (RNN) and generative adversarial network (GAN), to generate temporal high-resolution volume sequences from low-resolution ones. The design of TSR-TVD includes a generator and a discriminator. The generator takes a pair of volumes as input and outputs the synthesized intermediate volume sequence through forward and backward predictions. The discriminator takes the synthesized intermediate volumes as input and produces a score indicating the realness of the volumes. Our method handles multivariate data as well where the trained network from one variable is applied to generate TSR for another variable. To demonstrate the effectiveness of TSR-TVD, we show quantitative and qualitative results with several time-varying multivariate data sets and compare our method against standard linear interpolation and solutions solely based on RNN or CNN.","1941-0506","","10.1109/TVCG.2019.2934255","U.S. National Science Foundation(grant numbers:IIS-1455886,CNS-1629914,DUE-1833129); NVIDIA GPU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802285","Time-varying data visualization;super-resolution;deep learning;recurrent generative network","Gallium nitride;Data visualization;Deep learning;Spatial resolution;Training;Generators;Generative adversarial networks","data analysis;data visualisation;learning (artificial intelligence);recurrent neural nets","TSR-TVD;temporal super-resolution;time-varying data analysis;recurrent generative network;generative adversarial network;time-varying multivariate data sets;time-varying data visualization;recurrent neural network;RGN;RNN;GAN;deep learning","","8","","62","IEEE","15 Aug 2019","","","IEEE","IEEE Journals"
"TeleGam: Combining Visualization and Verbalization for Interpretable Machine Learning","F. Hohman; A. Srinivasan; S. M. Drucker",Georgia Institute of Technology; Georgia Institute of Technology; Microsoft Research,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","151","155","While machine learning (ML) continues to find success in solving previously-thought hard problems, interpreting and exploring ML models remains challenging. Recent work has shown that visualizations are a powerful tool to aid debugging, analyzing, and interpreting ML models. However, depending on the complexity of the model (e.g., number of features), interpreting these visualizations can be difficult and may require additional expertise. Alternatively, textual descriptions, or verbalizations, can be a simple, yet effective way to communicate or summarize key aspects about a model, such as the overall trend in a model's predictions or comparisons between pairs of data instances. With the potential benefits of visualizations and verbalizations in mind, we explore how the two can be combined to aid ML interpretability. Specifically, we present a prototype system, TeleGam, that demonstrates how visualizations and verbalizations can collectively support interactive exploration of ML models, for example, generalized additive models (GAMs). We describe TELEGAM's interface and underlying heuristics to generate the verbalizations. We conclude by discussing how TeleGam can serve as a platform to conduct future studies for understanding user expectations and designing novel interfaces for interpretable ML.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933695","Human-centered computing;Visual Analytics","Data models;Data visualization;Predictive models;Analytical models;Shape;Natural languages;Additives","data visualisation;interactive systems;learning (artificial intelligence);program debugging;user interfaces","TeleGam;visualization;verbalization;interpretable machine learning;hard problems;ML models;verbalizations;ML interpretability;interactive exploration;generalized additive models;heuristics;interpretable ML","","8","","41","","19 Dec 2019","","","IEEE","IEEE Conferences"
"V<sc>i</sc>B<sc>r</sc>: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle","G. Y. -Y. Chan; P. Xu; Z. Dai; L. Ren","New York University; Bosch Research North America, Sunnyvale; Bosch Research North America, Sunnyvale; Bosch Research North America, Sunnyvale","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","321","330","Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people's affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.","1941-0506","","10.1109/TVCG.2018.2864826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440048","Bipartite Graph;Visual Summarization;Minimum Description Length;Information Theory","Data visualization;Bipartite graph;Visualization;Clustering algorithms;Complexity theory;Data models;Noise measurement","data analysis;data visualisation;graph theory;pattern clustering","minimum description length principle;bipartite graphs model;balanced granularity;visual analytics framework;interactive data exploration;synthetic data;roll-call vote record analysis;vehicle fault pattern analysis;social groups;visual design;visual summarization technique;people affiliation;ViBr;interactive time constraints;bipartite relation visualization;legislators voting;MDL;co-clustering problem;locality sensitive hashing;LSH;political science community;automotive industry;customer purchasing items","","8","","47","IEEE","19 Aug 2018","","","IEEE","IEEE Journals"
"Volumetric Isosurface Rendering with Deep Learning-Based Super-Resolution","S. Weiss; M. Chu; N. Thuerey; R. Westermann","Technical University of Munich, München, Germany; Technical University of Munich, München, Germany; Technical University of Munich, München, Germany; Technical University of Munich, München, Germany","IEEE Transactions on Visualization and Computer Graphics","12 May 2021","2021","27","6","3064","3078","Rendering an accurate image of an isosurface in a volumetric field typically requires large numbers of data samples. Reducing this number lies at the core of research in volume rendering. With the advent of deep learning networks, a number of architectures have been proposed recently to infer missing samples in multidimensional fields, for applications such as image super-resolution. In this article, we investigate the use of such architectures for learning the upscaling of a low resolution sampling of an isosurface to a higher resolution, with reconstruction of spatial detail and shading. We introduce a fully convolutional neural network, to learn a latent representation generating smooth, edge-aware depth and normal fields as well as ambient occlusions from a low resolution depth and normal field. By adding a frame-to-frame motion loss into the learning stage, upscaling can consider temporal variations and achieves improved frame-to-frame coherence. We assess the quality of inferred results and compare it to bi-linear and cubic upscaling. We do this for isosurfaces which were never seen during training, and investigate the improvements when the network can train on the same or similar isosurfaces. We discuss remote visualization and foveated rendering as potential applications.","1941-0506","","10.1109/TVCG.2019.2956697","ERC(grant numbers:StG-2015-637014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918030","Machine learning;extraction of surfaces (isosurfaces, material boundaries);volume rendering","Isosurfaces;Image reconstruction;Spatial resolution;Signal resolution;Rendering (computer graphics);Training","data visualisation;image reconstruction;image resolution;image sampling;learning (artificial intelligence);neural nets;rendering (computer graphics)","frame-to-frame coherence;learning stage;frame-to-frame motion loss;low resolution depth;normal field;smooth edge-aware depth;fully convolutional neural network;low resolution sampling;image super-resolution;multidimensional fields;missing samples;deep learning networks;volume rendering;data samples;volumetric field;accurate image;deep learning-based super-resolution;volumetric isosurface rendering;similar isosurfaces;same isosurfaces;cubic upscaling;inferred results","","8","","59","IEEE","29 Nov 2019","","","IEEE","IEEE Journals"
"A Framework for Holographic Scene Representation and Image Synthesis","R. Ziegler; P. Kaufmann; M. Gross","ETH Zentrum, IFW D27.1, Haldeneggsteig 4, 8092 Zurich, Switzerland; NA; ETH Zentrum, IFW D28.1, Haldeneggsteig 4, 8092 Zurich, Switzerland","IEEE Transactions on Visualization and Computer Graphics","22 Jan 2007","2007","13","2","403","415","We present a framework for the holographic representation and display of graphics objects. As opposed to traditional graphics representations, our approach reconstructs the light wave reflected or emitted by the original object directly from the underlying digital hologram. Our novel holographic graphics pipeline consists of several stages including the digital recording of a full-parallax hologram, the reconstruction and propagation of its wavefront, and rendering of the final image onto conventional, framebuffer-based displays. The required view-dependent depth image is computed from the phase information inherently represented in the complex-valued wavefront. Our model also comprises a correct physical modeling of the camera taking into account optical elements, such as lens and aperture. It thus allows for a variety of effects including depth of field, diffraction, interference, and features built-in anti-aliasing. A central feature of our framework is its seamless integration into conventional rendering and display technology which enables us to elegantly combine traditional 3D object or scene representations with holograms. The presented work includes the theoretical foundations and allows for high quality rendering of objects consisting of large numbers of elementary waves while keeping the hologram at a reasonable size","1941-0506","","10.1109/TVCG.2007.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069247","Holography;light propagation;wave;diffraction;aliasing;image synthesis;graphics representation.","Holography;Layout;Image generation;Graphics;Displays;Image reconstruction;Pipelines;Digital recording;Optical propagation;Rendering (computer graphics)","holography;image representation;rendering (computer graphics);solid modelling","holographic scene representation;image synthesis;graphics objects;light wave reflection;digital hologram;full-parallax hologram;image rendering;antialiasing;3D object;object rendering;light propagation;wave diffraction","Algorithms;Computer Graphics;Data Display;Holography;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Sensitivity and Specificity","7","7","42","","22 Jan 2007","","","IEEE","IEEE Journals"
"A Novel CNN-Based Poisson Solver for Fluid Simulation","X. Xiao; Y. Zhou; H. Wang; X. Yang","School of Software, Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2020","2020","26","3","1454","1465","Solving a large-scale Poisson system is computationally expensive for most of the Eulerian fluid simulation applications. We propose a novel machine learning-based approach to accelerate this process. At the heart of our approach is a deep convolutional neural network (CNN), with the capability of predicting the solution (pressure) of a Poisson system given the discretization structure and the intermediate velocities as input. Our system consists of four main components, namely, a deep neural network to solve the large linear equations, a geometric structure to describe the spatial hierarchies of the input vector, a Principal Component Analysis (PCA) process to reduce the dimension of input in training, and a novel loss function to control the incompressibility constraint. We have demonstrated the efficacy of our approach by simulating a variety of high-resolution smoke and liquid phenomena. In particular, we have shown that our approach accelerates the projection step in a conventional Eulerian fluid simulator by two orders of magnitude. In addition, we have also demonstrated the generality of our approach by producing a diversity of animations deviating from the original datasets.","1941-0506","","10.1109/TVCG.2018.2873375","National Natural Science Foundation of China(grant numbers:61772329,61373085); Natural Key Research and Development Program of China(grant numbers:2018YFB1004902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478400","Linear equation;poisson solver;machine learning;deep convolutional neural network","Mathematical model;Poisson equations;Sparse matrices;Linear systems;Computational modeling;Acceleration;Artificial neural networks","convolutional neural nets;flow simulation;learning (artificial intelligence);linear differential equations;physics computing;Poisson equation;principal component analysis;vectors","large-scale Poisson system;Eulerian fluid simulation applications;deep convolutional neural network;discretization structure;intermediate velocities;linear equations;geometric structure;spatial hierarchies;input vector;principal component analysis process;loss function;high-resolution smoke;CNN-based Poisson solver;machine learning-based approach;animations deviation","","7","","48","IEEE","30 Sep 2018","","","IEEE","IEEE Journals"
"A Programmable Display Layer for Virtual Reality System Architectures","F. Smit; R. van Liere; B. Froehlich","Centrum Wiskunde and Informatica (CWI), Amsterdam; Centrum Wiskunde and Informatica (CWI), Amsterdam; Bauhaus-Universität Weimar, Weimar","IEEE Transactions on Visualization and Computer Graphics","13 Nov 2009","2010","16","1","28","42","Display systems typically operate at a minimum rate of 60 Hz. However, existing VR-architectures generally produce application updates at a lower rate. Consequently, the display is not updated by the application every display frame. This causes a number of undesirable perceptual artifacts. We describe an architecture that provides a programmable display layer (PDL) in order to generate updated display frames. This replaces the default display behavior of repeating application frames until an update is available. We will show three benefits of the architecture typical to VR. First, smooth motion is provided by generating intermediate display frames by per-pixel depth-image warping using 3D motion fields. Smooth motion eliminates various perceptual artifacts due to judder. Second, we implement fine-grained latency reduction at the display frame level using a synchronized prediction of simulation objects and the viewpoint. This improves the average quality and consistency of latency reduction. Third, a crosstalk reduction algorithm for consecutive display frames is implemented, which improves the quality of stereoscopic images. To evaluate the architecture, we compare image quality and latency to that of a classic level-of-detail approach.","1941-0506","","10.1109/TVCG.2009.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5156497","Display algorithms;virtual reality;image-based rendering.","Displays;Virtual reality;Rendering (computer graphics);Delay;Hardware;Page description languages;Crosstalk;Image quality;Layout;Graphics","computer displays;rendering (computer graphics);software architecture;virtual reality","programmable display layer;virtual reality system;VR architecture;display frame generation;smooth motion;latency reduction;crosstalk reduction algorithm;display systems;frequency 60 Hz","Computer Graphics;Equipment Design;Equipment Failure Analysis;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Models, Theoretical;User-Computer Interface","7","","23","","6 Jul 2009","","","IEEE","IEEE Journals"
"Cartographic Relief Shading with Neural Networks","B. Jenny; M. Heitzler; D. Singh; M. Farmakis-Serebryakova; J. C. Liu; L. Hurni","Monash University, Melbourne; Institute of Cartography and Geoinformation, ETH, Zurich; Monash University, Melbourne; Institute of Cartography and Geoinformation, ETH, Zurich; Monash University, Melbourne; Institute of Cartography and Geoinformation, ETH, Zurich","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1225","1235","Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.","1941-0506","","10.1109/TVCG.2020.3030456","National Geographic Society; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222263","Relief shading;shaded relief;hillshade;neural rendering;illustrative visualisation;image-to-image translation","Neural networks;Lighting;Manuals;Rendering (computer graphics);Digital elevation models;Computational modeling;Visualization","cartography;digital elevation models;feature extraction;geophysical image processing;image matching;learning (artificial intelligence);neural nets;terrain mapping;topography (Earth)","cartographic relief shading;topographic maps;individual terrain features;digital shading algorithms;hand-crafted masterpieces;highly specialised cartographers;hand-drawn relief shading;U-Net neural networks;deep neural networks;manual shaded relief images;Swiss topographic map series;hand-drawn shaded relief;manual relief;unnecessary terrain details;illumination direction;neural network shadings;18 relief shading experts","","7","","82","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Comparing simplification and image-based techniques for 3D client-server rendering systems","W. Pasman; F. W. Jansen","Delft Univ. of Technol., Netherlands; Delft Univ. of Technol., Netherlands","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2003","2003","9","2","226","240","A mathematical model is presented for comparing geometric and image-based simplification methods. Geometric simplification reduces the number of polygons in the virtual object and image-based simplification replaces the object with an image. Our model integrates and extrapolates existing accuracy estimates, enabling the comparison of different simplification methods in order to choose the most efficient method in a given situation. The model compares data transfer and rendering load of the methods. Byte size and expected lifetime of simplifications are calculated as a function of the desired visual quality and the position and movement of the viewer. An example result is that, in typical viewing and rendering conditions and for objects with a radius in the order of one meter, imposter techniques can be used at viewing distances above 15 meters. Below that, simplified polygon objects are required and, below one meter distance, the full-resolution virtual object has to be rendered. An electronic version of the model is available on the web.","1941-0506","","10.1109/TVCG.2003.1196009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196009","","Rendering (computer graphics);Layout;Engines;Mathematical model;Mobile communication;Life estimation;Lifetime estimation;Geometry;Solid modeling;Bandwidth","rendering (computer graphics);client-server systems;augmented reality;bibliographies;real-time systems","3D client-server rendering systems;image-based techniques;geometric simplification methods;data transfer;rendering load;visual quality;rendering conditions;imposter techniques;full-resolution virtual object;thin client;dynamic geometry simplification;real-time rendering","","7","3","79","","29 Apr 2003","","","IEEE","IEEE Journals"
"Composition and Configuration Patterns in Multiple-View Visualizations","X. Chen; W. Zeng; Y. Lin; H. M. AI-maneea; J. Roberts; R. Chang","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Bangor University; Bangor University; Tufts University","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1514","1524","Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.","1941-0506","","10.1109/TVCG.2020.3030338","National Natural Science Foundation of China(grant numbers:61802388); National Science Foundation(grant numbers:OAC-1940175,OAC-1939945,IIS-1452977,DGE-1855886); DARPA(grant numbers:FA8750-17-2-0107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222323","Multiple views;design pattern;quantitative analysis;example-based design","Data visualization;Layout;Visualization;Tools;Task analysis;Guidelines","data visualisation","configuration patterns;multiple-view visualization;layout design;data attributes;single cohesive representation;MV design;visualization community;high-dimensional data;design space;multiple-view patterns;view types;visualization images;layout topology;MV recommendation system;example-based design;view layouts;IEEE VIS;EuroVis;PacificVis publications;term frequency;interactive tools;quantitative metrics","","7","","59","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Context-aware Sampling of Large Networks via Graph Representation Learning","Z. Zhou; C. Shi; X. Shen; L. Cai; H. Wang; Y. Liu; Y. Zhao; W. Chen","School of Information, Zhejiang University of Finance and Economics; School of Information, Zhejiang University of Finance and Economics; School of Information, Zhejiang University of Finance and Economics; School of Information, Zhejiang University of Finance and Economics; School of Information, Zhejiang University of Finance and Economics; School of Information, Zhejiang University of Finance and Economics; Central South University; State Key Lab of CAD & CGZhejiang University","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1709","1719","Numerous sampling strategies have been proposed to simplify large-scale networks for highly readable visualizations. It is of great challenge to preserve contextual structures formed by nodes and edges with tight relationships in a sampled graph, because they are easily overlooked during the process of sampling due to their irregular distribution and immunity to scale. In this paper, a new graph sampling method is proposed oriented to the preservation of contextual structures. We first utilize a graph representation learning (GRL) model to transform nodes into vectors so that the contextual structures in a network can be effectively extracted and organized. Then, we propose a multi-objective blue noise sampling model to select a subset of nodes in the vectorized space to preserve contextual structures with the retention of relative data and cluster densities in addition to those features of significance, such as bridging nodes and graph connections. We also design a set of visual interfaces enabling users to interactively conduct context-aware sampling, visually compare results with various sampling strategies, and deeply explore large networks. Case studies and quantitative comparisons based on real-world datasets have demonstrated the effectiveness of our method in the abstraction and exploration of large networks.","1941-0506","","10.1109/TVCG.2020.3030440","National Natural Science Foundation of China(grant numbers:61872314,61802339,41901363,61872388,61772456,61761136); Humanities and Social Sciences Foundation of Ministry of Education in China(grant numbers:18YJC910017); Natural Science Foundation of Zhejiang Province(grant numbers:LY18F020024,LGF20G010003); Major Humanities and Social Sciences Research Projects in Colleges of Zhejiang Province(grant numbers:2018QN021); Open Project Program of the State Key Lab of CAD&CG of Zhejiang University(grant numbers:A2001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224191","Graph sampling;Graph representation learning;Blue noise sampling;Graph evaluation","Visualization;Measurement;Sampling methods;Context modeling;Task analysis;Clutter;Layout","data visualisation;learning (artificial intelligence);network theory (graphs);pattern clustering;sampling methods;ubiquitous computing","graph sampling method;contextual structures;graph representation learning model;multiobjective blue noise sampling model;bridging nodes;graph connections;sampling strategies;large-scale networks;highly readable visualizations;sampled graph;irregular distribution;immunity;context-aware sampling;vectorized space;visual interfaces","","7","","58","IEEE","14 Oct 2020","","","IEEE","IEEE Journals"
"Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks","S. R. Gomez; R. Jianu; R. Cabeen; H. Guo; D. H. Laidlaw","Department of Computer Science, Brown University, Providence, RI; School of Computing and Information Sciences, Florida International University, Miami, FL; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2016","2017","23","2","1042","1055","We present the design and evaluation of a method for estimating gaze locations during the analysis of static visualizations using crowdsourcing. Understanding gaze patterns is helpful for evaluating visualizations and user behaviors, but traditional eye-tracking studies require specialized hardware and local users. To avoid these constraints, we developed a method called Fauxvea, which crowdsources visualization tasks on the Web and estimates gaze fixations through cursor interactions without eye-tracking hardware. We ran experiments to evaluate how gaze estimates from our method compare with eye-tracking data. First, we evaluated crowdsourced estimates for three common types of information visualizations and basic visualization tasks using Amazon Mechanical Turk (MTurk). In another, we reproduced findings from a previous eye-tracking study on tree layouts using our method on MTurk. Results from these experiments show that fixation estimates using Fauxvea are qualitatively and quantitatively similar to eye tracking on the same stimulus-task pairs. These findings suggest that crowdsourcing visual analysis tasks with static information visualizations could be a viable alternative to traditional eye-tracking studies for visualization research and design.","1941-0506","","10.1109/TVCG.2016.2532331","US National Science Foundation (NSF)(grant numbers:IIS-10-16623); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7414495","Eye tracking;crowdsourcing;focus window;information visualization;visual analysis;user studies","Data visualization;Visualization;Crowdsourcing;Gaze tracking;Presses;Hardware;Layout","computer vision;crowdsourcing;gaze tracking","crowdsourcing gaze location estimation;Fauxvea;visualization analysis tasks;user behaviors;gaze fixations;cursor interactions;eye-tracking hardware;eye-tracking data;Amazon Mechanical Turk;MTurk;crowdsourcing visual analysis tasks;static information visualizations","Adult;Attention;Crowdsourcing;Eye Movement Measurements;Female;Fixation, Ocular;Humans;Internet;Male;Task Performance and Analysis","7","","31","IEEE","19 Feb 2016","","","IEEE","IEEE Journals"
"Generalized Local-to-Global Shape Feature Detection Based on Graph Wavelets","N. Li; S. Wang; M. Zhong; Z. Su; H. Qin","School of Mathematical Sciences, Dalian University of Technology, Dalian, Liaoning, China; School of Software Technology and Key Laboratory for Ubiquitous Network and Service Software of Liaoning ProvinceDalian University of Technology; Department of Computer Science, Stony Brook University, NY; School of Mathematical Sciences, Dalian University of Technology and National Engineering Research Center of Digital Life, Dalian, Liaoning, China; Department of Computer Science, Stony Brook University, NY","IEEE Transactions on Visualization and Computer Graphics","28 Jul 2016","2016","22","9","2094","2106","Informative and discriminative feature descriptors are vital in qualitative and quantitative shape analysis for a large variety of graphics applications. Conventional feature descriptors primarily concentrate on discontinuity of certain differential attributes at different orders that naturally give rise to their discriminative power in depicting point, line, small patch features, etc. This paper seeks novel strategies to define generalized, user-specified features anywhere on shapes. Our new region-based feature descriptors are constructed primarily with the powerful spectral graph wavelets (SGWs) that are both multi-scale and multi-level in nature, incorporating both local (differential) and global (integral) information. To our best knowledge, this is the first attempt to organize SGWs in a hierarchical way and unite them with the bi-harmonic diffusion field towards quantitative region-based shape analysis. Furthermore, we develop a local-to-global shape feature detection framework to facilitate a host of graphics applications, including partial matching without point-wise correspondence, coarse-to-fine recognition, model recognition, etc. Through the extensive experiments and comprehensive comparisons with the state-of-the-art, our framework has exhibited many attractive advantages such as being geometry-aware, robust, discriminative, isometry-invariant, etc.","1941-0506","","10.1109/TVCG.2015.2498557","National Natural Science Foundation of China(grant numbers:61300083,61432003,61173103,91230103,61320106008,61532002,61190120,61190121,61190125); US National Science Foundation(grant numbers:IIS-0949467,IIS-1047715,IIS-1049448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321833","Shape feature detection;spectral graph wavelets;bi-harmonic field;region descriptor;partial matching","Shape;Feature extraction;Geometry;Wavelet analysis;Robustness;Harmonic analysis","computer graphics;feature extraction;graph theory;image matching;shape recognition;wavelet transforms","partial matching;quantitative region-based shape analysis;biharmonic diffusion;SGW;spectral graph wavelets;region-based feature descriptors;generalized user-specified features;discriminative power;differential attributes discontinuity;graphics applications;qualitative shape analysis;discriminative feature descriptors;informative feature descriptors;generalized local-to-global shape feature detection","","7","","46","IEEE","6 Nov 2015","","","IEEE","IEEE Journals"
"Graph-Based Feature-Preserving Mesh Normal Filtering","W. Zhao; X. Liu; S. Wang; X. Fan; D. Zhao","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","3","1937","1952","Distinguishing between geometric features and noise is of paramount importance for mesh denoising. In this paper, a graph-based feature-preserving mesh normal filtering scheme is proposed, which includes two stages: graph-based feature detection and feature-aware guided normal filtering. In the first stage, faces in the input noisy mesh are represented by patches, which are then modelled as weighted graphs. In this way, feature detection can be cast as a graph-cut problem. Subsequently, an iterative normalized cut algorithm is applied on each patch to separate the patch into smooth regions according to the detected features. In the second stage, a feature-aware guidance normal is constructed for each face, and guided normal filtering is applied to achieve robust feature-preserving mesh denoising. The results of experiments on synthetic and real scanned models indicate that the proposed scheme outperforms state-of-the-art mesh denoising works in terms of both objective and subjective evaluations.","1941-0506","","10.1109/TVCG.2019.2944357","Major State Basic Research Development Program of China(grant numbers:2015CB351804); National Natural Science Foundation of China(grant numbers:61922027,61932022,61872116); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851293","Mesh denoising;graph modelling;feature detection;normalized cuts;guided normal filtering","Noise reduction;Feature detection;Feature extraction;Computational modeling;Shape;Image edge detection","feature extraction;filtering theory;graph theory;image denoising;smoothing methods","geometric features;graph-based feature-preserving mesh normal filtering scheme;graph-based feature detection;input noisy mesh;weighted graphs;graph-cut problem;iterative normalized cut algorithm;detected features;feature-aware guidance normal;robust feature-preserving mesh denoising;feature-aware guided normal filtering","","7","","43","IEEE","27 Sep 2019","","","IEEE","IEEE Journals"
"H-CNN: Spatial Hashing Based CNN for 3D Shape Analysis","T. Shao; Y. Yang; Y. Weng; Q. Hou; K. Zhou","State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, USA; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","28 May 2020","2020","26","7","2403","2416","We present a novel spatial hashing based data structure to facilitate 3D shape analysis using convolutional neural networks (CNNs). Our method builds hierarchical hash tables for an input model under different resolutions that leverage the sparse occupancy of 3D shape boundary. Based on this data structure, we design two efficient GPU algorithms namely hash2col and col2hash so that the CNN operations like convolution and pooling can be efficiently parallelized. The perfect spatial hashing is employed as our spatial hashing scheme, which is not only free of hash collision but also nearly minimal so that our data structure is almost of the same size as the raw input. Compared with existing 3D CNN methods, our data structure significantly reduces the memory footprint during the CNN training. As the input geometry features are more compactly packed, CNN operations also run faster with our data structure. The experiment shows that, under the same network structure, our method yields comparable or better benchmark results compared with the state-of-the-art while it has only one-third memory consumption when under high resolutions (i.e., 2563).","1941-0506","","10.1109/TVCG.2018.2887262","National Key Research & Development Program of China(grant numbers:2018YFB1004300); National Natural Science Foundation of China(grant numbers:61890954,61772462,61572429,61472352); Microsoft Research Asia; NSF(grant numbers:CHS-1845026); Air Force Research Laboratory(grant numbers:FA9453-18-2-0022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580422","Perfect hashing;convolutional neural network;shape classification;shape retrieval;shape segmentation","Three-dimensional displays;Shape;Solid modeling;Convolution;Data structures;Two dimensional displays;Computational modeling","convolutional neural nets;data structures;file organisation;graphics processing units;shape recognition","H-CNN;spatial hashing based data structure;spatial hashing based CNN;CNN training;3D CNN methods;hash collision;GPU algorithms;3D shape boundary;convolutional neural networks;3D shape analysis","","7","","60","IEEE","18 Dec 2018","","","IEEE","IEEE Journals"
"Interactive View-Dependent Rendering over Networks","Z. Zheng; E. Prakash; T. Chan","Nanyang Technol. Univ., Singapore; NA; Nanyang Technological University","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2008","2008","14","3","576","589","For a client-server-based view-dependent rendering system, the overhead of view-dependent rendering and the network latency are major obstacles in achieving interactivity. In this paper, we first present a multiresolution hierarchy traversal management strategy to control the overhead of view-dependent rendering for low-capacity clients. Then, we propose a predictive parallel strategy to overcome the network latency for client-server-based view-dependent multiresolution rendering systems. Our solution is to make the client process and the server process run in parallel using the rendering time to cover the network latency. For networks with long round-trip times, we manage to overlap the network latency for one frame with the rendering time for multiple frames. View parameter prediction is incorporated to make the parallelism of the client and the server feasible. In order to maintain an acceptable view-dependent rendering quality in the network environment, we develop a synchronization mechanism and a dynamic adjustment mechanism to handle the transient network slowdowns and the changes in the network condition. Our experimental results, in comparison with the sequential method, show that our predictive parallel approach can achieve an interactive frame rate while keeping an acceptable rendering quality for large triangle models over networks with relatively long round-trip times.","1941-0506","","10.1109/TVCG.2007.70626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4384480","Display algorithms;Viewing algorithms;Distributed/network graphics;Display algorithms;Viewing algorithms;Distributed/network graphics","Delay;Network servers;Rendering (computer graphics);Graphics;Power system modeling;Handheld computers;Parallel processing;Predictive models;Computer science education;Educational products","client-server systems;computer network management;rendering (computer graphics);synchronisation","interactive view-dependent rendering;client-server-based view-dependent rendering system;network latency;multiresolution hierarchy traversal management strategy;predictive parallel strategy;synchronization mechanism;dynamic adjustment mechanism","Algorithms;Computer Communication Networks;Computer Graphics;Data Display;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Signal Processing, Computer-Assisted;User-Computer Interface","7","6","28","","21 Mar 2008","","","IEEE","IEEE Journals"
"Interactive Visualisation of Hierarchical Quantitative Data: An Evaluation","L. Woodburn; Y. Yang; K. Marriott",Monash University; Monash University; Monash University,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","96","100","We have compared three common visualisations for hierarchical quantitative data, treemaps, icicle plots and sunburst charts as well as a semicircular variant of sunburst charts we call the sundown chart. In a pilot study, we found that the sunburst chart was least preferred. In a controlled study with 12 participants, we compared treemaps, icicle plots and sundown charts. Treemap was the least preferred and had a slower performance on a basic navigation task and slower performance and accuracy in hierarchy understanding tasks. The icicle plot and sundown chart had similar performance with slight user preference for the icicle plot.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933545","Human-centered computing—Visualization— Treemaps;Visualization design and evaluation methods","Data visualization;Task analysis;Navigation;Layout;Fires;Aggregates;Image color analysis","data visualisation;image representation;trees (mathematics)","interactive visualisation;hierarchical quantitative data;treemap;icicle plot;sunburst chart;sundown chart","","7","","45","","19 Dec 2019","","","IEEE","IEEE Conferences"
"LassoNet: Deep Lasso-Selection of 3D Point Clouds","Z. Chen; W. Zeng; Z. Yang; L. Yu; C. -W. Fu; H. Qu","Hong Kong University of Science and Technology; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; University of Groningen; Chinese University of Hong Kong; Hong Kong University of Science and Technology","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","195","204","Selection is a fundamental task in exploratory analysis and visualization of 3D point clouds. Prior researches on selection methods were developed mainly based on heuristics such as local point density, thus limiting their applicability in general data. Specific challenges root in the great variabilities implied by point clouds (e.g., dense vs. sparse), viewpoint (e.g., occluded vs. non-occluded), and lasso (e.g., small vs. large). In this work, we introduce LassoNet, a new deep neural network for lasso selection of 3D point clouds, attempting to learn a latent mapping from viewpoint and lasso to point cloud regions. To achieve this, we couple user-target points with viewpoint and lasso information through 3D coordinate transform and naive selection, and improve the method scalability via an intention filtering and farthest point sampling. A hierarchical network is trained using a dataset with over 30K lasso-selection records on two different point cloud data. We conduct a formal user study to compare LassoNet with two state-of-the-art lasso-selection methods. The evaluations confirm that our approach improves the selection effectiveness and efficiency across different combinations of 3D point clouds, viewpoints, and lasso selections.","1941-0506","","10.1109/TVCG.2019.2934332","National Natural Science Foundation of China(grant numbers:61802388,61602139); MSRA(grant numbers:MRA19EG02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805456","Point Clouds;Lasso Selection;Deep Learning","Three-dimensional displays;Two dimensional displays;Deep learning;Neural networks;Shape;Task analysis;Visualization","data visualisation;feature selection;learning (artificial intelligence);neural nets;sampling methods;stereo image processing","farthest point sampling;point cloud data;LassoNet;3D point cloud visualization;intention filtering;exploratory analysis;deep neural network;deep lasso selection;3D coordinate transform;naive selection;hierarchical network training;2D images;3D object space","","7","","43","IEEE","19 Aug 2019","","","IEEE","IEEE Journals"
"Latency in Distributed Acquisition and Rendering for Telepresence Systems","S. Ohl; M. Willert; O. Staadt","Fraunhofer IGD and the Department of Computer Science, University of Rostock, Rostock, Germany; Department of Computer Science, University of Rostock, Germany; Department of Computer Science, University of Rostock, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2015","2015","21","12","1442","1448","Telepresence systems use 3D techniques to create a more natural human-centered communication over long distances. This work concentrates on the analysis of latency in telepresence systems where acquisition and rendering are distributed. Keeping latency low is important to immerse users in the virtual environment. To better understand latency problems and to identify the source of such latency, we focus on the decomposition of system latency into sub-latencies. We contribute a model of latency and show how it can be used to estimate latencies in a complex telepresence dataflow network. To compare the estimates with real latencies in our prototype, we modify two common latency measurement methods. This presented methodology enables the developer to optimize the design, find implementation issues and gain deeper knowledge about specific sources of latency.","1941-0506","","10.1109/TVCG.2015.2407403","German Federal State of Mecklenburg-Western Pomerania; European Social Fund (ESF); European Regional Development Fund (ERDF)(grant numbers:ESV/IV-BM-B35-0006/12,V630-S-179-2013/238); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050364","Telepresence;latency;distributed rendering;camera arrays;Telepresence;latency;distributed rendering;camera arrays","Cameras;Distributed processing;Rendering (computer graphics);Virtual reality;Logic gates;Bandwidth;Data models;Telepresence systems;Human computer interaction","computer networks;delays;rendering (computer graphics);teleconferencing;video communication;virtual reality","distributed acquisition;rendering;latency analysis;telepresence systems;system latency decomposition;sub-latencies;complex telepresence dataflow network;latency measurement methods;video conferencing;virtual reality","Algorithms;Computer Graphics;Humans;Imaging, Three-Dimensional;Software;Telecommunications;Time Factors","7","","23","IEEE","26 Feb 2015","","","IEEE","IEEE Journals"
"Live Semantic 3D Perception for Immersive Augmented Reality","L. Han; T. Zheng; Y. Zhu; L. Xu; L. Fang",Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University,"IEEE Transactions on Visualization and Computer Graphics","31 Mar 2020","2020","26","5","2012","2022","Semantic understanding of 3D environments is critical for both the unmanned system and the human involved virtual/augmented reality (VR/AR) immersive experience. Spatially-sparse convolution, taking advantage of the intrinsic sparsity of 3D point cloud data, makes high resolution 3D convolutional neural networks tractable with state-of-the-art results on 3D semantic segmentation problems. However, the exhaustive computations limits the practical usage of semantic 3D perception for VR/AR applications in portable devices. In this paper, we identify that the efficiency bottleneck lies in the unorganized memory access of the sparse convolution steps, i.e., the points are stored independently based on a predefined dictionary, which is inefficient due to the limited memory bandwidth of parallel computing devices (GPU). With the insight that points are continuous as 2D surfaces in 3D space, a chunk-based sparse convolution scheme is proposed to reuse the neighboring points within each spatially organized chunk. An efficient multi-layer adaptive fusion module is further proposed for employing the spatial consistency cue of 3D data to further reduce the computational burden. Quantitative experiments on public datasets demonstrate that our approach works 11× faster than previous approaches with competitive accuracy. By implementing both semantic and geometric 3D reconstruction simultaneously on a portable tablet device, we demo a foundation platform for immersive AR applications.","1941-0506","","10.1109/TVCG.2020.2973477","National Natural Science Foundation of China(grant numbers:61722209,6181001011); Shenzhen Science and Technology Research and Development Funds(grant numbers:JCYJ20180507183706645); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998140","Dense 3D Reconstruction;3D Semantic Segmentation;3D Convolutional Network;Virtual Reality;Augmented Reality","Three-dimensional displays;Convolution;Semantics;Two dimensional displays;Image segmentation;Graphics processing units;Solid modeling","augmented reality;computer graphics;convolutional neural nets;image reconstruction;image segmentation","multilayer adaptive fusion module;spatial consistency cue;semantic 3D reconstruction;geometric 3D reconstruction;portable tablet device;immersive AR applications;live semantic 3D perception;immersive augmented reality;unmanned system;reality immersive experience;spatially-sparse convolution;3D point cloud data;high resolution 3D convolutional neural networks;3D semantic segmentation problems;sparse convolution steps;parallel computing devices;chunk-based sparse convolution scheme","Augmented Reality;Computer Graphics;Humans;Imaging, Three-Dimensional;Neural Networks, Computer;Semantics;Virtual Reality","7","","48","IEEE","13 Feb 2020","","","IEEE","IEEE Journals"
"Mechanics-Aware Modeling of Cloth Appearance","Z. Montazeri; C. Xiao; Y. Fei; C. Zheng; S. Zhao","Department of Computer Science, University of California, Irvine, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Department of Computer Science, University of California, Irvine, CA, USA","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","137","150","Micro-appearance models have brought unprecedented fidelity and details to cloth rendering. Yet, these models neglect fabric mechanics: when a piece of cloth interacts with the environment, its yarn and fiber arrangement usually changes in response to external contact and tension forces. Since subtle changes of a fabric's microstructures can greatly affect its macroscopic appearance, mechanics-driven appearance variation of fabrics has been a phenomenon that remains to be captured. We introduce a mechanics-aware model that adapts the microstructures of cloth yarns in a physics-based manner. Our technique works on two distinct physical scales: using physics-based simulations of individual yarns, we capture the rearrangement of yarn-level structures in response to external forces. These yarn structures are further enriched to obtain appearance-driving fiber-level details. The cross-scale enrichment is made practical through a new parameter fitting algorithm for simulation, an augmented procedural yarn model coupled with a custom-design regression neural network. We train the network using a dataset generated by joint simulations at both the yarn and the fiber levels. Through several examples, we demonstrate that our model is capable of synthesizing photorealistic cloth appearance in a mechanically plausible way.","1941-0506","","10.1109/TVCG.2019.2937301","National Science Foundation(grant numbers:1453101,1717178,1813553); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812922","Cloth appearance;cloth mechanics","Yarn;Fabrics;Computational modeling;Microstructure;Training;Geometry;Neural networks","clothing;clothing industry;fabrics;mechanical contact;neural nets;production engineering computing;regression analysis;rendering (computer graphics);yarn","mechanics-aware modeling;cloth rendering;fiber arrangement;external contact;tension forces;cloth yarn microstructures;physics-based simulations;cross-scale enrichment;photorealistic cloth appearance;fabric mechanics;parameter fitting algorithm;custom-design regression neural network;joint simulations","","7","","36","IEEE","26 Aug 2019","","","IEEE","IEEE Journals"
"Minimizing the Number of Edges via Edge Concentration in Dense Layered Graphs","Y. Onoue; N. Kukimoto; N. Sakamoto; K. Koyamada","Department of Electrical Engineering, Graduate School of Engineering, Kyoto University, Kyoto, Japan; Center for the Promotion of Interdisciplinary Education and Research, Kyoto University, Kyoto, Japan; Department of Computational Science, Graduate School of System Informatics, Kobe University, Kobe, Japan; Academic Center for Computing and Media Studies, Kyoto University, Kyoto, Japan","IEEE Transactions on Visualization and Computer Graphics","28 Apr 2016","2016","22","6","1652","1661","Edge concentration in dense bipartite graphs is a technique for reducing the numbers of edges and edge crossings in graph drawings. The conventional method proposed by Newbery is designed to reduce the number of edge crossings; however, it does not always reduce the number of edges. Reducing the number of edges is also an important factor for improving the readability of graphs. However, no edge concentration method with the explicit purpose of minimizing the number of edges has previously been studied. In this study, we propose a novel, efficient heuristic method for minimizing the number of edges during edge concentration. We demonstrate the efficiency of the proposed method via a comparison using randomly generated graphs. We find that Newbery's method fails to reduce the number of edges when the number of vertices is large. By contrast, the proposed method achieves an average compression ratio of 47 to 82 percent for all generated graph groups. We also present a real-world application of the proposed method using a causality network of biological data.","1941-0506","","10.1109/TVCG.2016.2534519","Ministry of Education, Culture, Sports, Science and Technology; Data Integration and Analysis System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422136","Graph drawing;edge concentration;layered drawing;Graph drawing;edge concentration;layered drawing","Bipartite graph;Semantics;Data visualization;Visualization;Software;Heuristic algorithms;Biology","graph theory","dense layered graphs;edge concentration;dense bipartite graphs;edge crossings;graph drawings;heuristic method;Newbery method;biological data","","7","","37","IEEE","29 Feb 2016","","","IEEE","IEEE Journals"
"MixedFusion: Real-Time Reconstruction of an Indoor Scene with Dynamic Objects","H. Zhang; F. Xu","Tsinghua University, Beijing, P. R. China; Tsinghua University, Beijing, P. R. China","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2018","2018","24","12","3137","3146","Real-time indoor scene reconstruction aims to recover the 3D geometry of an indoor scene in real time with a sensor scanning the scene. Previous works of this topic consider pure static scenes, but in this paper, we focus on more challenging cases that the scene contains dynamic objects, for example, moving people and floating curtains, which are quite common in reality and thus are eagerly required to be handled. We develop an end-to-end system using a depth sensor to scan a scene on the fly. By proposing a Sigmoid-based Iterative Closest Point (S-ICP) method, we decouple the camera motion and the scene motion from the input sequence and segment the scene into static and dynamic parts accordingly. The static part is used to estimate the camera rigid motion, while for the dynamic part, graph node-based motion representation and model-to-depth fitting are applied to reconstruct the scene motions. With the camera and scene motions reconstructed, we further propose a novel mixed voxel allocation scheme to handle static and dynamic scene parts with different mechanisms, which helps to gradually fuse a large scene with both static and dynamic objects. Experiments show that our technique successfully fuses the geometry of both the static and dynamic objects in a scene in real time, which extends the usage of the current techniques for indoor scene reconstruction.","1941-0506","","10.1109/TVCG.2017.2786233","National Natural Science Foundation of China(grant numbers:61671268,61727808); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241434","Scene reconstruction;dynamic reconstruction;single view","Dynamics;Three-dimensional displays;Cameras;Real-time systems;Image reconstruction;Geometry;Solid modeling","cameras;computer vision;graph theory;image fusion;image reconstruction;image representation;image segmentation;image sensors;image sequences;iterative methods;motion estimation;stereo image processing","dynamic objects;scene motion;static scene parts;dynamic scene parts;static objects;real-time reconstruction;real-time indoor scene reconstruction;3D geometry recovery;moving people;floating curtains;depth sensor;scene scanning;sigmoid-based iterative closest point method;camera motion;scene segmentation;camera rigid motion estimation;graph node-based motion representation;model-to-depth fitting;mixed voxel allocation;MixedFusion","","7","","30","IEEE","28 Dec 2017","","","IEEE","IEEE Journals"
"NNWarp: Neural Network-Based Nonlinear Deformation","R. Luo; T. Shao; H. Wang; W. Xu; X. Chen; K. Zhou; Y. Yang","Electrical and Computer Engineering Department, University of New Mexico, NM, USA; School of Computing, University of Leeds, Leeds, United Kingdom; Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; Electrical and Computer Engineering Department, University of New Mexico, NM, USA","IEEE Transactions on Visualization and Computer Graphics","27 Feb 2020","2020","26","4","1745","1759","NNWarp is a highly re-usable and efficient neural network (NN) based nonlinear deformable simulation framework. Unlike other machine learning applications such as image recognition, where different inputs have a uniform and consistent format (e.g., an array of all the pixels in an image), the input for deformable simulation is quite variable, high-dimensional, and parametrization-unfriendly. Consequently, even though the neural network is known for its rich expressivity of nonlinear functions, directly using an NN to reconstruct the force-displacement relation for general deformable simulation is nearly impossible. NNWarp obviates this difficulty by partially restoring the force-displacement relation via warping the nodal displacement simulated using a simplistic constitutive model-the linear elasticity. In other words, NNWarp yields an incremental displacement fix per mesh node based on a simplified (therefore incorrect) simulation result other than synthesizing the unknown displacement directly. We introduce a compact yet effective feature vector including geodesic, potential and digression to sort training pairs of per-node linear and nonlinear displacement. NNWarp is robust under different model shapes and tessellations. With the assistance of deformation substructuring, one NN training is able to handle a wide range of 3D models of various geometries. Thanks to the linear elasticity and its constant system matrix, the underlying simulator only needs to perform one pre-factorized matrix solve at each time step, which allows NNWarp to simulate large models in real time.","1941-0506","","10.1109/TVCG.2018.2881451","National Science Foundation(grant numbers:CHS-1717972); AFRL(grant numbers:FA9453-18-2-0022); NSFC(grant numbers:61772462,U1736217); Microsoft Research Asia; NSFC(grant numbers:61732016); Alibaba IDEA Lab; Fundamental Research Funds for the Central Universities(grant numbers:2017YFB1002600); National Science Foundation(grant numbers:CHS-1524992); NSFC(grant numbers:61772024,61732016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536417","Neural network;machine learning;data-driven animation;nonlinear regression;deformable model;physics-based simulation","Artificial neural networks;Deformable models;Strain;Computational modeling;Animation;Elasticity","deformation;elasticity;mechanical engineering computing;mesh generation;neural nets;solid modelling","linear elasticity;digression feature vector;potential feature vector;geodesic feature vector;effective feature vector;compact feature vector;incremental displacement fix per mesh node;deformable simulation;highly re-usable and efficient neural network;NNWarp;highly reusable network;deformation substructuring;nodal displacement;force-displacement relation;nonlinear deformable simulation framework;neural network-based nonlinear deformation","","7","","85","IEEE","15 Nov 2018","","","IEEE","IEEE Journals"
"Nonlinear Dot Plots","N. Rodrigues; D. Weiskopf","VISUS, University of Stuttgart, Germany; VISUS, University of Stuttgart, Germany","IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","616","625","Conventional dot plots use a constant dot size and are typically applied to show the frequency distribution of small data sets. Unfortunately, they are not designed for a high dynamic range of frequencies. We address this problem by introducing nonlinear dot plots. Adopting the idea of nonlinear scaling from logarithmic bar charts, our plots allow for dots of varying size so that columns with a large number of samples are reduced in height. For the construction of these diagrams, we introduce an efficient two-way sweep algorithm that leads to a dense and symmetrical layout. We compensate aliasing artifacts at high dot densities by a specifically designed low-pass filtering method. Examples of nonlinear dot plots are compared to conventional dot plots as well as linear and logarithmic histograms. Finally, we include feedback from an expert review.","1941-0506","","10.1109/TVCG.2017.2744018","German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017644","Nonlinear dot plot;statistical graphics;sweep algorithm;layout","Histograms;Data visualization;Layout;Dynamic range;Bars;Rendering (computer graphics);Algorithm design and analysis","data handling;data visualisation;low-pass filters","constant dot size;nonlinear dot plots;logarithmic histograms;linear histograms;low-pass filtering method;aliasing artifacts;two-way sweep algorithm;logarithmic bar charts;nonlinear scaling;frequency distribution","","7","","38","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Pointfilter: Point Cloud Filtering via Encoder-Decoder Modeling","D. Zhang; X. Lu; H. Qin; Y. He","State Key Laboratory of Virtual Reality Technology and Systems, Beihang Unviersity, Beijing, China; School of Information Technology, Deakin University, Geelong, Australia; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2021","2021","27","3","2015","2027","Point cloud filtering is a fundamental problem in geometry modeling and processing. Despite of significant advancement in recent years, the existing methods still suffer from two issues: 1) they are either designed without preserving sharp features or less robust in feature preservation; and 2) they usually have many parameters and require tedious parameter tuning. In this article, we propose a novel deep learning approach that automatically and robustly filters point clouds by removing noise and preserving their sharp features. Our point-wise learning architecture consists of an encoder and a decoder. The encoder directly takes points (a point and its neighbors) as input, and learns a latent representation vector which goes through the decoder to relate the ground-truth position with a displacement vector. The trained neural network can automatically generate a set of clean points from a noisy input. Extensive experiments show that our approach outperforms the state-of-the-art deep learning techniques in terms of both visual quality and quantitative error metrics. The source code and dataset can be found at https://github.com/dongbo-BUAA-VR/Pointfilter.","1941-0506","","10.1109/TVCG.2020.3027069","National Key R&D Program of China(grant numbers:2017YFF0106407); Deakin University(grant numbers:CY01-251301-F003-PJ03906-PG00447); industry Grant(grant numbers:PJ06625); Australian Cancer Research Foundation(grant numbers:20/20); National Natural Science Foundation of China(grant numbers:61532002); National Science Foundation(grant numbers:IIS-0949467,IIS-1047715,IIS-1812606,IIS-1715985,IIS-1049448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207844","Automatic point cloud filtering;deep learning;autoencoder;feature-preserving denoising","Three-dimensional displays;Noise measurement;Machine learning;Robustness;Tuning;Network architecture;Filtering","codecs;deep learning (artificial intelligence);image coding;image filtering;neural nets;vectors","geometry modeling;feature preservation;parameter tuning;point-wise learning architecture;clean points;deep learning techniques;point cloud filtering;encoder-decoder modeling;trained neural network;latent representation vector;visual quality;quantitative error metrics;displacement vector","","7","","45","IEEE","28 Sep 2020","","","IEEE","IEEE Journals"
"Radian: Visual Exploration of Traceroutes","M. Candela; M. Di Bartolomeo; G. D. Battista; C. Squarcella","RIPE NCC, Amsterdam, AB, Netherlands; Department of Engineering, Roma Tre University, Roma, Italy; Department of Engineering, Roma Tre University, Roma, Italy; Sysdig, San Francisco, CA","IEEE Transactions on Visualization and Computer Graphics","25 May 2018","2018","24","7","2194","2208","Several projects deploy probes in the Internet. Probes are systems that continuously perform traceroutes and other networking measurements (e.g., ping) towards selected targets. Measurements can be stored and analyzed to gain knowledge on several aspects of the Internet, but making sense of such data requires suitable methods and tools for exploration and visualization. We present Radian, a tool that allows to visualize traceroute paths at different levels of detail and to animate their evolution during a selected time interval. We also describe extensive tests of the tool using traceroutes performed by RIPE Atlas Internet probes.","1941-0506","","10.1109/TVCG.2017.2716937","European Community's Seventh Framework Programme (FP7/2007-2013)(grant numbers:317647); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953527","Traceroute;graph drawing;network visualization;network probes","Probes;Tools;Routing;Data visualization;Internet;Performance evaluation;IP networks","data visualisation;Internet;telecommunication network routing;telecommunication network topology","Radian;visual exploration;networking measurements;selected time interval;RIPE Atlas Internet probes;traceroutes paths visualization","","7","","48","IEEE","19 Jun 2017","","","IEEE","IEEE Journals"
"Reconstructing Open Surfaces via Graph-Cuts","M. Wan; Y. Wang; E. Bae; X. Tai; D. Wang","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; University of Bergen, Brunsgate; Nanyang Technological University, Singapore and University of Bergen, Brunsgate; Nanyang Technological University, Singapore","IEEE Transactions on Visualization and Computer Graphics","10 Dec 2012","2013","19","2","306","318","A novel graph-cuts-based method is proposed for reconstructing open surfaces from unordered point sets. Through a Boolean operation on the crust around the data set, the open surface problem is translated to a watertight surface problem within a restricted region. Integrating the variational model, Delaunay-based tetrahedral mesh and multiphase technique, the proposed method can reconstruct open surfaces robustly and effectively. Furthermore, a surface reconstruction method with domain decomposition is presented, which is based on the new open surface reconstruction method. This method can handle more general surfaces, such as nonorientable surfaces. The algorithm is designed in a parallel-friendly way and necessary measures are taken to eliminate cracks and conflicts between the subdomains. Numerical examples are included to demonstrate the robustness and effectiveness of the proposed method on watertight, open orientable, open nonorientable surfaces and combinations of such.","1941-0506","","10.1109/TVCG.2012.119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197189","Graph cuts;open surface;domain decomposition;Delaunay triangulation","Surface reconstruction;Level set;Surface cracks;Surface treatment;Reconstruction algorithms;Minimization;Robustness","Boolean functions;computer graphics;graph theory;mesh generation","graph-cuts-based method;unordered point sets;Boolean operation;open surface problem;Delaunay-based tetrahedral mesh;multiphase technique;domain decomposition;open surface reconstruction method;open nonorientable surfaces;watertight surfaces","","7","","51","","8 May 2012","","","IEEE","IEEE Journals"
"Structure-aware Fisheye Views for Efficient Large Graph Exploration","Y. Wang; Y. Wang; H. Zhang; Y. Sun; C. -W. Fu; M. Sedlmair; B. Chen; O. Deussen","Shandong University; Shandong University; Shandong University; Shandong University; Chinese University of Hong Kong; VISUSUniversity of Stuttgart; Peking University; Konstanz University, Germany","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","566","575","Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for structure-aware fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance.","1941-0506","","10.1109/TVCG.2018.2864911","National Key Research and Development Plan of China(grant numbers:2016YFB1001404); NSFC(grant numbers:61772315); NSFC-Guangdong Joint(grant numbers:U1501255); Science Challenge Project(grant numbers:TZ2016002); Shandong Provincial Natural Science Foundation(grant numbers:ZR2016FM12); Open Research Fund of Beijing Key Laboratory of Big Data Technology for Food Safety(grant numbers:BUBD-2017KF02); Beijing Technology and Business University the Open Project Program of the State Key Lab of CAD and CG(grant numbers:A1801); Zhejiang University and the Fundamental Research Funds of Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440835","Graph Visualization;Focus-Context Technique;Structure-aware Zoom;Graph Layout Technique","Layout;Lenses;Optimization;Task analysis;Distortion;Visualization;Sun","data visualisation;graph theory;lenses;optimisation","graph exploration;edge orientations;spatial temporal distortions;GPU implementation;path lenses;cluster lenses;polyfocal lenses;fisheye lenses;graph structure;fisheye zooms;graph layout optimization;structure-aware fisheye views","","7","","56","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Tele-Immersion Concepts","S. Ohl","Computer Science, University of Rostock, Rostock, Germany","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2018","2018","24","10","2827","2842","Tele-immersive systems development is always driven as well as restricted by the available immersive technology. Hence, existing such systems are described mainly from a technological point of view; their conceptual description is usually limited to the description of a scenario that is implementable with or circumvents the limitations of the chosen technology. This focus on technology makes it difficult to compare systems' concepts; moreover, it has led to different views on tele-immersion in different fields, such as remotely controlled robots, immersive video conferencing, and tele-collaboration. In this work, we give a general, structured principle to describe the conceptual part of any tele-immersion system. This principle naturally unifies the different views on tele-immersion. Our idea is based on the insight that, in order to be general, immersion must be described separately for each direction of communication. We characterize communication between locations using a graph; for each directed edge of this graph, we describe immersion as operations on volumes. Using this principle, we define a typology, which enables the comparison and enumeration of tele-immersion concepts. We apply this typology to survey the concepts of existing tele-immersion systems and thereby demonstrate how three well-known tele-immersive scenarios-Marvin Minsky's tele-operated robot, the Office of the Future, and the asymmetric Beaming scenario-integrate naturally. We show how the general principle can be utilized conveniently to grasp conceptual ideas in tele-immersion, such as direct interaction, locational presence, spatial consistency, symmetries, and self-inclusion.","1941-0506","","10.1109/TVCG.2017.2767590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093688","Tele-immersion;telepresence;immersive tele-collaboration;virtual reality;augmented reality;mixed reality;communication notation;immersive extent;joint social attention","Avatars;Communication channels;Real-time systems;Robot sensing systems","directed graphs;telerobotics","tele-immersion concepts;tele-immersive systems development;immersive video conferencing;tele-collaboration;tele-immersion system;immersive technology;Marvin Minsky's tele-operated robot;directed edge;asymmetric Beaming scenario","","7","","56","IEEE","1 Nov 2017","","","IEEE","IEEE Journals"
"Uncluttering Graph Layouts Using Anisotropic Diffusion and Mass Transport","Y. Frishman; A. Tal","Technion—Israel Institute of Technology, Haifa; Technion—Israel Institute of Technology, Haifa","IEEE Transactions on Visualization and Computer Graphics","17 Jul 2009","2009","15","5","777","788","Many graph layouts include very dense areas, making the layout difficult to understand. In this paper, we propose a technique for modifying an existing layout in order to reduce the clutter in dense areas. A physically inspired evolution process based on a modified heat equation is used to create an improved layout density image, making better use of available screen space. Using results from optimal mass transport problems, a warp to the improved density image is computed. The graph nodes are displaced according to the warp. The warp maintains the overall structure of the graph, thus limiting disturbances to the mental map, while reducing the clutter in dense areas of the layout. The complexity of the algorithm depends mainly on the resolution of the image visualizing the graph and is linear in the size of the graph. This allows scaling the computation according to required running times. It is demonstrated how the algorithm can be significantly accelerated using a graphics processing unit (GPU), resulting in the ability to handle large graphs in a matter of seconds. Results on several layout algorithms and applications are demonstrated.","1941-0506","","10.1109/TVCG.2009.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967578","Graph layout;graph visualization;GPU;anisotropic heat equation;mass transport.","Anisotropic magnetoresistance;Layout;Visualization;Application software;Space heating;Equations;Clustering algorithms;Evolution (biology);Image resolution;Acceleration","computational complexity;data visualisation","uncluttering graph layouts;anisotropic diffusion;optimal mass transport;evolution process;layout density image;graphics processing unit;graph visualization;heat equation","","7","","40","IEEE","26 May 2009","","","IEEE","IEEE Journals"
"Visual Analysis of High-Dimensional Event Sequence Data via Dynamic Hierarchical Aggregation","D. Gotz; J. Zhang; W. Wang; J. Shrestha; D. Borland","School of Information and Library Science, University of North Carolina, Chapel Hill; Dept. of Biostatistics, University of North Carolina, Chapel Hill; School of Information and Library Science, University of North Carolina, Chapel Hill; Dept. of Computer Science, University of North Carolina, Chapel Hill; RENCI, University of North Carolina, Chapel Hill","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","440","450","Temporal event data are collected across a broad range of domains, and a variety of visual analytics techniques have been developed to empower analysts working with this form of data. These techniques generally display aggregate statistics computed over sets of event sequences that share common patterns. Such techniques are often hindered, however, by the high-dimensionality of many real-world event sequence datasets which can prevent effective aggregation. A common coping strategy for this challenge is to group event types together prior to visualization, as a pre-process, so that each group can be represented within an analysis as a single event type. However, computing these event groupings as a pre-process also places significant constraints on the analysis. This paper presents a new visual analytics approach for dynamic hierarchical dimension aggregation. The approach leverages a predefined hierarchy of dimensions to computationally quantify the informativeness, with respect to a measure of interest, of alternative levels of grouping within the hierarchy at runtime. This information is then interactively visualized, enabling users to dynamically explore the hierarchy to select the most appropriate level of grouping to use at any individual step within an analysis. Key contributions include an algorithm for interactively determining the most informative set of event groupings for a specific analysis context, and a scented scatter-plus-focus visualization design with an optimization-based layout algorithm that supports interactive hierarchical exploration of alternative event type groupings. We apply these techniques to high-dimensional event sequence data from the medical domain and report findings from domain expert interviews.","1941-0506","","10.1109/TVCG.2019.2934661","National Science Foundation(grant numbers:1704018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807220","Temporal event sequence visualization;visual analytics;hierarchical aggregation;medical informatics","Data visualization;Visual analytics;Runtime;Sequences;Layout;Navigation","data aggregation;data analysis;data visualisation","dynamic hierarchical aggregation;temporal event data;visual analysis;high-dimensional event sequence data;alternative event type groupings;scented scatter-plus-focus visualization design;dynamic hierarchical dimension aggregation;event groupings;single event type;group event types;real-world event sequence datasets;visual analytics techniques","","7","","60","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems","R. R. Sambasivan; I. Shafer; M. L. Mazurek; G. R. Ganger",Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2466","2475","Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system's many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.","1941-0506","","10.1109/TVCG.2013.233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634197","Distributed processing;Human factors;Layout;Training;visualization;Distributed systems;human factors;problem diagnosis","Distributed processing;Human factors;Layout;Training","computer animation;data visualisation;distributed processing","request-flow comparison visualization;performance diagnosis;distributed systems;visualization techniques;side-by-side visualization approach;diff visualization approach;animation visualization approach;request-flow comparison technique;automated localization technique","Algorithms;Computer Graphics;Humans;Image Enhancement;Information Storage and Retrieval;Task Performance and Analysis;User-Computer Interface;Visual Perception","7","","37","","16 Oct 2013","","","IEEE","IEEE Journals"
"Vol<sup>2</sup>velle: Printable Interactive Volume Visualization","S. Stoppel; S. Bruckner",University of Bergen; University of Bergen,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","861","870","Interaction is an indispensable aspect of data visualization. The presentation of volumetric data, in particular, often significantly benefits from interactive manipulation of parameters such as transfer functions, rendering styles, or clipping planes. However, when we want to create hardcopies of such visualizations, this essential aspect is lost. In this paper, we present a novel approach for creating hardcopies of volume visualizations which preserves a certain degree of interactivity. We present a method for automatically generating Volvelles, printable tangible wheel charts that can be manipulated to explore different parameter settings. Our interactive system allows the flexible mapping of arbitrary visualization parameters and supports advanced features such as linked views. The resulting designs can be easily reproduced using a standard printer and assembled within a few minutes.","1941-0506","","10.1109/TVCG.2016.2599211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539578","Physical Visualization;Interaction;Volume Visualization;Illustrative Visualization","Data visualization;Wheels;Layout;Transfer functions;Standards;Three-dimensional displays;Complexity theory","data visualisation","printable interactive volume visualization;data visualization;volumetric data;interactivity degree;Volvelles;printable tangible wheel charts;arbitrary visualization parameters;standard printer","","7","","45","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"WeSeer: Visual Analysis for Better Information Cascade Prediction of WeChat Articles","Q. Li; Z. Wu; L. Yi; K. S. N.; H. Qu; X. Ma","Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; WeChat, Tencent, Shenzhen, China; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","31 Dec 2019","2020","26","2","1399","1412","Social media, such as Facebook and WeChat, empowers millions of users to create, consume, and disseminate online information on an unprecedented scale. The abundant information on social media intensifies the competition of WeChat Public Official Articles (i.e., posts) for gaining user attention due to the zero-sum nature of attention. Therefore, only a small portion of information tends to become extremely popular while the rest remains unnoticed or quickly disappears. Such a typical “long-tail” phenomenon is very common in social media. Thus, recent years have witnessed a growing interest in predicting the future trend in the popularity of social media posts and understanding the factors that influence the popularity of the posts. Nevertheless, existing predictive models either rely on cumbersome feature engineering or sophisticated parameter tuning, which are difficult to understand and improve. In this paper, we study and enhance a point process-based model by incorporating visual reasoning to support communication between the users and the predictive model for a better prediction result. The proposed system supports users to uncover the working mechanism behind the model and improve the prediction accuracy accordingly based on the insights gained. We use realistic WeChat articles to demonstrate the effectiveness of the system and verify the improved model on a large scale of WeChat articles. We also elicit and summarize the feedback from WeChat domain experts.","1941-0506","","10.1109/TVCG.2018.2867776","WeChat-HKUST Joint Lab on AI Technology(grant numbers:#1617170-0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451903","Visual reasoning;propagation prediction;model understanding;information propagation visualization","Predictive models;Social network services;Visual analytics;Analytical models;Feature extraction;Cognition","social networking (online)","WeChat public official articles;abundant information;unprecedented scale;online information;information cascade prediction;visual analysis;WeChat domain experts;predictive model;point process-based model;social media posts;user attention","","7","","49","IEEE","30 Aug 2018","","","IEEE","IEEE Journals"
"Weakly Supervised Adversarial Learning for 3D Human Pose Estimation from Point Clouds","Z. Zhang; L. Hu; X. Deng; S. Xia","Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences; Bejing Key Laboratory of Human Computer Interactions, Institute of Software, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences","IEEE Transactions on Visualization and Computer Graphics","31 Mar 2020","2020","26","5","1851","1859","Point clouds-based 3D human pose estimation that aims to recover the 3D locations of human skeleton joints plays an important role in many AR/VR applications. The success of existing methods is generally built upon large scale data annotated with 3D human joints. However, it is a labor-intensive and error-prone process to annotate 3D human joints from input depth images or point clouds, due to the self-occlusion between body parts as well as the tedious annotation process on 3D point clouds. Meanwhile, it is easier to construct human pose datasets with 2D human joint annotations on depth images. To address this problem, we present a weakly supervised adversarial learning framework for 3D human pose estimation from point clouds. Compared to existing 3D human pose estimation methods from depth images or point clouds, we exploit both the weakly supervised data with only annotations of 2D human joints and fully supervised data with annotations of 3D human joints. In order to relieve the human pose ambiguity due to weak supervision, we adopt adversarial learning to ensure the recovered human pose is valid. Instead of using either 2D or 3D representations of depth images in previous methods, we exploit both point clouds and the input depth image. We adopt 2D CNN to extract 2D human joints from the input depth image, 2D human joints aid us in obtaining the initial 3D human joints and selecting effective sampling points that could reduce the computation cost of 3D human pose regression using point clouds network. The used point clouds network can narrow down the domain gap between the network input i.e. point clouds and 3D joints. Thanks to weakly supervised adversarial learning framework, our method can achieve accurate 3D human pose from point clouds. Experiments on the ITOP dataset and EVAL dataset demonstrate that our method can achieve state-of-the-art performance efficiently.","1941-0506","","10.1109/TVCG.2020.2973076","Natural Science Foundation of Beijing Municipality(grant numbers:L182052); National Key R&D Program of China(grant numbers:2016YFB1001201); National Natural Science Foundation of China(grant numbers:61772499,61473276); Distinguished Young Researcher Program; Institute of Software, Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998337","Human Pose Estimation;Point Clouds;Depth Map","Three-dimensional displays;Two dimensional displays;Pose estimation;Heating systems;Proposals;Training data;Computers","convolutional neural nets;image representation;pose estimation;stereo image processing;supervised learning","human skeleton joints;depth images;weakly supervised adversarial learning framework;Point clouds-based 3D human pose estimation;2D CNN;2D human joints;2D representations;3D representations","Humans;Imaging, Three-Dimensional;Joints;Posture;Supervised Machine Learning","7","","40","IEEE","13 Feb 2020","","","IEEE","IEEE Journals"
"Would You Like A Chart With That? Incorporating Visualizations into Conversational Interfaces","M. Hearst; M. Tory","UC Berkeley; Tableau Software, Inc.","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Conversational interfaces, such as chatbots, are increasing in prevalence, and have been shown to be preferred by and help users to complete tasks more efficiently than standard web interfaces in some cases. However, little is understood about if and how information should be visualized during the course of an interactive conversation. This paper describes studies in which participants report their preferences for viewing visualizations in chat-style interfaces when answering questions about comparisons and trends. We find a significant split in preferences among participants; approximately 40% prefer not to see charts and graphs in the context of a conversational interface. For those who do prefer to see charts, most preferred to see additional supporting context beyond the direct answer to the question. These results have important ramifications for the design of conversational interfaces to data.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933766","Human-centered computing;Visualization","Bars;Data visualization;Market research;Web search;Task analysis","data visualisation;human computer interaction;interactive systems;Internet","Web interfaces;interactive conversation;chat-style interfaces;conversational interface;visualizations;chatbots","","7","","24","","19 Dec 2019","","","IEEE","IEEE Conferences"
"4D Light Field Segmentation From Light Field Super-Pixel Hypergraph Representation","X. Lv; X. Wang; Q. Wang; J. Yu","School of Computer Science, Northwestern Polytechnical University, Xi'an, China; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Shanghai Tech University, Shanghai, China","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2021","2021","27","9","3597","3610","Efficient and accurate segmentation of full 4D light fields is an important task in computer vision and computer graphics. The massive volume and the redundancy of light fields make it an open challenge. In this article, we propose a novel light field hypergraph (LFHG) representation using the light field super-pixel (LFSP) for interactive light field segmentation. The LFSPs not only maintain the light field spatio-angular consistency, but also greatly contribute to the hypergraph coarsening. These advantages make LFSPs useful to improve segmentation performance. Based on the LFHG representation, we present an efficient light field segmentation algorithm via graph-cut optimization. Experimental results on both synthetic and real scene data demonstrate that our method outperforms state-of-the-art methods on the light field segmentation task with respect to both accuracy and efficiency.","1941-0506","","10.1109/TVCG.2020.2982158","National Natural Science Foundation of China(grant numbers:61531014,61801396); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043741","Hypergraph representation;light field segmentation;light field super-pixel;graph-cut optimization","Image segmentation;Optimization;Light fields;Estimation;Cameras;Two dimensional displays;Task analysis","computer vision;graph theory;image representation;image resolution;image segmentation","4D light field segmentation;light field super-pixel hypergraph representation;interactive light field segmentation;LFHG representation;computer vision","","6","","38","IEEE","20 Mar 2020","","","IEEE","IEEE Journals"
"A method to generate soft shadows using a layered depth image and warping","Yeon-Ho Im; Chang-Young Han; Lee-Sup Kim","Dept. of Electr. Eng. & Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea; Dept. of Electr. Eng. & Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea; Dept. of Electr. Eng. & Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2005","2005","11","3","265","272","We present an image-based method for propagating area light illumination through a layered depth image (LDI) to generate soft shadows from opaque and nonrefractive transparent objects. In our approach, using the depth peeling technique, we render an LDI from a reference light sample on a planar light source. Light illumination of all pixels in an LDI is then determined for all the other sample points via warping, an image-based rendering technique, which approximates ray tracing in our method. We use an image-warping equation and McMillan's warp ordering algorithm to find the intersections between rays and polygons and to find the order of intersections. Experiments for opaque and nonrefractive transparent objects are presented. Results indicate our approach generates soft shadows fast and effectively. Advantages and disadvantages of the proposed method are also discussed.","1941-0506","","10.1109/TVCG.2005.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407859","Index Terms- Image-based rendering;shadowing;soft shadows.","Lighting;Rendering (computer graphics);Light sources;Page description languages;Ray tracing;Layout;Optical propagation;Pixel;Image generation;Equations","rendering (computer graphics);ray tracing","layered depth image;area light illumination propagation;soft shadows;opaque object;nonrefractive transparent object;depth peeling technique;light illumination;image pixels;image sampling;image-based rendering technique;ray tracing;image-warping equation;McMillan warp ordering algorithm;image shadowing","Algorithms;Artificial Intelligence;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Light;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique;User-Computer Interface","6","1","27","IEEE","21 Mar 2005","","","IEEE","IEEE Journals"
"Analyzing Locomotion Synthesis with Feature-Based Motion Graphs","M. Mahmudi; M. Kallmann","University of California, Merced, Merced; University of California Merced, Merced","IEEE Transactions on Visualization and Computer Graphics","19 Mar 2013","2013","19","5","774","786","We propose feature-based motion graphs for realistic locomotion synthesis among obstacles. Among several advantages, feature-based motion graphs achieve improved results in search queries, eliminate the need of postprocessing for foot skating removal, and reduce the computational requirements in comparison to traditional motion graphs. Our contributions are threefold. First, we show that choosing transitions based on relevant features significantly reduces graph construction time and leads to improved search performances. Second, we employ a fast channel search method that confines the motion graph search to a free channel with guaranteed clearance among obstacles, achieving faster and improved results that avoid expensive collision checking. Lastly, we present a motion deformation model based on Inverse Kinematics applied over the transitions of a solution branch. Each transition is assigned a continuous deformation range that does not exceed the original transition cost threshold specified by the user for the graph construction. The obtained deformation improves the reachability of the feature-based motion graph and in turn also reduces the time spent during search. The results obtained by the proposed methods are evaluated and quantified, and they demonstrate significant improvements in comparison to traditional motion graph techniques.","1941-0506","","10.1109/TVCG.2012.149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6231626","Computer animation;locomotion;motion capture;human-like motion planning","Motion segmentation;Feature extraction;Image segmentation;Detectors;Joints;Databases;Foot","collision avoidance;computer animation;inverse problems;motion control;reachability analysis;search problems","locomotion synthesis analyzing;feature-based motion graph;realistic locomotion synthesis;search query;foot skating removal;graph construction time;search performance;fast channel search method;motion graph search;free channel;obstacle clearance;collision checking;motion deformation model;inverse kinematics;continuous deformation range;transition cost threshold;reachability;motion graph technique;animation","Algorithms;Biomimetics;Computer Graphics;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Locomotion;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface","6","","35","","3 Jul 2012","","","IEEE","IEEE Journals"
"Analyzing the Noise Robustness of Deep Neural Networks","K. Cao; M. Liu; H. Su; J. Wu; J. Zhu; S. Liu","School of Software, BNRist, Tsinghua University, Beijing, China; Microsoft, Redmond, WA, USA; Department of Computer Science and Technology, Institute for AI, THBI Lab, Tsinghua University, Beijing, China; Cardiff University, Cardiff, United Kingdom; Department of Computer Science and Technology, Institute for AI, THBI Lab, Tsinghua University, Beijing, China; School of Software, BNRist, Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","27 May 2021","2021","27","7","3289","3304","Adversarial examples, generated by adding small but intentionally imperceptible perturbations to normal examples, can mislead deep neural networks (DNNs) to make incorrect predictions. Although much work has been done on both adversarial attack and defense, a fine-grained understanding of adversarial examples is still lacking. To address this issue, we present a visual analysis method to explain why adversarial examples are misclassified. The key is to compare and analyze the datapaths of both the adversarial and normal examples. A datapath is a group of critical neurons along with their connections. We formulate the datapath extraction as a subset selection problem and solve it by constructing and training a neural network. A multi-level visualization consisting of a network-level visualization of data flows, a layer-level visualization of feature maps, and a neuron-level visualization of learned features, has been designed to help investigate how datapaths of adversarial and normal examples diverge and merge in the prediction process. A quantitative evaluation and a case study were conducted to demonstrate the promise of our method to explain the misclassification of adversarial examples.","1941-0506","","10.1109/TVCG.2020.2969185","National Key Research and Development Program of China(grant numbers:2018YFB1004300); National Natural Science Foundation of China(grant numbers:61936002,61761136020,61672308); Tsinghua University; National Key Research and Development Program of China(grant numbers:2017YFA0700904); NSFC Projects(grant numbers:61620106010,61621136008); Beijing NSF Project(grant numbers:L172037); Beijing Academy of Artificial Intelligence; JP Morgan Faculty Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967166","Robustness;deep neural networks;adversarial examples;explainable machine learning","Neurons;Visualization;Data visualization;Feature extraction;Training;Merging;Biological neural networks","data visualisation;deep learning (artificial intelligence)","network-level visualization;layer-level visualization;neuron-level visualization;datapath;normal examples;adversarial examples;deep neural networks;adversarial attack;visual analysis method;neural network;multilevel visualization","","6","","55","IEEE","23 Jan 2020","","","IEEE","IEEE Journals"
"Automatic Optimization of Wayfinding Design","H. Huang; N. -C. Lin; L. Barrett; D. Springer; H. -C. Wang; M. Pomplun; L. -F. Yu","University of Massachusetts Boston, Boston, MA; National Chiao Tung University, Hsinchu, Taiwan; University of Massachusetts Boston, Boston, MA; University of Massachusetts Boston, Boston, MA; National Chiao Tung University, Hsinchu, Taiwan; University of Massachusetts Boston, Boston, MA; University of Massachusetts Boston, Boston, MA","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2018","2018","24","9","2516","2530","Wayfinding signs play an important role in guiding users to navigate in a virtual environment and in helping pedestrians to find their ways in a real-world architectural site. Conventionally, the wayfinding design of a virtual environment is created manually, so as the wayfinding design of a real-world architectural site. The many possible navigation scenarios, as well as the interplay between signs and human navigation, can make the manual design process overwhelming and non-trivial. As a result, creating a wayfinding design for a typical layout can take months to several years. In this paper, we introduce the Way to Go! approach for automatically generating a wayfinding design for a given layout. The designer simply has to specify some navigation scenarios; our approach will automatically generate an optimized wayfinding design with signs properly placed considering human agents' visibility and possibility of making mistakes during a navigation. We demonstrate the effectiveness of our approach in generating wayfinding designs for different layouts such as a train station, a downtown and a canyon. We evaluate our results by comparing different wayfinding designs and show that our optimized wayfinding design can guide pedestrians to their destinations effectively and efficiently. Our approach can also help the designer visualize the accessibility of a destination from different locations, and correct any “blind zone” with additional signs.","1941-0506","","10.1109/TVCG.2017.2761820","UMass Boston StartUp(grant numbers:P20150000029280); Office of the Vice Provost for Research and Strategic Initiatives; Dean of Graduate Studies of UMass Boston; US National Science Foundation(grant numbers:1565978); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8063899","Wayfinding;navigation;procedural modeling;level design;spatial orientation","Navigation;Virtual environments;Visualization;Layout;Games;Optimization;Roads","design;mobile computing;optimisation;pedestrians;traffic engineering computing;virtual reality","wayfinding signs;real-world architectural site;optimized wayfinding design;virtual environment;user navigation;Way to Go!;human agent visibility;pedestrian guidance;automatic optimization;mobile navigation system","","6","","65","IEEE","10 Oct 2017","","","IEEE","IEEE Journals"
"<italic>CNN</italic>Pruner: Pruning Convolutional Neural Networks with Visual Analytics","G. Li; J. Wang; H. -W. Shen; K. Chen; G. Shan; Z. Lu",Computer Network Information CenterChinese Academy of Sciences; Visa Research; Ohio State University; Computer Network Information CenterChinese Academy of Sciences; Computer Network Information CenterChinese Academy of Sciences; Computer Network Information CenterChinese Academy of Sciences,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1364","1373","Convolutional neural networks (CNNs) have demonstrated extraordinarily good performance in many computer vision tasks. The increasing size of CNN models, however, prevents them from being widely deployed to devices with limited computational resources, e.g., mobile/embedded devices. The emerging topic of model pruning strives to address this problem by removing less important neurons and fine-tuning the pruned networks to minimize the accuracy loss. Nevertheless, existing automated pruning solutions often rely on a numerical threshold of the pruning criteria, lacking the flexibility to optimally balance the trade-off between efficiency and accuracy. Moreover, the complicated interplay between the stages of neuron pruning and model fine-tuning makes this process opaque, and therefore becomes difficult to optimize. In this paper, we address these challenges through a visual analytics approach, named CNNPruner. It considers the importance of convolutional filters through both instability and sensitivity, and allows users to interactively create pruning plans according to a desired goal on model size or accuracy. Also, CNNPruner integrates state-of-the-art filter visualization techniques to help users understand the roles that different filters played and refine their pruning plans. Through comprehensive case studies on CNNs with real-world sizes, we validate the effectiveness of CNNPruner.","1941-0506","","10.1109/TVCG.2020.3030461","Strategic Priority Research Program of the Chinese Academy of Sciences(grant numbers:XDA19080102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222510","visualization;model pruning;convolutional neural network;explainable artificial intelligence","Computational modeling;Numerical models;Analytical models;Visual analytics;Predictive models;Deep learning","computer vision;convolutional neural nets;data analysis;data visualisation;learning (artificial intelligence);mobile computing","neuron pruning;visual analytics approach;convolutional filters;pruning plans;CNNs;convolutional neural networks;computer vision tasks;CNN models;pruned networks;pruning criteria;filter visualization techniques;CNNPruner","Computer Graphics;Neural Networks, Computer;Neurons","6","","46","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"CiSE: A Circular Spring Embedder Layout Algorithm","U. Dogrusoz; M. E. Belviranli; A. Dilek","Bilkent University, Ankara; University of California, Riverside, Riverside; The Scientific and Technological Reserch Council of Turkey, Ankara","IEEE Transactions on Visualization and Computer Graphics","5 Apr 2013","2013","19","6","953","966","We present a new algorithm for automatic layout of clustered graphs using a circular style. The algorithm tries to determine optimal location and orientation of individual clusters intrinsically within a modified spring embedder. Heuristics such as reversal of the order of nodes in a cluster and swap of neighboring node pairs in the same cluster are employed intermittently to further relax the spring embedder system, resulting in reduced inter-cluster edge crossings. Unlike other algorithms generating circular drawings, our algorithm does not require the quotient graph to be acyclic, nor does it sacrifice the edge crossing number of individual clusters to improve respective positioning of the clusters. Moreover, it reduces the total area required by a cluster by using the space inside the associated circle. Experimental results show that the execution time and quality of the produced drawings with respect to commonly accepted layout criteria are quite satisfactory, surpassing previous algorithms. The algorithm has also been successfully implemented and made publicly available as part of a compound and clustered graph editing and layout tool named Chisio.","1941-0506","","10.1109/TVCG.2012.178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6295613","Information visualization;visualization techniques and methodologies;visualization systems and software;graph algorithms;algorithm design and analysis;graph visualization;graph drawing;force-directed layout;circular layout;clustered graphs;sequence alignment","Layout;Clustering algorithms;Springs;Force;Algorithm design and analysis;Software algorithms;Data visualization","data visualisation;pattern clustering","CiSE algorithm;circular spring embedder layout algorithm;graph clustering;circular style clustering;spring embedder system;inter-cluster edge crossing;quotient graph;layout criteria;Chisio tool;graph editing tool;graph layout tool","","6","","23","","5 Sep 2012","","","IEEE","IEEE Journals"
"Deep Neural Representation Guided Face Sketch Synthesis","B. Sheng; P. Li; C. Gao; K. -L. Ma","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Faculty of Information Technology, Macau University of Science and Technology, Macau, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science, University of California, Davis, CA, USA","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2019","2019","25","12","3216","3230","Face sketch synthesis shows great applications in a lot of fields such as online entertainment and suspects identification. Existing face sketch synthesis methods learn the patch-wise sketch style from the training dataset containing photo-sketch pairs. These methods manipulate the whole process directly in the field of RGB space, which unavoidably results in unsmooth noises at patch boundaries. If denoising methods are used, the sketch edges would be blurred and face structures could not be restored. Recent researches of feature maps, which are the outputs of a certain neural network layer, have achieved great success in texture synthesis and artistic image generation. In this paper, we reformulate the face sketch synthesis problem into a neural network feature maps based optimization task. Our results accurately capture the sketch drawing style and make full use of the whole stylistic information hidden in the training dataset. Unlike former feature map based methods, we utilize the Enhanced 3D PatchMatch and cross-layer cost aggregation methods to obtain the target feature maps for the final results. Multiple experiments have shown that our approach imitates hand-drawn sketch style vividly, and has high-quality visual effects on CUHK, AR, XM2VTS and CUFSF face sketch datasets.","1941-0506","","10.1109/TVCG.2018.2866090","National Natural Science Foundation of China(grant numbers:61572316,61671290,61872241); National Key Research and Development Program of China(grant numbers:2016 YFC1300302,2017YFE0104000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440073","Non-photorealistic rendering;face sketch synthesis;convolutional neural network (CNN);style transformation","Rendering (computer graphics);Face recognition;Feature extraction;Image restoration;Three-dimensional displays;Noise reduction;Convolutional neural networks","face recognition;feature extraction;image denoising;image representation;neural nets;optimisation","deep neural representation guided face sketch synthesis;patch boundaries;neural network layer;texture synthesis;cross-layer cost aggregation methods;RGB space;unsmooth noises;denoising methods;artistic image generation;Enhanced 3D PatchMatch","Algorithms;Art;Computer Graphics;Databases, Factual;Face;Humans;Image Processing, Computer-Assisted;Neural Networks, Computer","6","","49","IEEE","19 Aug 2018","","","IEEE","IEEE Journals"
"Design and Evaluation of MagnetViz—A Graph Visualization Tool","A. S. Spritzer; C. M. D. S. Freitas","Universidade Federal do Rio Grande do Sul (UFRGS), Porto Alegre; Universidade Federal do Rio Grande do Sul (UFRGS), Porto Alegre","IEEE Transactions on Visualization and Computer Graphics","15 Mar 2012","2012","18","5","822","835","MagnetViz was designed for the interactive manipulation of force-directed graph layouts, allowing the user to obtain visualizations based on the graph topology and/or the attributes of its nodes and edges. The user can introduce virtual magnets anywhere in the graph and these can be set to attract nodes and edges that fulfill user-defined criteria. When a magnet is placed, the force-directed nature of the layout forces it to reorganize itself in order to reflect the changes in the balance of forces, consequently changing the visualization into one that is more semantically relevant to the user. This paper describes MagnetViz's concepts, illustrating them with examples and a case study based on a usage scenario. We also describe how the MagnetViz has evolved since its original version and present the evaluation of its latest version. This evaluation consists of two user studies aiming at assessing generated layout quality and how well the concepts can be apprehended and employed, and a task taxonomy assessment focusing on establishing which graph visualization tasks the technique is able to handle.","1941-0506","","10.1109/TVCG.2011.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928333","Graph visualization;force-directed layout;evaluation;social networks visualization.","Layout;Visualization;Magnetic separation;Shape;Data visualization;Topology;Color","data visualisation;directed graphs;user interfaces","MagnetViz tool;graph visualization tool;force-directed graph layout;graph topology;graph node;graph edge;virtual magnet;user-defined criteria;layout force;force balance;usage scenario;user studies;generated layout quality;task taxonomy assessment","","6","2","23","","23 Jun 2011","","","IEEE","IEEE Journals"
"Dynamic Nested Tracking Graphs","J. Lukasczyk; C. Garth; G. H. Weber; T. Biedert; R. Maciejewski; H. Leitte","Technische Universität Kaiserslautern; Technische Universität Kaiserslautern; Lawrence Berkeley National Laboratory, University of California, Davis; NVIDIA Corporation; Arizona State University; Technische Universität Kaiserslautern","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","249","258","This work describes an approach for the interactive visual analysis of large-scale simulations, where numerous superlevel set components and their evolution are of primary interest. The approach first derives, at simulation runtime, a specialized Cinema database that consists of images of component groups, and topological abstractions. This database is processed by a novel graph operation-based nested tracking graph algorithm (GO-NTG) that dynamically computes NTGs for component groups based on size, overlap, persistence, and level thresholds. The resulting NTGs are in turn used in a feature-centered visual analytics framework to query specific database elements and update feature parameters, facilitating flexible post hoc analysis.","1941-0506","","10.1109/TVCG.2019.2934368","DFG; IRTG; U.S. Department of Energy Office of Science; National Nuclear Security Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854335","Topological Data Analysis;Nested Tracking Graphs;Image Databases;Feature Tracking;Post Hoc Visual Analytics","Databases;Computational modeling;Analytical models;Motion pictures;Vegetation;Visual analytics;Task analysis","data analysis;data visualisation;graph theory;interactive systems;query processing","feature-centered visual analytics framework;flexible post hoc analysis;dynamic nested tracking graphs;interactive visual analysis;large-scale simulations;topological abstractions;superlevel set components;cinema database;graph operation-based nested tracking graph algorithm;query specific database","","6","","35","IEEE","1 Oct 2019","","","IEEE","IEEE Journals"
"Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading","S. K. Badam; Z. Liu; N. Elmqvist","University of Maryland, College Park, MD, USA; Adobe Research, Seattle, WA, USA; University of Maryland, College Park, MD, USA","IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","661","671","Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, figures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.","1941-0506","","10.1109/TVCG.2018.2865119","National Science Foundation(grant numbers:IIS-1539534); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440810","Document reading;contextual visualizations;visual aids;comprehension;summarization","Data visualization;Visualization;Layout;Portable document format;Media;Hurricanes;Couplings","collections of physical data;data visualisation;information retrieval;text analysis","elastic documents;coupling text;enhanced document reading;data tables;access content;contextual visualization technique;print document;keyword-based matching algorithm","","6","","66","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Fast, Memory-Efficient Construction of Voxelized Shadows","V. Kämpe; E. Sintorn; D. Dolonius; U. Assarsson","Department of Computer Science, Chalmers University, Goteborg, Sweden; Department of Computer Science, Chalmers University, Goteborg, Sweden; Department of Computer Science, Chalmers University, Goteborg, Sweden; Department of Computer Science, Chalmers University, Goteborg, Sweden","IEEE Transactions on Visualization and Computer Graphics","31 Aug 2016","2016","22","10","2239","2248","We present a fast and memory efficient algorithm for generating Compact Precomputed Voxelized Shadows. By performing much of the common sub-tree merging before identical nodes are ever created, we improve construction times by several orders of magnitude for large data structures, and require much less working memory. To further improve performance, we suggest two new algorithms with which the remaining common sub-trees can be merged. We also propose a new set of rules for resolving undefined regions, which significantly reduces the final memory footprint of the already heavily compressed data structure. Additionally, we examine the feasibility of using CPVS for many local lights and present two improvements to the original algorithm that allow us to handle hundreds of lights with high-quality, filtered shadows at real-time frame rates.","1941-0506","","10.1109/TVCG.2016.2539955","Swedish Foundation for Strategic Research(grant numbers:RIT10-0033); Swedish Research Council(grant numbers:2014-4559); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429785","Shadow, voxel, directed acyclic graph, real-time","Geometry;Memory management;Real-time systems;Rendering (computer graphics);Data structures;Approximation algorithms;Optimization","data compression;rendering (computer graphics);tree data structures","memory efficient algorithm;compact precomputed voxelized shadows;subtree merging;data structures;memory footprint;compressed data structure","","6","","18","IEEE","9 Mar 2016","","","IEEE","IEEE Journals"
"Feature Tracking by Two-Step Optimization","A. Schnorr; D. N. Helmrich; D. Denker; T. W. Kuhlen; B. Hentschel","JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany; JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany; Institute for Combustion Technology, RWTH Aachen University, Aachen, Germany; JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany; JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany","IEEE Transactions on Visualization and Computer Graphics","30 Apr 2020","2020","26","6","2219","2233","Tracking the temporal evolution of features in time-varying data is a key method in visualization. For typical feature definitions, such as vortices, objects are sparsely distributed over the data domain. In this paper, we present a novel approach for tracking both sparse and space-filling features. While the former comprise only a small fraction of the domain, the latter form a set of objects whose union covers the domain entirely while the individual objects are mutually disjunct. Our approach determines the assignment of features between two successive time-steps by solving two graph optimization problems. It first resolves one-to-one assignments of features by computing a maximum-weight, maximum-cardinality matching on a weighted bi-partite graph. Second, our algorithm detects events by creating a graph of potentially conflicting event explanations and finding a weighted, independent set in it. We demonstrate our method's effectiveness on synthetic and simulation data sets, the former of which enables quantitative evaluation because of the availability of ground-truth information. Here, our method performs on par or better than a well-established reference algorithm. In addition, manual visual inspection by our collaborators confirm the results' plausibility for simulation data.","1941-0506","","10.1109/TVCG.2018.2883630","DFG(grant numbers:KU 1132/10-1); German Excellence Initiative via JARA-HPC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546802","Global optimization;simulation output analysis;flow visualization","Feature extraction;Target tracking;Optimization;Data visualization;Data models;Analytical models;Heuristic algorithms","computational complexity;data visualisation;feature extraction;graph theory;optimisation","two-step optimization;time-varying data;feature definition;data domain;sparse space-filling features;graph optimization problems;maximum-weight matching;maximum-cardinality matching;weighted bi-partite graph;feature tracking","","6","","40","IEEE","27 Nov 2018","","","IEEE","IEEE Journals"
"FeatureExplorer: Interactive Feature Selection and Exploration of Regression Models for Hyperspectral Images","J. Zhao; M. Karimzadeh; A. Masjedi; T. Wang; X. Zhang; M. M. Crawford; D. S. Ebert",Purdue University; University of Colorado Boulder; Purdue University; Purdue University; Purdue University; Purdue University; Purdue University,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","161","165","Feature selection is used in machine learning to improve predictions, decrease computation time, reduce noise, and tune models based on limited sample data. In this article, we present FeatureExplorer, a visual analytics system that supports the dynamic evaluation of regression models and importance of feature subsets through the interactive selection of features in high-dimensional feature spaces typical of hyperspectral images. The interactive system allows users to iteratively refine and diagnose the model by selecting features based on their domain knowledge, interchangeable (correlated) features, feature importance, and the resulting model performance.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933619","Feature selection;regression models;hyperspectral images;high-dimensional data;visual analytics","Hyperspectral imaging;Feature extraction;Biomass;Correlation;Biological system modeling;Analytical models","data analysis;data visualisation;feature selection;geophysical image processing;hyperspectral imaging;interactive systems;learning (artificial intelligence);regression analysis","FeatureExplorer;interactive feature selection;regression models;hyperspectral images;machine learning;visual analytics system;interactive system","","6","","27","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach","T. Major; R. C. Basole",Georgia Institute of Technology; Georgia Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","576","585","Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.","1941-0506","","10.1109/TVCG.2018.2865151","UCB Inc.(grant numbers:RH175); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440854","Unit visualization;network visualization;context","Data visualization;Layout;Visualization;Medical services;Aggregates;Bars;Organizations","data visualisation","network structure;visualization systems;blended visualization approach;unit visualization techniques;Graphicle;relational data;multivariate data;visual exploration;network visualizations","","6","","46","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"MemAxes: Visualization and Analytics for Characterizing Complex Memory Performance Behaviors","A. Giménez; T. Gamblin; I. Jusufi; A. Bhatele; M. Schulz; P. Bremer; B. Hamann","University of California, Davis, CA; Lawrence Livermore National Laboratory, Livermore, CA; Linnaeus University in Växjö, Växjö, Sweden; Lawrence Livermore National Laboratory, Livermore, CA; Lawrence Livermore National Laboratory, Livermore, CA; Lawrence Livermore National Laboratory, Livermore, CA; University of California, Davis, CA","IEEE Transactions on Visualization and Computer Graphics","25 May 2018","2018","24","7","2180","2193","Memory performance is often a major bottleneck for high-performance computing (HPC) applications. Deepening memory hierarchies, complex memory management, and non-uniform access times have made memory performance behavior difficult to characterize, and users require novel, sophisticated tools to analyze and optimize this aspect of their codes. Existing tools target only specific factors of memory performance, such as hardware layout, allocations, or access instructions. However, today's tools do not suffice to characterize the complex relationships between these factors. Further, they require advanced expertise to be used effectively. We present MemAxes, a tool based on a novel approach for analytic-driven visualization of memory performance data. MemAxes uniquely allows users to analyze the different aspects related to memory performance by providing multiple visual contexts for a centralized dataset. We define mappings of sampled memory access data to new and existing visual metaphors, each of which enabling a user to perform different analysis tasks. We present methods to guide user interaction by scoring subsets of the data based on known performance problems. This scoring is used to provide visual cues and automatically extract clusters of interest. We designed MemAxes in collaboration with experts in HPC and demonstrate its effectiveness in case studies.","1941-0506","","10.1109/TVCG.2017.2718532","Lawrence Livermore National Laboratory (LLNL); University of California (UC) at Davis; UC Laboratory Fees Research Grant Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7955092","Performance visualization;high-performance computing;memory visualization","Hardware;Data visualization;Resource management;Tools;Radiation detectors;Visualization;Memory management","data analysis;data visualisation;parallel processing;storage management;user interfaces","complex memory performance behavior characterization;memory access data;visual metaphors;centralized dataset;HPC;memory performance data;analytic-driven visualization;nonuniform access times;complex memory management;memory hierarchies;high-performance computing applications;MemAxes","","6","","30","USGov","22 Jun 2017","","","IEEE","IEEE Journals"
"Mesh Saliency via Weakly Supervised Classification-for-Saliency CNN","R. Song; Y. Liu; P. L. Rosin","Centre for Secure, Intelligent and Usable Systems, School of Computing, Engineering and Mathematics, University of Brighton, Brighton, United Kingdom; Department of Computer Science, Edge Hill University, Ormskirk, United Kingdom; School of Computer Science and Informatics, Cardiff University, Cardiff, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","151","164","Recently, effort has been made to apply deep learning to the detection of mesh saliency. However, one major barrier is to collect a large amount of vertex-level annotation as saliency ground truth for training the neural networks. Quite a few pilot studies showed that this task is difficult. In this work, we solve this problem by developing a novel network trained in a weakly supervised manner. The training is end-to-end and does not require any saliency ground truth but only the class membership of meshes. Our Classification-for-Saliency CNN (CfS-CNN) employs a multi-view setup and contains a newly designed two-channel structure which integrates view-based features of both classification and saliency. It essentially transfers knowledge from 3D object classification to mesh saliency. Our approach significantly outperforms the existing state-of-the-art methods according to extensive experimental results. Also, the CfS-CNN can be directly used for scene saliency. We showcase two novel applications based on scene saliency to demonstrate its utility.","1941-0506","","10.1109/TVCG.2019.2928794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765747","Mesh saliency;deep learning;transfer learning;weak supervision","Three-dimensional displays;Training;Two dimensional displays;Neural networks;Deep learning;Task analysis;Solid modeling","convolutional neural nets;feature extraction;image classification;mesh generation;stereo image processing;supervised learning","mesh saliency detection;CfS-CNN;3D object classification;deep learning;vertex level annotation;neural network training;weakly supervised classification for saliency CNN;weakly supervised training;end-to-end training;view based features;convolutional neural network;knowledge transfer","","6","","43","IEEE","18 Jul 2019","","","IEEE","IEEE Journals"
"MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework","A. Wu; W. Tong; T. Dwyer; B. Lee; P. Isenberg; H. Qu",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Monash University; Microsoft Research; Inria; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","464","474","We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.","1941-0506","","10.1109/TVCG.2020.3030423","Microsoft Research Asia(grant numbers:MRA19EG02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229072","Mobile visualization;Responsive visualization;Machine learning for visualizations;Reinforcement learning","Data visualization;Visualization;Mobile handsets;Sociology;Statistics;Encoding;Layout","data visualisation;decision theory;gradient methods;learning (artificial intelligence);Markov processes;mobile computing;mobile handsets;optimisation","web visualizations;mobile phones;explainable reinforcement learning framework;mobile devices;frustrating user experience;tedious time-consuming process;designs scale;libraries;diagnosing;repairing issues;mobile-friendly visualization re-design process;reinforcement learning framework;SVG-based visualizations;common mobile-friendly issues;single-view Cartesian visualizations;Markov Decision Process model;MobileVisFixer;data visualizations","","6","","78","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Multi-Depth-Map Raytracing for Efficient Large-Scene Reconstruction","M. Arikan; R. Preiner; M. Wimmer","Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria; Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria; Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2015","2016","22","2","1127","1137","With the enormous advances of the acquisition technology over the last years, fast processing and high-quality visualization of large point clouds have gained increasing attention. Commonly, a mesh surface is reconstructed from the point cloud and a high-resolution texture is generated over the mesh from the images taken at the site to represent surface materials. However, this global reconstruction and texturing approach becomes impractical with increasing data sizes. Recently, due to its potential for scalability and extensibility, a method for texturing a set of depth maps in a preprocessing and stitching them at runtime has been proposed to represent large scenes. However, the rendering performance of this method is strongly dependent on the number of depth maps and their resolution. Moreover, for the proposed scene representation, every single depth map has to be textured by the images, which in practice heavily increases processing costs. In this paper, we present a novel method to break these dependencies by introducing an efficient raytracing of multiple depth maps. In a preprocessing phase, we first generate high-resolution textured depth maps by rendering the input points from image cameras and then perform a graph-cut based optimization to assign a small subset of these points to the images. At runtime, we use the resulting point-to-image assignments (1) to identify for each view ray which depth map contains the closest ray-surface intersection and (2) to efficiently compute this intersection point. The resulting algorithm accelerates both the texturing and the rendering of the depth maps by an order of magnitude.","1941-0506","","10.1109/TVCG.2015.2430333","Austrian Research Promotion Agency(grant numbers:835948); EU FP7 project HARVEST4D(grant numbers:323567); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102754","Point-based rendering;raytracing depth maps;large-scale models;Point-based rendering;raytracing depth maps;large-scale models","Rendering (computer graphics);Labeling;Three-dimensional displays;Image reconstruction;Surface texture;Surface reconstruction;Runtime","cameras;data visualisation;graph theory;image reconstruction;image resolution;image texture;mesh generation;optimisation;ray tracing;rendering (computer graphics)","multidepth-map raytracing;large-scene reconstruction;high-quality visualization;mesh surface;high-resolution texture;image texture;image representation;surface material representation;rendering performance;high-resolution textured depth map;graph-cut based optimization;closest ray-surface intersection","","6","","19","IEEE","6 May 2015","","","IEEE","IEEE Journals"
"Narrative Collage of Image Collections by Scene Graph Recombination","F. Fang; M. Yi; H. Feng; S. Hu; C. Xiao","State Key Lab of Software Engineering, School of Computer, Wuhan University, Wuhan, China; School of Mathematics and Statistics, Wuhan University, Wuhan, China; School of Mathematics and Statistics, Wuhan University, Wuhan, China; State Key Lab of Software Engineering, Wuhan University, Wuhan, China; State Key Lab of Software Engineering, School of Computer, Wuhan University, Wuhan, China","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2018","2018","24","9","2559","2572","A narrative collage is an interesting image editing method for summarizing the main theme or storyline behind an image collection. We present a novel method to generate narrative images with plausible semantic scene structures. To achieve this goal, we introduce a layer graph and a scene graph to represent the relative depth order and semantic relationship between image objects, respectively. We first cluster the input image collection to select representative images, and then we extract a group of semantic salient objects from each representative image. Both layer graphs and scene graphs are constructed and combined according to our specific rules for reorganizing the extracted objects in every image. We design an energy model to appropriately locate every object on the final canvas. The experimental results show that our method can produce competitive narrative collage results and that it performs well on a wide range of image collections.","1941-0506","","10.1109/TVCG.2017.2759265","The National Key Research and Development Program of China(grant numbers:2017YFB1002600); NSFC(grant numbers:61472288,61672390); Foundation of Key Research Institute of Humanities and Social Science at Universities(grant numbers:16JJD870002); Chinese Ministry of Education; Wuhan Science and Technology Plan Project(grant numbers:2017010201010109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057796","Narrative collage;image collections;image segmentation;scene graphs;image synthesis","Semantics;Visualization;Image segmentation;Painting;Layout;Databases;Image generation","graph theory;image classification;image representation;pattern clustering","scene graph recombination;plausible semantic scene structures;layer graph;image objects;semantic salient objects;image collection;image editing method;energy model;image representation","","6","","34","IEEE","4 Oct 2017","","","IEEE","IEEE Journals"
"Predominance Tag Maps","M. Reckziegel; M. F. Cheema; G. Scheuermann; S. Jänicke","Leipzig University, Leipzig, Germany; Leipzig University, Leipzig, Germany; Leipzig University, Leipzig, Germany; Leipzig University, Leipzig, Germany","IEEE Transactions on Visualization and Computer Graphics","30 Apr 2018","2018","24","6","1893","1904","A <italic>predominance map</italic> expresses the predominant data category for each geographical entity and colors are used to differentiate a small number of data categories. In <italic>tag maps</italic>, many data categories are present in the form of different tags, but related tag map approaches do not account for predominance, as tags are either displaced from their respective geographical locations or visual clutter occurs. We propose <italic> predominance tag maps</italic>, a layout algorithm that accounts for predominance for arbitrary aggregation granularities. The algorithm is able to utilize the font sizes of the tags as visual variable and it is further configurable to implement aggregation strategies beyond visualizing predominance. We introduce various measures to evaluate numerically the qualitative aspects of tag maps regarding local predominance, global features, and layout stability and we comparatively analyze our method to the tag map approach by Thom et al.  <xref ref-type=""bibr"" rid=""ref1"">[1]</xref> on the basis of real world data sets.","1941-0506","","10.1109/TVCG.2018.2816208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320795","Geospatial visualization;point-based data;data aggregation","Tag clouds;Geospatial analysis;Layout;Image color analysis;Data visualization;Shape;Visualization","cartography;data analysis;data visualisation","predominance tag maps;predominant data category;geographical entity;colors;related tag map approaches;local predominance;predominance visualization;geographical locations;visual clutter;arbitrary aggregation granularities;visual variable;aggregation strategies","","6","","53","IEEE","21 Mar 2018","","","IEEE","IEEE Journals"
"Ray-tracing triangular trimmed free-form surfaces","W. Sturzlinger","Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1998","4","3","202","214","This paper presents a new approach to rendering triangular algebraic free-form surfaces. A hierarchical subdivision of the surface with associated tight bounding volumes provides for quick identification of the surface regions likely to be hit by a ray. For each leaf of the hierarchy, an approximation to the corresponding surface region is stored. The approximation is used to compute a good starting point for the iteration, which ensures rapid convergence. Trimming curves are described by a tree of trimming primitives, such as squares, circles, polygons, and free-form curves, combined with Boolean operations. For trimmed surfaces, an irregular adaptive subdivision is constructed to quickly eliminate all parts outside the trimming curve from consideration during rendering. Cost heuristics are introduced to optimize the rendering time further.","1941-0506","","10.1109/2945.722295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722295","","Ray tracing;Design automation;Tensile stress;Solids;Layout;Surface cracks;Iterative methods;Convergence;Chebyshev approximation;Automobiles","ray tracing;rendering (computer graphics);splines (mathematics);surface fitting;computational geometry","ray tracing;triangular trimmed free-form surfaces;hierarchical subdivision;tight bounding volumes;convergence;trimming curves;squares;circles;polygons;free-form curves;Boolean operations;irregular adaptive subdivision;rendering;cost heuristics;NURBS;CAD","","6","","22","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Real-Time Rendering Method and Performance Evaluation of Composable 3D Lenses for Interactive VR","C. W. Borst; J. -P. Tiesel; C. M. Best","University of Louisiana at Lafayette, Lafayette; University of Louisiana at Lafayette, Lafayette; Willian J. Hughes Technical Center, Atlantic City International Airport","IEEE Transactions on Visualization and Computer Graphics","11 Mar 2010","2010","16","3","394","410","We present and evaluate a new approach for real-time rendering of composable 3D lenses for polygonal scenes. Such lenses, usually called “volumetric lenses,” are an extension of 2D Magic Lenses to 3D volumes in which effects are applied to scene elements. Although the composition of 2D lenses is well known, 3D composition was long considered infeasible due to both geometric and semantic complexity. Nonetheless, for a scene with multiple interactive 3D lenses, the problem of intersecting lenses must be considered. Intersecting 3D lenses in meaningful ways supports new interfaces such as hierarchical 3D windows, 3D lenses for managing and composing visualization options, or interactive shader development by direct manipulation of lenses providing component effects. Our 3D volumetric lens approach differs from other approaches and is one of the first to address efficient composition of multiple lenses. It is well-suited to head-tracked VR environments because it requires no view-dependent generation of major data structures, allowing caching and reuse of full or partial results. A Composite Shader Factory module composes shader programs for rendering composite visual styles and geometry of intersection regions. Geometry is handled by Boolean combinations of region tests in fragment shaders, which allows both convex and nonconvex CSG volumes for lens shape. Efficiency is further addressed by a Region Analyzer module and by broad-phase culling. Finally, we consider the handling of order effects for composed 3D lenses.","1941-0506","","10.1109/TVCG.2009.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5184832","Interaction styles;virtual reality;volumetric lens;windowing systems.","Lenses;Virtual reality;Layout;Rendering (computer graphics);Visualization;Geometry;Shape;Data structures;Production facilities;Testing","interactive systems;performance evaluation;real-time systems;rendering (computer graphics);virtual reality","real time rendering method;performance evaluation;composable 3D lense;interactive VR;polygonal scene;volumetric lense;2D magic lenses;geometric complexity;semantic complexity;multiple interactive 3D lenses;composite shader factory module;Boolean combination;region analyzer module;hierarchical 3D window","Computer Simulation;Computer Systems;Computer-Aided Design;Equipment Design;Equipment Failure Analysis;Image Interpretation, Computer-Assisted;Lenses;Models, Theoretical;Software;User-Computer Interface","6","","19","IEEE","31 Jul 2009","","","IEEE","IEEE Journals"
"Runtime Visualization of the Human Arterial Tree","J. A. Insley; M. E. Papka; S. Dong; G. Karniadakis; N. T. Karonis","Argonne National Laboratory, 9700 S. Cass Ave., Argonne, IL 60439; Argonne National Laboratory, 9700 S. Cass Ave., Argonne, IL 60439; Center for Computational and Applied Mathematics, Department of Mathematics, Purdue University, 150 N. University Street, West Lafayette, IN 47907; Division of Applied Mathematics, Brown University, Box F, Providence, RI 02912; Computer Science Department, Northern Illinois University, Psychology-Computer Science Building, DeKalb, IL 60115","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","810","821","Large-scale simulation codes typically execute for extended periods of time and often on distributed computational resources. Because these simulations can run for hours, or even days, scientists like to get feedback about the state of the computation and the validity of its results as it runs. It is also important that these capabilities be made available with little impact on the performance and stability of the simulation. Visualizing and exploring data in the early stages of the simulation can help scientists identify problems early, potentially avoiding a situation where a simulation runs for several days, only to discover that an error with an input parameter caused both time and resources to be wasted. We describe an application that aids in the monitoring and analysis of a simulation of the human arterial tree. The application provides researchers with high-level feedback about the state of the ongoing simulation and enables them to investigate particular areas of interest in greater detail. The application also offers monitoring information about the amount of data produced and data transfer performance among the various components of the application.","1941-0506","","10.1109/TVCG.2007.1017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293023","Real-time visualization;flow visualization;computer graphics;graphics systems;distributed/network graphics;simulation and modeling;simulation output/analysis.","Runtime;Humans;Computational modeling;State feedback;Monitoring;Large-scale systems;Distributed computing;Stability;Data visualization;Analytical models","biology computing;data visualisation","data transfer performance;monitoring information;high-level feedback;human arterial tree simulation;computation state feedback;runtime data visualization","Algorithms;Arteries;Arteries;Blood Flow Velocity;Blood Pressure;Computer Graphics;Computer Simulation;Computer Systems;Humans;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Cardiovascular","6","","20","","20 Aug 2007","","","IEEE","IEEE Journals"
"Semantic Flow Graph: A Framework for Discovering Object Relationships in Flow Fields","J. Tao; C. Wang; N. V. Chawla; L. Shi; S. H. Kim","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; University of Chinese Academy of Sciences, Beijing, China; Department of Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2018","2018","24","12","3200","3213","Visual exploration of flow fields is important for studying dynamic systems. We introduce semantic flow graph (SFG), a novel graph representation and interaction framework that enables users to explore the relationships among key objects (i.e., field lines, features, and spatiotemporal regions) of both steady and unsteady flow fields. The objects and their relationships are organized as a heterogeneous graph. We assign each object a set of attributes, based on which a semantic abstraction of the heterogeneous graph is generated. This semantic abstraction is SFG. We design a suite of operations to explore the underlying flow fields based on this graph representation and abstraction mechanism. Users can flexibly reconfigure SFG to examine the relationships among groups of objects at different abstraction levels. Three linked views are developed to display SFG, its node split criteria and history, and the objects in the spatial volume. For simplicity, we introduce SFG construction and exploration for steady flow fields with critical points being the only features. Then we demonstrate that SFG can be naturally extended to deal with unsteady flow fields and multiple types of features. We experiment with multiple data sets and conduct an expert evaluation to demonstrate the effectiveness of our approach.","1941-0506","","10.1109/TVCG.2017.2773071","US National Science Foundation(grant numbers:IIS-1456763,IIS-1455886); Notre Dame Global Collaboration Initiative Program; China National 973 project(grant numbers:2014CB340301); National Natural Science Foundation of China(grant numbers:61379088,61772504); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8118164","Flow visualization;heterogeneous graph;semantic abstraction;critical points;vortex cores;FTLE;field lines","Semantics;Visualization;History;Two dimensional displays;Clutter;Three-dimensional displays;Aerodynamics","data visualisation;graph theory","SFG;unsteady flow fields;semantic flow graph;object relationships;visual exploration;field lines;heterogeneous graph;semantic abstraction;abstraction mechanism;steady flow fields;graph representation;spatiotemporal regions","","6","","36","IEEE","22 Nov 2017","","","IEEE","IEEE Journals"
"Space-Time Light Field Rendering","H. Wang; M. Sun; R. Yang","Georgia Institute of Technology, Tech Square Research Building, Atlanta, GA; Georgia Institute of Technology, Tech Square Research Building, Atlanta, GA; Department of Computer Science, University of Kentucky, Lexington, KY","IEEE Transactions on Visualization and Computer Graphics","20 Aug 2007","2007","13","4","697","710","In this paper, we propose a novel framework called space-time light field rendering, which allows continuous exploration of a dynamic scene in both space and time. Compared to existing light field capture/rendering systems, it offers the capability of using unsynchronized video inputs and the added freedom of controlling the visualization in the temporal domain, such as smooth slow motion and temporal integration. In order to synthesize novel views from any viewpoint at any time instant, we develop a two-stage rendering algorithm. We first interpolate in the temporal domain to generate globally synchronized images using a robust spatial-temporal image registration algorithm followed by edge-preserving image morphing. We then interpolate these software-synchronized images in the spatial domain to synthesize the final view. In addition, we introduce a very accurate and robust algorithm to estimate subframe temporal offsets among input video sequences. Experimental results from unsynchronized videos with or without time stamps show that our approach is capable of maintaining photorealistic quality from a variety of real scenes.","1941-0506","","10.1109/TVCG.2007.1019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293014","Image-based rendering;space-time light field;epipolar constraint;image morphing.","Layout;Robustness;Motion control;Lighting control;Control systems;Visualization;Control system synthesis;Rendering (computer graphics);Image generation;Image registration","data visualisation;image morphing;image registration;image sequences;realistic images;rendering (computer graphics);spatiotemporal phenomena","space-time light field rendering;unsynchronized input video sequences;data visualization;smooth slow motion;two-stage rendering algorithm;global synchronized image;spatial-temporal image registration algorithm;edge-preserving image morphing;photorealistic images","Algorithms;Artificial Intelligence;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Lighting;Models, Theoretical;Numerical Analysis, Computer-Assisted;User-Computer Interface","6","2","41","","20 Aug 2007","","","IEEE","IEEE Journals"
"Surface Motion Capture Animation Synthesis","A. Boukhayma; E. Boyer","University of Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France; University of Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France","IEEE Transactions on Visualization and Computer Graphics","30 Apr 2019","2019","25","6","2270","2283","We propose to generate novel animations from a set of elementary examples of video-based surface motion capture, under user-specified constraints. 4D surface capture animation is motivated by the increasing demand from media production for highly realistic 3D content. To this aim, data driven strategies that consider video-based information can produce animation with real shapes, kinematics and appearances. Our animations rely on the combination and the interpolation of textured 3D mesh data, which requires examining two aspects: (1) Shape geometry and (2) appearance. First, we propose an animation synthesis structure for the shape geometry, the Essential graph, that outperforms standard Motion graphs in optimality with respect to quantitative criteria, and we extend optimized interpolated transition algorithms to mesh data. Second, we propose a compact view-independent representation for the shape appearance. This representation encodes subject appearance changes due to viewpoint and illumination, and due to inaccuracies in geometric modelling independently. Besides providing compact representations, such decompositions allow for additional applications such as interpolation for animation.","1941-0506","","10.1109/TVCG.2018.2831233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352750","Character animation;3D video;multiview reconstruction;video-based animation;4D modeling;4D performance capture","Animation;Shape;Geometry;Interpolation;Three-dimensional displays;Pipelines;Motion segmentation","computational geometry;computer animation;graph theory;image capture;image motion analysis;image texture;interpolation;mesh generation;solid modelling","textured 3D mesh data;optimized interpolated transition algorithms;video-based surface motion capture;4D surface capture animation;shape geometry;view-independent representation;surface motion capture animation synthesis","","6","","56","IEEE","30 Apr 2018","","","IEEE","IEEE Journals"
"TOD-Tree: Task-Overlapped Direct Send Tree Image Compositing for Hybrid MPI Parallelism and GPUs","A. V. P. Grosset; M. Prasad; C. Christensen; A. Knoll; C. Hansen","Scientific Computing and Imaging Institute at the University of Utah, Salt Lake City, UT; Google, Mountain View, California, CA; Scientific Computing and Imaging Institute at the University of Utah, Salt Lake City, UT; Scientific Computing and Imaging Institute at the University of Utah, Salt Lake City, UT; Scientific Computing and Imaging Institute at the University of Utah, Salt Lake City, UT","IEEE Transactions on Visualization and Computer Graphics","28 Apr 2017","2017","23","6","1677","1690","Modern supercomputers have thousands of nodes, each with CPUs and/or GPUs capable of several teraflops. However, the network connecting these nodes is relatively slow, on the order of gigabits per second. For time-critical workloads such as interactive visualization, the bottleneck is no longer computation but communication. In this paper, we present an image compositing algorithm that works on both CPU-only and GPU-accelerated supercomputers and focuses on communication avoidance and overlapping communication with computation at the expense of evenly balancing the workload. The algorithm has three stages: a parallel direct send stage, followed by a tree compositing stage and a gather stage. We compare our algorithm with radix-k and binary-swap from the IceT library in a hybrid OpenMP/MPI setting on the Stampede and Edison supercomputers, show strong scaling results and explain how we generally achieve better performance than these two algorithms. We developed a GPU-based image compositing algorithm where we use CUDA kernels for computation and GPU Direct RDMA for inter-node GPU communication. We tested the algorithm on the Piz Daint GPU-accelerated supercomputer and show that we achieve performance on par with CPUs. Last, we introduce a workflow in which both rendering and compositing are done on the GPU.","1941-0506","","10.1109/TVCG.2016.2542069","DOE; NNSA(grant numbers:DE-NA0002375); PSAAP; DOE; SciDAC Institute of Scalable Data Management Analysis and Visualization; DOE(grant numbers:DE-SC0007446,NSF ACI-1339881,NSF IIS-1162013); Texas Advanced Computing Center (TACC); University of Texas at Austin; National Energy Research Scientific Computing Center (NERSC); Swiss National Supercomputing Centre (CSCS); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433468","Distributed volume rendering;image compositing;parallel processing","Graphics processing units;Rendering (computer graphics);Supercomputers;Parallel processing;Data visualization;Loading;Message systems","application program interfaces;graphics processing units;image processing;message passing;rendering (computer graphics);tree data structures","TOD-tree;task-overlapped direct send tree image compositing;hybrid MPI parallelism;interactive visualization;CPU-only supercomputers;GPU-accelerated supercomputers;communication avoidance;overlapping communication;radix-k;binary-swap;IceT library;hybrid OpenMP/MPI setting;GPU-based image compositing algorithm;CUDA kernels;GPU direct RDMA;internode GPU communication;Piz Daint GPU-accelerated supercomputer;rendering","","6","","47","IEEE","14 Mar 2016","","","IEEE","IEEE Journals"
"Toward Interface Defaults for Vague Modifiers in Natural Language Interfaces for Visual Analysis","M. Hearst; M. Tory; V. Setlur","UC Berkeley; Tableau Software, Inc.; Tableau Research","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","21","25","Natural language interfaces for data visualizations tools are growing in importance, but little research has been done on how a system should respond to questions that contain vague modifiers like ""high"" and ""expensive."" This paper makes a first step toward design guidelines for this problem, based on existing research from cognitive linguistics and the results of a new empirical study with 274 crowdsourcing participants. A comparison of four bar chart-based views finds that highlighting the top items according to distribution-sensitive values is preferred in most cases and is a good starting point as a design guideline.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933569","Human-centered computing;Visualization","Shape;Bars;Data visualization;Linguistics;Visualization;Tools","crowdsourcing;data visualisation;linguistics;natural language interfaces","interface defaults;vague modifiers;natural language interfaces;visual analysis;data visualizations tools;bar chart-based views;cognitive linguistics;crowdsourcing participants","","6","","27","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Uncovering Data Landscapes through Data Reconnaissance and Task Wrangling","A. Crisan; T. Munzner","University of British Columbia,Dept. of Computer Science; University of British Columbia,Dept. of Computer Science","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","46","50","Domain experts are inundated with new and heterogeneous types of data and require better and more specific types of data visualization systems to help them. In this paper, we consider the data landscape that domain experts seek to understand, namely the set of datasets that are either currently available or could be obtained. Experts need to understand this landscape to triage which data analysis projects might be viable, out of the many possible research questions that they could pursue. We identify data reconnaissance and task wrangling as processes that experts undertake to discover and identify sources of data that could be valuable for some specific analysis goal. These processes have thus far not been formally named or defined by the research community. We provide formal definitions of data reconnaissance and task wrangling and describe how they relate to the data landscape that domain experts must uncover. We propose a conceptual framework with a four-phase cycle of acquire, view, assess, and pursue that occurs within three distinct chronological stages, which we call fog and friction, informed data ideation, and demarcation of final data. Collectively, these four phases embedded within three temporal stages delineate an expert's progressively evolving understanding of the data landscape. We describe and provide concrete examples of these processes within the visualization community through an initial systematic analysis of previous design studies, identifying situations where there is evidence that they were at play. We also comment on the response of domain experts to this framework, and suggest design implications stemming from these processes to motivate future research directions. As technological changes will only keep adding unknown terrain to the data landscape, data reconnaissance and task wrangling are important processes that need to be more widely understood and supported by the data visualization tools. By articulating a concrete understanding of this challenge and its implications, our work impacts the design and evaluation of data visualization systems.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933542","Human-centered computing;Visualization;Visualization design and evaluation methods","Task analysis;Data visualization;Reconnaissance;Visualization;Tools;Friction","data analysis;data visualisation","data landscape;data reconnaissance;task wrangling;data visualization tools;data visualization systems;data analysis projects;data ideation","","6","","15","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visual Interactive Map Matching","R. Krüger; G. Simeonov; F. Beck; T. Ertl","Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany; Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany; Paluno, University of Duisburg-Essen, Duisburg, Germany; Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany","IEEE Transactions on Visualization and Computer Graphics","30 Apr 2018","2018","24","6","1881","1892","Map matching is the process of assigning observed geographic positions of vehicles and their trajectories to the actual road links in a road network. In this paper, we present Visual Interactive Map Matching, a visual analytics approach to fine-tune the data preprocessing and matching process. It is based on ST-matching, a state-of-the-art and easy-to-understand map matching algorithm. Parameters of the preprocessing step and algorithm can be optimized with immediate visual feedback. Visualizations show current matching issues and performance metrics on a map and in diagrams. Manual and computer-supported editing of the road network model leads to a refined alignment of trajectories and roads. We demonstrate our approach with large-scale taxi trajectory data. We show that optimizing the matching on a subsample results in considerably improved matching quality, also when later scaled to the full dataset. An optimized matching ensures data faithfulness and prevents misinterpretation when the matched data might be investigated in follow-up analysis.","1941-0506","","10.1109/TVCG.2018.2816219","European project Cimplex(grant numbers:641191); Data-Driven Intelligent Transportation between China; Ministry of Science and Technology of China; Zhejiang Provincial Natural Science Foundation(grant numbers:LR14F020002); DFG SPP 1894 project Volunteered Geographic Information (VGI); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320847","Map matching;data cleaning;data transformation and representation;geographic visualization","Trajectory;Roads;Data visualization;Visual analytics;Data preprocessing;Global Positioning System","cartography;data analysis;data visualisation;geographic information systems;Global Positioning System;image matching;optimisation;road traffic;traffic information systems","visual analytics approach;data preprocessing;visualizations;road network model;large-scale taxi trajectory data;road links;visual interactive map matching;ST-matching algorithm;visual feedback;matching optimization;vehicles geographic positions;performance metrics;computer-supported editing;manual supported editing;follow-up analysis","","6","","26","IEEE","21 Mar 2018","","","IEEE","IEEE Journals"
"Why Visualize? Untangling a Large Network of Arguments","D. Streeb; M. El-Assady; D. A. Keim; M. Chen","Group of Data Analysis and Visualization, University of Konstanz, Konstanz, Germany; Group of Data Analysis and Visualization, University of Konstanz, Konstanz, Germany; Group of Data Analysis and Visualization, University of Konstanz, Konstanz, Germany; Department of Engineering Science, University of Oxford, Oxford, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","3","2220","2236","Visualization has been deemed a useful technique by researchers and practitioners, alike, leaving a trail of arguments behind that reason why visualization works. In addition, examples of misleading usages of visualizations in information communication have occasionally been pointed out. Thus, to contribute to the fundamental understanding of our discipline, we require a comprehensive collection of arguments on “why visualize?” (or “why not?”), untangling the rationale behind positive and negative viewpoints. In this paper, we report a theoretical study to understand the underlying reasons of various arguments; their relationships (e.g., built-on, and conflict); and their respective dependencies on tasks, users, and data. We curated an argumentative network based on a collection of arguments from various fields, including information visualization, cognitive science, psychology, statistics, philosophy, and others. Our work proposes several categorizations for the arguments, and makes their relations explicit. We contribute the first comprehensive and systematic theoretical study of the arguments on visualization. Thereby, we provide a roadmap towards building a foundation for visualization theory and empirical research as well as for practical application in the critique and design of visualizations. In addition, we provide our argumentation network and argument collection online at https://whyvis.dbvis.de, supported by an interactive visualization.","1941-0506","","10.1109/TVCG.2019.2940026","Universität Konstanz; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827956","Visualization;theory;argument network;cognition;design","Data visualization;Visualization;Task analysis;Pipelines;Biology;Bars;Manuals","data visualisation;inference mechanisms;interactive systems","argumentative network;visualization theory;argumentation network;interactive visualization","","6","","85","IEEE","10 Sep 2019","","","IEEE","IEEE Journals"
"scenery: Flexible Virtual Reality Visualization on the Java VM","U. Günther; T. Pietzsch; A. Gupta; K. I. S. Harrington; P. Tomancak; S. Gumhold; I. F. Sbalzarini","Center for Systems Biology Dresden MPI-CBG,Technische Universität Dresden,Dresden; MPI-CBG,Center for Systems Biology Dresden,Dresden; Center for Systems Biology Dresden MPI-CBG,Technische Universität Dresden,Dresden; Howard Hughes Medical Institute,University of Idaho; IT4Innovations, VŠB - Technical University of Ostrava,MPI-CBG, Dresden; Technische Universität Dresden; Center for Systems Biology Dresden MPI-CBG,Technische Universität Dresden,Dresden","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","The following topics are dealt with: data visualisation; data analysis; interactive systems; learning (artificial intelligence); pattern clustering; rendering (computer graphics); medical image processing; graph theory; neurophysiology; trees (mathematics).","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933605","Human-centered computing;Visualization;Visualization systems and tools Human-centered computing;Virtual reality","Rendering (computer graphics);Data visualization;Pipelines;Java;Tools;Microscopy;Systems biology","data analysis;data visualisation;interactive systems;learning (artificial intelligence);pattern clustering","data visualisation;data analysis;interactive systems;learning (artificial intelligence);pattern clustering;rendering (computer graphics);medical image processing;graph theory;neurophysiology;trees (mathematics)","","6","","34","","19 Dec 2019","","","IEEE","IEEE Conferences"
"A Deep Learning Approach to Selecting Representative Time Steps for Time-Varying Multivariate Data","W. P. Porter; Y. Xing; B. R. von Ohlen; J. Han; C. Wang",Univ. of Notre Dame; Sichuan Univ.; Univ. of Notre Dame; Univ. of Notre Dame; Univ. of Notre Dame,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","We present a deep learning approach that selects representative time steps from a given time-varying multivariate data set. Our solution leverages an autoencoder that implicitly learns feature descriptors of each individual volume in a latent space. These feature descriptors are used to reconstruct respective volumes for error estimation during network training. We then perform dimensionality reduction of these feature descriptors and select representative time steps in the projected space. Unlike previous approaches, our solution can handle time-varying multivariate data sets where the multivariate features can be learned using a multichannel input to the autoencoder. We demonstrate the effectiveness of our approach using several time-varying multivariate data sets and compare our selection results with those generated using an information-theoretic approach.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933759","","Training;Decoding;Deep learning;Earthquakes;Combustion;Feature extraction;Two dimensional displays","data visualisation;learning (artificial intelligence);neural nets","feature descriptors;time-varying multivariate data sets;multivariate features;deep learning approach;autoencoder;information-theoretic approach","","5","","15","","19 Dec 2019","","","IEEE","IEEE Conferences"
"A Topologically-Informed Hyperstreamline Seeding Method for Alignment Tensor Fields","F. Fu; N. M. Abukhdeir","Department of Chemical Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Chemical Engineering, University of Waterloo, Waterloo, ON, Canada","IEEE Transactions on Visualization and Computer Graphics","27 Jan 2015","2015","21","3","413","419","A topologically-informed hyperstreamline seeding method is presented for visualization of alignment tensor fields. The method is inspired by and applied to visualization of nematic liquid crystal (LC) orientation dynamics simulations. The method distributes hyperstreamlines along domain boundaries and edges of a nearest-neighbor graph whose vertices are degenerate regions of the alignment tensor field, which correspond to orientational defects in a nematic LC domain. This is accomplished without iteration while conforming to a user-specified spacing between hyperstreamlines and avoids possible failure modes associated with hyperstreamline integration in the vicinity of degeneracies in alignment (orientational defects). It is shown that the presented seeding method enables automated hyperstreamline-based visualization of a broad range of alignment tensor fields which enhances the ability of researchers to interpret these fields and provides an alternative to using glyph-based techniques.","1941-0506","","10.1109/TVCG.2014.2363828","Natural Sciences and Engineering Research Council of Canada; Shared Hierarchical Academic Research Computing Network; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933942","scientific visualization;tensor visualization;hyperstreamlines;nematic liquid crystals;Scientific visualization;tensor visualization;hyperstreamlines;nematic liquid crystals","Tensile stress;Visualization;Eigenvalues and eigenfunctions;Vectors;Streaming media;Measurement;Approximation methods","data visualisation;graph theory","glyph-based techniques;hyperstreamline integration;nematic LC domain;orientational defects;nearest-neighbor graph edge;nearest-neighbor graph boundary;nematic liquid crystal;LC orientation dynamics simulation;alignment tensor field visualization;topologically-informed hyperstreamline seeding method","","5","","34","IEEE","22 Oct 2014","","","IEEE","IEEE Journals"
"A Visual Analytics Approach for Exploratory Causal Analysis: Exploration, Validation, and Applications","X. Xie; F. Du; Y. Wu",State Key Lab of CAD&CGZhejiang University; State Key Lab of CAD&CGZhejiang University; Adobe Research,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1448","1458","Using causal relations to guide decision making has become an essential analytical task across various domains, from marketing and medicine to education and social science. While powerful statistical models have been developed for inferring causal relations from data, domain practitioners still lack effective visual interface for interpreting the causal relations and applying them in their decision-making process. Through interview studies with domain experts, we characterize their current decision-making workflows, challenges, and needs. Through an iterative design process, we developed a visualization tool that allows analysts to explore, validate, and apply causal relations in real-world decision-making scenarios. The tool provides an uncertainty-aware causal graph visualization for presenting a large set of causal relations inferred from high-dimensional data. On top of the causal graph, it supports a set of intuitive user controls for performing what-if analyses and making action plans. We report on two case studies in marketing and student advising to demonstrate that users can effectively explore causal relations and design action plans for reaching their goals.","1941-0506","","10.1109/TVCG.2020.3028957","National Key R&D Program of China(grant numbers:2018YFB1004300); NSFC(grant numbers:61761136020); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:U1609217); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216629","Exploratory causal analysis;correlation and causation;causal graph","Data visualization;Uncertainty;Decision making;Analytical models;Predictive models;Machine learning;Visual analytics","data visualisation;decision making;statistical analysis","visual analytics approach;exploratory causal analysis;decision making;causal relations;effective visual interface;decision-making process;uncertainty-aware causal graph visualization","","5","","64","IEEE","7 Oct 2020","","","IEEE","IEEE Journals"
"A graphical representation of the state spaces of hierarchical level-of-detail scene descriptions","A. E. W. Mason; E. H. Blake","Dept. of Comput. Sci., Cape Town Univ., Rondebosch, South Africa; NA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2001","7","1","70","75","We present a new graphical representation of the level-of-detail state spaces generated by hierarchical geometric scene descriptions with multiple levels of detail. These level-of-detail graphs permit the analytical investigation of the hierarchical level-of-detail optimization problem that arises for such descriptions. As an example of their use, we prove the equivalence of two hierarchical level-of-detail algorithms.","1941-0506","","10.1109/2945.910824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=910824","","Layout;State-space methods;Algorithm design and analysis;Computer Society;Robustness;Cost function;Computer science;Cities and towns;Africa","rendering (computer graphics);optimisation;graph theory","graphical representation;hierarchical level-of-detail scene descriptions;level-of-detail state spaces;hierarchical geometric scene descriptions;graphs;optimization;rendering","","5","","7","IEEE","7 Aug 2002","","","IEEE","IEEE Journals"
"An Energy-Driven Motion Planning Method for Two Distant Postures","H. Wang; E. S. L. Ho; T. Komura","School of Informatics, University of Edinburgh, Edinburgh, Midlothian, United Kingdom; Department of Computer Science, Hong Kong Baptist University, Hong Kong; School of Informatics, University of Edinburgh, Edinburgh, Midlothian, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2014","2015","21","1","18","30","In this paper, we present a local motion planning algorithm for character animation. We focus on motion planning between two distant postures where linear interpolation leads to penetrations. Our framework has two stages. The motion planning problem is first solved as a Boundary Value Problem (BVP) on an energy graph which encodes penetrations, motion smoothness and user control. Having established a mapping from the configuration space to the energy graph, a fast and robust local motion planning algorithm is introduced to solve the BVP to generate motions that could only previously be computed by global planning methods. In the second stage, a projection of the solution motion onto a constraint manifold is proposed for more user control. Our method can be integrated into current keyframing techniques. It also has potential applications in motion planning problems in robotics.","1941-0506","","10.1109/TVCG.2014.2327976","EPSRC(grant numbers:EP/H012338/1); HKBU Science Faculty Research(grant numbers:FRG1/12-13/055,FRG2/12-13/078); Hong Kong RGC GRF(grant numbers:210813); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824787","Character animation;motion planning","Planning;Interpolation;Equations;Couplings;Animation;Manifolds;Joints","boundary-value problems;computer animation;graph theory","energy-driven motion planning method;distant posture;local motion planning algorithm;character animation;boundary value problem;BVP;energy graph;configuration space;motion generation;keyframing techniques;robotics","","5","","39","IEEE","3 Jun 2014","","","IEEE","IEEE Journals"
"An architecture for Java-based real-time distributed visualization","J. Mahovsky; L. Benedicenti","Dept. of Comput. Sci., Calgary Univ., Alta., Canada; NA","IEEE Transactions on Visualization and Computer Graphics","21 Jan 2004","2003","9","4","570","579","In this paper, we present a Java-based software architecture for real-time visualization that utilizes a cluster of conventional PCs to generate high-quality interactive graphics. Normally, a large multiprocessor computer would be needed for interactive visualization tasks requiring more processing power than a single PC can provide. By using clusters of PCs, enormous cost savings can be realized, and proprietary ""high-end"" hardware is no longer necessary for these tasks. Our architecture minimizes the amount of synchronization needed between PCs, resulting in excellent scalability. It provides a modular framework that can accommodate a wide variety of rendering algorithms and data formats, provided that the rendering algorithms can generate pixels individually and the data is duplicated on each PC. Demonstration modules that implement ray tracing, fractal rendering, and volume rendering algorithms were developed to evaluate the architecture. Results are encouraging-using 15 PCs connected to a standard 100 Megabit/s Ethernet network, the system can interactively render simple to moderately complex data sets at modest resolution. Excellent scalability is achieved; however, our tests were limited to a cluster of 15 PCs. Results also demonstrate that Java is a viable platform for real-time distributed visualization.","1941-0506","","10.1109/TVCG.2003.1260749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260749","","Java;Visualization;Personal communication networks;Computer architecture;Computer graphics;Scalability;Clustering algorithms;Software architecture;Costs;Hardware","Java;real-time systems;data visualisation;rendering (computer graphics);ray tracing;fractals;software architecture","Java-based real-time distributed visualization;Java-based software architecture;PC cluster;high-quality interactive graphics;modular framework;rendering algorithms;data formats;ray tracing;fractal rendering;volume rendering;Ethernet;real-time distributed visualization","","5","","25","","21 Jan 2004","","","IEEE","IEEE Journals"
"Automatic Constraint Detection for 2D Layout Regularization","H. Jiang; L. Nan; D. Yan; W. Dong; X. Zhang; P. Wonka","National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences, Beijing, China; KAUST, Thuwal, Saudi Arabia; KAUST, Thuwal, Saudi Arabia; National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences, Beijing, China; KAUST, Thuwal, Saudi Arabia","IEEE Transactions on Visualization and Computer Graphics","29 Jun 2016","2016","22","8","1933","1944","In this paper, we address the problem of constraint detection for layout regularization. The layout we consider is a set of two-dimensional elements where each element is represented by its bounding box. Layout regularization is important in digitizing plans or images, such as floor plans and facade images, and in the improvement of user-created contents, such as architectural drawings and slide layouts. To regularize a layout, we aim to improve the input by detecting and subsequently enforcing alignment, size, and distance constraints between layout elements. Similar to previous work, we formulate layout regularization as a quadratic programming problem. In addition, we propose a novel optimization algorithm that automatically detects constraints. We evaluate the proposed framework using a variety of input layouts from different applications. Our results demonstrate that our method has superior performance to the state of the art.","1941-0506","","10.1109/TVCG.2015.2480059","KAUST Visual Computing Center; China National 863 Program(grant numbers:2015AA016402); National Natural Science Foundation of China(grant numbers:61372168,61331018,61372190,61272327); U.S. National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272131","Layout regularization;constraint detection;constraint analysis;linear integer programming","Layout;Shape;Optimization;Three-dimensional displays;Electronic mail;Complexity theory;Standards","object detection;quadratic programming","automatic constraint detection;2D layout regularization;two-dimensional elements;bounding box;user-created contents;layout element alignment;layout element size;layout element distance constraints;quadratic programming problem;optimization algorithm","","5","","37","IEEE","18 Sep 2015","","","IEEE","IEEE Journals"
"Automatic Layout of Structured Hierarchical Reports","E. Bakke; D. R. Karger; R. C. Miller",MIT Computer Science and Artificial Intelligence Laboratory (CSAIL); MIT Computer Science and Artificial Intelligence Laboratory (CSAIL); MIT Computer Science and Artificial Intelligence Laboratory (CSAIL),"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2586","2595","Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets.","1941-0506","","10.1109/TVCG.2013.137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634099","Layout;Data visualization;XML;layout management;Hierarchy data;tabular data;nested relations","Layout;Data visualization;XML","data visualisation;user interfaces","structured hierarchical reports;domain-specific database applications;table-style visualization view;form-style visualization view;report-style visualization view;low-level presentation details;horizontally constrained layout management algorithm;structured hierarchical data display;hand-designed database UI;user interface;outline layouts;horizontally unconstrained table layouts","Algorithms;Computer Graphics;Computer Simulation;Documentation;Image Enhancement;Information Storage and Retrieval;Models, Theoretical;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface;Workflow","5","","31","","16 Oct 2013","","","IEEE","IEEE Journals"
"BarcodeTree: Scalable Comparison of Multiple Hierarchies","G. Li; Y. Zhang; Y. Dong; J. Liang; J. Zhang; J. Wang; M. J. Mcguffin; X. Yuan","Key Laboratory of Machine Perception (Ministry of Education), National Engineering Laboratory for Big Data Analysis and Application, Peking University; University of Oxford, Peking University; University of Technology, Sydney, Australia; University of Technology, Sydney, Australia; University of Technology, Sydney, Australia; Southwest Electric and Telecom Engineering Institute; Ecole de technologie superieure, Canada; Key Laboratory of Machine Perception (Ministry of Education), National Engineering Laboratory for Big Data Analysis and Application, Peking University","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","1022","1032","We propose BarcodeTree (BCT), a novel visualization technique for comparing topological structures and node attribute values of multiple trees. BCT can provide an overview of one hundred shallow and stable trees simultaneously, without aggregating individual nodes. Each BCT is shown within a single row using a style similar to a barcode, allowing trees to be stacked vertically with matching nodes aligned horizontally to ease comparison and maintain space efficiency. We design several visual cues and interactive techniques to help users understand the topological structure and compare trees. In an experiment comparing two variants of BCT with icicle plots, the results suggest that BCTs make it easier to visually compare trees by reducing the vertical distance between different trees. We also present two case studies involving a dataset of hundreds of trees to demonstrate BCT's utility.","1941-0506","","10.1109/TVCG.2019.2934535","National Natural Science Foundation of China(grant numbers:61672055); National Basic Research Program of China (973 Program)(grant numbers:2016QY02D0304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845772","tree visualization;comparison;multiple trees","Vegetation;Visualization;Encoding;Task analysis;Data visualization;Layout;Libraries","data visualisation;interactive systems;mathematics computing;trees (mathematics)","visual cues;interactive techniques;topological structure;BCT;visualization technique;BarcodeTree","","5","","69","IEEE","20 Sep 2019","","","IEEE","IEEE Journals"
"Complex Logarithmic Views for Small Details in Large Contexts","J. Bottger; M. Balzer; O. Deussen","Dept. of Comput. & Inf. Sci., Konstanz Univ.; Dept. of Comput. & Inf. Sci., Konstanz Univ.; Dept. of Comput. & Inf. Sci., Konstanz Univ.","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","845","852","Commonly known detail in context techniques for the two-dimensional Euclidean space enlarge details and shrink their context using mapping functions that introduce geometrical compression. This makes it difficult or even impossible to recognize shapes for large differences in magnification factors. In this paper we propose to use the complex logarithm and the complex root functions to show very small details even in very large contexts. These mappings are conformal, which means they only locally rotate and scale, thus keeping shapes intact and recognizable. They allow showing details that are orders of magnitude smaller than their surroundings in combination with their context in one seamless visualization. We address the utilization of this universal technique for the interaction with complex two-dimensional data considering the exploration of large graphs and other examples.","1941-0506","","10.1109/TVCG.2006.126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015438","Detail in context;complex logarithm;conformal mappings;analytic functions;interaction.","Shape;Conformal mapping;Data visualization;Nonlinear distortion;Image coding;Navigation;Image recognition;Information science;Information geometry;Computer graphics","computational geometry;conformal mapping;data visualisation;graph theory","complex logarithmic view;Euclidean space;conformal mapping function;geometrical compression;complex root function;data visualization","","5","","9","IEEE","20 Nov 2006","","","IEEE","IEEE Journals"
"ConfusionFlow: A Model-Agnostic Visualization for Temporal Analysis of Classifier Confusion","A. Hinterreiter; P. Ruch; H. Stitz; M. Ennemoser; J. Bernard; H. Strobelt; M. Streit","Johannes Kepler University Linz, Linz, Austria; Imperial College London, London, United Kingdom; Johannes Kepler University Linz, Linz, Austria; Johannes Kepler University Linz, Linz, Austria; Salesbeat GmbH, Leonding, Austria; Datavisyn GmbH, Linz, Austria; Imperial College London, London, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1222","1236","Classifiers are among the most widely used supervised machine learning algorithms. Many classification models exist, and choosing the right one for a given task is difficult. During model selection and debugging, data scientists need to assess classifiers' performances, evaluate their learning behavior over time, and compare different models. Typically, this analysis is based on single-number performance measures such as accuracy. A more detailed evaluation of classifiers is possible by inspecting class errors. The confusion matrix is an established way for visualizing these class errors, but it was not designed with temporal or comparative analysis in mind. More generally, established performance analysis systems do not allow a combined temporal and comparative analysis of class-level information. To address this issue, we propose ConfusionFlow, an interactive, comparative visualization tool that combines the benefits of class confusion matrices with the visualization of performance characteristics over time. ConfusionFlow is model-agnostic and can be used to compare performances for different model types, model architectures, and/or training and test datasets. We demonstrate the usefulness of ConfusionFlow in a case study on instance selection strategies in active learning. We further assess the scalability of ConfusionFlow and present a use case in the context of neural network pruning.","1941-0506","","10.1109/TVCG.2020.3012063","State of Upper Austria; Bundesministerium für Bildung, Wissenschaft und Forschung(grant numbers:LIT-2019-7-SEE-117); State of Upper Austria; Austrian Research Promotion Agency(grant numbers:FFG 851460); Austrian Science Fund(grant numbers:FWF P27975-NBL); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9149790","Classification;performance analysis;time series visualization;machine learning;information visualization;quality assessment","Task analysis;Analytical models;Data models;Training;Tools;Adaptation models;Data visualization","data visualisation;feature selection;matrix algebra;neural nets;pattern classification;supervised learning","active learning;ConfusionFlow;model-agnostic visualization;classifier confusion;supervised machine learning;confusion matrix;temporal analysis;class-level information;class confusion matrices;performance characteristics;instance selection strategies;neural network pruning","","5","","63","IEEE","27 Jul 2020","","","IEEE","IEEE Journals"
"Content-Based Visual Summarization for Image Collections","X. Pan; F. Tang; W. Dong; C. Ma; Y. Meng; F. Huang; T. -Y. Lee; C. Xu","NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Fosafer, Beijing, China; NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Kuaishou Technology, Beijing, China; Didi Chuxing, Beijing, China; YouTu Lab, Tencent, Shanghai, China; National Cheng Kung University, Tainan, Taiwan; NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","25 Feb 2021","2021","27","4","2298","2312","With the surge of images in the information era, people demand an effective and accurate way to access meaningful visual information. Accordingly, effective and accurate communication of information has become indispensable. In this article, we propose a content-based approach that automatically generates a clear and informative visual summarization based on design principles and cognitive psychology to represent image collections. We first introduce a novel method to make representative and nonredundant summarizations of image collections, thereby ensuring data cleanliness and emphasizing important information. Then, we propose a tree-based algorithm with a two-step optimization strategy to generate the final layout that operates as follows: (1) an initial layout is created by constructing a tree randomly based on the grouping results of the input image set; (2) the layout is refined through a coarse adjustment in a greedy manner, followed by gradient back propagation drawing on the training procedure of neural networks. We demonstrate the usefulness and effectiveness of our method via extensive experimental results and user studies. Our visual summarization algorithm can precisely and efficiently capture the main content of image collections better than alternative methods or commercial tools.","1941-0506","","10.1109/TVCG.2019.2948611","National Key R&D Program of China(grant numbers:2018YFC0807500); National Natural Science Foundation of China(grant numbers:61832016,61672520,61702488); Ministry of Science and Technology(grant numbers:108-2221-E-006-038-MY3); CASIA-Tencent Youtu; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880504","Visual summarization;photo collection;collage layout;tree-based algorithm;gradient back propagation","Visualization;Layout;Correlation;Backpropagation;Optimization;Computational modeling;Semantics","content-based retrieval;data mining;data visualisation;feature extraction;image representation;neural nets;optimisation;pattern clustering;psychology;trees (mathematics)","image collections;representative summarizations;nonredundant summarizations;data cleanliness;emphasizing important information;tree-based algorithm;input image set;visual summarization algorithm;information era;meaningful visual information;content-based approach;clear summarization;informative visual summarization","","5","","52","IEEE","23 Oct 2019","","","IEEE","IEEE Journals"
"Context-Aware Computer Aided Inbetweening","W. Yang","School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2017","2018","24","2","1049","1062","This paper presents a context-aware computer aided inbetweening (CACAI) technique that interpolates planar strokes to generate inbetween frames from a given set of key frames. The inbetweening is context-aware in the sense that not only the stroke's shape but also the context (i.e., the neighborhood of a stroke) in which a stroke appears are taken into account for the stroke correspondence and interpolation. Given a pair of successive key frames, the CACAI automatically constructs the stroke correspondence between them by exploiting the context coherence between the corresponding strokes. Meanwhile, the construction algorithm is able to incorporate the user's interaction with ease and allows the user more effective control over the correspondence process than existing stroke matching techniques. With a one-to-one stroke correspondence, the CACAI interpolates the shape and context between the corresponding strokes for the generation of intermediate frames. In the interpolation sequence, both the shape of individual strokes and the spatial layout between them are well retained such that the feature characteristics and visual appearance of the objects in the key frames can be fully preserved even when complex motions are involved in these objects. We have developed a prototype system to demonstrate the ease of use and effectiveness of the CACAI.","1941-0506","","10.1109/TVCG.2017.2657511","Natural Science Foundation of China(grant numbers:61003189); Science and Technology Agency projects of Zhejiang Province(grant numbers:2016C33171); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7831370","Inbetween;correspondence construction;stroke interpolation;context mesh;CACAI","Interpolation;Shape;Context;Layout;Two dimensional displays;Visualization;Distortion","computational geometry;computer animation;interpolation;mesh generation","context coherence;corresponding strokes;correspondence process;stroke matching techniques;stroke correspondence;CACAI;intermediate frames;individual strokes;context-aware computer;inbetweening technique;inbetween frames;stroke appears;successive key frames;context-aware computer aided inbetweening","","5","","35","IEEE","24 Jan 2017","","","IEEE","IEEE Journals"
"DNF-Net: A Deep Normal Filtering Network for Mesh Denoising","X. Li; R. Li; L. Zhu; C. -W. Fu; P. -A. Heng","Chinese University of Hong Kong, Hong Kong; Chinese University of Hong Kong, Hong Kong; Chinese University of Hong Kong, Hong Kong; Chinese University of Hong Kong, Hong Kong; Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2021","2021","27","10","4060","4072","This article presents a deep normal filtering network, called DNF-Net, for mesh denoising. To better capture local geometry, our network processes the mesh in terms of local patches extracted from the mesh. Overall, DNF-Net is an end-to-end network that takes patches of facet normals as inputs and directly outputs the corresponding denoised facet normals of the patches. In this way, we can reconstruct the geometry from the denoised normals with feature preservation. Besides the overall network architecture, our contributions include a novel multi-scale feature embedding unit, a residual learning strategy to remove noise, and a deeply-supervised joint loss function. Compared with the recent data-driven works on mesh denoising, DNF-Net does not require manual input to extract features and better utilizes the training data to enhance its denoising performance. Finally, we present comprehensive experiments to evaluate our method and demonstrate its superiority over the state of the art on both synthetic and real-scanned meshes.","1941-0506","","10.1109/TVCG.2020.3001681","Hong Kong Research Grants Council(grant numbers:CUHK 14225616); Key-Area Research and Development Program of Guangdong Province, China(grant numbers:2020B010165004); National Natural Science Foundation of China(grant numbers:U1813204); Research Grants Council of the Hong Kong Special Administrative Region(grant numbers:CUHK 14201717); National Natural Science Foundation of China(grant numbers:61902275); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115285","Mesh denoising;normal filtering;deep neural network;data-driven learning;local patches","Three-dimensional displays;Noise reduction;Feature extraction;Noise measurement;Neural networks;Geometry;Shape","deep learning (artificial intelligence);feature extraction;image denoising;image filtering;image reconstruction","real-scanned mesh;synthetic mesh;features extraction;deeply-supervised joint loss function;noise removal;residual learning strategy;multiscale feature embedding unit;feature preservation;geometry reconstruction;extracted mesh;network process;denoised facet normals;denoising performance;network architecture;denoised normals;end-to-end network;local patches;local geometry;DNF-Net;mesh denoising;deep normal filtering network","","5","","52","IEEE","11 Jun 2020","","","IEEE","IEEE Journals"
"EllSeg: An Ellipse Segmentation Framework for Robust Gaze Tracking","R. S. Kothari; A. K. Chaudhary; R. J. Bailey; J. B. Pelz; G. J. Diaz",Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","15 Apr 2021","2021","27","5","2757","2767","Ellipse fitting, an essential component in pupil or iris tracking based video oculography, is performed on previously segmented eye parts generated using various computer vision techniques. Several factors, such as occlusions due to eyelid shape, camera position or eyelashes, frequently break ellipse fitting algorithms that rely on well-defined pupil or iris edge segments. In this work, we propose training a convolutional neural network to directly segment entire elliptical structures and demonstrate that such a framework is robust to occlusions and offers superior pupil and iris tracking performance (at least 10% and 24% increase in pupil and iris center detection rate respectively within a two-pixel error margin) compared to using standard eye parts segmentation for multiple publicly available synthetic segmentation datasets.","1941-0506","","10.1109/TVCG.2021.3067765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9389650","Head mounted eye-tracking;ellipse fitting;eye-segmentation;AR/VR","Pupils;Iris;Image segmentation;Computer architecture;Feature extraction;Cameras;Decoding","computer vision;convolutional neural nets;edge detection;eye;gaze tracking;image segmentation;image sensors;iris recognition;shape recognition;video signal processing","EllSeg;ellipse segmentation framework;robust gaze tracking;video oculography;segmented eye parts;computer vision techniques;camera position;ellipse fitting algorithms;iris edge segments;convolutional neural network;iris tracking performance;iris center detection rate;standard eye parts segmentation;multiple publicly available synthetic segmentation datasets;superior pupil","Algorithms;Augmented Reality;Eye-Tracking Technology;Female;Humans;Image Processing, Computer-Assisted;Male;Smart Glasses;Video Recording;Virtual Reality","5","","56","IEEE","29 Mar 2021","","","IEEE","IEEE Journals"
"Event-Based Dynamic Graph Visualisation","P. Simonetto; D. Archambault; S. Kobourov","Swansea University, Swansea, Wales; Swansea University, Swansea, Wales; University of Arizona, Tucson, AZ, USA","IEEE Transactions on Visualization and Computer Graphics","28 May 2020","2020","26","7","2373","2386","Dynamic graph drawing algorithms take as input a series of timeslices that standard, force-directed algorithms can exploit to compute a layout. However, often dynamic graphs are expressed as a series of events where the nodes and edges have real coordinates along the time dimension that are not confined to discrete timeslices. Current techniques for dynamic graph drawing impose a set of timeslices on this event-based data in order to draw the dynamic graph, but it is unclear how many timeslices should be selected: too many timeslices slows the computation of the layout, while too few timeslices obscures important temporal features, such as causality. To address these limitations, we introduce a novel model for drawing event-based dynamic graphs and the first dynamic graph drawing algorithm, DynNoSlice, that is capable of drawing dynamic graphs in this model. DynNoSlice is an offline, force-directed algorithm that draws event-based, dynamic graphs in the space-time cube (2D+time). We also present a method to extract representative small multiples from the space-time cube. To demonstrate the advantages of our approach, DynNoSlice is compared with state-of-the-art timeslicing methods using a metrics-based experiment. Finally, we present case studies of event-based dynamic data visualised with the new model and algorithm.","1941-0506","","10.1109/TVCG.2018.2886901","Engineering and Physical Sciences Research Council(grant numbers:EP/N005724/1); NSF(grant numbers:CCF-1712119,CCF-1740858,DMS-1839274); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580419","Information visualisation;graph drawing;dynamic graphs;event-based analytics;no timeslices","Heuristic algorithms;Data visualization;Dynamics;Three-dimensional displays;Computational modeling;Layout;Animation","data visualisation;graph theory","DynNoSlice;event-based dynamic graph visualisation;event-based dynamic data;space-time cube;draws event-based;force-directed algorithm;dynamic graph drawing algorithm;timeslices","","5","","68","CCBY","18 Dec 2018","","","IEEE","IEEE Journals"
"Fast iterative refinement of articulated solid dynamics","F. Faure","Inst. fur Computergraphik, Tech. Univ. Wien, Austria","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1999","5","3","268","276","A new dynamics algorithm for articulated solid animation is presented. It provides enhancements of computational efficiency and accuracy control with respect to previous solutions. Iterative refinement allows us to perform interactive animations which could be only computed off-line using previous methods. The efficiency results from managing two sets of constraints associated with the kinematic graph, and proceeding in two steps. First, the acyclic constraints are solved in linear time. An iterative process then reduces the closed-loop errors while maintaining the acyclic constraints. This allows the user to efficiently trade off accuracy for computation time. We analyze the complexity and investigate practical efficiency compared with other approaches. In contrast with previous research, we present a single method which is computationally efficient for acyclic bodies as well as for mesh-like bodies. The accuracy control is provided by the iterative improvement performed by the algorithm and also from the existence of two constraint priority levels induced by the method. Used in conjunction with a robust integration scheme, this new algorithm allows the interactive animation of scenes containing a few thousand geometric constraints, including closed loops. It has been successfully applied to real-time simulations.","1941-0506","","10.1109/2945.795217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=795217","","Solids;Animation;Layout;Iterative algorithms;Iterative methods;Computational efficiency;Virtual reality;Computational modeling;Equations;Heuristic algorithms","iterative methods;computer animation;dynamics;integration;computational complexity;kinematics;solid modelling;interactive systems","fast iterative refinement;articulated solid dynamics algorithm;articulated solid animation;computational efficiency;accuracy control;interactive animation;constraint sets;kinematic graph;acyclic constraints;linear-time solution;closed-loop errors;complexity;efficiency;mesh-like bodies;constraint priority levels;robust integration scheme;geometric constraints;real-time simulations","","5","","21","","6 Aug 2002","","","IEEE","IEEE Journals"
"Frame-to-frame coherent animation with two-pass radiosity","I. Martin; X. Pueyo; D. Tost","Inst. d'Informatica i Aplicacions, Univ. de Girona, Spain; Inst. d'Informatica i Aplicacions, Univ. de Girona, Spain; NA","IEEE Transactions on Visualization and Computer Graphics","6 Feb 2003","2003","9","1","70","84","This paper proposes an efficient method for the production of high quality radiosity solutions which uses an a priori knowledge of the dynamic properties of the scene to exploit temporal coherence. The method is based on a two-pass strategy that provides user-control on the final frame quality. In the first pass, it computes a coarse global solution of the radiosities along a time interval and then, in the second pass, it performs a frame-to-frame incremental gathering step using hardware graphic accelerators. Computing cost is thus reduced because the method takes advantage of frame-to-frame coherence by identifying the changes produced by dynamic objects and by decoupling them from computations that remain unchanged. The input data is a dynamic model of the environment through a period of time corresponding to the same camera recording. The method proceeds by incrementally updating two data structures: a space-time hierarchical radiosity solution for a given interval of time and a hierarchical tree of textures representing the space-time final illumination of the visible surfaces. These data structures are computed for a given viewpoint, either static or dynamic. The main contribution of this work is the efficient construction of the texture tree by identifying the changes produced by dynamic objects and by only recomputing these changes.","1941-0506","","10.1109/TVCG.2003.1175098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1175098","","Animation;Production;Layout;Hardware;Graphics;Costs;Coherence;Cameras;Tree data structures;Lighting","computer animation;realistic images","high quality radiosity;a priori knowledge;scene;temporal coherence;hardware graphic accelerators;data structures;energy transport;photo-realistic animations;animation","","5","","29","IEEE","6 Feb 2003","","","IEEE","IEEE Journals"
"High-Quality Rendering of Quartic Spline Surfaces on the GPU","G. Reis; F. Zeilfelder; M. Hering-Bertram; G. E. Farin; H. Hagen","TU Kaiserslautern, Kaiserslautern; TU Darmstadt, Darmstadt; Fraunhofer Institut, Kaiserslautern; Arizona State University, Tempe; University of Kaiserslautern , Kaiserslautern","IEEE Transactions on Visualization and Computer Graphics","15 Jul 2008","2008","14","5","1126","1139","We present a novel GPU-based algorithm for high-quality rendering of bivariate spline surfaces. An essential difference to the known methods for rendering graph surfaces is that we use quartic smooth splines on triangulations rather than triangular meshes. Our rendering approach is direct since we do not use an intermediate tessellation but rather compute ray-surface intersections (by solving quartic equations numerically) as well as surface normals (by using Bernstein-Bezier techniques) for Phong illumination on the GPU. Inaccurate shading and artifacts appearing for triangular tesselated surfaces are completely avoided. Level of detail is automatic since all computations are done on a per fragment basis. We compare three different (quasi-) interpolating schemes for uniformly sampled gridded data, which differ in the smoothness and the approximation properties of the splines. The results show that our hardware-based renderer leads to visualizations (including texturing, multiple light sources, environment mapping, and so forth) of highest quality.","1941-0506","","10.1109/TVCG.2008.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4509429","Raytracing;Spline and piecewise polynomial approximation;Raytracing;Spline and piecewise polynomial approximation","Spline;Rendering (computer graphics);Data visualization;Piecewise linear techniques;Lighting;Piecewise linear approximation;Ray tracing;Large-scale systems;Polynomials;Artificial intelligence","interpolation;rendering (computer graphics);splines (mathematics)","high-quality rendering;quartic spline surfaces;bivariate spline surfaces;triangulations;intermediate tessellation;compute ray-surface intersections;quartic equations;interpolating schemes;uniformly sampled gridded data;smoothness property;approximation property","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Reproducibility of Results;Sensitivity and Specificity","5","","50","","10 Jun 2008","","","IEEE","IEEE Journals"
"Interactive transparency rendering for large CAD models","J. Huang; M. B. Carter","UGS PLM Solutions, Ames, IA, USA; UGS PLM Solutions, Ames, IA, USA","IEEE Transactions on Visualization and Computer Graphics","25 Jul 2005","2005","11","5","584","595","Transparency is an important graphics effect that can be used to significantly increase the realism of the rendered scene or to enable more effective visual inspection in engineering visualization. In this paper, we propose achieving interactive transparency rendering of a static scene by sorting the triangles in back-to-front order on CPU and supplying the sorted triangles to the graphics pipeline for rendering on GPU hardware. Our sorting method sorts the triangles in object space and is built upon the binary space partition (BSP) and depth-sort methods with its behavior readily tunable to exploit the strengths of both methods. We propose novel techniques to optimize the BSP construction process with respect to multiple factors including tree construction time, tree size, and expected sorting cost. We also propose an improved depth-sort algorithm that can produce correct depth order without triangle split when no cyclic occlusion exists. We demonstrate that the proposed system results in a penalty factor of 4/spl sim/6 for various types of parts, among which the largest one has nearly 1.2 million triangles. In addition, the penalty factor may be further improved if sorting in CPU and rendering in GPU are executed in parallel. Two approximation strategies are also studied to test the practicality of our system against large CAD assemblies. Experimental results on an assembly containing over 16 million triangles distributed in about 10,000 transparent parts show that the proposed system still results in a penalty factor of 4/spl sim/6 while producing few artifacts.","1941-0506","","10.1109/TVCG.2005.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471695","Index Terms- BSP;depth sort;transparency rendering;triangle sorting.","Rendering (computer graphics);Sorting;Graphics;Layout;Assembly systems;Inspection;Visualization;Pipelines;Hardware;Cost function","CAD;engineering graphics;rendering (computer graphics);data visualisation;solid modelling;interactive systems;computer graphic equipment;tree data structures;computational geometry;sorting","interactive transparency rendering;large CAD model;scene rendering;visual inspection;engineering visualization;graphics pipeline;GPU hardware rendering;binary space partition construction;depth-sort algorithm;tree construction;tree size;cyclic occlusion;triangle sorting","Algorithms;Computer Graphics;Computer Simulation;Computer Systems;Computer-Aided Design;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Theoretical;User-Computer Interface","5","1","15","IEEE","25 Jul 2005","","","IEEE","IEEE Journals"
"JanusVF: Accurate Navigation Using SCAAT and Virtual Fiducials","M. Hutson; D. Reiners","University of Louisiana at Lafayette, Lafayette; University of Louisiana at Lafayette, Lafayette","IEEE Transactions on Visualization and Computer Graphics","11 Nov 2010","2011","17","1","3","13","Several critical limitations exist in the currently available tracking technologies for fully enclosed virtual reality (VR) systems. While several 6DOF tracking projects such as Hedgehog have successfully demonstrated excellent accuracy, precision, and robustness within moderate budgets, these projects still include elements of hardware that can interfere with the user's visual experience. The objective of this project is to design a tracking solution for fully enclosed VR displays that achieves comparable performance to available commercial solutions but without any artifacts that can obscure the user's view. JanusVF is a tracking solution involving a cooperation of both the hardware sensors and the software rendering system. A small, high-resolution camera is worn on the user's head, but faces backward (180 degree rotation about vertical from the user's perspective). After acquisition of the initial state, the VR rendering software draws specific fiducial markers with known size and absolute position inside the VR scene. These virtual markers are only drawn behind the user and in view of the camera. These fiducials are tracked by ARToolkitPlus and integrated by a single-constraint-at-a-time (SCAAT) filter algorithm to update the head pose. Experiments analyzing accuracy, precision, and latency in a six-sided CAVE-like system show performance that is comparable to alternative commercial technologies.","1941-0506","","10.1109/TVCG.2010.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487515","Virtual reality;input devices and strategies;stereo;tracking.","Navigation;Virtual reality;Hardware;Cameras;Robustness;Displays;Sensor systems;Software systems;Layout;Filters","rendering (computer graphics);virtual reality","virtual reality system;Hedgehog tracking project;fully enclosed VR displays;virtual fiducials;JanusVF solution;software rendering system;single-constraint-at-a-time filter algorithm;SCAAT filter algorithm","Algorithms;Computer Graphics;Data Display;Equipment Design;Humans;Imaging, Three-Dimensional;Software;User-Computer Interface","5","","29","","17 Jun 2010","","","IEEE","IEEE Journals"
"Low-Rank Matrix Completion to Reconstruct Incomplete Rendering Images","P. Liu; J. Lewis; T. Rhee","Computer Graphics Lab, Victoria University of Wellington, Wellington, New Zealand; Computer Graphics Lab, Victoria University of Wellington, Wellington, New Zealand; Computer Graphics Lab, Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Visualization and Computer Graphics","29 Jun 2018","2018","24","8","2353","2365","Path tracing provides photo-realistic rendering in many applications but intermediate previsualization often suffers from distracting noise. Since the fundamental underlying problem is insufficient samples, we exploit the coherence of the visual signal to reconstruct missing samples, using a low-rank matrix completion framework. We present novel methods to construct low rank matrices for incomplete images including missing pixel, missing sub-pixel, and multi-frame scenarios. A convolutional neural network provides fast pre-completion for initialising missing values, and subsequent weighted nuclear norm minimisation (WNNM) with a parameter adjustment strategy (PAWNNM) efficiently recovers missing values even in high frequency details. The result shows better visual quality than recent methods including compressed sensing based reconstruction.","1941-0506","","10.1109/TVCG.2017.2722414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7967887","Previsualisation;path-tracing;sampling and reconstruction;matrix completion;nuclear norm minimization;convolutional neural network","Image reconstruction;Rendering (computer graphics);Visualization;Minimization;Image coding;Monte Carlo methods","compressed sensing;convolution;feedforward neural nets;image reconstruction;image restoration;image sampling;matrix algebra;minimisation;rendering (computer graphics)","distracting noise;visual signal;low-rank matrix completion framework;low rank matrices;incomplete images;missing pixel;multiframe scenarios;convolutional neural network;initialising missing values;subsequent weighted nuclear norm minimisation;visual quality;sensing based reconstruction;incomplete rendering images;path tracing;photo-realistic rendering;intermediate previsualization","","5","","40","IEEE","3 Jul 2017","","","IEEE","IEEE Journals"
"MetroSets: Visualizing Sets as Metro Maps","B. Jacobsen; M. Wallinger; S. Kobourov; M. Nöllenburg",University of Arizona; TU Wien; TU Wien; University of Arizona,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1257","1267","We propose MetroSets, a new, flexible online tool for visualizing set systems using the metro map metaphor. We model a given set system as a hypergraph H = (V, S), consisting of a set V of vertices and a set S, which contains subsets of V called hyperedges. Our system then computes a metro map representation of H, where each hyperedge E in S corresponds to a metro line and each vertex corresponds to a metro station. Vertices that appear in two or more hyperedges are drawn as interchanges in the metro map, connecting the different sets. MetroSets is based on a modular 4-step pipeline which constructs and optimizes a path-based hypergraph support, which is then drawn and schematized using metro map layout algorithms. We propose and implement multiple algorithms for each step of the MetroSet pipeline and provide a functional prototype with easy-to-use preset configurations. Furthermore, using several real-world datasets, we perform an extensive quantitative evaluation of the impact of different pipeline stages on desirable properties of the generated maps, such as octolinearity, monotonicity, and edge uniformity.","1941-0506","","10.1109/TVCG.2020.3030475","NSF(grant numbers:CCF-1740858,CCF-1712119,DMS-1839274); Vienna Science and Technology Fund (WWTF)(grant numbers:ICT19-035); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224192","Set visualization;metro map metaphor;hypergraphs","Data visualization;Layout;Pipelines;Fats;Task analysis;Visual analytics","cartography;data visualisation;graph theory;set theory","metro line;vertex corresponds;metro station;hyperedges;path-based hypergraph support;metro map layout algorithms;MetroSet pipeline;generated maps;flexible online tool;set systems;metro map metaphor;metro map representation;hyperedge","","5","","91","IEEE","14 Oct 2020","","","IEEE","IEEE Journals"
"Overlap-Free Drawing of Generalized Pythagoras Trees for Hierarchy Visualization","T. Munz; M. Burch; T. v. Benthem; Y. Poels; F. Beck; D. Weiskopf","University of Stuttgart,VISUS; Eindhoven University of Technology; Eindhoven University of Technology; Eindhoven University of Technology; University of Duisburg-Essen; University of Stuttgart,VISUS","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","251","255","Generalized Pythagoras trees were developed for visualizing hierarchical data, producing organic, fractal-like representations. However, the drawback of the original layout algorithm is visual overlap of tree branches. To avoid such overlap, we introduce an adapted drawing algorithm using ellipses instead of circles to recursively place tree nodes representing the subhierarchies. Our technique is demonstrated by resolving overlap in diverse real-world and generated datasets, while comparing the results to the original approach.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933606","Human-centered computing;Visualization;Visualization application domains;Information visualization","Vegetation;Force;Layout;Shape;Data visualization;Visualization;Taxonomy","data visualisation;trees (mathematics)","tree branches;tree nodes;overlap-free drawing;generalized Pythagoras trees;hierarchy visualization;hierarchical data;fractal-like representations","","5","","20","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Personalized Exposure Control Using Adaptive Metering and Reinforcement Learning","H. Yang; B. Wang; N. Vesdapunt; M. Guo; S. B. Kang","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Microsoft Research, Redmond, WA, USA","IEEE Transactions on Visualization and Computer Graphics","2 Sep 2019","2019","25","10","2953","2968","We propose a reinforcement learning approach for real-time exposure control of a mobile camera that is personalizable. Our approach is based on Markov Decision Process (MDP). In the camera viewfinder or live preview mode, given the current frame, our system predicts the change in exposure so as to optimize the trade-off among image quality, fast convergence, and minimal temporal oscillation. We model the exposure prediction function as a fully convolutional neural network that can be trained through Gaussian policy gradient in an end-to-end fashion. As a result, our system can associate scene semantics with exposure values; it can also be extended to personalize the exposure adjustments for a user and device. We improve the learning performance by incorporating an adaptive metering module that links semantics with exposure. This adaptive metering module generalizes the conventional spot or matrix metering techniques. We validate our system using the MIT FiveK [1] and our own datasets captured using iPhone 7 and Google Pixel. Experimental results show that our system exhibits stable real-time behavior while improving visual quality compared to what is achieved through native camera control.","1941-0506","","10.1109/TVCG.2018.2865555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8437183","Auto exposure;reinforcement learning;personalization","Cameras;Real-time systems;Learning (artificial intelligence);Semantics;Training data;Supervised learning;Lighting","cameras;convolutional neural nets;digital photography;gradient methods;image colour analysis;learning (artificial intelligence);Markov processes","Markov decision process;matrix metering techniques;native camera control;adaptive metering module;Gaussian policy gradient;fully convolutional neural network;exposure prediction function;minimal temporal oscillation;image quality;camera viewfinder;MDP;mobile camera;reinforcement learning approach;personalized exposure control","Databases, Factual;Humans;Image Processing, Computer-Assisted;Lighting;Markov Chains;Neural Networks, Computer;Photography;Semantics","5","","38","IEEE","15 Aug 2018","","","IEEE","IEEE Journals"
"Realtime and Accurate 3D Eye Gaze Capture with DCNN-Based Iris and Pupil Segmentation","Z. Wang; J. Chai; S. Xia","Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Texas A&M University, College Station, TX, USA; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","190","203","This paper presents a realtime and accurate method for 3D eye gaze tracking with a monocular RGB camera. Our key idea is to train a deep convolutional neural network(DCNN) that automatically extracts the iris and pupil pixels of each eye from input images. To achieve this goal, we combine the power of Unet [1] and Squeezenet [2] to train an efficient convolutional neural network for pixel classification. In addition, we track the 3D eye gaze state in the Maximum A Posteriori (MAP) framework, which sequentially searches for the most likely state of the 3D eye gaze at each frame. When eye blinking occurs, the eye gaze tracker can obtain an inaccurate result. We further extend the convolutional neural network for eye close detection in order to improve the robustness and accuracy of the eye gaze tracker. Our system runs in realtime on desktop PCs and smart phones. We have evaluated our system on live videos and Internet videos, and our results demonstrate that the system is robust and accurate for various genders, races, lighting conditions, poses, shapes and facial expressions. A comparison against Wang et al. [3] shows that our method advances the state of the art in 3D eye tracking using a single RGB camera.","1941-0506","","10.1109/TVCG.2019.2938165","Natural Science Foundation of Beijing Municipality(grant numbers:L182052); National Natural Science Foundation of China(grant numbers:61772499); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818661","3D eye gaze tracking;convolutional neural network;facial capture","Three-dimensional displays;Gaze tracking;Iris;Cameras;Convolutional neural nets;Image reconstruction;Videos","cameras;convolutional neural nets;eye;face recognition;feature extraction;gaze tracking;image capture;image classification;image colour analysis;image segmentation;iris recognition;maximum likelihood estimation;object detection;object tracking;video signal processing","pupil pixels;eye blinking;deep convolutional neural network;eye gaze tracker;realtime 3D eye gaze capture;DCNN;iris segmentation;pupil segmentation;monocular RGB camera;iris extraction;Unet;Squeezenet;pixel classification;maximum a posteriori;eye close detection;desktop PC;smart phone;live videos;Internet videos","","5","","71","IEEE","28 Aug 2019","","","IEEE","IEEE Journals"
"Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics","W. Zeng; C. Lin; J. Lin; J. Jiang; J. Xia; C. Turkay; W. Chen","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Xiamen University, China; Xiamen University, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Central South University, China; University of Warwick, UK; State Key Lab of CAD&CG, Zhejiang University, China","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","839","848","Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a Bivariate Map equipped with an advanced bivariate colormap to simultaneously depict input traffic and prediction errors across space, 2) a Moran's I Scatterplot that provides local indicators of spatial association analysis, and 3) a Multi-scale Attribution View that arranges non-linear dot plots in a tree layout to promote model analysis and comparison across scales. We evaluate our approach through a series of case studies involving a real-world dataset of Shenzhen taxi trips, and through interviews with domain experts. We observe that geographical scale variations have important impact on prediction performances, and interactive visual exploration of dynamically varying inputs and outputs benefit experts in the development of deep traffic prediction models.","1941-0506","","10.1109/TVCG.2020.3030410","National Natural Science Foundation of China(grant numbers:61802388,61702433,61872389,41701452,61772456,U1609217); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9228894","MAUP;traffic prediction;deep learning;model diagnostic;visual analytics","Predictive models;Visual analytics;Data visualization;Analytical models;Uncertainty;Perturbation methods","data analysis;data visualisation;geographic information systems;learning (artificial intelligence);neural nets;traffic information systems","visual analytics solution;advanced bivariate colormap;prediction errors;spatial association analysis;arranges nonlinear dot plots;model analysis;domain expert;prediction performances;interactive visual exploration;deep traffic prediction models;urban traffic prediction;spatiotemporal traffic data;sequentially organized matrices;convolution-based residual neural networks;modifiable areal unit problem;aggregation processes;network inputs;feature embeddings;deep networks;unit visualization techniques;dynamically varied multiscalar aggregations;urban traffic data;neural network predictions;multiscale attribution view;bivariate map;Moran I scatterplot;Shenzhen taxi trips","","5","","54","IEEE","16 Oct 2020","","","IEEE","IEEE Journals"
"Robust Tracing and Visualization of Heterogeneous Microvascular Networks","P. A. Govyadinov; T. Womack; J. L. Eriksen; G. Chen; D. Mayerich","Department of Computer Science, University of Houston, Houston, TX; Department of Pharmacological and Pharmaceutical Sciences, University of Houston, Houston, TX; Department of Pharmacological and Pharmaceutical Sciences, University of Houston, Houston, TX; Department of Computer Science, University of Houston, Houston, TX; Department of Electrical and Computer Engineering, University of Houston, Houston, TX","IEEE Transactions on Visualization and Computer Graphics","28 Feb 2019","2019","25","4","1760","1773","Advances in high-throughput imaging allow researchers to collect three-dimensional images of whole organ microvascular networks. These extremely large images contain networks that are highly complex, time consuming to segment, and difficult to visualize. In this paper, we present a framework for segmenting and visualizing vascular networks from terabyte-sized three-dimensional images collected using high-throughput microscopy. While these images require terabytes of storage, the volume devoted to the fiber network is <inline-formula><tex-math notation=""LaTeX"">$\approx 4$</tex-math><alternatives> <inline-graphic xlink:href=""govyadinov-ieq1-2818701.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> percent of the total volume size. While the networks themselves are sparse, they are tremendously complex, interconnected, and vary widely in diameter. We describe a parallel GPU-based predictor-corrector method for tracing filaments that is robust to noise and sampling errors common in these data sets. We also propose a number of visualization techniques designed to convey the complex statistical descriptions of fibers across large tissue sections—including commonly studied microvascular characteristics, such as orientation and volume.","1941-0506","","10.1109/TVCG.2018.2818701","Cancer Prevention and Research Institute of Texas(grant numbers:#RR140013); National Institutes of Health(grant numbers:#4 R00 LM011390-02); National Cancer Institute(grant numbers:#1R21CA21 4299-01); US National Science Foundation(grant numbers:IIS 1553329); US National Science Foundation(grant numbers:IIS 1553329); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326724","Microvessel;network tracking;glyph visualization;predictor-corrector;segmantation;spherical harmonics;superquadrics;KESM","Data visualization;Diseases;Robustness;Microscopy;Image segmentation;Biomedical imaging;Anisotropic magnetoresistance","","","Algorithms;Animals;Brain;Computer Graphics;Imaging, Three-Dimensional;Mice;Microscopy;Microvessels","5","","51","USGov","27 Mar 2018","","","IEEE","IEEE Journals"
"Sabrina: Modeling and Visualization of Financial Data over Time with Incremental Domain Knowledge","A. Arleo; C. Tsigkanos; C. Jia; R. A. Leite; I. Murturi; M. Klaffenböck; S. Dustdar; M. Wimmer; S. Miksch; J. Sorger","TU Wien; TU Wien; TU Wien; TU Wien; TU Wien; TU Wien; TU Wien; TU Wien; TU Wien,IIASA; IIASA,Complexity Science Hub Vienna","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","51","55","Investment planning requires knowledge of the financial landscape on a large scale, both in terms of geo-spatial and industry sector distribution. There is plenty of data available, but it is scattered across heterogeneous sources (newspapers, open data, etc.), which makes it difficult for financial analysts to understand the big picture. In this paper, we present Sabrina, a financial data analysis and visualization approach that incorporates a pipeline for the generation of firm-to-firm financial transaction networks. The pipeline is capable of fusing the ground truth on individual firms in a region with (incremental) domain knowledge on general macroscopic aspects of the economy. Sabrina unites these heterogeneous data sources within a uniform visual interface that enables the visual analysis process. In a user study with three domain experts, we illustrate the usefulness of Sabrina, which eases their analysis process.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933598","Human-centered computing;Visualization;Visualization application domains;Visual Analytics;Computing methodologies;Modeling methodologies","Biological system modeling;Data models;Analytical models;Companies;Task analysis;Visualization;Data visualization","data analysis;data visualisation;financial data processing;financial management;investment;planning (artificial intelligence)","Sabrina;uniform visual interface;visual analysis process;incremental domain knowledge;investment planning;financial landscape;industry sector distribution;open data;financial data analysis;visualization approach;firm-to-firm financial transaction networks;heterogeneous data sources;geo-spatial distribution","","5","","26","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Scalability of Network Visualisation from a Cognitive Load Perspective","V. Yoghourdjian; Y. Yang; T. Dwyer; L. Lawrence; M. Wybrow; K. Marriott","Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia; Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia; Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia; Faculty of Business and Economics, Monash University, Melbourne, Australia; Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia; Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1677","1687","Node-link diagrams are widely used to visualise networks. However, even the best network layout algorithms ultimately result in ‘hairball’ visualisations when the graph reaches a certain degree of complexity, requiring simplification through aggregation or interaction (such as filtering) to remain usable. Until now, there has been little data to indicate at what level of complexity node-link diagrams become ineffective or how visual complexity affects cognitive load. To this end, we conducted a controlled study to understand workload limits for a task that requires a detailed understanding of the network topology-finding the shortest path between two nodes. We tested performance on graphs with 25 to 175 nodes with varying density. We collected performance measures (accuracy and response time), subjective feedback, and physiological measures (EEG, pupil dilation, and heart rate variability). To the best of our knowledge this is the first network visualisation study to include physiological measures. Our results show that people have significant difficulty finding the shortest path in high density node-link diagrams with more than 50 nodes and even low density graphs with more than 100 nodes. From our collected EEG data we observe functional differences in brain activity between hard and easy tasks. We found that cognitive load increased up to certain level of difficulty after which it decreased, likely because participants had given up. We also explored the effects of global network layout features such as size or number of crossings, and features of the shortest path such as length or straightness on task difficulty. We found that global features generally had a greater impact than those of the shortest path.","1941-0506","","10.1109/TVCG.2020.3030459","Australian Research Council (ARC)(grant numbers:DP140100077); Harvard Physical Sciences and Engineering Accelerator Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290431","Data Visualisation;Network Visualisation;Cognitive Load;EEG","Task analysis;Data visualization;Particle measurements;Atmospheric measurements;Electroencephalography;Visualization;Physiology","cognition;electroencephalography;feedback;medical signal processing;neural nets","network topology;heart rate variability;network visualisation;high density node-link diagrams;cognitive load perspective;network layout algorithms;complexity node-link diagrams;visual complexity;EEG;pupil dilation;brain activity","Algorithms;Cognition;Computer Graphics;Humans","5","","67","IEEE","10 Dec 2020","","","IEEE","IEEE Journals"
"Security in Process: Visually Supported Triage Analysis in Industrial Process Data","A. -P. Lohfink; S. D. D. Anton; H. D. Schotten; H. Leitte; C. Garth",Scientific Visualization LabUniversity of Kaiserslautern; German Research Center for Artificial Intelligence Kaiserslautern; German Research Center for Artificial Intelligence Kaiserslautern; Visual Information Analysis GroupUniversity of Kaiserslautern; Scientific Visualization LabUniversity of Kaiserslautern,"IEEE Transactions on Visualization and Computer Graphics","28 Feb 2020","2020","26","4","1638","1649","Operation technology networks, i.e. hard- and software used for monitoring and controlling physical/industrial processes, have been considered immune to cyber attacks for a long time. A recent increase of attacks in these networks proves this assumption wrong. Several technical constraints lead to approaches to detect attacks on industrial processes using available sensor data. This setting differs fundamentally from anomaly detection in IT-network traffic and requires new visualization approaches adapted to the common periodical behavior in OT-network data. We present a tailored visualization system that utilizes inherent features of measurements from industrial processes to full capacity to provide insight into the data and support triage analysis by laymen and experts. The novel combination of spiral plots with results from anomaly detection was implemented in an interactive system. The capabilities of our system are demonstrated using sensor and actuator data from a real-world water treatment process with introduced attacks. Exemplary analysis strategies are presented. Finally, we evaluate effectiveness and usability of our system and perform an expert evaluation.","1941-0506","","10.1109/TVCG.2020.2969007","Deutsche Forschungsgemeinschaft(grant numbers:252408385 - IRTG 2057); Federal Ministry of Education and Research of the Federal Republic of Germany; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968740","Cyber Security;Information Visualization;Anomaly Detection;Triage Analysis;Operation Technology Networks","Data visualization;Anomaly detection;Monitoring;Time series analysis;Computer crime;Spirals","data visualisation;production engineering computing;security of data;water treatment","visually supported triage analysis;industrial process data;operation technology networks;technical constraints;sensor data;common periodical behavior;OT-network data;tailored visualization system;support triage analysis;actuator data;real-world water treatment process;exemplary analysis strategies;interactive system;water treatment process","","5","","30","IEEE","24 Jan 2020","","","IEEE","IEEE Journals"
"<italic>Sketch-R2CNN</italic>: An RNN-Rasterization-CNN Architecture for Vector Sketch Recognition","L. Li; C. Zou; Y. Zheng; Q. Su; H. Fu; C. -L. Tai","Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong; Huawei HMI Lab, Huawei Technologies, Shenzhen, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China; A.I. Labs, Alibaba Group, Hangzhou, China; School of Creative Media, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2021","2021","27","9","3745","3754","Sketches in existing large-scale datasets like the recent QuickDraw collection are often stored in a vector format, with strokes consisting of sequentially sampled points. However, most existing sketch recognition methods rasterize vector sketches as binary images and then adopt image classification techniques. In this article, we propose a novel end-to-end single-branch network architecture RNN-Rasterization-CNN (Sketch-R2CNN for short) to fully leverage the vector format of sketches for recognition. Sketch-R2CNN takes a vector sketch as input and uses an RNN for extracting per-point features in the vector space. We then develop a neural line rasterization module to convert the vector sketch and the per-point features to multi-channel point feature maps, which are subsequently fed to a CNN for extracting convolutional features in the pixel space. Our neural line rasterization module is designed in a differentiable way for end-to-end learning. We perform experiments on existing large-scale sketch recognition datasets and show that the RNN-Rasterization design brings consistent improvement over CNN baselines and that Sketch-R2CNN substantially outperforms the state-of-the-art methods.","1941-0506","","10.1109/TVCG.2020.2987626","Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:HKUST 16210718,CityU 11212119); City University of Hong Kong(grant numbers:7005176); Centre for Applied Computing and Interactive Media (ACIM) of School of Creative Media; Fundamental Research Funds for the Central Universities; China Young 1000 talent program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068451","Freehand sketching;RNN;CNN;neural rasterization;object classification;QuickDraw","Feature extraction;Recurrent neural networks;Image recognition;Computer architecture;Task analysis;Network architecture","feature extraction;image classification;learning (artificial intelligence);neural nets","per-point features;neural line rasterization module;large-scale sketch recognition datasets;RNN-Rasterization design;Sketch-R2CNN;vector Sketch recognition;vector format;existing sketch recognition methods;end-to-end single-branch network architecture RNN-Rasterization-CNN;RNN-rasterization-CNN architecture","","5","","52","IEEE","15 Apr 2020","","","IEEE","IEEE Journals"
"Social-Event-Driven Camera Control for Multicharacter Animations","I. Yeh; W. Lin; T. Lee; H. Han; J. Lee; M. Kim","National Cheng Kung University, Tainan; National Chiao Tung University, Hsinchu; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; Seoul National University, Seoul; Seoul National University, Seoul","IEEE Transactions on Visualization and Computer Graphics","12 Jul 2012","2012","18","9","1496","1510","In a virtual world, a group of virtual characters can interact with each other, and these characters may leave a group to join another. The interaction among individuals and groups often produces interesting events in a sequence of animation. The goal of this paper is to discover social events involving mutual interactions or group activities in multicharacter animations and automatically plan a smooth camera motion to view interesting events suggested by our system or relevant events specified by a user. Inspired by sociology studies, we borrow the knowledge in Proxemics, social force, and social network analysis to model the dynamic relation among social events and the relation among the participants within each event. By analyzing the variation of relation strength among participants and spatiotemporal correlation among events, we discover salient social events in a motion clip and generate an overview video of these events with smooth camera motion using a simulated annealing optimization method. We tested our approach on different motions performed by multiple characters. Our user study shows that our results are preferred in 66.19 percent of the comparisons with those by the camera control approach without event analysis and are comparable (51.79 percent) to professional results by an artist.","1941-0506","","10.1109/TVCG.2011.273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065732","MOCAP;multicharacter animation;event analysis;social network analysis.","Cameras;Trajectory;Animation;Social network services;Force;Particle measurements;Atmospheric measurements","cameras;computer animation;virtual reality","social event driven camera control;multicharacter animations;virtual world;virtual characters;social events;group activities;mutual interactions;smooth camera motion;social network analysis;social force;Proxemics;spatiotemporal correlation;motion clip;simulated annealing optimization method","Algorithms;Computer Graphics;Female;Humans;Imaging, Three-Dimensional;Male;Social Behavior;Video Games","5","1","32","","1 Nov 2011","","","IEEE","IEEE Journals"
"The Impact of a Character Posture Model on the Communication of Affect in an Immersive Virtual Environment","V. Vinayagamoorthy; A. Steed; M. Slater","British Broadcasting Corporation, London; University College London, London; University College London, London","IEEE Transactions on Visualization and Computer Graphics","15 Jul 2008","2008","14","5","965","982","This paper presents the quantitative and qualitative findings from an experiment designed to evaluate a developing model of affective postures for full-body virtual characters in immersive virtual environments (IVEs). Forty-nine participants were each requested to explore a virtual environment by asking two virtual characters for instructions. The participants used a CAVE-like system to explore the environment. Participant responses and their impression of the virtual characters were evaluated through a wide variety of both quantitative and qualitative methods. Combining a controlled experimental approach with various data-collection methods provided a number of advantages such as providing a reason to the quantitative results. The quantitative results indicate that posture plays an important role in the communication of affect by virtual characters. The qualitative findings indicated that participants attribute a variety of psychological states to the behavioral cues displayed by virtual characters. In addition, participants tended to interpret the social context portrayed by the virtual characters in a holistic manner. This suggests that one aspect of the virtual scene colors the perception of the whole social context portrayed by the virtual characters. We conclude by discussing the importance of designing holistically congruent virtual characters especially in immersive settings.","1941-0506","","10.1109/TVCG.2008.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4492773","Virtual reality;Animation;Virtual reality;Animation","Virtual environment;Virtual reality;Humans;Psychology;Communication system control;Context;Layout;Physiology;Animation;Instruments","virtual reality","character posture model;immersive virtual environment;affective postures;full-body virtual characters;CAVE-like system;data-collection methods;virtual scene colors","Affect;Communication;Computer Graphics;Cues;Facial Expression;Humans;Posture;Task Performance and Analysis;User-Computer Interface;Visual Perception","5","","53","","18 Apr 2008","","","IEEE","IEEE Journals"
"Topology Density Map for Urban Data Visualization and Analysis","Z. Feng; H. Li; W. Zeng; S. -H. Yang; H. Qu","Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Southern University of Science and Technology; Hong Kong University of Science and Technology","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","828","838","Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density Map supplies accurate information to users and provides an intuitive visualization for decision making. An interview with domain experts demonstrates the feasibility, usability, and effectiveness of our method.","1941-0506","","10.1109/TVCG.2020.3030469","National Key Research and Development Plans(grant numbers:2019YFC0810705,2018YFC0807002); P. R. China, National Natural Science Foundation of China(grant numbers:61802388); HK RGC GRF(grant numbers:16208514); HKUST SSC(grant numbers:F0707); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222248","Density map;network topology;urban data","Roads;Topology;Data visualization;Estimation;Network topology;Urban areas;Two dimensional displays","computational geometry;decision making;directed graphs;road traffic","urban data visualization;effective visualization technique;scalar field distribution;urban analysis;urban traffic;intuitive density maps;urban environment;nonlinear scalar fields;1D road networks;topology density map;directed acyclic graph;DAG","","5","","52","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Towards Quantifying Multiple View Layouts in Visualisation as Seen from Research Publications","H. M. Al-maneea; J. C. Roberts",Bangor University and University of Basrah; Bangor University,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","121","121","We present initial results of a quantitative analysis of how developers layout the visualisations in their multiple view systems. Many developers create multiple view systems and the technique is commonly used by the visualisation community. Each visualisation shows data in a different way, and often user interaction is coordinated between the views. But it is not always clear to know how many views a developer should use, or what would be the best layout. We extract images of visualisation tools, across TVCG journal, conference, posters and workshop papers 2012-2018 to analyse the quantity and layout of the views in these visualisation systems. Focusing on view juxtaposition, we code the layout of 491 images and analyse view topology in juxtaposed views. Our analysis acts as a starting point to help designers create better visualisations, acts as a taxonomy of visualisation layouts, and provides a quantitative analysis of how many views developers have used in their visualisation systems.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933655","Information visualization;multiple view layouts","Layout;Topology;Data visualization;Tools;Image coding;Visualization;Conferences","data visualisation;image retrieval","multiple view systems;visualisation tools;visualisation systems;view juxtaposition;juxtaposed views;visualisation layouts;multiple view layouts;view topology","","5","","27","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visibility-driven Mesh Analysis and Visualization through Graph Cuts","K. Zhou; E. Zhang; J. Bittner; P. Wonka",Arizona State University; Oregon State University; Czech Technical University in Prague; Arizona State University,"IEEE Transactions on Visualization and Computer Graphics","24 Oct 2008","2008","14","6","1667","1674","In this paper we present an algorithm that operates on a triangular mesh and classifies each face of a triangle as either inside or outside. We present three example applications of this core algorithm: normal orientation, inside removal, and layer-based visualization. The distinguishing feature of our algorithm is its robustness even if a difficult input model that includes holes, coplanar triangles, intersecting triangles, and lost connectivity is given. Our algorithm works with the original triangles of the input model and uses sampling to construct a visibility graph that is then segmented using graph cut.","1941-0506","","10.1109/TVCG.2008.176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658189","Index Terms—;Interior/Exterior Classification;Normal Orientation;Layer Classification;Inside Removal;Graph Cut","Visualization;Electronic mail;Face detection;Robustness;Sampling methods;Solid modeling;Geometry;Iterative algorithms;Algorithm design and analysis;Surface cracks","computational geometry;data visualisation;graph theory;mesh generation;sampling methods","visibility-driven triangular mesh analysis;data visualization;graph cut;computational geometry;sampling method","","5","7","21","IEEE","24 Oct 2008","","","IEEE","IEEE Journals"
"Visual Analytics for Temporal Hypergraph Model Exploration","M. T. Fischer; D. Arya; D. Streeb; D. Seebacher; D. A. Keim; M. Worring","University of Konstanz, Germany; University of Amsterdam, The Netherlands; University of Konstanz, Germany; University of Konstanz, Germany; University of Konstanz, Germany; University of Amsterdam, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","550","560","Many processes, from gene interaction in biology to computer networks to social media, can be modeled more precisely as temporal hypergraphs than by regular graphs. This is because hypergraphs generalize graphs by extending edges to connect any number of vertices, allowing complex relationships to be described more accurately and predict their behavior over time. However, the interactive exploration and seamless refinement of such hypergraph-based prediction models still pose a major challenge. We contribute Hyper-Matrix, a novel visual analytics technique that addresses this challenge through a tight coupling between machine-learning and interactive visualizations. In particular, the technique incorporates a geometric deep learning model as a blueprint for problem-specific models while integrating visualizations for graph-based and category-based data with a novel combination of interactions for an effective user-driven exploration of hypergraph models. To eliminate demanding context switches and ensure scalability, our matrix-based visualization provides drill-down capabilities across multiple levels of semantic zoom, from an overview of model predictions down to the content. We facilitate a focused analysis of relevant connections and groups based on interactive user-steering for filtering and search tasks, a dynamically modifiable partition hierarchy, various matrix reordering techniques, and interactive model feedback. We evaluate our technique in a case study and through formative evaluation with law enforcement experts using real-world internet forum communication data. The results show that our approach surpasses existing solutions in terms of scalability and applicability, enables the incorporation of domain knowledge, and allows for fast search-space traversal. With the proposed technique, we pave the way for the visual analytics of temporal hypergraphs in a wide variety of domains.","1941-0506","","10.1109/TVCG.2020.3030408","European Union's Horizon 2020 research and innovation programme(grant numbers:700381); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222341","Hypergraph;communication analysis;geometric deep learning;semantic zoom;matrix ordering;visual analytics","Visualization;Computational modeling;Machine learning;Predictive models;Analytical models;Semantics;Data models","data analysis;data visualisation;deep learning (artificial intelligence);geometry;graph theory;interactive systems;Internet;law administration;matrix algebra","temporal hypergraph model exploration;Hyper-Matrix;visual analytics;machine-learning;interactive visualizations;geometric deep learning model;problem-specific models;category-based data;user-driven exploration;matrix-based visualization;matrix reordering techniques;interactive model feedback;graph-based data;Internet forum communication data;law enforcement experts","","5","","46","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Visual Cascade Analytics of Large-scale Spatiotemporal Data","Z. Deng; D. Weng; Y. Liang; J. Bao; Y. Zheng; T. Schreck; M. Xu; Y. Wu","Research Center for Integrated Intelligence, Zhejiang Lab, 559075 Hangzhou, Zhejiang, China, (e-mail: zikun_rain@zju.edu.cn); Research Center for Integrated Intelligence, Zhejiang Lab, 559075 Hangzhou, Zhejiang, China, (e-mail: mystery.wd@gmail.com); School of Computing, National University of Singapore, 37580 Singapore, Singapore, Singapore, (e-mail: yuxliang@outlook.com); none, JD Intelligent Cities Research, Beijing, Beijing, China, (e-mail: baojie@jd.com); Urban Computing, JD Intelligent Cities Research, Beijing, Beijing, China, (e-mail: msyuzheng@outlook.com); Computer Science and Biomedical Engineering, Graz University of Technology, 27253 Graz, Styria, Austria, 8010 (e-mail: tobias.schreck@cgv.tugraz.at); School of Information Engineering, Zhengzhou University, 12636 Zhengzhou, Henan, China, (e-mail: iexumingliang@zzu.edu.cn); Research Center for Integrated Intelligence, Zhejiang Lab, 559075 Hangzhou, Zhejiang, China, (e-mail: ycwu@zju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Many spatiotemporal events can be viewed as contagions. These events implicitly propagate across space and time by following cascading patterns, expanding their influence, and generating event cascades that involve multiple locations. Analyzing such cascading processes presents valuable implications in various urban applications, such as traffic planning and pollution diagnostics. Motivated by the limited capability of the existing approaches in mining and interpreting cascading patterns, we propose a visual analytics system called VisCas. VisCas combines an inference model with interactive visualizations and empowers analysts to infer and interpret the latent cascading patterns in the spatiotemporal context. To develop VisCas, we address three major challenges, 1) generalized pattern inference, 2) implicit influence visualization, and 3) multifaceted cascade analysis. For the first challenge, we adapt the state-of-the-art cascading network inference technique to general urban scenarios, where cascading patterns can be reliably inferred from large-scale spatiotemporal data. For the second and third challenges, we assemble a set of effective visualizations to support location navigation, influence inspection, and cascading exploration, and facilitate the in-depth cascade analysis. We design a novel influence view based on a three-fold optimization strategy for analyzing the implicit influences of the inferred patterns. We demonstrate the capability and effectiveness of VisCas with two case studies conducted on real-world traffic congestion and air pollution datasets with domain experts.","1941-0506","","10.1109/TVCG.2021.3071387","The 100 Talents Program of Zhejiang University; National Natural Science Foundation of China(grant numbers:61822701,62072400); Natural Science Foundation of Zhejiang Province(grant numbers:LR18F020001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397369","Spatial cascade;pattern mining;spatiotemporal data","Spatiotemporal phenomena;Air pollution;Probabilistic logic;Adaptation models;Visual analytics;Time series analysis;Sensors","","","","5","","","IEEE","6 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Visual Encoding of Dissimilarity Data via Topology-Preserving Map Deformation","Q. W. Bouts; T. Dwyer; J. Dykes; B. Speckmann; S. Goodwin; N. H. Riche; S. Carpendale; A. Liebman","TU Eindhoven, The Netherlands; Monash University, Australia; City University London, United Kingdom; TU Eindhoven, The Netherlands; Monash University, Australia; Microsoft Research; University of Calgary, Canada; Monash University, Australia","IEEE Transactions on Visualization and Computer Graphics","28 Jul 2016","2016","22","9","2200","2213","We present an efficient technique for topology-preserving map deformation and apply it to the visualization of dissimilarity data in a geographic context. Map deformation techniques such as value-by-area cartograms are well studied. However, using deformation to highlight (dis)similarity between locations on a map in terms of their underlying data attributes is novel. We also identify an alternative way to represent dissimilarities on a map through the use of visual overlays. These overlays are complementary to deformation techniques and enable us to assess the quality of the deformation as well as to explore the design space of blending the two methods. Finally, we demonstrate how these techniques can be useful in several-quite different-applied contexts: travel-time visualization, social demographics research and understanding energy flowing in a wide-area power-grid.","1941-0506","","10.1109/TVCG.2015.2500225","ARC(grant numbers:DP140100077); Putting Data on the Map; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328332","Dissimilarity;maps;cartographic visualization;multidimensional scaling;deformation","Topology;Stress;Data visualization;Shape;Roads;Geography;Network topology","cartography;data visualisation;demography;geographic information systems;power grids;social sciences computing;topology","visual encoding;dissimilarity data visualization;topology-preserving map deformation;geographic context;data attributes;travel-time visualization;social demographics;wide-area power-grid","","5","","40","IEEE","12 Nov 2015","","","IEEE","IEEE Journals"
"Visualization Assessment: A Machine Learning Approach","X. Fu; Y. Wang; H. Dong; W. Cui; H. Zhang",Wuhan University; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","126","130","Researchers assess visualizations from multiple aspects, such as aesthetics, memorability, engagement, and efficiency. However, these assessments are mostly carried out through user studies. There is a lack of automatic visualization assessment approaches, which hinders further applications like visualization recommendation, indexing, and generation. In this paper, we propose automating the visualization assessment process with modern machine learning approaches. We utilize a semi-supervised learning method, which first employs Variational Autoencoder (VAE) to learn effective features from visualizations, subsequently training machine learning models for different assessment tasks. Then, we can automatically assess new visualization images by predicting their scores or rankings with the trained model. To evaluate our method, we run two different assessment tasks, namely, aesthetics and memorability, on different visualization datasets. Experiments show that our method can learn effective visual features and achieves good performance on these assessment tasks.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933570","Visualization;automated design;visualization assessment;presentation","Task analysis;Visualization;Machine learning;Feature extraction;Data visualization;Training;Predictive models","data visualisation;supervised learning","visual features;automatic visualization assessment approaches;visualization recommendation;visualization assessment process;semisupervised learning method;machine learning models;visualization images;variational autoencoder","","5","","34","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visualizing a Moving Target: A Design Study on Task Parallel Programs in the Presence of Evolving Data and Concerns","K. Williams; A. Bigelow; K. Isaacs",University of Arizona; University of Arizona; University of Arizona,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","1118","1128","Common pitfalls in visualization projects include lack of data availability and the domain users' needs and focus changing too rapidly for the design process to complete. While it is often prudent to avoid such projects, we argue it can be beneficial to engage them in some cases as the visualization process can help refine data collection, solving a “chicken and egg” problem of having the data and tools to analyze it. We found this to be the case in the domain of task parallel computing where such data and tooling is an open area of research. Despite these hurdles, we conducted a design study. Through a tightly-coupled iterative design process, we built Atria, a multi-view execution graph visualization to support performance analysis. Atria simplifies the initial representation of the execution graph by aggregating nodes as related to their line of code. We deployed Atria on multiple platforms, some requiring design alteration. We describe how we adapted the design study methodology to the “moving target” of both the data and the domain experts' concerns and how this movement kept both the visualization and programming project healthy. We reflect on our process and discuss what factors allow the project to be successful in the presence of changing data and user needs.","1941-0506","","10.1109/TVCG.2019.2934285","United States Department of Defense(grant numbers:FA8075-14-D-0002-0007); National Science Foundation(grant numbers:NSF III-1656958); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805434","design studies;software visualization;parallel computing;graph visualization","Task analysis;Data visualization;Computational modeling;Runtime;Tools;Parallel processing;Data collection","graph theory;parallel programming;program visualisation","iterative design process;Atria;multiview execution graph visualization;moving target visualization;programming project;task parallel programs;visualization projects;data availability;visualization process;data collection","","5","","64","IEEE","19 Aug 2019","","","IEEE","IEEE Journals"
"Why Shouldn’t All Charts Be Scatter Plots? Beyond Precision-Driven Visualizations","E. Bertini; M. Correll; S. Franconeri",New York University; Tableau Research; Northwestern University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","206","210","A central tenet of information visualization research and practice is the notion of visual variable effectiveness, or the perceptual precision at which values are decoded given visual channels of encoding. Formative work from Cleveland & McGill has shown that position along a common axis is the most effective visual variable for comparing individual values. One natural conclusion is that any chart that is not a dot plot or scatterplot is deficient and should be avoided. In this paper we refute a caricature of this ""scatterplots only"" argument as a way to call for new perspectives on how information visualization is researched, taught, and evaluated.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331277","Human-centered computing;Visualization;Visualization theory;concepts and paradigms","Visualization;Pediatrics;Data visualization;Tools;Lead;Sparks;Guidelines","data visualisation","Cleveland & McGill;formative work;perceptual precision;visual variable effectiveness;information visualization research;central tenet;precision-driven visualizations;scatter plots;chart;scatterplots;dot plot","","5","","51","","1 Feb 2021","","","IEEE","IEEE Conferences"
"A Deep Learning-Based Framework for Intersectional Traffic Simulation and Editing","H. Bi; T. Mao; Z. Wang; Z. Deng","University of Chinese Academy of Sciences, Huairou, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Haidian, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Haidian, Beijing, China; Computer Science Department, University of Houston, Houston, TX, USA","IEEE Transactions on Visualization and Computer Graphics","28 May 2020","2020","26","7","2335","2348","Most of existing traffic simulation methods have been focused on simulating vehicles on freeways or city-scale urban networks. However, relatively little research has been done to simulate intersectional traffic to date despite its broad potential applications. In this paper, we propose a novel deep learning-based framework to simulate and edit intersectional traffic. Specifically, based on an in-house collected intersectional traffic dataset, we employ the combination of convolution network (CNN) and recurrent network (RNN) to learn the patterns of vehicle trajectories in intersectional traffic. Besides simulating novel intersectional traffic, our method can be used to edit existing intersectional traffic. Through many experiments as well as comparative user studies, we demonstrate that the results by our method are visually indistinguishable from ground truth, and our method can outperform existing methods.","1941-0506","","10.1109/TVCG.2018.2889834","National Basic Research Program of China (973 Program)(grant numbers:2017YFC0804900); National Natural Science Foundation of China(grant numbers:61532002); 13th Five-Year Common Technology pre Research Program(grant numbers:41402050301-170441402065); Science and Technology Mobilization Program of Dongguan(grant numbers:KZ2017-06); National Science Foundation(grant numbers:IIS 1524782); CSC Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8600335","Traffic simulation;crowd simulation;data-driven;deep learning;intersectional traffic","Trajectory;Solid modeling;Computational modeling;Vehicle dynamics;Traffic control;Data models;Deep learning","convolutional neural nets;learning (artificial intelligence);recurrent neural nets;road traffic;traffic engineering computing","freeways;city-scale urban networks;deep learning-based framework;intersectional traffic dataset;recurrent network;novel intersectional traffic;intersectional traffic simulation;traffic simulation methods;simulating vehicles;CNN;convolution network;RNN;vehicle trajectories","","4","","63","IEEE","3 Jan 2019","","","IEEE","IEEE Journals"
"A Markov Model of Users’ Interactive Behavior in Scatterplots","E. Wall; A. Arcalgud; K. Gupta; A. Jo",Georgia Tech; Georgia Tech; Georgia Tech; Georgia Tech,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","81","85","Recently, Wall et al. proposed a set of computational metrics for quantifying cognitive bias based on user interaction sequences. The metrics rely on a Markov model to predict a user's next interaction based on the current interaction. The metrics characterize how a user's actual interactive behavior deviates from a theoretical baseline, where ""unbiased behavior"" was previously defined to be equal probabilities of all interactions. In this paper, we analyze the assumptions made of these metrics. We conduct a study in which participants, subject to anchoring bias, interact with a scatterplot to complete a categorization task. Our results indicate that, rather than equal probabilities of all interactions, unbiased behavior across both bias conditions can be better approximated by proximity of data points.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933779","Human-centered computing—Human Computer Interaction (HCI);Human-centered computing—Visualization","Markov processes;Measurement;Task analysis;Decision making;Data models;Predictive models;Data visualization","cognition;human factors;Markov processes;probability;user interfaces","categorization task;user interactive behavior;user interaction sequences;cognitive bias;computational metrics;Markov model;bias conditions;scatterplot;anchoring bias;equal probabilities;unbiased behavior;theoretical baseline;current interaction","","4","","25","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Aggregated Dendrograms for Visual Comparison between Many Phylogenetic Trees","Z. Liu; S. H. Zhan; T. Munzner","Computer Science, University of British Columbia, Vancouver, BC, Canada; Zoology, University of British Columbia, Vancouver, BC, Canada; Computer Science, University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2020","2020","26","9","2732","2747","We address the visual comparison of multiple phylogenetic trees that arises in evolutionary biology, specifically between one reference tree and a collection of dozens to hundreds of other trees. We abstract the domain questions of phylogenetic tree comparison as tasks to look for supporting or conflicting evidence for hypotheses that requires inspection of both topological structure and attribute values at different levels of detail in the tree collection. We introduce the new visual encoding idiom of aggregated dendrograms to concisely summarize the topological relationships between interactively chosen focal subtrees according to biologically meaningful criteria, and provide a layout algorithm that automatically adapts to the available screen space. We design and implement the ADView system, which represents trees at multiple levels of detail across multiple views: the entire collection, a subset of trees, an individual tree, specific subtrees of interest, and the individual branch level. We benchmark the algorithms developed for ADView, compare its information density to previous work, and demonstrate its utility for quickly gathering evidence about biological hypotheses through usage scenarios with data from recently published phylogenetic analysis and case studies of expert use with real-world data, drawn from a summative interview study.","1941-0506","","10.1109/TVCG.2019.2898186","Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2016-03711); Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2014-06309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636969","Tree comparison;phylogenetic trees;level of detail","Vegetation;Visualization;Phylogeny;Task analysis;Tools;Biological information theory;Encoding","bioinformatics;data visualisation;evolution (biological);genetics;topology;trees (mathematics)","phylogenetic analysis;aggregated dendrograms;visual comparison;multiple phylogenetic trees;evolutionary biology;reference tree;topological structure;attribute values;tree collection;visual encoding idiom;topological relationships;individual branch level;biological hypotheses;ADView system","Cluster Analysis;Computer Graphics;Humans;Phylogeny;Software","4","","49","IEEE","7 Feb 2019","","","IEEE","IEEE Journals"
"<italic>AutoSweep</italic>: Recovering 3D Editable Objects from a Single Photograph","X. Chen; Y. Li; X. Luo; T. Shao; J. Yu; K. Zhou; Y. Zheng","School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Computing, University of Leeds, Leeds, United Kingdom; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China; State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2020","2020","26","3","1466","1475","This paper presents a fully automatic framework for extracting editable 3D objects directly from a single photograph. Unlike previous methods which recover either depth maps, point clouds, or mesh surfaces, we aim to recover 3D objects with semantic parts and can be directly edited. We base our work on the assumption that most human-made objects are constituted by parts and these parts can be well represented by generalized primitives. Our work makes an attempt towards recovering two types of primitive-shaped objects, namely, generalized cuboids and generalized cylinders. To this end, we build a novel instance-aware segmentation network for accurate part separation. Our GeoNet outputs a set of smooth part-level masks labeled as profiles and bodies. Then in a key stage, we simultaneously identify profile-body relations and recover 3D parts by sweeping the recognized profile along their body contour and jointly optimize the geometry to align with the recovered masks. Qualitative and quantitative experiments show that our algorithm can recover high quality 3D models and outperforms existing methods in both instance segmentation and 3D reconstruction.","1941-0506","","10.1109/TVCG.2018.2871190","National Key Research & Development Program of China(grant numbers:2016YFB1001403); National Natural Science Foundation of China(grant numbers:61502306,61772462,U1736217,U1609215); Microsoft Research; Science and Technology Commission of Shanghai Municipality(grant numbers:17JC1403800); Shanghai Academic/Technology Research Leader(grant numbers:17XD1402900); China Young 1000 Talents Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8467994","Editable objects;instance-aware segmentation;sweep surfaces","Three-dimensional displays;Solid modeling;Image segmentation;Shape;Trajectory;Semantics;Geometry","image reconstruction;image segmentation;solid modelling","generalized cylinders;smooth part-level masks;profile-body relations;recognized profile;body contour;recovered masks;high quality 3D models;instance segmentation;AutoSweep;3D editable objects;fully automatic framework;depth maps;point clouds;semantic parts;generalized primitives;primitive-shaped objects;generalized cuboids;instance-aware segmentation network","","4","","65","IEEE","19 Sep 2018","","","IEEE","IEEE Journals"
"CerebroVis: Designing an Abstract yet Spatially Contextualized Cerebral Artery Network Visualization","A. Pandey; H. Shukla; G. S. Young; L. Qin; A. A. Zamani; L. Hsu; R. Huang; C. Dunne; M. A. Borkin",Northeastern University; Northeastern University; Brigham and Women's Hospital; Dana-Farber Cancer Institute; Brigham and Women's Hospital; Brigham and Women's Hospital; Brigham and Women's Hospital; Northeastern University; Northeastern University,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","938","948","Blood circulation in the human brain is supplied through a network of cerebral arteries. If a clinician suspects a patient has a stroke or other cerebrovascular condition, they order imaging tests. Neuroradiologists visually search the resulting scans for abnormalities. Their visual search tasks correspond to the abstract network analysis tasks of browsing and path following. To assist neuroradiologists in identifying cerebral artery abnormalities, we designed CerebroVis, a novel abstract-yet spatially contextualized-cerebral artery network visualization. In this design study, we contribute a novel framing and definition of the cerebral artery system in terms of network theory and characterize neuroradiologist domain goals as abstract visualization and network analysis tasks. Through an iterative, user-centered design process we developed an abstract network layout technique which incorporates cerebral artery spatial context. The abstract visualization enables increased domain task performance over 3D geometry representations, while including spatial context helps preserve the user's mental map of the underlying geometry. We provide open source implementations of our network layout technique and prototype cerebral artery visualization tool. We demonstrate the robustness of our technique by successfully laying out 61 open source brain scans. We evaluate the effectiveness of our layout through a mixed methods study with three neuroradiologists. In a formative controlled experiment our study participants used CerebroVis and a conventional 3D visualization to examine real cerebral artery imaging data to identify a simulated intracranial artery stenosis. Participants were more accurate at identifying stenoses using CerebroVis (absolute risk difference 13%). A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/e5sxt.","1941-0506","","10.1109/TVCG.2019.2934402","NSF CISE CRII(grant numbers:1657466); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842614","Network Visualization;Spatial Context;Abstract Design;Flow Network;Medical Imaging;Cerebral Arteries","Arteries;Blood;Visualization;Three-dimensional displays;Two dimensional displays;Task analysis;Imaging","biomedical MRI;blood vessels;brain;data visualisation;diseases;haemodynamics;medical image processing;user centred design","CerebroVis;stroke;neuroradiologists;visual search tasks;abstract network analysis tasks;cerebral artery abnormalities;contextualized-cerebral artery network visualization;cerebral artery system;network theory;neuroradiologist domain goals;abstract visualization;user-centered design process;abstract network layout technique;cerebral artery spatial context;domain task performance;including spatial context;prototype cerebral artery visualization tool;conventional 3D visualization;simulated intracranial artery stenosis;open source brain scans","","4","","68","IEEE","17 Sep 2019","","","IEEE","IEEE Journals"
"Characterizing Automated Data Insights","P. -M. Law; A. Endert; J. Stasko",Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","171","175","Many researchers have explored tools that aim to recommend data insights to users. These tools automatically communicate a rich diversity of data insights and offer such insights for many different purposes. However, there is a lack of structured understanding concerning what researchers of these tools mean by ""insight"" and what tasks in the analysis workflow these tools aim to support. We conducted a systematic review of existing systems that seek to recommend data insights. Grounded in the review, we propose 12 types of automated insights and four purposes of automating insights. We further discuss the design opportunities emerged from our analysis.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331320","Human-centered computing;Visualization;Visualization theory;concepts and paradigms","Systematics;Automation;Conferences;Data visualization;Tools;Task analysis","data analysis","automated data insights;analysis workflow","","4","","42","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Chess Evolution Visualization","W. -L. Lu; Y. -S. Wang; W. -C. Lin","Department of Computer Science , National Chiao Tung University, 1001 University Road, Taiwan; Department of Computer Science , National Chiao Tung University, 1001 University Road, Taiwan; Department of Computer Science , National Chiao Tung University, 1001 University Road, Taiwan","IEEE Transactions on Visualization and Computer Graphics","17 Mar 2014","2014","20","5","702","713","We present a chess visualization to convey the changes in a game over successive generations. It contains a score chart, an evolution graph and a chess board, such that users can understand a game from global to local viewpoints. Unlike current graphical chess tools, which focus only on highlighting pieces that are under attack and require sequential investigation, our visualization shows potential outcomes after a piece is moved and indicates how much tactical advantage the player can have over the opponent. Users can first glance at the score chart to roughly obtain the growth and decline of advantages from both sides, and then examine the position relations and the piece placements, to know how the pieces are controlled and how the strategy works. To achieve this visualization, we compute the decision tree using artificial intelligence to analyze a game, in which each node represents a chess position and each edge connects two positions that are one-move different. We then merge nodes representing the same chess position, and shorten branches where nodes on them contain only two neighbors, in order to achieve readability. During the graph rendering, the nodes containing events such as draws, effective checks and checkmates, are highlighted because they show how a game is ended. As a result, our visualization helps players understand a chess game so that they can efficiently learn strategies and tactics. The presented results, evaluations, and the conducted user studies demonstrate the feasibility of our visualization design.","1941-0506","","10.1109/TVCG.2014.2299803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710145","Chess visualization;graph","Games;Visualization;Data visualization;Decision trees;Artificial intelligence;Licenses;Market research","artificial intelligence;computer games;data visualisation;decision trees;graph theory;rendering (computer graphics)","chess evolution visualization;successive generations;score chart;evolution graph;chess board;graphical chess tools;position relations;piece placements;tactical advantage;decision tree;artificial intelligence;graph rendering;checkmates;visualization design","","4","","40","OAPA","13 Jan 2014","","","IEEE","IEEE Journals"
"Conditional Parallel Coordinates","D. K. I. Weidele",IBM Research AI,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","221","225","Parallel Coordinates [11],[12] are a popular data visualization technique for multivariate data. Dating back to as early as 1880 [8] PC are nearly as old as John Snow's famous cholera outbreak map [18] of 1855, which is frequently regarded as a historic landmark for modern data visualization. Numerous extensions have been proposed to address integrity, scalability and readability. We make a new case to employ PC on conditional data, where additional dimensions are only unfolded if certain criteria are met in an observation. Compared to standard PC which operate on a flat set of dimensions the ontology of our input to Conditional Parallel Coordinates is of hierarchical nature. We therefore briefly review related work around hierarchical PC using aggregation or nesting techniques. Our contribution is a visualization to seamlessly adapt PC for conditional data under preservation of intuitive interaction patterns to select or highlight polylines. We conclude with intuitions on how to operate CPC on two data sets: an AutoML hyperparameter search log, and session results from a conversational agent.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933632","Human-centered computing;Visualization;Visualization techniques;Visualization design and evaluation methods","Data visualization;Automobiles;Prototypes;Snow;Brushes;Visualization;Market research","data visualisation;learning (artificial intelligence);statistical analysis","multivariate data;modern data visualization;numerous extensions;readability;conditional data;standard PC;hierarchical PC;aggregation;data sets;cholera outbreak map;conditional parallel coordinates","","4","","24","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Door and Doorway Etiquette for Virtual Humans","W. Huang; D. Terzopoulos","Houzz, Inc., Palo Alto, CA, USA; Computer Science Department, University of California, Los Angeles, Los Angeles, CA, USA","IEEE Transactions on Visualization and Computer Graphics","30 Jan 2020","2020","26","3","1502","1517","We introduce a framework for simulating a variety of nontrivial, socially motivated behaviors that underlie the orderly passage of pedestrians through doorways, especially the common courtesy of opening and holding doors open for others, an important etiquette that has been overlooked in the literature on autonomous multi-human animation. Emulating such social activity requires serious attention to the interplay of visual perception, navigation in constrained doorway environments, manipulation of a variety of door types, and high-level decision making based on social considerations. To tackle this complex human simulation problem, we take an artificial life approach to modeling autonomous pedestrians, proposing a layered architecture comprising mental, behavioral, and motor layers. The behavioral layer couples two stages: (1) a decentralized, agent-based strategy for dynamically determining the well-mannered ordering of pedestrians around doorways, and (2) a state-based model that directs and coordinates a pedestrian's interactions with the door. The mental layer is a Bayesian network decision model that dynamically selects appropriate door-holding behaviors by considering both internal and external social factors pertinent to pedestrians interacting with one another in and around doorways. Our framework addresses the various door types in common use and supports a variety of doorway etiquette scenarios with efficient, real-time performance.","1941-0506","","10.1109/TVCG.2018.2874050","National Science Foundation(grant numbers:0905671); UCLA Dissertation Year Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481548","Virtual humans;multi-human simulation;behavioral animation;social animation;door and doorway etiquette","Task analysis;Animation;Visualization;Context modeling;Planning;Real-time systems","artificial life;belief networks;computer animation;decision making;virtual reality","autonomous pedestrians;door etiquette;doorway etiquette;social factors;Bayesian network decision model;decentralized agent-based strategy;artificial life approach;complex human simulation problem;social considerations;high-level decision making;visual perception;social activity;autonomous multihuman animation;orderly passage;virtual humans","Bayes Theorem;Female;Humans;Male;Pedestrians;Social Interaction;Spatial Navigation;Virtual Reality;Visual Perception","4","","48","IEEE","4 Oct 2018","","","IEEE","IEEE Journals"
"Dynamic Visualization of Coexpression in Systems Genetics Data","J. New; W. Kendall; J. Huang; E. Chesler","University of Tennesee, Knoxville; University of Tennessee, Knoxville; University of Tennesee, Knoxville; Oak Ridge National Lab, Oak Ridge","IEEE Transactions on Visualization and Computer Graphics","15 Jul 2008","2008","14","5","1081","1095","Biologists hope to address grand scientific challenges by exploring the abundance of data made available through modern microarray technology and other high-throughput techniques. The impact of this data, however, is limited unless researchers can effectively assimilate such complex information and integrate it into their daily research; interactive visualization tools are called for to support the effort. Specifically, typical studies of gene co-expression require novel visualization tools that enable the dynamic formulation and fine-tuning of hypotheses to aid the process of evaluating sensitivity of key parameters. These tools should allow biologists to develop an intuitive understanding of the structure of biological networks and discover genes residing in critical positions in networks and pathways. By using a graph as a universal representation of correlation in gene expression, our system employs several techniques that when used in an integrated manner provide innovative analytical capabilities. Our tool for interacting with gene co-expression data integrates techniques such as: graph layout, qualitative subgraph extraction through a novel 2D user interface, quantitative subgraph extraction using graph-theoretic algorithms or by compound queries, dynamic level-of-detail abstraction, and template-based fuzzy classification. We demonstrate our system using a real-world workflow from a large-scale, systems genetics study of mammalian gene coexpression.","1941-0506","","10.1109/TVCG.2008.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4492772","Applications;Multivariate visualization;Visualization systems and software;Applications;Multivariate visualization;Visualization systems and software","Data visualization;Genetics;Gene expression;Organisms;Bioinformatics;Data mining;Proteins;DNA;Sequences;Genomics","biology computing;data visualisation;fuzzy set theory;genetics;graph theory;interactive systems;pattern classification;user interfaces","dynamic genetic coexpression data visualization;microarray technology;interactive visualization tool;biological network structure;graph layout;qualitative subgraph extraction;2D user interface;quantitative subgraph extraction;graph-theoretic algorithm;compound query;dynamic level-of-detail abstraction;template-based fuzzy classification;mammalian gene coexpression;bioinformatics visualization","Computer Graphics;Computer Simulation;Database Management Systems;Databases, Genetic;Gene Expression Profiling;Models, Biological;Proteome;Signal Transduction;User-Computer Interface","4","","42","","10 Jun 2008","","","IEEE","IEEE Journals"
"Exploring Evolution of Dynamic Networks via Diachronic Node Embeddings","J. Xu; Y. Tao; Y. Yan; H. Lin","State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, P.R. China","IEEE Transactions on Visualization and Computer Graphics","28 May 2020","2020","26","7","2387","2402","Dynamic networks evolve with their structures changing over time. It is still a challenging problem to efficiently explore the evolution of dynamic networks in terms of both their structural and temporal properties. In this paper, we propose a visual analytics methodology to interactively explore the temporal evolution of dynamic networks in the context of their structure. A novel diachronic node embedding method is first proposed to learn latent representations of the structural and temporal features of nodes in a vector space. Diachronic node embeddings are then used to discover communities with similar structural proximity and temporal evolution patterns. A visual analytics system is designed to enable users to visually explore the evolutions of nodes, communities, and the network as a whole in terms of their structural and temporal properties. We evaluate the effectiveness of our method using artificial and real-world dynamic networks and comparisons with previous methods.","1941-0506","","10.1109/TVCG.2018.2887230","National Key Research & Development Program of China(grant numbers:2017YFB0202203); National Natural Science Foundation of China(grant numbers:61472354,61672452,61890954); National Natural Science Foundation of China-Guangdong Joint Fund(grant numbers:U1611263); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580402","Graph/network data;data transformation and representation;sequence of data;dimensionality reduction","Visual analytics;Collaboration;Dimensionality reduction;Periodic structures;Cognition;Neural networks","data analysis;data visualisation;evolutionary computation;learning (artificial intelligence);network theory (graphs)","temporal evolution patterns;similar structural proximity;visual analytics methodology;diachronic node embeddings;exploring evolution;real-world dynamic networks;temporal properties;structural properties","","4","","42","IEEE","18 Dec 2018","","","IEEE","IEEE Journals"
"GLoG: Laplacian of Gaussian for Spatial Pattern Detection in Spatio-Temporal Data","L. G. Nonato; F. P. do Carmo; C. T. Silva","University of São Paulo, São Paulo, Brazil; Federal University of Espírito Santo, Espírito Santo, Brazil; New York University, New York, NY, USA","IEEE Transactions on Visualization and Computer Graphics","30 Jun 2021","2021","27","8","3481","3492","Boundary detection has long been a fundamental tool for image processing and computer vision, supporting the analysis of static and time-varying data. In this work, we built upon the theory of Graph Signal Processing to propose a novel boundary detection filter in the context of graphs, having as main application scenario the visual analysis of spatio-temporal data. More specifically, we propose the equivalent for graphs of the so-called Laplacian of Gaussian edge detection filter, which is widely used in image processing. The proposed filter is able to reveal interesting spatial patterns while still enabling the definition of entropy of time slices. The entropy reveals the degree of randomness of a time slice, helping users to identify expected and unexpected phenomena over time. The effectiveness of our approach appears in applications involving synthetic and real data sets, which show that the proposed methodology is able to uncover interesting spatial and temporal phenomena. The provided examples and case studies make clear the usefulness of our approach as a mechanism to support visual analytic tasks involving spatio-temporal data.","1941-0506","","10.1109/TVCG.2020.2978847","CNPq-Brazil(grant numbers:302643/2013-3); Fundação de Amparo à Pesquisa do Estado de São Paulo(grant numbers:2016/04391-2,2014/12236-1,2013/07375-0); Moore-Sloan Data Science Environment; National Aeronautics and Space Administration; National Science Foundation(grant numbers:CNS-1229185,CCF-1533564,CNS-1544753,CNS-1730396,CNS-1828576,CNS-1626098); NVIDIA NVAIL; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9026910","Data filtering;data transformation;feature detection","Feature extraction;Entropy;Visualization;Laplace equations;Tools;Data visualization;Data mining","computer vision;data analysis;data visualisation;edge detection;entropy;graph theory;spatiotemporal phenomena","real data sets;interesting spatial phenomena;temporal phenomena;spatio-temporal data;spatial pattern detection;image processing;time-varying;Graph Signal Processing;boundary detection filter;main application scenario;visual analysis;interesting spatial patterns;time slice;synthetic data sets","","4","","45","IEEE","6 Mar 2020","","","IEEE","IEEE Journals"
"High-Dynamic-Range Texture Compression for Rendering Systems of Different Capacities","W. Sun; Y. Lu; F. Wu; S. Li; J. Tardif","University of Science and Technology of China, Hefei; Microsoft Research Asia, Beijing; Microsoft Research Asia, Beijing; Microsoft Research Asia, Beijing; Microsoft Corporation, Redmond","IEEE Transactions on Visualization and Computer Graphics","13 Nov 2009","2010","16","1","57","69","In this paper, we propose a novel approach for high-dynamic-range (HDR) texture compression (TC) suitable for rendering systems of different capacities. Based on the previously proposed DHTC scheme, we first work out an improved joint-channel compression framework, which is robust and flexible enough to provide compressed HDR textures at different bit rates. Then, two compressed HDR texture formats based on the proposed framework are developed. The 8 bpp format is of near lossless visual quality, improving upon known state-of-the-art algorithms. And, to our knowledge, the 4 bpp format is the first workable 4 bpp solution with good quality. We also show that HDR textures in the proposed 4 bpp and 8 bpp formats can compose a layered architecture in the texture consumption pipeline, to significantly save the memory bandwidth and storage in real-time rendering. In addition, the 8 bpp format can also be used to handle traditional low dynamic range (LDR) RGBA textures. Our scheme exhibits a practical solution for compressing HDR textures at different rates and LDR textures with alpha maps.","1941-0506","","10.1109/TVCG.2009.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5072211","High dynamic range;texture compression;graphics hardware.","Hardware;Bandwidth;Rendering (computer graphics);Graphics;Bit rate;Dynamic range;Sun;Robustness;Pipelines;Layout","data compression;image texture;rendering (computer graphics)","high dynamic range texture compression;rendering system;DHTC scheme;joint channel compression framework;8 bpp format;lossless visual quality;4 bpp format;layered architecture;texture consumption pipeline;low dynamic range RGBA texture","Computer Graphics;Computer Simulation;Data Compression;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Theoretical;Signal Processing, Computer-Assisted;User-Computer Interface","4","","29","IEEE","12 Jun 2009","","","IEEE","IEEE Journals"
"How Does Visualization Help People Learn Deep Learning? Evaluating GAN Lab with Observational Study and Log Analysis","M. Kahng; D. H. P. Chau",Oregon State University; Georgia Institute of Technology,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","266","270","While a rapidly growing number of people want to learn artificial intelligence (AI) and deep learning, the increasing complexity of such models poses significant learning barriers. Recently, interactive visualizations, such as TensorFlow Playground and GAN Lab, have demonstrated success in lowering these barriers. However, there has been little work in evaluating these tools with human subjects. This paper presents two studies on evaluating GAN Lab, an interactive tool designed to help people learn how Generated Adversarial Networks (GANs) work. First, through an observational study, we investigate how the tool is used and what users learn from their usage. Second, we conduct a log analysis of the deployed tool to investigate how its visitors engage with GAN Lab. Based on the studies and our experience in developing and successfully deploying the tool, we provide design considerations and discuss further evaluation challenges for interactive educational tools for deep learning.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331260","Human-centered computing;Visualization;Visualization design and evaluation methods","Deep learning;Visualization;Design methodology;Learning (artificial intelligence);Tools;Generative adversarial networks;Gallium nitride","computer aided instruction;data visualisation;deep learning (artificial intelligence);interactive systems;neural nets","GAN Lab;evaluation challenges;interactive educational tools;deep learning;log analysis;artificial intelligence;interactive visualizations;interactive tool;GANs;generated adversarial networks;TensorFlow Playground;observational study","","4","","23","","1 Feb 2021","","","IEEE","IEEE Conferences"
"IStar: A Raster Representation for Scalable Image and Volume Data","J. Kniss; W. Hunt; K. Potter; P. Sen",Advanced Graphics Lab at the University of New Mexico; Advanced Graphics Lab at the University of New Mexico; School of Computing at the University of Utah; Advanced Graphics Lab at the University of New Mexico,"IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1424","1431","Topology has been an important tool for analyzing scalar data and flow fields in visualization. In this work, we analyze the topology of multivariate image and volume data sets with discontinuities in order to create an efficient, raster-based representation we call IStar. Specifically, the topology information is used to create a dual structure that contains nodes and connectivity information for every segmentable region in the original data set. This graph structure, along with a sampled representation of the segmented data set, is embedded into a standard raster image which can then be substantially downsampled and compressed. During rendering, the raster image is upsampled and the dual graph is used to reconstruct the original function. Unlike traditional raster approaches, our representation can preserve sharp discontinuities at any level of magnification, much like scalable vector graphics. However, because our representation is raster-based, it is well suited to the real-time rendering pipeline. We demonstrate this by reconstructing our data sets on graphics hardware at real-time rates.","1941-0506","","10.1109/TVCG.2007.70572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376170","Topology;Compression;Image Representation;Multi-field Visualization","Topology;Image segmentation;Rendering (computer graphics);Image reconstruction;Graphics;Data analysis;Data visualization;Image analysis;Image coding;Pipelines","image representation;image segmentation;rendering (computer graphics);topology","IStar;raster representation;scalable image representation;volume data;multivariate image;topology information;graph structure;segmented data set;dual graph;real-time rendering;graphics hardware;real-time rates","","4","1","28","","5 Nov 2007","","","IEEE","IEEE Journals"
"Interactive Metro Map Editing","Y. Wang; W. Peng","Department of Computer Science, National Chiao Tung University, Taiwan; Department of Computer Science, National Chiao Tung University, Taiwan","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2015","2016","22","2","1115","1126","Manual editing of a metro map is essential because many aesthetic and readability demands in map generation cannot be achieved by using a fully automatic method. In addition, a metro map should be updated when new metro lines are developed in a city. Considering that manually designing a metro map is time-consuming and requires expert skills, we present an interactive editing system that considers human knowledge and adjusts the layout to make it consistent with user expectations. In other words, only a few stations are controlled and the remaining stations are relocated by our system. Our system supports both curvilinear and octilinear layouts when creating metro maps. It solves an optimization problem, in which even spaces, route straightness, and maximum included angles at junctions are considered to obtain a curvilinear result. The system then rotates each edge to extend either vertically, horizontally, or diagonally while approximating the station positions provided by users to generate an octilinear layout. Experimental results, quantitative and qualitative evaluations, and user studies show that our editing system is easy to use and allows even non-professionals to design a metro map.","1941-0506","","10.1109/TVCG.2015.2430290","National Science Council(grant numbers:101-2628-E-009-020-MY3,100-2628-E-006-031-MY3,100-2221-E-006-188-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102775","Metro Map;Interactive editing;octilinear;least squares optimization;Metro map;interactive editing;octilinear;least squares optimization","Optimization;Junctions;Visualization;Linear programming;Topology;Urban areas","cartography;graph theory;least squares approximations;optimisation;railways","interactive metro map editing;manual metro map editing;map generation;expert skills;interactive editing system;human knowledge;curvilinear layouts;octilinear layouts;route straightness","","4","","20","IEEE","6 May 2015","","","IEEE","IEEE Journals"
"Learning Vis Tools: Teaching Data Visualization Tutorials","L. Y. -H. Lo; Y. Ming; H. Qu",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","11","15","Teaching and advocating data visualization are among the most important activities in the visualization community. With growing interest in data analysis from business and science professionals, data visualization courses attract students across different disciplines. However, comprehensive visualization training requires students to have a certain level of proficiency in programming, a requirement that imposes challenges on both teachers and students. With recent developments in visualization tools, we have managed to overcome these obstacles by teaching a wide range of visualization and supporting tools. Starting with GUI-based visualization tools and data analysis with Python, students put visualization knowledge into practice with increasing amounts of programming. At the end of the course, students can design and implement visualizations with D3 and other programming-based visualization tools. Throughout the course, we continuously collect student feedback and refine the teaching materials. This paper documents our teaching methods and considerations when designing the teaching materials.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933751","Teaching data visualization;education;toolkit tutorials","Data visualization;Tutorials;Tools;Programming profession;Data analysis","computer science education;data analysis;data visualisation;educational courses;graphical user interfaces;teaching","student feedback;teaching materials;teaching methods;teaching data visualization tutorials;visualization community;data analysis;data visualization courses;comprehensive visualization training;GUI-based visualization tools;visualization knowledge;programming-based visualization tools","","4","","42","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Learning on 3D Meshes With Laplacian Encoding and Pooling","Y. -L. Qiao; L. Gao; J. Yang; P. L. Rosin; Y. -K. Lai; X. Chen","Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1317","1327","3D models are commonly used in computer vision and graphics. With the wider availability of mesh data, an efficient and intrinsic deep learning approach to processing 3D meshes is in great need. Unlike images, 3D meshes have irregular connectivity, requiring careful design to capture relations in the data. To utilize the topology information while staying robust under different triangulations, we propose to encode mesh connectivity using Laplacian spectral analysis, along with mesh feature aggregation blocks (MFABs) that can split the surface domain into local pooling patches and aggregate global information amongst them. We build a mesh hierarchy from fine to coarse using Laplacian spectral clustering, which is flexible under isometric transformations. Inside the MFABs there are pooling layers to collect local information and multi-layer perceptrons to compute vertex features of increasing complexity. To obtain the relationships among different clusters, we introduce a Correlation Net to compute a correlation matrix, which can aggregate the features globally by matrix multiplication with cluster features. Our network architecture is flexible enough to be used on meshes with different numbers of vertices. We conduct several experiments including shape segmentation and classification, and our method outperforms state-of-the-art algorithms for these tasks on the ShapeNet and COSEG datasets.","1941-0506","","10.1109/TVCG.2020.3014449","National Natural Science Foundation of China(grant numbers:61872440,61828204); Beijing Municipal Natural Science Foundation(grant numbers:L182016); Royal Society Newton Advanced Fellowship(grant numbers:NAF\R2\192151); Youth Innovation Promotion Association of the Chinese Academy of Sciences; National Laboratory of Pattern Recognition(grant numbers:201900055); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159927","Mesh processing;segmentation;laplacian;deep learning","Three-dimensional displays;Laplace equations;Shape;Correlation;Machine learning;Topology;Computational modeling","belief networks;computational geometry;computer graphics;computer vision;feature extraction;graph theory;image coding;image recognition;image representation;image segmentation;learning (artificial intelligence);mesh generation;multilayer perceptrons;object recognition;pattern clustering;solid modelling;spectral analysis","cluster features;computer vision;wider availability;mesh data;efficient learning approach;intrinsic deep learning approach;irregular connectivity;topology information;different triangulations;mesh connectivity;Laplacian spectral analysis;mesh feature aggregation blocks;MFABs;local pooling patches;aggregate global information;mesh hierarchy;coarse using Laplacian spectral clustering;local information;vertex features","","4","","61","IEEE","5 Aug 2020","","","IEEE","IEEE Journals"
"Localized Topological Simplification of Scalar Data","J. Lukasczyk; C. Garth; R. Maciejewski; J. Tierny","Arizona State University; Technische Universitat Kaiserslautern; Arizona State University; Sorbonne Universite, CNRS","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","572","582","This paper describes a localized algorithm for the topological simplification of scalar data, an essential pre-processing step of topological data analysis (TDA). Given a scalar field f and a selection of extrema to preserve, the proposed localized topological simplification (LTS) derives a function g that is close to f and only exhibits the selected set of extrema. Specifically, suband superlevel set components associated with undesired extrema are first locally flattened and then correctly embedded into the global scalar field, such that these regions are guaranteed-from a combinatorial perspective-to no longer contain any undesired extrema. In contrast to previous global approaches, LTS only and independently processes regions of the domain that actually need to be simplified, which already results in a noticeable speedup. Moreover, due to the localized nature of the algorithm, LTS can utilize shared-memory parallelism to simplify regions simultaneously with a high parallel efficiency (70%). Hence, LTS significantly improves interactivity for the exploration of simplification parameters and their effect on subsequent topological analysis. For such exploration tasks, LTS brings the overall execution time of a plethora of TDA pipelines from minutes down to seconds, with an average observed speedup over state-of-the-art techniques of up to ×36. Furthermore, in the special case where preserved extrema are selected based on topological persistence, an adapted version of LTS partially computes the persistence diagram and simultaneously simplifies features below a predefined persistence threshold. The effectiveness of LTS, its parallel efficiency, and its resulting benefits for TDA are demonstrated on several simulated and acquired datasets from different application domains, including physics, chemistry, and biomedical imaging.","1941-0506","","10.1109/TVCG.2020.3030353","U.S. Department of Homeland Security(grant numbers:2017-ST-061-QA0001,17STQAC00001-03-03); National Science Foundation Program(grant numbers:1350573); European Commission(grant numbers:ERC-2019-COG); “TORI”(grant numbers:863464); German research foundation (DFG)(grant numbers:2057); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222093","Topological data analysis;scalar data;simplification;feature extraction;parallel computing","Computational modeling;Parallel processing;Data visualization;Data analysis;Atmospheric measurements;Particle measurements;Topology","computational geometry;data analysis;data visualisation;graph theory;parallel algorithms","localized topological simplification;scalar data;localized algorithm;topological data analysis;topological analysis;shared memory parallelism;parallel computing;visualization tasks","","4","","60","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Meta-PU: An Arbitrary-Scale Upsampling Network for Point Cloud","S. Ye; D. Chen; S. Han; Z. Wan; J. Liao","Computer Science, City University of Hong Kong, 53025 Kowloon, -, Hong Kong, (e-mail: shuquanye2-c@my.cityu.edu.hk); Microsoft Research, Microsoft Research, 214606 Redmond, Washington, United States, (e-mail: cddlyf@gmail.com); ECE, HKUST, 58207 Kowloon, Hong Kong, Hong Kong, (e-mail: hansongfang@gmail.com); Computer Science, City University of Hong Kong, 53025 Kowloon, -, Hong Kong, (e-mail: ziyuwan2-c@my.cityu.edu.hk); CSE, cityu of Hong Kong, Hong Kong, Kowloon, Hong Kong, (e-mail: jingliao@cityu.edu.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Point cloud upsampling is vital for the quality of the mesh in three-dimensional reconstruction. Recent research on point cloud upsampling has achieved great success due to the development of deep learning. However, the existing methods regard point cloud upsampling of different scale factors as independent tasks. Thus, the methods need to train a specific model for each scale factor, which is both inefficient and impractical for storage and computation in real applications. To address this limitation, in this work, we propose a novel method called ``Meta-PU"" to firstly support point cloud upsampling of arbitrary scale factors with a single model. In the Meta-PU method, besides the backbone network consisting of residual graph convolution (RGC) blocks, a meta-subnetwork is learned to adjust the weights of the RGC blocks dynamically, and a farthest sampling block is adopted to sample different numbers of points. Together, these two blocks enable our Meta-PU to continuously upsample the point cloud with arbitrary scale factors by using only a single model. In addition, the experiments reveal that training on multiple scales simultaneously is beneficial to each other. Thus, Meta-PU even outperforms the existing methods trained for a specific scale factor only.","1941-0506","","10.1109/TVCG.2021.3058311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351772","Point cloud;upsampling;meta-learning;deep learning","Three-dimensional displays;Feature extraction;Task analysis;Convolution;Neural networks;Deep learning;Computational modeling","","","","4","","","IEEE","9 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Narrative Transitions in Data Videos","J. Tang; L. Yu; T. Tang; X. Shu; L. Ying; Y. Zhou; P. Ren; Y. Wu","Zhejiang University,Hangzhou,China; Xi’an Jiaotong-Liverpool University,Suzhou,China; Zhejiang University,Hangzhou,China; The Hong Kong University of Science and Technology,Hong Kong,China; Zhejiang University,Hangzhou,China; Zhejiang Sci-Tech University,Hangzhou,China; Alibaba Group,Hangzhou,China; Zhejiang University,Hangzhou,China","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","151","155","Transitions are widely used in data videos to seamlessly connect data-driven charts or connect visualizations and non-data-driven motion graphics. To inform the transition designs in data videos, we conduct a content analysis based on more than 3500 clips extracted from 284 data videos. We annotate visualization types and transition designs on these segments, and examine how these transitions help make connections between contexts. We propose a taxonomy of transitions in data videos, where two transition categories are defined in building fluent narratives by using visual variables.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331289","Human-centered computing;Visualization;Visualization theory;concepts and paradigms","Visualization;Motion segmentation;Conferences;Taxonomy;Data visualization;Data mining;Videos","data visualisation;video signal processing","narrative transitions;data-driven charts;nondata-driven motion graphics;transition designs;data videos;transition taxonomy;visual variables;visualization types","","4","","27","","1 Feb 2021","","","IEEE","IEEE Conferences"
"O-buffer: a framework for sample-based graphics","H. Qu; A. E. Kaufman","Dept. of Comput. Sci., Stony Brook Univ., NY, USA; Dept. of Comput. Sci., Stony Brook Univ., NY, USA","IEEE Transactions on Visualization and Computer Graphics","18 May 2004","2004","10","4","410","421","We present an innovative modeling and rendering primitive, called the O-buffer, as a framework for sample-based graphics. The 2D or 3D O-buffer is, in essence, a conventional image or a volume, respectively, except that samples are not restricted to a regular grid. A sample position in the O-buffer is recorded as an offset to the nearest grid point of a regular base grid (hence the name O-buffer). The O-buffer can greatly improve the expressive power of images and volumes. Image quality can be improved by storing more spatial information with samples and by avoiding multiple resamplings. It can be exploited to represent and render unstructured primitives, such as points, particles, and curvilinear or irregular volumes. The O-buffer is therefore a unified representation for a variety of graphics primitives and supports mixing them in the same scene. It is a semiregular structure which lends itself to efficient construction and rendering. O-buffers may assume a variety of forms including 2D O-buffers, 3D O-buffers, uniform O-buffers, nonuniform O-buffers, adaptive O-buffers, layered-depth O-buffers, and O-buffer trees. We demonstrate the effectiveness of the O-buffer in a variety of applications, such as image-based rendering, point sample rendering, and volume rendering.","1941-0506","","10.1109/TVCG.2004.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298798","Sample-based rendering;image-based rendering;hybrid rendering;irregular sampling;hierarchy;offset;frame buffer;layered depth image.","Rendering (computer graphics);Computer graphics;Buffer storage;Solid modeling;Image sampling;Image resolution;Layout;Pixel;Spatial resolution;Clouds","rendering (computer graphics);data structures;antialiasing","sample-based graphics;regular base grid;2D O-buffers;3D O-buffers;uniform O-buffers;nonuniform O-buffers;adaptive O-buffers;layered-depth O-buffers;O-buffer trees;image-based rendering;point sample rendering;volume rendering;hybrid rendering;frame buffer;antialiasing","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","4","1","22","","18 May 2004","","","IEEE","IEEE Journals"
"Preserving Command Line Workflow for a Package Management System Using ASCII DAG Visualization","K. E. Isaacs; T. Gamblin","University of Arizona, Tucson, AZ, USA; Lawrence Livermore National Laboratory, Livermore, CA, USA","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2019","2019","25","9","2804","2820","Package managers provide ease of access to applications by removing the time-consuming and sometimes completely prohibitive barrier of successfully building, installing, and maintaining the software for a system. A package dependency contains dependencies between all packages required to build and run the target software. Package management system developers, package maintainers, and users may consult the dependency graph when a simple listing is insufficient for their analyses. However, users working in a remote command line environment must disrupt their workflow to visualize dependency graphs in graphical programs, possibly needing to move files between devices or incur forwarding lag. Such is the case for users of Spack, an open source package management system originally developed to ease the complex builds required by supercomputing environments. To preserve the command line workflow of Spack, we develop an interactive ASCII visualization for its dependency graphs. Through interviews with Spack maintainers, we identify user goals and corresponding visual tasks for dependency graphs. We evaluate the use of our visualization through a command line-centered study, comparing it to the system's two existing approaches. We observe that despite the limitations of the ASCII representation, our visualization is preferred by participants when approached from a command line interface workflow.","1941-0506","","10.1109/TVCG.2018.2859974","U.S. Department of Energy(grant numbers:DE-AC52-07NA27344,LLNL-JRNL-746358); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419271","Software visualization;information visualization;command line interface","Layout;Tools;Visualization;Task analysis;Data visualization;Python","data visualisation;graph theory;interactive systems;public domain software;software maintenance;software management;software packages","command line interface workflow;ASCII DAG visualization;package maintainers;dependency graph;open source package management system;interactive ASCII visualization;Spack maintainers;graphical programs","","4","","54","IEEE","25 Jul 2018","","","IEEE","IEEE Journals"
"QLens: Visual Analytics of MUlti-step Problem-solving Behaviors for Improving Question Design","M. Xia; R. P. Velumani; Y. Wang; H. Qu; X. Ma",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","870","880","With the rapid development of online education in recent years, there has been an increasing number of learning platforms that provide students with multi-step questions to cultivate their problem-solving skills. To guarantee the high quality of such learning materials, question designers need to inspect how students' problem-solving processes unfold step by step to infer whether students' problem-solving logic matches their design intent. They also need to compare the behaviors of different groups (e.g., students from different grades) to distribute questions to students with the right level of knowledge. The availability of fine-grained interaction data, such as mouse movement trajectories from the online platforms, provides the opportunity to analyze problem-solving behaviors. However, it is still challenging to interpret, summarize, and compare the high dimensional problem-solving sequence data. In this paper, we present a visual analytics system, QLens, to help question designers inspect detailed problem-solving trajectories, compare different student groups, distill insights for design improvements. In particular, QLens models problem-solving behavior as a hybrid state transition graph and visualizes it through a novel glyph-embedded Sankey diagram, which reflects students' problem-solving logic, engagement, and encountered difficulties. We conduct three case studies and three expert interviews to demonstrate the usefulness of QLens on real-world datasets that consist of thousands of problem-solving traces.","1941-0506","","10.1109/TVCG.2020.3030337","Theme-based Research Scheme of the Hong Kong RGC(grant numbers:T44-707/16-N); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222360","Learning Behavior Analysis;Visual Analytics;Time Series Data","Problem-solving;Hidden Markov models;Visual analytics;Data visualization;Task analysis;Programming","data analysis;data visualisation;educational administrative data processing","multistep questions;problem-solving skills;question designers;online platforms;high dimensional problem-solving sequence data;visual analytics system;design improvements;problem-solving traces;question design;multistep problem-solving behaviors;problem-solving behavior;online education;hybrid state transition graph;glyph-embedded Sankey diagram;learning platforms;QLens","","4","","51","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Real-Time High-Fidelity Surface Flow Simulation","B. Ren; T. Yuan; C. Li; K. Xu; S. Hu","Nankai University, Tianjin, China; Department of Computer Science and Technology, Tsinghua University, Beijing, P. R. China; Swansea, United Kingdom; Department of Computer Science and Technology, Tsinghua University, Beijing, P. R. China; Department of Computer Science and Technology, Tsinghua University, Beijing, P. R. China","IEEE Transactions on Visualization and Computer Graphics","29 Jun 2018","2018","24","8","2411","2423","Surface flow phenomena, such as rain water flowing down a tree trunk and progressive water front in a shower room, are common in real life. However, compared with the 3D spatial fluid flow, these surface flow problems have been much less studied in the graphics community. To tackle this research gap, we present an efficient, robust and high-fidelity simulation approach based on the shallow-water equations. Specifically, the standard shallow-water flow model is extended to general triangle meshes with a feature-based bottom friction model, and a series of coherent mathematical formulations are derived to represent the full range of physical effects that are important for real-world surface flow phenomena. In addition, by achieving compatibility with existing 3D fluid simulators and by supporting physically realistic interactions with multiple fluids and solid surfaces, the new model is flexible and readily extensible for coupled phenomena. A wide range of simulation examples are presented to demonstrate the performance of the new approach.","1941-0506","","10.1109/TVCG.2017.2720672","Natural Science Foundation of China(grant numbers:61602265,61521002); Beijing Higher Institution Engineering Research Center; European Community's Seventh Framework Programme (Marie Curie International Research Staff Exchange Scheme)(grant numbers:612607); Sêr Cymru National Research Network in Advanced Engineering and Materials; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964760","Shallow-water equation;flow on curved surfaces;finite volume method;coupled simulation","Mathematical model;Three-dimensional displays;Computational modeling;Two dimensional displays;Liquids;Solid modeling;Sea surface","computational fluid dynamics;flow simulation;friction;geophysical fluid dynamics;mesh generation;shallow water equations","high-fidelity simulation approach;shallow-water equations;standard shallow-water flow model;general triangle meshes;feature-based bottom friction model;real-world surface flow phenomena;solid surfaces;coupled phenomena;rain water;progressive water front;shower room;3D spatial fluid flow;surface flow problems;real-time high-fidelity surface flow simulation;3D fluid simulators","","4","","42","IEEE","30 Jun 2017","","","IEEE","IEEE Journals"
"Revisiting Spatio-Angular Trade-off in Light Field Cameras and Extended Applications in Super-Resolution","H. Zhu; M. Guo; H. Li; Q. Wang; A. Robles-Kelly","School of Computer Science, Northwestern Polytechnical University, Xi'an, China; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Australian National University, Canberra, ACT, Australia; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Data61, CSIRO, Canberra, ACT, Australia","IEEE Transactions on Visualization and Computer Graphics","12 May 2021","2021","27","6","3019","3033","Light field cameras (LFCs) have received increasing attention due to their wide-spread applications. However, current LFCs suffer from the well-known spatio-angular trade-off, which is considered an inherent and fundamental limit for LFC designs. In this article, by doing a detailed optical analysis of the sampling process in an LFC, we show that the effective resolution is generally higher than the number of micro-lenses. This contribution makes it theoretically possible to super-resolve a light field. Further optical analysis proves the “2D predictable series” nature of the 4D light field, which provides new insights for analyzing light field using series processing techniques. To model this nature, a specifically designed epipolar plane image (EPI) based CNN-LSTM network is proposed to super-resolve a light field in the spatial and angular dimensions simultaneously. Rather than leveraging semantic information, our network focuses on extracting geometric continuity in the EPI domain. This gives our method an improved generalization ability and makes it applicable to a wide range of previously unseen scenes. Experiments on both synthetic and real light fields demonstrate the improvements over state-of-the-arts, especially in large disparity areas.","1941-0506","","10.1109/TVCG.2019.2957761","National Natural Science Foundation of China(grant numbers:61531014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924770","Spatio-angular trade-off;light field reconstruction;super-resolution;epipolar plane image;LSTM","Spatial resolution;Image reconstruction;Two dimensional displays;Optical imaging;Lenses;Frequency modulation","angular measurement;cameras;image resolution;image sampling;optical sensors","optical analysis;synthetic light field cameras;epipolar plane image based CNN-LSTM network;LFC;2D predictable series;4D light field analysis;EPI","","4","","65","IEEE","5 Dec 2019","","","IEEE","IEEE Journals"
"Stack Zooming for Multifocus Interaction in Skewed-Aspect Visual Spaces","W. Javed; N. Elmqvist","Purdue University, West Lafayette; Purdue University, West Lafayette","IEEE Transactions on Visualization and Computer Graphics","12 Jun 2013","2013","19","8","1362","1374","Many 2D visual spaces have a virtually one-dimensional nature with very high aspect ratio between the dimensions: examples include time-series data, multimedia data such as sound or video, text documents, and bipartite graphs. Common among these is that the space can become very large, e.g., temperature measurements could span a long time period, surveillance video could cover entire days or weeks, and documents can have thousands of pages. Many analysis tasks for such spaces require several foci while retaining context and distance awareness. In this extended version of our IEEE PacificVis 2010 paper, we introduce a method for supporting this kind of multifocus interaction that we call stack zooming. The approach is based on building hierarchies of 1D strips stacked on top of each other, where each subsequent stack represents a higher zoom level, and sibling strips represent branches in the exploration. Correlation graphics show the relation between stacks and strips of different levels, providing context and distance awareness for the foci. The zoom hierarchies can also be used as graphical histories and for communicating insights to stakeholders and can be further extended with annotation and integrated statistics.","1941-0506","","10.1109/TVCG.2012.323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392832","Multifocus interaction;temporal data;comparative visualization;visual exploration;visual analytics;interaction","Visualization;Strips;Context;Layout;Navigation;Nonlinear distortion;Vegetation","data visualisation;rendering (computer graphics)","stack zooming;multifocus interaction;skewed-aspect visual space;2D visual space;time-series data;multimedia data;1D strips;correlation graphics;context awareness;distance awareness","","4","","42","","24 Dec 2012","","","IEEE","IEEE Journals"
"Temporal Upsampling of Depth Maps Using a Hybrid Camera","M. -Z. Yuan; L. Gao; H. Fu; S. Xia","Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Beijing, China; City University of Hong Kong, Hong Kong; Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2019","2019","25","3","1591","1602","In recent years, consumer-level depth cameras have been adopted for various applications. However, they often produce depth maps at only a moderately high frame rate (approximately 30 frames per second), preventing them from being used for applications such as digitizing human performance involving fast motion. On the other hand, low-cost, high-frame-rate video cameras are available. This motivates us to develop a hybrid camera that consists of a high-frame-rate video camera and a low-frame-rate depth camera and to allow temporal interpolation of depth maps with the help of auxiliary color images. To achieve this, we develop a novel algorithm that reconstructs intermediate depth maps and estimates scene flow simultaneously. We test our algorithm on various examples involving fast, non-rigid motions of single or multiple objects. Our experiments show that our scene flow estimation method is more precise than a tracking-based method and the state-of-the-art techniques.","1941-0506","","10.1109/TVCG.2018.2812879","National Natural Science Foundation of China(grant numbers:61502453,61772499,61611130215); Royal Society-Newton Mobility(grant numbers:IE150731); Science and Technology Service Network Initiative of Chinese Academy of Sciences(grant numbers:KFJ-STS-ZDTP-017); Institute of Computing Technology of the Chinese Academy of Sciences(grant numbers:ICT20166040); Hong Kong Research Grants Council(grant numbers:CityU CityU 11237116); ACIM-SCM; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307258","Hybrid camera;scene flow estimation;depth upsampling","Cameras;Color;Image reconstruction;Estimation;Image resolution;Optimization;Tracking","image colour analysis;image motion analysis;image resolution;interpolation;video cameras","auxiliary color images;scene flow estimation method;temporal interpolation;intermediate depth maps;moderately high frame rate;consumer-level depth cameras;low-frame-rate depth camera;high-frame-rate video camera","","4","","65","IEEE","6 Mar 2018","","","IEEE","IEEE Journals"
"The Effect of Edge Bundling and Seriation on Sensemaking of Biclusters in Bipartite Graphs","M. Sun; J. Zhao; H. Wu; K. Luther; C. North; N. Ramakrishnan","Department of Computer and Information Science, University of Massachusetts Dartmouth, North Dartmouth, MA, USA; FX Palo Alto Laboratory, Palo Alto, CA, USA; Google, Mountain View, CA, USA; Computer Science Department, Virginia Tech, Blacksburg, VA, USA; Computer Science Department, Virginia Tech, Blacksburg, VA, USA; Computer Science Department, Virginia Tech, Blacksburg, VA, USA","IEEE Transactions on Visualization and Computer Graphics","4 Sep 2019","2019","25","10","2983","2998","Exploring coordinated relationships (e.g., shared relationships between two sets of entities) is an important analytics task in a variety of real-world applications, such as discovering similarly behaved genes in bioinformatics, detecting malware collusions in cyber security, and identifying products bundles in marketing analysis. Coordinated relationships can be formalized as biclusters. In order to support visual exploration of biclusters, bipartite graphs based visualizations have been proposed, and edge bundling is used to show biclusters. However, it suffers from edge crossings due to possible overlaps of biclusters, and lacks in-depth understanding of its impact on user exploring biclusters in bipartite graphs. To address these, we propose a novel bicluster-based seriation technique that can reduce edge crossings in bipartite graphs drawing and conducted a user experiment to study the effect of edge bundling and this proposed technique on visualizing biclusters in bipartite graphs. We found that they both had impact on reducing entity visits for users exploring biclusters, and edge bundles helped them find more justified answers. Moreover, we identified four key trade-offs that inform the design of future bicluster visualizations. The study results suggest that edge bundling is critical for exploring biclusters in bipartite graphs, which helps to reduce low-level perceptual problems and support high-level inferences.","1941-0506","","10.1109/TVCG.2018.2861397","National Science Foundation(grant numbers:IIS-1447416); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423100","Bicluster;edge bundling;seriation;visual analytics","Bipartite graph;Layout;Image edge detection;Bioinformatics;Visual analytics","data analysis;data visualisation;graph theory;pattern clustering","edge bundling;edge crossings;edge bundles;bicluster visualizations;product bundles;bicluster-based seriation;bipartite graph based visualizations;visual analytics;exploratory data analysis","","4","","46","IEEE","30 Jul 2018","","","IEEE","IEEE Journals"
"The Longitudinal Use of SaNDVis: Visual Social Network Analytics in the Enterprise","A. Perer; I. Guy; E. Uziel; I. Ronen; M. Jacovi","IBM Research, Yorktown Heights; IBM Research, Haifa; IBM Research, Haifa; IBM Research, Haifa; IBM Research, Haifa","IEEE Transactions on Visualization and Computer Graphics","6 May 2013","2013","19","7","1095","1108","As people continue to author and share increasing amounts of information in social media, the opportunity to leverage such information for relationship discovery tasks increases. In this paper, we describe a set of systems that mine, aggregate, and infer a social graph from social media inside an enterprise, resulting in over 73 million relationships between 450,000 people. We then describe SaNDVis, a novel visual analytics tool that supports people-centric tasks like expertise location, team building, and team coordination in the enterprise. We provide details of a 22-month-long, large-scale deployment to over 2,300 users from which we analyze longitudinal usage patterns, classify types of visual analytics queries and users, and extract dominant use cases from log and interview data. By integrating social position, evidence, and facets into SaNDVis, we demonstrate how users can use a visual analytics tool to reflect on existing relationships as well as build new relationships in an enterprise setting.","1941-0506","","10.1109/TVCG.2012.322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381408","Information discovery;social networks;social data mining;social visualization","Social network services;Visual analytics;Tagging;Data visualization;Blogs;Databases","organisational aspects;social aspects of automation;social networking (online)","SaNDVis;visual social network analytics;social media;relationship discovery task;social graph;visual analytics tool;people centric tasks;team building;team coordination;longitudinal usage patterns;visual analytics queries;enterprise setting","","4","","55","","13 Dec 2012","","","IEEE","IEEE Journals"
"Truth or Square: Aspect Ratio Biases Recall of Position Encodings","C. R. Ceja; C. M. McColeman; C. Xiong; S. L. Franconeri",Northwestern University; Northwestern University; Northwestern University; Northwestern University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1054","1062","Bar charts are among the most frequently used visualizations, in part because their position encoding leads them to convey data values precisely. Yet reproductions of single bars or groups of bars within a graph can be biased. Curiously, some previous work found that this bias resulted in an overestimation of reproduced data values, while other work found an underestimation. Across three empirical studies, we offer an explanation for these conflicting findings: this discrepancy is a consequence of the differing aspect ratios of the tested bar marks. Viewers are biased to remember a bar mark as being more similar to a prototypical square, leading to an overestimation of bars with a wide aspect ratio, and an underestimation of bars with a tall aspect ratio. Experiments 1 and 2 showed that the aspect ratio of the bar marks indeed influenced the direction of this bias. Experiment 3 confirmed that this pattern of misestimation bias was present for reproductions from memory, suggesting that this bias may arise when comparing values across sequential displays or views. We describe additional visualization designs that might be prone to this bias beyond bar charts (e.g., Mekko charts and treemaps), and speculate that other visual channels might hold similar biases toward prototypical values.","1941-0506","","10.1109/TVCG.2020.3030422","National Science Foundation Graduate Research Fellowship(grant numbers:DGE-1842165,IIS-1901485); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222047","Memory biases;position estimation;bar charts;aspect ratio;area","Bars;Image color analysis;Encoding;Visualization;Data visualization;Estimation;Prototypes","data visualisation;visual perception","bar mark;misestimation bias;bar charts;similar biases;prototypical values;position encoding;overestimation;reproduced data values;underestimation;prototypical square;wide aspect ratio;tall aspect ratio;bar marks","","4","","36","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Unbiased Sampling and Meshing of Isosurfaces","D. Yan; J. Wallner; P. Wonka","KAUST, Thuwal, Makkah, Saudi Arabia; TU Graz, Kopernikusg. 24, Graz, Austria; KAUST and the Department of Computer Science and Engineering, Arizona State University, Tempe, AZ","IEEE Transactions on Visualization and Computer Graphics","24 Sep 2014","2014","20","11","1579","1589","In this paper, we present a new technique to generate unbiased samples on isosurfaces. An isosurface, F(x; y; z) = c, of a function, F, is implicitly defined by trilinear interpolation of background grid points. The key idea of our approach is that of treating the isosurface within a grid cell as a graph (height) function in one of the three coordinate axis directions, restricted to where the slope is not too high, and integrating / sampling from each of these three. We use this unbiased sampling algorithm for applications in Monte Carlo integration, Poisson-disk sampling, and isosurface meshing.","1941-0506","","10.1109/TVCG.2014.2322357","KAUST Visual Computing Center, the National Natural Science Foundation(grant numbers:61372168,61331018,61271431,61272327); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6811174","Isosurface extraction;unbiased sampling;Poisson-disk sampling;blue noise","Isosurfaces;Density functional theory;Interpolation;Monte Carlo methods;Level set;Feature extraction","computer graphics;graph theory;mesh generation;Monte Carlo methods;sampling methods;stochastic processes","isosurface meshing;trilinear interpolation;background grid points;grid cell;graph function;unbiased sampling algorithm;Monte Carlo integration;Poisson-disk sampling","","4","","40","IEEE","7 May 2014","","","IEEE","IEEE Journals"
"V2V: A Deep Learning Approach to Variable-to-Variable Selection and Translation for Multivariate Time-Varying Data","J. Han; H. Zheng; Y. Xing; D. Z. Chen; C. Wang",University of Notre Dame; University of Notre Dame; Sichuan University; University of Notre Dame; University of Notre Dame,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1290","1300","We present V2V, a novel deep learning framework, as a general-purpose solution to the variable-to-variable (V2V) selection and translation problem for multivariate time-varying data (MTVD) analysis and visualization. V2V leverages a representation learning algorithm to identify transferable variables and utilizes Kullback-Leibler divergence to determine the source and target variables. It then uses a generative adversarial network (GAN) to learn the mapping from the source variable to the target variable via the adversarial, volumetric, and feature losses. V2V takes the pairs of time steps of the source and target variable as input for training, Once trained, it can infer unseen time steps of the target variable given the corresponding time steps of the source variable. Several multivariate time-varying data sets of different characteristics are used to demonstrate the effectiveness of V2V, both quantitatively and qualitatively. We compare V2V against histogram matching and two other deep learning solutions (Pix2Pix and CycleGAN).","1941-0506","","10.1109/TVCG.2020.3030346","U.S. National Science Foundation(grant numbers:IIS-1455886,CCF-1617735,CNS-1629914,DUE-1833129,IIS-1955395); NVIDIA GPU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230431","Multivariate time-varying data;variable selection and translation;generative adversarial network;data extrapolation","Deep learning;Feature extraction;Task analysis;Input variables;Generative adversarial networks;Three-dimensional displays","computer vision;data analysis;data visualisation;deep learning (artificial intelligence)","V2V;deep learning approach;variable-to-variable selection;translation problem;data visualization;transferable variables;target variable;multivariate time-varying data sets;multivariate time-varying data analysis;representation learning algorithm;Kullback-Leibler divergence;generative adversarial network;GAN;source variable;histogram matching;Pix2Pix;CycleGAN;MTVD","","4","","47","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data","Y. Wang; G. Yan; H. Zhu; S. Buch; Y. Wang; E. M. Haacke; J. Hua; Z. Zhong","Department of Radiology, Wayne State University, Detroit, MI; Department of Computer Science, Wayne State University, Detroit, MI; Department of Computer Science, Wayne State University, Detroit, MI; Department of Radiology, Wayne State University, Detroit, MI; Department of Computer Science, Wayne State University, Detroit, MI; Department of Radiology, Wayne State University, Detroit, MI; Department of Computer Science, Wayne State University, Detroit, MI; Department of Computer Science, Wayne State University, Detroit, MI","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1301","1311","The fundamental motivation of the proposed work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration. For example, extracting and visualizing microstructures in-vivo have been a long-standing challenging problem. However, due to the high sparseness and noisiness in cerebrovasculature data as well as highly complex geometry and topology variations of micro vessels, it is still extremely challenging to extract the complete 3D vessel structure and visualize it in 3D with high fidelity. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvascular structure through embedding the image composition, generated by maximum intensity projection (MIP), into the 3D volumetric image learning process to enhance the overall performance. The core novelty is to automatically leverage the volume visualization technique (e.g., MIP - a volume rendering scheme for 3D volume images) to enhance the 3D data exploration at the deep learning level. The MIP embedding features can enhance the local vessel signal (through canceling out the noise) and adapt to the geometric variability and scalability of vessels, which is of great importance in microvascular tracking. A multi-stream convolutional neural network (CNN) framework is proposed to effectively learn the 3D volume and 2D MIP feature vectors, respectively, and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the 2D feature vectors into the 3D volume embedding space. It is noted that the proposed framework can better capture the small/micro vessels and improve the vessel connectivity. To our knowledge, this is the first time that a deep learning framework is proposed to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are evaluated and compared with the traditional 3D vessel segmentation methods and the state-of-the-art in deep learning, by using extensive public and real patient (micro- )cerebrovascular image datasets. The application of this accurate segmentation and visualization of sparse and complicated 3D microvascular structure facilitated by our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular disease.","1941-0506","","10.1109/TVCG.2020.3030374","NSF(grant numbers:IIS-1816511,CNS-1647200,OAC-1657364,OAC-1845962,OAC-1910469); Wayne State University Subaward(grant numbers:4207299A,CNS-1821962); NIH(grant numbers:1R56AG060822-01A1,1R44HL145826-01A1,ZJNSF LZ16F020002); National Natural Science Foundation of China(grant numbers:61972353); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222053","Deep neural network;3D cerebrovascular segmentation and visualization;maximum intensity projection (MIP);joint embedding","Three-dimensional displays;Image segmentation;Two dimensional displays;Data visualization;Deep learning;Rendering (computer graphics);Feature extraction","biomedical MRI;blood vessels;convolutional neural nets;data visualisation;diseases;feature extraction;image segmentation;learning (artificial intelligence);medical image processing;rendering (computer graphics)","VC-Net;deep volume-composition networks;sparse image;noisy image;cerebrovasculature data;3D vessel structure;end-to-end deep learning;image composition;maximum intensity projection;volume visualization;volume rendering;3D volume images;3D data exploration;MIP embedding features;local vessel signal;geometric variability;2D feature vectors;3D volume embedding space;vessel connectivity;joint convolutional embedding space;cerebrovascular image datasets;visualization-guided computing;3D volumetric image learning;multistream convolutional neural network;joint volume-composition embedding space;vessel probabilities;sparse 3D microvascular structure;traditional 3D vessel segmentation","Computer Graphics;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Neural Networks, Computer","4","","47","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"VisCode: Embedding Information in Visualization Images using Encoder-Decoder Network","P. Zhang; C. Li; C. Wang",School of Computer Science and TechnologyEast China Normal University; School of Computer Science and TechnologyEast China Normal University; School of Computer Science and TechnologyEast China Normal University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","326","336","We present an approach called VisCode for embedding information into visualization images. This technology can implicitly embed data information specified by the user into a visualization while ensuring that the encoded visualization image is not distorted. The VisCode framework is based on a deep neural network. We propose to use visualization images and QR codes data as training data and design a robust deep encoder-decoder network. The designed model considers the salient features of visualization images to reduce the explicit visual loss caused by encoding. To further support large-scale encoding and decoding, we consider the characteristics of information visualization and propose a saliency-based QR code layout algorithm. We present a variety of practical applications of VisCode in the context of information visualization and conduct a comprehensive evaluation of the perceptual quality of encoding, decoding success rate, anti-attack capability, time performance, etc. The evaluation results demonstrate the effectiveness of VisCode.","1941-0506","","10.1109/TVCG.2020.3030343","NSFC(grant numbers:61802128,61672237,61532002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222358","Information visualization;information steganography;autocoding;saliency detection;visualization retargeting","Data visualization;Visualization;Decoding;Image coding;Encoding;Image color analysis;Media","codecs;data visualisation;decoding;deep learning (artificial intelligence);image coding;neural nets","antiattack capability;decoding success rate;robust deep encoder-decoder network;QR codes data;deep neural network;encoded visualization image;data information;embedding information;VisCode;saliency-based QR code layout algorithm;information visualization;visual loss;visualization images","","4","","61","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"VisMatchmaker: Cooperation of the User and the Computer in Centralized Matching Adjustment","P. Law; W. Wu; Y. Zheng; H. Qu",Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2016","2017","23","1","231","240","Centralized matching is a ubiquitous resource allocation problem. In a centralized matching problem, each agent has a preference list ranking the other agents and a central planner is responsible for matching the agents manually or with an algorithm. While algorithms can find a matching which optimizes some performance metrics, they are used as a black box and preclude the central planner from applying his domain knowledge to find a matching which aligns better with the user tasks. Furthermore, the existing matching visualization techniques (i.e. bipartite graph and adjacency matrix) fail in helping the central planner understand the differences between matchings. In this paper, we present VisMatchmaker, a visualization system which allows the central planner to explore alternatives to an algorithm-generated matching. We identified three common tasks in the process of matching adjustment: problem detection, matching recommendation and matching evaluation. We classified matching comparison into three levels and designed visualization techniques for them, including the number line view and the stacked graph view. Two types of algorithmic support, namely direct assignment and range search, and their interactive operations are also provided to enable the user to apply his domain knowledge in matching adjustment.","1941-0506","","10.1109/TVCG.2016.2599378","RGC(grant numbers:GRF16208514); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539560","Centralized matching;matching visualization;interaction techniques;visual analytics","Visualization;Measurement;Processor scheduling;Computers;Resource management;Bipartite graph;Encoding","data visualisation;pattern matching;resource allocation;ubiquitous computing;user interfaces","VisMatchmaker;computer;centralized matching adjustment;ubiquitous resource allocation problem;centralized matching problem;preference list ranking;central planner;performance metrics;black box;user tasks;visualization system;algorithm-generated matching;matching recommendation;matching evaluation;visualization techniques;stacked graph view;range search;interactive operations;domain knowledge","","4","","32","IEEE","10 Aug 2016","","","IEEE","IEEE Journals"
"Visual Causality Analysis of Event Sequence Data","Z. Jin; S. Guo; N. Chen; D. Weiskopf; D. Gotz; N. Cao",iDVx Lab at Tongji University; iDVx Lab at Tongji University; iDVx Lab at Tongji University; University of Stuttgart; University of North Carolina at Chapel Hill; iDVx Lab at Tongji University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1343","1352","Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.","1941-0506","","10.1109/TVCG.2020.3030465","Fundamental Research Funds for the Central Universities(grant numbers:22120190216); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222294","Event sequence data;causality analysis;visual analytics","Analytical models;Visual analytics;Data visualization;Data models;Layout;Computational modeling","Bayes methods;causality;data analysis;data mining;data visualisation;interactive systems;iterative methods","observational event sequences;heterogeneous event variables;high-dimensional event variables;event excitation mechanisms;event sequence data;Granger causality analysis algorithm;causal model refinement;visualization system;interactive causal analysis framework;bottom-up causal exploration;iterative causal verification;visual causality analysis;causal relations;Hawkes processes;user feedback","","4","","53","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Visual Cause Analytics for Traffic Congestion","M. Pi; H. Yeon; H. Son; Y. Jang","Sejong University, Seoul, South Korea; Sejong University, Seoul, South Korea; Sejong University, Seoul, South Korea; Sejong University, Seoul, South Korea","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","3","2186","2201","Urban traffic congestion has become an important issue not only affecting our daily lives, but also limiting economic development. The primary cause of urban traffic congestion is that the number of vehicles is higher than the permissible limit of the road. Previous studies have focused on dispersing traffic volume by detecting urban traffic congestion zones and predicting future trends. However, to solve the fundamental problem, it is necessary to discover the cause of traffic congestion. Nevertheless, it is difficult to find a research which presents an approach to identify the causes of traffic congestion. In this paper, we propose a technique to analyze the cause of traffic congestion based on the traffic flow theory. We extract vehicle flows from traffic data, such as GPS trajectory and Vehicle Detector data. We detect vehicle flow changes utilizing the entropy from the information theory. Then, we build cumulative vehicle count curves (N-curve) that can quantify the flow of the vehicles in the traffic congestion area. The N-curves are classified into four different traffic congestion patterns by a convolutional neural network. Analyzing the causes and influence of traffic congestion is difficult and requires considerable experience and knowledge. Therefore, we present a visual analytics system that can efficiently perform a series of processes to analyze the cause and influence of traffic congestion. Through case studies, we have evaluated that our system can classify the causes of traffic congestion and can be used efficiently in road planning.","1941-0506","","10.1109/TVCG.2019.2940580","Textitute of Information & communications Technology Planning & Evaluation(grant numbers:2019-0-00136,2019-0-00374,2019-0-00795); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827957","Causes of traffic congestion;traffic flow theory;information entropy;convolutional neural network;visual analytics","Roads;Visual analytics;Trajectory;Global Positioning System;Spatiotemporal phenomena;Data visualization","data visualisation;pattern classification;road traffic;road vehicles;traffic engineering computing","traffic congestion cause;visual cause analytics;future trends prediction;urban traffic congestion zones;traffic congestion patterns;traffic congestion area;traffic flow theory","","4","","95","IEEE","10 Sep 2019","","","IEEE","IEEE Journals"
"A Distributed Memory Hierarchy and Data Management for Interactive Scene Navigation and Modification on Tiled Display Walls","D. Lai; B. Sajadi; S. Jiang; G. Meenakshisundaram; A. Majumder","Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2015","2015","21","6","714","729","Simultaneous modification and navigation of massive 3D models are difficult because repeated data edits affect the data layout and coherency on a secondary storage, which in turn affect the interactive out-of-core rendering performance. In this paper, we propose a novel approach for distributed data management for simultaneous interactive navigation and modification of massive 3D data using the readily available infrastructure of a tiled display. Tiled multi-displays, projection or LCD panel based, driven by a PC cluster, can be viewed as a cluster of storage-compute-display (SCD) nodes. Given a cluster of SCD node infrastructure, we first propose a distributed memory hierarchy for interactive rendering applications. Second, in order to further reduce the latency in such applications, we propose a new data partitioning approach for distributed storage among the SCD nodes that reduces the variance in the data load across the SCD nodes. Our data distribution method takes in a data set of any size, and reorganizes it into smaller partitions, and stores it across the multiple SCD nodes. These nodes store, manage, and coordinate data with other SCD nodes to simultaneously achieve interactive navigation and modification. Specifically, the data is not duplicated across these distributed secondary storage devices. In addition, coherency in data access, due to screen-space adjacency of adjacent displays in the tile, as well as object space adjacency of the data sets, is well leveraged in the design of the data management technique. Empirical evaluation on two large data sets, with different data density distribution, demonstrates that the proposed data management approach achieves superior performance over alternative state-of-the-art methods.","1941-0506","","10.1109/TVCG.2015.2398439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7027856","Management of computing and information systems;project and people management;life cycle;the computing profession miscellaneous ethics","Rendering (computer graphics);Distributed databases;Data models;Navigation;Layout;Three-dimensional displays;Memory management","distributed memory systems;interactive devices;liquid crystal displays;rendering (computer graphics);solid modelling;storage management","data density distribution;data management technique;object space adjacency;screen-space adjacency;secondary storage devices;interactive rendering applications;SCD node infrastructure;storage-compute-display nodes;PC cluster;LCD panel;tiled multidisplays;simultaneous interactive navigation;distributed data management;interactive out-of-core rendering performance;data layout;repeated data edits;massive 3D models;simultaneous modification;tiled display walls;interactive scene navigation;distributed memory hierarchy","","3","","31","IEEE","30 Jan 2015","","","IEEE","IEEE Journals"
"A Survey on Visual Analysis of Event Sequence Data","Y. Guo; S. Guo; Z. Jin; S. Kaul; D. Gotz; N. Cao","College of Design and Innovation, Tongji University, 12476 Shanghai, Shanghai, China, (e-mail: dennis.guo.china@gmail.com); Software Engineering, East China Normal University, 12655 ShangHai, ShangHai, China, 200062 (e-mail: g.shunan@gmail.com); College of Design and Innovation, Tongji University, 12476 Shanghai, Shanghai, China, 200092 (e-mail: chjzcjames@gmail.com); Computer Science, University of North Carolina at Chapel Hill, 2331 Chapel Hill, North Carolina, United States, (e-mail: smiti@unc.edu); School of Information and Library Science, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, United States, 27599 (e-mail: gotz@unc.edu); College of Design and Innovation, Tongji University, 12476 Shanghai, Shanghai, China, (e-mail: nan.cao@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Event sequence data record series of discrete events in the time order of occurrence. They are commonly observed in a variety of applications ranging from electronic health records to network logs, with the characteristics of large-scale, high-dimensional and heterogeneous. This high complexity of event sequence data makes it difficult for analysts to manually explore and find patterns, resulting in ever-increasing needs for computational and perceptual aids from visual analytics techniques to extract and communicate insights from event sequence datasets. In this paper, we review the state-of-the-art visual analytics approaches, characterize them with our proposed design space, and categorize them based on analytical tasks and applications.","1941-0506","","10.1109/TVCG.2021.3100413","National Natural Science Foundation of China(grant numbers:62061136003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497654","Visual Analysis;Event Sequences;Visualization","Data visualization;Visual analytics;Task analysis;Data mining;Sequences;Pipelines;Medical diagnostic imaging","","","","3","","","IEEE","27 Jul 2021","","","IEEE","IEEE Early Access Articles"
"Animated Depth Images for Interactive Remote Visualization of Time-Varying Data Sets","J. Cui; Z. Ma; V. Popescu","Computer Science Department, Purdue University, 305 N. University St., West Lafayette; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University , PO Box 6863, Beijing, China; Computer Science Department, Purdue University, 305 N. University St., West Lafayette","IEEE Transactions on Visualization and Computer Graphics","24 Sep 2014","2014","20","11","1474","1489","Remote visualization has become both a necessity, as data set sizes have grown faster than computer network performance, and an opportunity, as laptop, tablet, and smartphone mobile computing platforms have become ubiquitous. However, the conventional remote visualization (CRV) approach of sending a new image from the server to the client for every view parameter change suffers from reduced interactivity. One problem is high latency, as the network has to be traversed twice, once to communicate the view parameters to the server and once to transmit the new image to the client. A second problem is reduced image quality due to aggressive compression or low resolution. We address these problems by constructing and transmitting enhanced images that are sufficient for quality output frame reconstruction at the client for a range of view parameter values. The client reconstructs thousands of frames locally, without any additional data from the server, which avoids latency and aggressive compression. We introduce animated depth images, which not only store a color and depth sample at every pixel, but also store the trajectory of the samples for a given time interval. Sample trajectories are stored compactly by partitioning the image into semi-rigid sample clusters and by storing one sequence of rigid body transformations per cluster. Animated depth images leverage sample trajectory coherence to achieve a good compression of animation data, with a small and user-controllable approximation error. We demonstrate animated depth images in the context of finite element analysis and SPH data sets.","1941-0506","","10.1109/TVCG.2013.259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671915","Remote visualization;time-varying data sets;animation data compression;rigid-body decomposition;bounded error","Trajectory;Image reconstruction;Image color analysis;Approximation methods;Data visualization;Rendering (computer graphics)","computer animation;data visualisation;finite element analysis;image processing;mobile computing","SPH data sets;finite element analysis;user controllable approximation error;animation data;trajectory coherence;parameter values;quality output frame reconstruction;image enhancement;image quality;CRV;conventional remote visualization;tablet;laptop;smartphone mobile computing platforms;computer network performance;time-varying data sets;interactive remote visualization;animated depth images","","3","","46","IEEE","21 Nov 2013","","","IEEE","IEEE Journals"
"Attribute-Conditioned Layout GAN for Automatic Graphic Design","J. Li; J. Yang; J. Zhang; C. Liu; C. Wang; T. Xu","Beijing Institute of Technology, Beijing, China; Adobe Inc., San Jose, CA, USA; Adobe Inc., San Jose, CA, USA; Adobe Inc., San Jose, CA, USA; Adobe Inc., San Jose, CA, USA; Beijing Institute of Technology, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2021","2021","27","10","4039","4048","Modeling layout is an important first step for graphic design. Recently, methods for generating graphic layouts have progressed, particularly with Generative Adversarial Networks (GANs). However, the problem of specifying the locations and sizes of design elements usually involves constraints with respect to element attributes, such as area, aspect ratio and reading-order. Automating attribute conditional graphic layouts remains a complex and unsolved problem. In this article, we introduce Attribute-conditioned Layout GAN to incorporate the attributes of design elements for graphic layout generation by forcing both the generator and the discriminator to meet attribute conditions. Due to the complexity of graphic designs, we further propose an element dropout method to make the discriminator look at partial lists of elements and learn their local patterns. In addition, we introduce various loss designs following different design principles for layout optimization. We demonstrate that the proposed method can synthesize graphic layouts conditioned on different element attributes. It can also adjust well-designed layouts to new sizes while retaining elements' original reading-orders. The effectiveness of our method is validated through a user study.","1941-0506","","10.1109/TVCG.2020.2999335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106863","Generative adversarial networks;graphic design;attribute","Layout;Generators;Generative adversarial networks;Optimization;Task analysis;Gallium nitride","computer graphics;integrated circuit layout;neural nets;optimisation","element attributes;layout optimization;design principles;element dropout method;graphic layout generation;attribute conditional graphic layouts;generative adversarial networks;modeling layout;automatic graphic design;attribute-conditioned layout GAN","","3","","34","IEEE","2 Jun 2020","","","IEEE","IEEE Journals"
"Continuous Control Monte Carlo Tree Search Informed by Multiple Experts","J. Rajamäki; P. Hämäläinen","Department of Computer Science, Aalto University, Helsinki, Finland; Department of Computer Science, Aalto University, Helsinki, Finland","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2019","2019","25","8","2540","2553","Efficient algorithms for 3D character control in continuous control setting remain an open problem in spite of the remarkable recent advances in the field. We present a sampling-based model-predictive controller that comes in the form of a Monte Carlo tree search (MCTS). The tree search utilizes information from multiple sources including two machine learning models. This allows rapid development of complex skills such as 3D humanoid locomotion with less than a million simulation steps, in less than a minute of computing on a modest personal computer. We demonstrate locomotion of 3D characters with varying topologies under disturbances such as heavy projectile hits and abruptly changing target direction. In this paper we also present a new way to combine information from the various sources such that minimal amount of information is lost. We furthermore extend the neural network, involved in the algorithm, to represent stochastic policies. Our approach yields a robust control algorithm that is easy to use. While learning, the algorithm runs in near real-time, and after learning the sampling budget can be reduced for real-time operation.","1941-0506","","10.1109/TVCG.2018.2849386","Academy of Finland(grant numbers:299358,305737); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401544","Monte Carlo tree search;continuous control;reinforcement learning","Learning (artificial intelligence);Neural networks;Planning;Monte Carlo methods;Real-time systems;Three-dimensional displays;Predictive models","control system analysis computing;humanoid robots;learning (artificial intelligence);mobile robots;Monte Carlo methods;predictive control;robust control;tree searching","multiple experts;3D character control;continuous control setting;open problem;remarkable recent advances;sampling-based model-predictive controller;multiple sources;machine learning models;3D humanoid locomotion;million simulation steps;modest personal computer;robust control algorithm;continuous control Monte Carlo tree search","","3","","54","CCBY","2 Jul 2018","","","IEEE","IEEE Journals"
"Deep Volumetric Ambient Occlusion","D. Engel; T. Ropinski","Ulm University; Ulm University and Linköping University, Norrköping","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1268","1278","We present a novel deep learning based technique for volumetric ambient occlusion in the context of direct volume rendering. Our proposed Deep Volumetric Ambient Occlusion (DVAO) approach can predict per-voxel ambient occlusion in volumetric data sets, while considering global information provided through the transfer function. The proposed neural network only needs to be executed upon change of this global information, and thus supports real-time volume interaction. Accordingly, we demonstrate DVAO's ability to predict volumetric ambient occlusion, such that it can be applied interactively within direct volume rendering. To achieve the best possible results, we propose and analyze a variety of transfer function representations and injection strategies for deep neural networks. Based on the obtained results we also give recommendations applicable in similar volume learning scenarios. Lastly, we show that DVAO generalizes to a variety of modalities, despite being trained on computed tomography data only.","1941-0506","","10.1109/TVCG.2020.3030344","Deutsche Forschungsgemeinschaft (DFG)(grant numbers:391107954); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222376","Volume illumination;deep learning;direct volume rendering","Rendering (computer graphics);Transfer functions;Lighting;Training;Three-dimensional displays;Neural networks;Deep learning","computerised tomography;learning (artificial intelligence);medical image processing;neural nets;real-time systems;rendering (computer graphics);transfer functions","deep learning based technique;direct volume rendering;DVAO;per-voxel ambient occlusion;volumetric data sets;global information;real-time volume interaction;deep neural networks;similar volume learning scenarios;deep volumetric ambient occlusion approach;computed tomography data","","3","","50","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Design Judgment in Data Visualization Practice","P. Parsons; C. M. Gray; A. Baigelenov; I. Carr",Purdue University; Purdue University; Purdue University; Purdue University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","176","180","Data visualization is becoming an increasingly popular field of design practice. Although many studies have highlighted the knowledge required for effective data visualization design, their focus has largely been on formal knowledge and logical decision-making processes that can be abstracted and codified. Less attention has been paid to the more situated and personal ways of knowing that are prevalent in all design activity. In this study, we conducted semistructured interviews with data visualization practitioners during which they were asked to describe the practical and situated aspects of their design processes. Using a philosophical framework of design judgment from Nelson and Stolterman [23], we analyzed the transcripts to describe the volume and complex layering of design judgments that are used by data visualization practitioners as they describe and interrogate their work. We identify aspects of data visualization practice that require further investigation beyond notions of rational, model- or principle-directed decision-making processes.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331322","Human-centered computing;Visualization","Conferences;Computational modeling;Decision making;Data visualization;Data models;Interviews","data visualisation;decision making","design judgment;data visualization practice;design practice;data visualization design;formal knowledge;logical decision-making processes;design activity;principle-directed decision-making processes;rational-directed decision-making processes;model-directed decision-making processes;philosophical framework","","3","","33","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Efficient and Flexible Hierarchical Data Layouts for a Unified Encoding of Scalar Field Precision and Resolution","D. Hoang; B. Summa; H. Bhatia; P. Lindstrom; P. Klacansky; W. Usher; P. -T. Bremer; V. Pascucci","SCI Institute, University of Utah; Tulane Universiy; Lawrence Livermore National LaboratoryCenter for Applied Scientific Computing; Lawrence Livermore National LaboratoryCenter for Applied Scientific Computing; SCI Institute, University of Utah; SCI Institute, University of Utah; Lawrence Livermore National LaboratoryCenter for Applied Scientific Computing; SCI Institute, University of Utah","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","603","613","To address the problem of ever-growing scientific data sizes making data movement a major hindrance to analysis, we introduce a novel encoding for scalar fields: a unified tree of resolution and precision, specifically constructed so that valid cuts correspond to sensible approximations of the original field in the precision-resolution space. Furthermore, we introduce a highly flexible encoding of such trees that forms a parameterized family of data hierarchies. We discuss how different parameter choices lead to different trade-offs in practice, and show how specific choices result in known data representation schemes such as zfp[52], idx[58], and jpeg2000 [76]. Finally, we provide system-level details and empirical evidence on how such hierarchies facilitate common approximate queries with minimal data movement and time, using real-world data sets ranging from a few gigabytes to nearly a terabyte in size. Experiments suggest that our new strategy of combining reductions in resolution and precision is competitive with state-of-the-art compression techniques with respect to data quality, while being significantly more flexible and orders of magnitude faster, and requiring significantly reduced resources.","1941-0506","","10.1109/TVCG.2020.3030381","U.S. Department of Energy; Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344); LLNL-LDRD Program(grant numbers:17-SI-004,20-SI-001); Department of Energy, National Nuclear Security Administration(grant numbers:DE-NA0002375); Exascale Computing Project(grant numbers:17-SC-20-SC); U.S. Department of Energy Office of Science; National Nuclear Security Administration; NSF DMS(grant numbers:1664848); NSF IIS(grant numbers:1657020); NSF OAC(grant numbers:1842042); NSF OAC(grant numbers:1941085); NSF CMMI(grant numbers:1629660); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222049","scalar field;large-scale data;data compression;multiresolution;wavelet transform;coarse approximation","Decoding;Spatial resolution;Layout;Wavelet transforms;Encoding;Data models","data analysis;data compression;data reduction;data structures;query processing;trees (mathematics)","data hierarchies;data representation;data quality;unified encoding;scalar field precision;unified tree;hierarchical data layouts;resolution reduction;compression techniques","","3","","83","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Evaluating Alignment Approaches in Superimposed Time-Series and Temporal Event-Sequence Visualizations","Y. Zhang; S. D. Bartolomeo; F. Sheng; H. Jimison; C. Dunne",Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Composite temporal event sequence visualizations have included sentinel event alignment techniques to cope with data volume and variety. Prior work has demonstrated the utility of using single-event alignment for understanding the precursor, co-occurring, and aftereffect events surrounding a sentinel event. However, the usefulness of single-event alignment has not been sufficiently evaluated in composite visualizations. Furthermore, recently proposed dual-event alignment techniques have not been empirically evaluated. In this work, we designed tasks around temporal event sequence and timing analysis and conducted a controlled experiment on Amazon Mechanical Turk to examine four sentinel event alignment approaches: no sentinel event alignment (NoAlign), single-event alignment (SingleAlign), dual-event alignment with left justification (DualLeft), and dual-event alignment with stretch justification (DualStretch). Differences between approaches were most pronounced with more rows of data. For understanding intermediate events between two sentinel events, dual-event alignment was the clear winner for correctness-71% vs. 18% for NoAlign and SingleAlign. For understanding the duration between two sentinel events, NoAlign was the clear winner: correctness-88% vs. 36% for DualStretch- completion time-55 seconds vs. 101 seconds for DualLeft-and error-1.5% vs. 8.4% for DualStretch. For understanding precursor and aftereffect events, there was no significant difference among approaches. A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/78fs5","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933584","Human-centered computing;Visualization;Empirical studies in visualization","Task analysis;Data visualization;Visualization;Blood;Timing;Diabetes","data visualisation;time series","timing analysis;intermediate events;aftereffect events;composite temporal event sequence visualizations;sentinel event alignment techniques;single-event alignment;dual-event alignment techniques;superimposed time-series;stretch justification;DualStretch;no sentinel event alignment;NoAlign;SingleAlign;Amazon Mechanical Turk;time 55.0 s;time 101.0 s","","3","","15","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Evidence for Area as the Primary Visual Cue in Pie Charts","R. Kosara",Tableau Research,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","101","105","The long-standing assumption of angle as the primary visual cue used to read pie charts has recently been called into question. We conducted a controlled, preregistered study using parallel-projected 3D pie charts. Angle, area, and arc length differ dramatically when projected and change over a large range of values. Modeling these changes and comparing them to study participants' estimates allows us to rank the different visual cues by model fit. Area emerges as the most likely cue used to read pie charts.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933547","","Analytical models;Three-dimensional displays;Two dimensional displays;Predictive models;Visualization;Bars;Computational modeling","charts;data visualisation;solid modelling","parallel-projected 3D pie charts;preregistered study;controlled study;primary visual cue","","3","","22","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Exemplar-based Layout Fine-tuning for Node-link Diagrams","J. Pan; W. Chen; X. Zhao; S. Zhou; W. Zeng; M. Zhu; J. Chen; S. Fu; Y. Wu","State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; State Key Lab of CAD&CG, Zhejiang University, China; Ohio State University, USA; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2021","2021","27","2","1655","1665","We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.","1941-0506","","10.1109/TVCG.2020.3030393","National Natural Science Foundation of China(grant numbers:61772456,61761136020); NSFC(grant numbers:61761136020); NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization(grant numbers:UI609217); Zhejiang Provincial Natural Science Foundation(grant numbers:LRI8F020001); National Science Foundation(grant numbers:NSF OAC-1945347,NSF DBI-1260795,NSF IIS-1302755,CNS-1531491,NIST MSE-70NANBI3HI81); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240072","Node-link diagram;graph layout;graph visualization;user interactions","Layout;Optimization;Merging;Topology;Two dimensional displays;Software algorithms;Measurement","graph theory;interactive systems","batching mode;user modifications;local substructure;node embedding techniques;on-the-fly substructure;intuitive adjustment;modification transfer;node-link diagrams;exemplar-based layout fine-tuning;layout fine-tuning technique;visual graph exploration;interactive system","","3","","69","IEEE","26 Oct 2020","","","IEEE","IEEE Journals"
"Fast and Scalable Position-Based Layout Synthesis","T. Weiss; A. Litteneker; N. Duncan; M. Nakada; C. Jiang; L. -F. Yu; D. Terzopoulos","University of California, Los Angeles, CA, USA; University of California, Los Angeles, CA, USA; WorkPatterns, Inc., San Francisco, CA; University of California, Los Angeles, CA, USA; University of Pennsylvania, Philadelphia, PA, USA; University of Massachusetts, Boston, MA, USA; University of California, Los Angeles, CA, USA","IEEE Transactions on Visualization and Computer Graphics","28 Oct 2019","2019","25","12","3231","3243","The arrangement of objects into a layout can be challenging for non-experts, as is affirmed by the existence of interior design professionals. Recent research into the automation of this task has yielded methods that can synthesize layouts of objects respecting aesthetic and functional constraints that are non-linear and competing. These methods usually adopt a stochastic optimization scheme, which samples from different layout configurations, a process that is slow and inefficient. We introduce an physics-motivated, continuous layout synthesis technique, which results in a significant gain in speed and is readily scalable. We demonstrate our method on a variety of examples and show that it achieves results similar to conventional layout synthesis based on Markov chain Monte Carlo (McMC) state-search, but is faster by at least an order of magnitude and can handle layouts of unprecedented size as well as tightly-packed layouts that can overwhelm McMC.","1941-0506","","10.1109/TVCG.2018.2866436","National Science Foundation(grant numbers:1565978); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8443151","Automatic layout synthesis;3D scene modeling;automatic content creation;position-based methods;constraints","Layout;Content management;Probabilistic logic;Three-dimensional displays;Computational modeling","integrated circuit layout;Markov processes;Monte Carlo methods;optimisation","interior design professionals;aesthetic constraints;functional constraints;nonlinear;stochastic optimization scheme;layout configurations;continuous layout synthesis technique;conventional layout synthesis;Markov chain Monte Carlo state-search;tightly-packed layouts","","3","","42","IEEE","21 Aug 2018","","","IEEE","IEEE Journals"
"FixationNet: Forecasting Eye Fixations in Task-Oriented Virtual Environments","Z. Hu; A. Bulling; S. Li; G. Wang","Peking University, China; University of Stuttgart, Germany; Peking University, China; Peking University, China","IEEE Transactions on Visualization and Computer Graphics","15 Apr 2021","2021","27","5","2681","2690","Human visual attention in immersive virtual reality (VR) is key for many important applications, such as content design, gaze-contingent rendering, or gaze-based interaction. However, prior works typically focused on free-viewing conditions that have limited relevance for practical applications. We first collect eye tracking data of 27 participants performing a visual search task in four immersive VR environments. Based on this dataset, we provide a comprehensive analysis of the collected data and reveal correlations between users' eye fixations and other factors, i.e. users' historical gaze positions, task-related objects, saliency information of the VR content, and users' head rotation velocities. Based on this analysis, we propose FixationNet - a novel learning-based model to forecast users' eye fixations in the near future in VR. We evaluate the performance of our model for free-viewing and task-oriented settings and show that it outperforms the state of the art by a large margin of 19.8% (from a mean error of 2.93° to 2.35°) in free-viewing and of 15.1% (from 2.05° to 1.74°) in task-oriented situations. As such, our work provides new insights into task-oriented attention in virtual environments and guides future work on this important topic in VR research.","1941-0506","","10.1109/TVCG.2021.3067779","National Key R&D Program of China(grant numbers:2017YFB0203002,2017YFB1002700); National Natural Science Foundation of China(grant numbers:61632003); European Research Council(grant numbers:801708); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382883","Fixation forecasting;task-oriented attention;visual search;convolutional neural network;deep learning;virtual reality","Visualization;Task analysis;Solid modeling;Predictive models;Virtual environments;Computational modeling;Two dimensional displays","gaze tracking;human computer interaction;learning (artificial intelligence);rendering (computer graphics);virtual reality","task-oriented situations;task-oriented settings;novel learning-based model;VR content;task-related objects;immersive VR environments;visual search task;eye tracking data;free-viewing conditions;gaze-based interaction;gaze-contingent rendering;content design;immersive virtual reality;human visual attention;task-oriented virtual environments;forecasting eye fixations;FixationNet;VR research;guides future work;task-oriented attention","Adolescent;Adult;Computer Graphics;Deep Learning;Female;Fixation, Ocular;Humans;Male;Models, Statistical;Neural Networks, Computer;Virtual Reality;Young Adult","3","","56","IEEE","22 Mar 2021","","","IEEE","IEEE Journals"
"GAN-based Multi-Style Photo Cartoonization","Y. Shu; R. Yi; M. Xia; Z. Ye; W. Zhao; Y. Chen; Y. -K. Lai; Y. -J. Liu","Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: shuyz19@mails.tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: yr16@mails.tsinghua.edu.cn); Mathmatical Science, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: xiamf16@mails.tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: yezp17@mails.tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: zhao-w19@mails.tsinghua.edu.cn); Tencent lab, Tencent, 508929 Shenzhen, Guangdong, China, (e-mail: cylily93@gmail.com); School of Computer Science and Informatics, Cardiff University, 2112 Cardiff, South Glamorgan, United Kingdom of Great Britain and Northern Ireland, (e-mail: laiy4@cardiff.ac.uk); Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, 100084 (e-mail: liuyongjin@tsinghua.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Cartoon is a common form of art in our daily life and automatic generation of cartoon images from photos is highly desirable. However, state-of-the-art single-style methods can only generate one style of cartoon images from photos and existing multi-style image style transfer methods still struggle to produce high-quality cartoon images due to their highly simplified and abstract nature. In this paper, we propose a novel multi-style generative adversarial network (GAN) architecture, called MS-CartoonGAN, which can transform photos into multiple cartoon styles. We develop a multi-domain architecture, where the generator consists of a shared encoder and multiple decoders for different cartoon styles, along with multiple discriminators for individual styles. By observing that cartoon images drawn by different artists have their unique styles while sharing some common characteristics, our shared network architecture exploits the common characteristics of cartoon styles, achieving better cartoonization and being more efficient than single-style cartoonization. We show that our multi-domain architecture can theoretically guarantee to output desired multiple cartoon styles. Through extensive experiments including a user study, we demonstrate the superiority of the proposed method, outperforming state-of-the-art single-style and multi-style image style transfer methods.","1941-0506","","10.1109/TVCG.2021.3067201","National Natural Science Foundation of China(grant numbers:61725204); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382902","Style transfer;cartoon styles;multi-style transfer;generative adversarial network","Training;Generative adversarial networks;Semantics;Image edge detection;Training data;Generators;Computer architecture","","","","3","","","IEEE","22 Mar 2021","","","IEEE","IEEE Early Access Articles"
"GUIRO: User-Guided Matrix Reordering","M. Behrisch; T. Schreck; H. Pfister","School of Engineering, Applied Sciences, Harvard University, United States; Graz University of Technology, Austria; School of Engineering, Applied Sciences, Harvard University, United States","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","184","194","Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices-similar to node-link diagrams-are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: “Which matrix reordering algorithm should I choose for my dataset at hand?” To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.","1941-0506","","10.1109/TVCG.2019.2934300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807245","Visual Analytics;matrix;black-box algorithms;seriation;ordering;sorting;steerable algorithm;interaction;2D projection","Visualization;Data visualization;Indexes;Topology;Measurement;Task analysis;Partitioning algorithms","data analysis;data visualisation;interactive systems;matrix algebra;topology","GUIRO;user-guided matrix reordering;matrix representations;visualization techniques;relational data;data topology;matrix reordering algorithm;visual analytics system;submatrix reordering;visual exploration;user-guided steering;visual matrix patterns;dataset topology;interaction techniques","","3","","85","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Hi-D Maps: An Interactive Visualization Technique for Multi-Dimensional Categorical Data","R. M. Reza; B. A. Watson",North Carolina State University; North Carolina State University,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","216","220","In this paper, we present Hi-D maps, a novel method for the visualization of multi-dimensional categorical data. Our work addresses the scarcity of techniques for visualizing a large number of data-dimensions in an effective and space-efficient manner. We have mapped the full data-space onto a 2D regular polygonal region. The polygon is cut hierarchically with lines parallel to a user-controlled, ordered sequence of sides, each representing a dimension. We have used multiple visual cues such as orientation, thickness, color, countable glyphs, and text to depict cross-dimensional information. We have added interactivity and hierarchical browsing to facilitate flexible exploration of the display: small areas can be scrutinized for details. Thus, our method is also easily extendable to visualize hierarchical information. Our glyph animations add an engaging aesthetic during interaction. Like many visualizations, Hi-D maps become less effective when a large number of dimensions stresses perceptual limits, but Hi-D maps may add clarity before those limits are reached.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933709","Human-centered computing;Visualization;Visualization techniques;Visualization design and evaluation methods","Data visualization;Visualization;Image color analysis;Mice;Two dimensional displays;Animation;Tools","data visualisation;interactive systems","multidimensional categorical data;Hi-D maps;data-dimensions;space-efficient manner;2D regular polygonal region;multiple visual cues;cross-dimensional information;interactive visualization technique;hierarchical browsing;glyph animations","","3","","24","","19 Dec 2019","","","IEEE","IEEE Conferences"
"High-Quality Textured 3D Shape Reconstruction with Cascaded Fully Convolutional Networks","Z. -N. Liu; Y. -P. Cao; Z. -F. Kuang; L. Kobbelt; S. -M. Hu","BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing, China; BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing, China; BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing, China; Visual Computing Institute, RWTH Aachen University, Aachen, Germany; BNRist, Department of Computer Science and Technology, Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","83","97","We present a learning-based approach to reconstructing high-resolution three-dimensional (3D) shapes with detailed geometry and high-fidelity textures. Albeit extensively studied, algorithms for 3D reconstruction from multi-view depth-and-color (RGB-D) scans are still prone to measurement noise and occlusions; limited scanning or capturing angles also often lead to incomplete reconstructions. Propelled by recent advances in 3D deep learning techniques, in this paper, we introduce a novel computation- and memory-efficient cascaded 3D convolutional network architecture, which learns to reconstruct implicit surface representations as well as the corresponding color information from noisy and imperfect RGB-D maps. The proposed 3D neural network performs reconstruction in a progressive and coarse-to-fine manner, achieving unprecedented output resolution and fidelity. Meanwhile, an algorithm for end-to-end training of the proposed cascaded structure is developed. We further introduce Human10, a newly created dataset containing both detailed and textured full-body reconstructions as well as corresponding raw RGB-D scans of 10 subjects. Qualitative and quantitative experimental results on both synthetic and real-world datasets demonstrate that the presented approach outperforms existing state-of-the-art work regarding visual quality and accuracy of reconstructed models.","1941-0506","","10.1109/TVCG.2019.2937300","Joint NSFC-DFG Research Program(grant numbers:61761136018); National Natural Science Foundation of China(grant numbers:61521002,61863031); China Postdoctoral Science Foundation(grant numbers:043260009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812900","High-fidelity reconstruction;texture reconstruction;3D vision;cascaded architecture","Three-dimensional displays;Shape;Image reconstruction;Geometry;Image color analysis;Solid modeling;Surface reconstruction","convolutional neural nets;geometry;image colour analysis;image denoising;image reconstruction;image representation;image texture;learning (artificial intelligence);solid modelling;stereo image processing","3D neural network;unprecedented output resolution;cascaded structure;full-body reconstructions;high-quality textured 3D shape reconstruction;cascaded fully convolutional networks;learning-based approach;high-resolution three-dimensional shapes;geometry;high-fidelity textures;3D deep learning techniques;memory-efficient cascaded 3D convolutional network architecture;color information;noisy RGB-D maps;RGB-D scans;multiview depth-and-color scans","","3","","97","IEEE","26 Aug 2019","","","IEEE","IEEE Journals"
"Integrating Prior Knowledge in Mixed-Initiative Social Network Clustering","A. Pister; P. Buono; J. -D. Fekete; C. Plaisant; P. Valdivia","Université Paris-Saclay, CNRS, Inria, LRI, France; University of Bari, Italy; Université Paris-Saclay, CNRS, Inria, LRI, France; Université Paris-Saclay, CNRS, Inria, LRI, France; Université Paris-Saclay, CNRS, Inria, LRI, France","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1775","1785","We propose a new approach-called PK-clustering-to help social scientists create meaningful clusters in social networks. Many clustering algorithms exist but most social scientists find them difficult to understand, and tools do not provide any guidance to choose algorithms, or to evaluate results taking into account the prior knowledge of the scientists. Our work introduces a new clustering approach and a visual analytics user interface that address this issue. It is based on a process that 1) captures the prior knowledge of the scientists as a set of incomplete clusters, 2) runs multiple clustering algorithms (similarly to clustering ensemble methods), 3) visualizes the results of all the algorithms ranked and summarized by how well each algorithm matches the prior knowledge, 4) evaluates the consensus between user-selected algorithms and 5) allows users to review details and iteratively update the acquired knowledge. We describe our approach using an initial functional prototype, then provide two examples of use and early feedback from social scientists. We believe our clustering approach offers a novel constructive method to iteratively build knowledge while avoiding being overly influenced by the results of often randomly selected black-box clustering algorithms.","1941-0506","","10.1109/TVCG.2020.3030347","DataIA Institute; European project IVAN; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237999","Social network analysis;network visualization;clustering;mixed-initiative;prior knowledge;user interface","Clustering algorithms;Social networking (online);Tools;Visualization;Heuristic algorithms;Clustering methods;Inference algorithms","data analysis;data visualisation;pattern clustering;social networking (online);user interfaces","approach-called PK-clustering-to;social scientists;meaningful clusters;social networks;clustering algorithms exist;clustering approach;visual analytics user interface;incomplete clusters;user-selected algorithms;acquired knowledge;black-box clustering algorithms;mixed-initiative social network clustering","","3","","58","IEEE","23 Oct 2020","","","IEEE","IEEE Journals"
"Interactive Structure-aware Blending of Diverse Edge Bundling Visualizations","Y. Wang; M. Xue; Y. Wang; X. Yan; B. Chen; C. -W. Fu; C. Hurter","Shandong University; Shandong University; Shandong University; Shandong University; Peking University; Chinese University of Hong Kong; ENAC, France","IEEE Transactions on Visualization and Computer Graphics","26 Nov 2019","2020","26","1","687","696","Many edge bundling techniques (i.e., data simplification as a support for data visualization and decision making) exist but they are not directly applicable to any kind of dataset and their parameters are often too abstract and difficult to set up. As a result, this hinders the user ability to create efficient aggregated visualizations. To address these issues, we investigated a novel way of handling visual aggregation with a task-driven and user-centered approach. Given a graph, our approach produces a decluttered view as follows: first, the user investigates different edge bundling results and specifies areas, where certain edge bundling techniques would provide user-desired results. Second, our system then computes a smooth and structural preserving transition between these specified areas. Lastly, the user can further fine-tune the global visualization with a direct manipulation technique to remove the local ambiguity and to apply different visual deformations. In this paper, we provide details for our design rationale and implementation. Also, we show how our algorithm gives more suitable results compared to current edge bundling techniques, and in the end, we provide concrete instances of usages, where the algorithm combines various edge bundling results to support diverse data exploration and visualizations.","1941-0506","","10.1109/TVCG.2019.2934805","NSFC(grant numbers:61772315,61861136012); NSFC-Guangdong Joint Fund(grant numbers:U1501255); Shenzhen Science and Technology Program(grant numbers:J-CYJ20170413162617606); Research Grants Council of the Hong Kong Special Administrative Region(grant numbers:CUHK 14203416); ANR(grant numbers:ANR-14-CE24-0006-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807234","path visualization;trajectory visualization;edge bundles","Layout;Data visualization;Visualization;Task analysis;Strain;Smoothing methods;Optimization","data analysis;data visualisation;decision making;graph theory","specified areas;edge bundling visualizations;visual aggregation;visual aggregation;efficient aggregated visualizations;user ability;decision making;data visualization;data simplification;interactive structure-aware blending;support diverse data exploration;current edge bundling techniques;direct manipulation technique;global visualization;structural preserving transition;smooth preserving transition;decluttered view;user-centered approach","","3","","55","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Interactive Visualization for Singular Fibers of Functions <italic>f</italic> : <italic>R</italic><sup>3</sup> → <italic>R</italic><sup>2</sup>","D. Sakurai; O. Saeki; H. Carr; H. -Y. Wu; T. Yamamoto; D. Duke; S. Takahashi","University of Tokyo, Kashiwa, Japan; Kyushu University, Fukuoka, Japan; University of Leeds, Leeds, UK; Keio University, Yokohama, Japan; Kyushu Sangyo University, Fukuoka, Japan; University of Leeds, Leeds, UK; University of Aizu, Aizu-Wakamatsu, Japan","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","945","954","Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R<sup>3</sup>→R<sup>2</sup>. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians.","1941-0506","","10.1109/TVCG.2015.2467433","EPSRC; MEXT KAKENHI; JSPS KAKENHI(grant numbers:EP/1013072/1,25120014,23244008,23654028,25540041,26730061,15K13438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192700","Singular fibers;fiber topology;mathematical visualization;design study;Singular fibers;fiber topology;mathematical visualization;design study","Topology;Isosurfaces;Shape;Visualization;Manuals;Polynomials","data analysis;data visualisation","interactive visualization;singular fibers visualization;scalar topology;Morse theory;data analysis;data visualization;Reeb graph;isocontours;fiber topology;Reeb spaces;joint contour net","Algorithms;Computer Graphics;Humans;Image Processing, Computer-Assisted;Research Design;Surface Properties;User-Computer Interface","3","","36","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Interpreting Distortions in Dimensionality Reduction by Superimposing Neighbourhood Graphs","B. Colange; L. Vuillon; S. Lespinats; D. Dutykh","Univ. Grenoble Alpes,INES,Le Bourget du Lac,France,F-73375; Univ. Grenoble Alpes, Univ. Savoie Mont Blanc,CNRS,Chambéry,France,73000; Univ. Grenoble Alpes,INES,Le Bourget du Lac,France,F-73375; Univ. Grenoble Alpes, Univ. Savoie Mont Blanc,CNRS,Chambéry,France,73000","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","211","215","To perform visual data exploration, many dimensionality reduction methods have been developed. These tools allow data analysts to represent multidimensional data in a 2D or 3D space, while preserving as much relevant information as possible. Yet, they cannot preserve all structures simultaneously and they induce some unavoidable distortions. Hence, many criteria have been introduced to evaluate a map's overall quality, mostly based on the preservation of neighbourhoods. Such global indicators are currently used to compare several maps, which helps to choose the most appropriate mapping method and its hyperparameters. However, those aggregated indicators tend to hide the local repartition of distortions. Thereby, they need to be supplemented by local evaluation to ensure correct interpretation of maps.In this paper, we describe a new method, called MING, for ""Map Interpretation using Neighbourhood Graphs"". It offers a graphical interpretation of pairs of map quality indicators, as well as local evaluation of the distortions. This is done by displaying on the map the nearest neighbours graphs computed in the data space and in the embedding. Shared and unshared edges exhibit reliable and unreliable neighbourhood information conveyed by the mapping. By this mean, analysts may determine whether proximity (or remoteness) of points on the map faithfully represents similarity (or dissimilarity) of original data, within the meaning of a chosen map quality criteria. We apply this approach to two pairs of widespread indicators: precision/recall and trustworthiness/continuity, chosen for their wide use in the community, which will allow an easy handling by users.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933568","Evaluation—Qualitative Evaluation;Non-Spatial Data and Techniques—Dimensionality Reduction;Visual Analysis and Knowledge Discovery—Visual Knowledge Discovery","Distortion;Reliability;Image color analysis;Data visualization;Visualization;Dimensionality reduction;Three-dimensional displays","data analysis;data visualisation;graph theory","local evaluation;correct interpretation;map interpretation;graphical interpretation;map quality indicators;data space;unreliable neighbourhood information;widespread indicators;visual data exploration;dimensionality reduction methods;data analysts;multidimensional data;unavoidable distortions;global indicators;mapping method;aggregated indicators;local repartition;neighbourhood graphs;MING;map quality criteria","","3","","22","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities","J. Koven; C. Felix; H. Siadati; M. Jakobsson; E. Bertini",NYU Tandon School of Engineering; NYU Tandon School of Engineering; NYU Tandon School of Engineering; Amber Solutions Inc.; NYU Tandon School of Engineering,"IEEE Transactions on Visualization and Computer Graphics","27 Nov 2018","2019","25","1","225","234","The forensic investigation of communication datasets which contain unstructured text, social network information, and metadata is a complex task that is becoming more important due to the immense amount of data being collected. Currently there are limited approaches that allow an investigator to explore the network, text and metadata in a unified manner. We developed Beagle as a forensic tool for email datasets that allows investigators to flexibly form complex queries in order to discover important information in email data. Beagle was successfully deployed at a security firm which had a large email dataset that was difficult to properly investigate. We discuss our experience developing Beagle as well as the lessons we learned applying visual analytic techniques to a difficult real-world problem.","1941-0506","","10.1109/TVCG.2018.2865023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440841","Visual Analytics;Email Investigation;Email Forensics","Electronic mail;Visual analytics;Forensics;Data security;Metadata;Data visualization;Query processing","data analysis;data visualisation;learning (artificial intelligence);meta data;query processing;security of data;social networking (online)","email dataset;visual analytics solution;investigative analysis;scamming activities;forensic investigation;communication datasets;unstructured text;social network information;metadata;forensic tool;complex queries;email data;security firm","","3","","26","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"MeetCues: Supporting Online Meetings Experience","B. Adriel Aseniero; M. Constantinides; S. Joglekar; K. Zhou; D. Quercia","University of Calgary,Alberta,Canada; Nokia Bell Labs,Cambridge; Nokia Bell Labs,Cambridge; Nokia Bell Labs,Cambridge; Nokia Bell Labs,Cambridge","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","236","240","The remote work ecosystem is transforming patterns of communication between teams and individuals located at distance. Particularly, the absence of certain subtle cues in current communication tools may hinder an online's meeting outcome by negatively impacting attendees' overall experience and, often, make them feeling disconnected. The problem here might be due to the fact that current tools fall short in capturing it. To partly address this, we developed an online platform-MeetCues- with the aim of supporting online communication during meetings. MeetCues is a companion platform for a commercial communication tool with interactive and visual UI features that support back-channels of communications. It allows attendees to be more engaged during a meeting, and reflect in real-time or post-meeting. We evaluated our platform in a diverse set of five, real-world corporate meetings, and we found that, not only people were more engaged and aware during their meetings, but they also felt more connected. These findings suggest promise in the design of new communications tools, and reinforce the role of InfoVis in augmenting and enriching online meetings.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331310","Visualization for Meetings;Engagement;Awareness;Reflection","Visualization;Conferences;Ecosystems;Tools;Real-time systems","business communication;data visualisation;interactive systems;Internet;teleconferencing;user experience;user interfaces","online meetings experience;remote work ecosystem;online platform;online communication;companion platform;interactive UI features;visual UI features;corporate meetings;communications tools;MeetCues;InfoVis","","3","","46","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Mixed Labeling: Integrating Internal and External Labels","L. &#x010C;mol&#x00ED;k; V. Pavlovec; H. -Y. Wu; M. N&#x00F6;llenburg","Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czechia; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czechia; Institute of Visual Computing and Human-Centered Technology, TU Wien, Vienna, Austria; Institute of Logic and Computation, TU Wien, Vienna, Austria","IEEE Transactions on Visualization and Computer Graphics","25 Feb 2022","2022","28","4","1848","1861","In this article, we present an algorithm capable of mixed labeling of 2D and 3D objects. In mixed labeling, the given objects are labeled with both internal labels placed (at least partially) over the objects and external labels placed in the space around the objects and connected with the labeled objects with straight-line leaders. The proposed algorithm determines the position and type of each label based on the user-specified ambiguity threshold and eliminates overlaps between the labels, as well as between the internal labels and the straight-line leaders of external labels. The algorithm is a screen-space technique; it operates in an image where the 2D objects or projected 3D objects are encoded. In other words, we can use the algorithm whenever we can render the objects to an image, which makes the algorithm fit for use in many domains. The algorithm operates in real-time, giving the results immediately. Finally, we present results from an expert evaluation, in which a professional illustrator has evaluated the label layouts produced with the proposed algorithm.","1941-0506","","10.1109/TVCG.2020.3027368","MEYS of Czechia OP VVV(grant numbers:CZ.02.1.01/0.0/0.0/16_019/0000765); Research Center for Informatics, Czech Technical University in Prague(grant numbers:SGS19/179/OHK3/3T/13); EU Horizon 2020 MSCA(grant numbers:747985); Austrian Science Fund(grant numbers:P 31119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207965","Labeling;mixed labeling;internal labeling;external labeling;expert evaluation","Labeling;Layout;Three-dimensional displays;Shape;Solid modeling;Two dimensional displays","computational geometry;data visualisation;image segmentation;rendering (computer graphics);solid modelling","mixed labeling;external labels;algorithm capable;given objects;internal labels;labeled objects;straight-line leaders;label layouts","","3","","44","IEEE","28 Sep 2020","","","IEEE","IEEE Journals"
"Motion Browser: Visualizing and Understanding Complex Upper Limb Movement Under Obstetrical Brachial Plexus Injuries","G. Y. -Y. Chan; L. G. Nonato; A. Chu; P. Raghavan; V. Aluru; C. T. Silva",New York University; University of São Paulo; Rutgers New Jersey Medical School; NYU Langone Medical Center; NYU Langone Medical Center; New York University,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","981","990","The brachial plexus is a complex network of peripheral nerves that enables sensing from and control of the movements of the arms and hand. Nowadays, the coordination between the muscles to generate simple movements is still not well understood, hindering the knowledge of how to best treat patients with this type of peripheral nerve injury. To acquire enough information for medical data analysis, physicians conduct motion analysis assessments with patients to produce a rich dataset of electromyographic signals from multiple muscles recorded with joint movements during real-world tasks. However, tools for the analysis and visualization of the data in a succinct and interpretable manner are currently not available. Without the ability to integrate, compare, and compute multiple data sources in one platform, physicians can only compute simple statistical values to describe patient's behavior vaguely, which limits the possibility to answer clinical questions and generate hypotheses for research. To address this challenge, we have developed MOTION BROWSER, an interactive visual analytics system which provides an efficient framework to extract and compare muscle activity patterns from the patient's limbs and coordinated views to help users analyze muscle signals, motion data, and video information to address different tasks. The system was developed as a result of a collaborative endeavor between computer scientists and orthopedic surgery and rehabilitation physicians. We present case studies showing physicians can utilize the information displayed to understand how individuals coordinate their muscles to initiate appropriate treatment and generate new hypotheses for future research.","1941-0506","","10.1109/TVCG.2019.2934280","National Aeronautics and Space Administration; NSF(grant numbers:CNS-1229185,CCF-1533564,CNS-1544753,CNS-1626098,CNS-1730396,CNS-1828576,302643/2013-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809920","Medical Data Visualization;Visual Analytics Application;Time Series Data;Multimodal Data;Brachial Plexus Injuries","Muscles;Data visualization;Brachytherapy;Time series analysis;Task analysis;Visual analytics","biomechanics;data analysis;data visualisation;diseases;electromyography;injuries;medical information systems;medical signal processing;muscle;neurophysiology;orthopaedics;patient rehabilitation;surgery","muscle activity patterns;coordinated views;muscle signals;motion data;video information;computer scientists;interactive visual analytics system;MOTION BROWSER;clinical questions;simple statistical values;multiple data sources;interpretable manner;succinct manner;visualization;real-world tasks;joint movements;multiple muscles;electromyographic signals;rich dataset;motion analysis assessments;medical data analysis;peripheral nerve injury;simple movements;peripheral nerves;complex network;obstetrical brachial plexus injuries;complex upper limb movement;motion browser;rehabilitation physicians;orthopedic surgery","","3","","48","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"Net2Vis – A Visual Grammar for Automatically Generating Publication-Tailored CNN Architecture Visualizations","A. Bäuerle; C. van Onzenoodt; T. Ropinski","Visual Computing Group at Ulm University, Ulm, Germany; Visual Computing Group at Ulm University, Ulm, Germany; Visual Computing Group at Ulm University, Ulm, Germany","IEEE Transactions on Visualization and Computer Graphics","12 May 2021","2021","27","6","2980","2991","To convey neural network architectures in publications, appropriate visualizations are of great importance. While most current deep learning papers contain such visualizations, these are usually handcrafted just before publication, which results in a lack of a common visual grammar, significant time investment, errors, and ambiguities. Current automatic network visualization tools focus on debugging the network itself and are not ideal for generating publication visualizations. Therefore, we present an approach to automate this process by translating network architectures specified in Keras into visualizations that can directly be embedded into any publication. To do so, we propose a visual grammar for convolutional neural networks (CNNs), which has been derived from an analysis of such figures extracted from all ICCV and CVPR papers published between 2013 and 2019. The proposed grammar incorporates visual encoding, network layout, layer aggregation, and legend generation. We have further realized our approach in an online system available to the community, which we have evaluated through expert feedback, and a quantitative study. It not only reduces the time needed to generate network visualizations for publications, but also enables a unified and unambiguous visualization design.","1941-0506","","10.1109/TVCG.2021.3057483","Carl-Zeiss Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350177","Neural networks;architecture visualization;graph layouting","Data visualization;Visualization;Network architecture;Computer architecture;Grammar;Layout;Encoding","convolutional neural nets;data visualisation;deep learning (artificial intelligence);grammars;neural net architecture","automatic network visualization tools;Net2Vis;unambiguous visualization design;unified visualization design;legend generation;network layout;visual encoding;convolutional neural networks;publication visualizations;visual grammar;deep learning;neural network architectures;automatically generating publication-tailored CNN architecture visualizations","","3","","65","IEEE","8 Feb 2021","","","IEEE","IEEE Journals"
"Optimal sampling for hemicubes","N. Max","California Univ., Davis, CA, USA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1995","1","1","60","76","The hemicube estimates of form factors are based on a finite set of sample directions. We obtain several optimal arrangements of sample directions, which minimize the variance of these estimates. They are based on changing the size or shape of the pixels or the shape of the hemicube, or using non-uniform pixel grids. The best reduces the variance by 43%. The variance calculation is based on the assumption that the errors in the estimate are caused by the projections of single polygon edges, and that the positions and orientations of these edges are random. This replaces the infinite dimensional space of possible environments by the two dimensional space of great circles on the unit sphere, making the numerical variance minimization possible.<<ETX>></ETX>","1941-0506","","10.1109/2945.468388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468388","","Sampling methods;Layout;Hardware;Shape;Ray tracing;Lighting;Technological innovation;Testing;Geometry;Costs","computer graphics;brightness;random processes;statistical analysis;error analysis;computational geometry;optimisation;optimal systems;ray tracing","hemicube estimates;form factors;finite sample direction set;optimal arrangements;optimal sampling;optimal sample direction arrangements;pixel shape changing;pixel size changing;hemicube shape changing;nonuniform pixel grids;variance calculation;estimate error;single polygon edges projections;random edge orientations;random edge positions;possible environments;two dimensional space;great circles;unit sphere;numerical variance minimization","","3","","22","","6 Aug 2002","","","IEEE","IEEE Journals"
"PRS-Net: Planar Reflective Symmetry Detection Net for 3D Models","L. Gao; L. -X. Zhang; H. -Y. Meng; Y. -H. Ren; Y. -K. Lai; L. Kobbelt","Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Maryland, College Park, MD, USA; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Computer Science and Informatics, Cardiff University, Wales, United Kingdom; Institute for Computer Graphics and Multimedia, RWTH Aachen University, Aachen, Germany","IEEE Transactions on Visualization and Computer Graphics","12 May 2021","2021","27","6","3007","3018","In geometry processing, symmetry is a universal type of high-level structural information of 3D models and benefits many geometry processing tasks including shape segmentation, alignment, matching, and completion. Thus it is an important problem to analyze various symmetry forms of 3D shapes. Planar reflective symmetry is the most fundamental one. Traditional methods based on spatial sampling can be time-consuming and may not be able to identify all the symmetry planes. In this article, we present a novel learning framework to automatically discover global planar reflective symmetry of a 3D shape. Our framework trains an unsupervised 3D convolutional neural network to extract global model features and then outputs possible global symmetry parameters, where input shapes are represented using voxels. We introduce a dedicated symmetry distance loss along with a regularization loss to avoid generating duplicated symmetry planes. Our network can also identify generalized cylinders by predicting their rotation axes. We further provide a method to remove invalid and duplicated planes and axes. We demonstrate that our method is able to produce reliable and accurate results. Our neural network based method is hundreds of times faster than the state-of-the-art methods, which are based on sampling. Our method is also robust even with noisy or incomplete input surfaces.","1941-0506","","10.1109/TVCG.2020.3003823","National Natural Science Foundation of China(grant numbers:61872440,61828204); Beijing Municipal Natural Science Foundation(grant numbers:L182016); Royal Society Newton Advanced Fellowship(grant numbers:NAF/R2/192151); Youth Innovation Promotion Association of the Chinese Academy of Sciences; CCF-Tencent Open Fund; Tencent AI Lab Rhino-Bird Focused Research Program(grant numbers:JR202024); National Laboratory of Pattern Recognition(grant numbers:201900055); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9127500","Unsupervised learning;convolutional neural network;symmetry detection;3D models;planar reflective symmetry","Three-dimensional displays;Shape;Geometry;Two dimensional displays;Feature extraction;Solid modeling;Computational modeling","computational geometry;computer vision;feature extraction;image segmentation;learning (artificial intelligence);neural nets;object recognition","PRS-net;planar reflective symmetry detection net;geometry processing;universal type;high-level structural information;symmetry forms;spatial sampling;novel learning framework;global planar reflective symmetry;unsupervised 3D convolutional neural network;global model features;possible global symmetry parameters;input shapes;dedicated symmetry distance loss;duplicated symmetry planes;duplicated planes;neural network based method","","3","","61","IEEE","29 Jun 2020","","","IEEE","IEEE Journals"
"Perceptual Real-Time 2D-to-3D Conversion Using Cue Fusion","T. Leimkühler; P. Kellnhofer; T. Ritschel; K. Myszkowski; H. Seidel","MPI Informatik, Saarbrucken, Saarland, Germany; MIT CSAIL, Cambridge, MA; University College London, Bloomsbury, London, United Kingdom; MPI Informatik, Saarbrucken, Saarland, Germany; MPI Informatik, Saarbrucken, Saarland, Germany","IEEE Transactions on Visualization and Computer Graphics","30 Apr 2018","2018","24","6","2037","2050","We propose a system to infer binocular disparity from a monocular video stream in real-time. Different from classic reconstruction of physical depth in computer vision, we compute perceptually plausible disparity, that is numerically inaccurate, but results in a very similar overall depth impression with plausible overall layout, sharp edges, fine details and agreement between luminance and disparity. We use several simple monocular cues to estimate disparity maps and confidence maps of low spatial and temporal resolution in real-time. These are complemented by spatially-varying, appearance-dependent and class-specific disparity prior maps, learned from example stereo images. Scene classification selects this prior at runtime. Fusion of prior and cues is done by means of robust MAP inference on a dense spatio-temporal conditional random field with high spatial and temporal resolution. Using normal distributions allows this in constant-time, parallel per-pixel work. We compare our approach to previous 2D-to-3D conversion systems in terms of different metrics, as well as a user study and validate our notion of perceptually plausible disparity.","1941-0506","","10.1109/TVCG.2017.2703612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7926422","Depth cues;stereo;image-based rendering;perceptual reasoning;video analysis;viewing algorithms;pixel classification;real-time systems","Real-time systems;Streaming media;Image edge detection;Three-dimensional displays;Image reconstruction;Spatial resolution;Runtime","computer vision;image classification;image fusion;image reconstruction;image resolution;normal distribution;stereo image processing;video streaming","cue fusion;binocular disparity;monocular video stream;computer vision;perceptually plausible disparity;simple monocular cues;confidence maps;temporal resolution;class-specific disparity prior maps;robust MAP inference;dense spatio-temporal conditional random field;spatial resolution;Perceptual Real-Time 2D-to-3D Conversion;classic physical depth reconstruction;spatially-varying disparity prior maps;appearance-dependent disparity prior maps;stereo images;scene classification;normal distributions","","3","","53","IEEE","11 May 2017","","","IEEE","IEEE Journals"
"Placement Retargeting of Virtual Avatars to Dissimilar Indoor Environments","L. Yoon; D. Yang; J. Kim; C. Chung; S. -H. Lee","Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2022","2022","28","3","1619","1633","Rapidly developing technologies are realizing a 3D telepresence, in which geographically separated users can interact with each other through their virtual avatars. In this article, we present novel methods to determine the avatar’s position in an indoor space to preserve the semantics of the user’s position in a dissimilar indoor space with different space configurations and furniture layouts. To this end, we first perform a user survey on the preferred avatar placements for various indoor configurations and user placements, and identify a set of related attributes, including interpersonal relation, visual attention, pose, and spatial characteristics, and quantify these attributes with a set of features. By using the obtained dataset and identified features, we train a neural network that predicts the similarity between two placements. Next, we develop an avatar placement method that preserves the semantics of the placement of the remote user in a different space as much as possible. We show the effectiveness of our methods by implementing a prototype AR-based telepresence system and user evaluations.","1941-0506","","10.1109/TVCG.2020.3018458","Samsung(grant numbers:SRFC-IT1701-14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173828","Telepresence;avatar;augmented reality;similarity learning","Avatars;Telepresence;Semantics;Three-dimensional displays;Layout;Prototypes;Indoor environment","avatars;furniture;radiowave propagation;virtual reality","related attributes;interpersonal relation;avatar placement method;semantics;remote user;user evaluations;placement retargeting;virtual avatars;dissimilar indoor environments;geographically separated users;dissimilar indoor space;different space configurations;furniture layouts;user survey;preferred avatar placements;indoor configurations;user placements","","3","","46","IEEE","21 Aug 2020","","","IEEE","IEEE Journals"
"Reconstructing Reflection Maps Using a Stacked-CNN for Mixed Reality Rendering","A. Chalmers; J. Zhao; D. Medeiros; T. Rhee","Computational Media Innovation Centre (CMIC), Victoria University of Wellington, Wellington, New Zealand; Computational Media Innovation Centre (CMIC), Victoria University of Wellington, Wellington, New Zealand; Computational Media Innovation Centre (CMIC), Victoria University of Wellington, Wellington, New Zealand; Computational Media Innovation Centre (CMIC), Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2021","2021","27","10","4073","4084","Corresponding lighting and reflectance between real and virtual objects is important for spatial presence in augmented and mixed reality (AR and MR) applications. We present a method to reconstruct real-world environmental lighting, encoded as a reflection map (RM), from a conventional photograph. To achieve this, we propose a stacked convolutional neural network (SCNN) that predicts high dynamic range (HDR) 360° RMs with varying roughness from a limited field of view, low dynamic range photograph. The SCNN is progressively trained from high to low roughness to predict RMs at varying roughness levels, where each roughness level corresponds to a virtual object's roughness (from diffuse to glossy) for rendering. The predicted RM provides high-fidelity rendering of virtual objects to match with the background photograph. We illustrate the use of our method with indoor and outdoor scenes trained on separate indoor/outdoor SCNNs showing plausible rendering and composition of virtual objects in AR/MR. We show that our method has improved quality over previous methods with a comparative user study and error metrics.","1941-0506","","10.1109/TVCG.2020.3001917","Smart Ideas Endeavour Fund; Entrepreneurial University Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115833","Light estimation;reflection map;environment map;image-based lighting;deep learning;mixed reality","Lighting;Rendering (computer graphics);Environmental management;Dynamic range;Real-time systems;Convolutional neural networks","augmented reality;convolutional neural nets;image reconstruction;learning (artificial intelligence);lighting;rendering (computer graphics)","stacked-CNN;mixed reality rendering;reflectance;virtual objects;spatial presence;augmented reality;environmental lighting;stacked convolutional neural network;SCNN;low dynamic range photograph;varying roughness levels;predicted RM;high-fidelity rendering;background photograph;plausible rendering;reflection map reconstruction;high dynamic range","","3","","43","IEEE","12 Jun 2020","","","IEEE","IEEE Journals"
"SAX Navigator: Time Series Exploration through Hierarchical Clustering","N. Ruta; N. Sawada; K. McKeough; M. Behrisch; J. Beyer",Harvard University; Harvard University; Harvard University; Harvard University; Harvard University,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","236","240","Comparing many long time series is challenging to do by hand. Clustering time series enables data analysts to discover relevance between and anomalies among multiple time series. However, even after reasonable clustering, analysts have to scrutinize correlations between clusters or similarities within a cluster. We developed SAX Navigator, an interactive visualization tool, that allows users to hierarchically explore global patterns as well as individual observations across large collections of time series data. Our visualization provides a unique way to navigate time series that involves a ""vocabulary of patterns"" developed by using a dimensionality reduction technique, Symbolic Aggregate approXimation (SAX). With SAX, the time series data clusters efficiently and is quicker to query at scale. We demonstrate the ability of SAX Navigator to analyze patterns in large time series data based on three case studies for an astronomy data set. We verify the usability of our system through a think-aloud study with an astronomy domain scientist.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933618","Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods","Time series analysis;Navigation;Heating systems;Visualization;Tools;Shape;Data visualization","astronomy computing;data analysis;data visualisation;interactive systems;mathematics computing;pattern clustering;time series","data analysts;multiple time series;reasonable clustering;SAX navigator;time series data clusters;time series exploration;hierarchical clustering;long time series;clustering time series;symbolic aggregate approximation;interactive visualization tool","","3","","18","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Sample-Based Cameras for Feed Forward Reflection Rendering","V. Popescu; E. Sacks; Chunhui Mei","Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN","IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1590","1600","This paper presents sample-based cameras for rendering high quality reflections on convex reflectors at interactive rates. The method supports change of view, moving objects and reflectors, higher order reflections, view-dependent lighting of reflected objects, and reflector surface properties. In order to render reflections with the feed forward graphics pipeline, one has to project reflected vertices. A sample-based camera is a collection of BSP trees of pinhole cameras that jointly approximate the projection function. It is constructed from the reflected rays defined by the desired view and the scene reflectors. A scene point is projected by invoking only the cameras that contain it in their frustums. Reflections are rendered by projecting the scene geometry and then rasterizing in hardware.","1941-0506","","10.1109/TVCG.2006.103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703378","Reflections;interactive rendering;image-based rendering;sample-based graphics.","Cameras;Feeds;Optical reflection;Rendering (computer graphics);Layout;Graphics;Pipelines;Tree graphs;Geometry;Hardware","computer graphic equipment;data visualisation;image texture;reflection;rendering (computer graphics);trees (mathematics)","Reflections;interactive rendering;image-based rendering;sample-based graphics.","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Photography;Photography;Photometry;Photometry;Reproducibility of Results;Sensitivity and Specificity","3","","36","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"Semantic Discriminability for Visual Communication","K. B. Schloss; Z. Leggon; L. Lessard","Psychology and Wisconsin Institute for Discovery, University of Wisconsin-Madison; Zachary Leggon Biology and Wisconsin Institute for Discovery, University of Wisconsin-Madison; Mechanical and Industrial Engineering, Northeastern University","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1022","1031","To interpret information visualizations, observers must determine how visual features map onto concepts. First and foremost, this ability depends on perceptual discriminability; observers must be able to see the difference between different colors for those colors to communicate different meanings. However, the ability to interpret visualizations also depends on semantic discriminability, the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without help from verbal cues such as legends or labels). Previous evidence suggested that observers were better at interpreting encoding systems that maximized semantic discriminability (maximizing association strength between assigned colors and concepts while minimizing association strength between unassigned colors and concepts), compared to a system that only maximized color-concept association strength. However, increasing semantic discriminability also resulted in increased perceptual distance, so it is unclear which factor was responsible for improved performance. In the present study, we conducted two experiments that tested for independent effects of semantic distance and perceptual distance on semantic discriminability of bar graph data visualizations. Perceptual distance was large enough to ensure colors were more than just noticeably different. We found that increasing semantic distance improved performance, independent of variation in perceptual distance, and when these two factors were uncorrelated, responses were dominated by semantic distance. These results have implications for navigating trade-offs in color palette design optimization for visual communication.","1941-0506","","10.1109/TVCG.2020.3030434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9239918","Visual Reasoning;Information Visualization;Visual Communication;Visual Encoding;Color Perception;Color Cognition","Semantics;Color;Visualization;Observers;Image color analysis;Data visualization;Encoding","data visualisation;encoding;graph theory","perceptual discriminability;semantic discriminability;visual features;encoding systems;association strength;perceptual distance;bar graph data visualizations;visual communication;information visualizations;semantic distance","","3","","41","IEEE","26 Oct 2020","","","IEEE","IEEE Journals"
"S<sc>equence</sc> B<sc>raiding:</sc> Visual Overviews of Temporal Event Sequences and Attributes","S. D. Bartolomeo; Y. Zhang; F. Sheng; C. Dunne",Northeastern University; Northeastern University; Northeastern University; Northeastern University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1353","1363","Temporal event sequence alignment has been used in many domains to visualize nuanced changes and interactions overtime. Existing approaches align one or two sentinel events. Overview tasks require examining all alignments of interest using interaction and time or juxtaposition of many visualizations. Furthermore, any event attribute overviews are not closely tied to sequence visualizations. We present SEQUENCE BRAIDING, a novel overview visualization for temporal event sequences and attributes using a layered directed acyclic network. SEQUENCE BRAIDING visually aligns many temporal events and attribute groups simultaneously and supports arbitrary ordering, absence, and duplication of events. In a controlled experiment we compare SEQUENCE BRAIDING and IDMVis on user task completion time, correctness, error, and confidence. Our results provide good evidence that users of SEQUENCE BRAIDING can understand high-level patterns and trends faster and with similar error. A full version of this paper with all appendices; the evaluation stimuli, data, and analysis code; and source code are available at osf.io/mq2wt.","1941-0506","","10.1109/TVCG.2020.3030442","National Science Foundation for support under CRII(grant numbers:1755901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231271","Temporal event sequence visualization;network visualization;algorithm;evaluation","Diabetes;Glucose;Data visualization;Blood;Task analysis;Insulin;Visualization","data visualisation","sequence visualizations;overview visualization;sequence braiding;visual overviews;temporal event sequence alignment;temporal event attributes","","3","","66","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"SpicyNodes: Radial Layout Authoring for the General Public","M. Douma; G. Ligierko; O. Ancuta; P. Gritsai; S. Liu",IDEA; IDEA; IDEA; IDEA; IDEA,"IEEE Transactions on Visualization and Computer Graphics","23 Oct 2009","2009","15","6","1089","1096","Trees and graphs are relevant to many online tasks such as visualizing social networks, product catalogs, educational portals, digital libraries, the semantic web, concept maps and personalized information management. SpicyNodes is an information-visualization technology that builds upon existing research on radial tree layouts and graph structures. Users can browse a tree, clicking from node to node, as well as successively viewing a node, immediately related nodes and the path back to the ldquohomerdquo nodes. SpicyNodes' layout algorithms maintain balanced layouts using a hybrid mixture of a geometric layout (a succession of spanning radial trees) and force-directed layouts to minimize overlapping nodes, plus several other improvements over prior art. It provides XML-based API and GUI authoring tools. The goal of the SpicyNodes project is to implement familiar principles of radial maps and focus+context with an attractive and inviting look and feel in an open system that is accessible to virtually any Internet user.","1941-0506","","10.1109/TVCG.2009.183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290716","Trees and network visualization;radial tree layout;information visualization;interaction;focus+context;hierarchy visualization;human-computer interaction","Tree graphs;Visualization;Social network services;Catalogs;Portals;Software libraries;Semantic Web;Information management;Art;Graphical user interfaces","authoring systems;data visualisation;trees (mathematics)","SpicyNodes;radial layout authoring;information-visualization technology;radial tree layouts;graph structures;geometric layout;force-directed layouts;XML-based API;GUI authoring tools","","3","1","39","","23 Oct 2009","","","IEEE","IEEE Journals"
"Staged Animation Strategies for Online Dynamic Networks","T. Crnovrsanin; Shilpika; S. Chandrasegaran; K. -L. Ma","University of California, Davis; University of California, Davis; University of California, Davis; University of California, Davis","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","539","549","Dynamic networks-networks that change over time-can be categorized into two types: offline dynamic networks, where all states of the network are known, and online dynamic networks, where only the past states of the network are known. Research on staging animated transitions in dynamic networks has focused more on offline data, where rendering strategies can take into account past and future states of the network. Rendering online dynamic networks is a more challenging problem since it requires a balance between timeliness for monitoring tasks-so that the animations do not lag too far behind the events-and clarity for comprehension tasks-to minimize simultaneous changes that may be difficult to follow. To illustrate the challenges placed by these requirements, we explore three strategies to stage animations for online dynamic networks: time-based, event-based, and a new hybrid approach that we introduce by combining the advantages of the first two. We illustrate the advantages and disadvantages of each strategy in representing low- and high-throughput data and conduct a user study involving monitoring and comprehension of dynamic networks. We also conduct a follow-up, think-aloud study combining monitoring and comprehension with experts in dynamic network visualization. Our findings show that animation staging strategies that emphasize comprehension do better for participant response times and accuracy. However, the notion of “comprehension” is not always clear when it comes to complex changes in highly dynamic networks, requiring some iteration in staging that the hybrid approach affords. Based on our results, we make recommendations for balancing event-based and time-based parameters for our hybrid approach.","1941-0506","","10.1109/TVCG.2020.3030385","National Science Foundation(grant numbers:IIS-1741536,IIS-1528203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231268","Dynamic networks;graph visualization;animation;mental map;user study","Animation;Layout;Dynamics;Monitoring;Visualization;Real-time systems;Task analysis","computer animation;data visualisation;user interfaces","highly dynamic networks;animation staging strategies;dynamic network visualization;offline dynamic networks;dynamic networks-networks;online dynamic networks;staged animation strategies","","3","","48","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Toward Localized Topological Data Structures: Querying the Forest for the Tree","P. Klacansky; A. Gyulassy; P. -T. Bremer; V. Pascucci","Scientific Computing and Imaging Institute, University of Utah; Scientific Computing and Imaging Institute, University of Utah; Lawrence Livermore National Laboratory; Scientific Computing and Imaging Institute, University of Utah","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","173","183","Topological approaches to data analysis can answer complex questions about the number, connectivity, and scale of intrinsic features in scalar data. However, the global nature of many topological structures makes their computation challenging at scale, and thus often limits the size of data that can be processed. One key quality to achieving scalability and performance on modern architectures is data locality, i.e., a process operates on data that resides in a nearby memory system, avoiding frequent jumps in data access patterns. From this perspective, topological computations are particularly challenging because the implied data structures represent features that can span the entire data set, often requiring a global traversal phase that limits their scalability. Traditionally, expensive preprocessing is considered an acceptable trade-off as it accelerates all subsequent queries. Most published use cases, however, explore only a fraction of all possible queries, most often those returning small, local features. In these cases, much of the global information is not utilized, yet computing it dominates the overall response time. We address this challenge for merge trees, one of the most commonly used topological structures. In particular, we propose an alternative representation, the merge forest, a collection of local trees corresponding to regions in a domain decomposition. Local trees are connected by a bridge set that allows us to recover any necessary global information at query time. The resulting system couples (i) a preprocessing that scales linearly in practice with (ii) fast runtime queries that provide the same functionality as traditional queries of a global merge tree. We test the scalability of our approach on a shared-memory parallel computer and demonstrate how data structure locality enables the analysis of large data with an order of magnitude performance improvement over the status quo. Furthermore, a merge forest reduces the memory overhead compared to a global merge tree and enables the processing of data sets that are an order of magnitude larger than possible with previous algorithms.","1941-0506","","10.1109/TVCG.2019.2934257","NSF(grant numbers:1314896,1602127,1649923,1842042); DOE/SciDAC(grant numbers:DESC0007446); PSAAP CCMSC(grant numbers:DE-NA0002375); Intel Graphics and Visualization; Institutes of XeLLENCE program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794560","Merge tree;parallel computation;topology","Vegetation;Forestry;Feature extraction;Data structures;Scalability;Acceleration;Task analysis","data analysis;query processing;shared memory systems;telecommunication network topology;tree data structures","localized topological data structures;data sets;data structure locality;shared-memory parallel computer;query time;necessary global information;local trees;local features;possible queries;global traversal phase;implied data structures;topological computations;data access patterns;nearby memory system;data locality;scalar data;intrinsic features;complex questions;data analysis","Algorithms;Computer Graphics;Databases, Factual;Foot Bones;Humans;Image Processing, Computer-Assisted","3","","48","IEEE","12 Aug 2019","","","IEEE","IEEE Journals"
"VisWall: Visual Data Exploration Using Direct Combination on Large Touch Displays","M. Agarwal; A. Srinivasan; J. Stasko","Georgia Institute of Technology,School of Interactive Computing,Atlanta,GA; Georgia Institute of Technology,School of Interactive Computing,Atlanta,GA; Georgia Institute of Technology,School of Interactive Computing,Atlanta,GA","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","26","30","An increasing number of data visualization tools are being designed for touch-based devices ranging from smartwatches to large wall-sized displays. While most of these tools have focused on exploring novel techniques to manually specify visualizations, recent touch-based visualization systems have begun to explore interface and interaction techniques for attribute-based visualization recommendations as a way to aid users (particularly novices) during data exploration. Advancing this line of work, we present a visualization system, VisWall, that enables visual data exploration in both single user and co-located collaborative settings on large touch displays. Coupling the concepts of direct combination and derivable visualizations, VisWall enables rapid construction of multivariate visualizations using attributes of previously created visualizations. By blending visualization recommendations and naturalistic interactions, VisWall seeks to help users visually explore their data by allowing them to focus more on aspects of the data (particularly, data attributes) rather than specifying and reconfiguring visualizations. We discuss the design, interaction techniques, and operations employed by VisWall along with a scenario of how these can be used to facilitate various tasks during visual data exploration.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933673","Human-centered computing;Visualization","Data visualization;Motion pictures;Visualization;Tools;Histograms;Tiles;Strips","data visualisation;touch sensitive screens","VisWall;visual data exploration;touch displays;derivable visualizations;multivariate visualizations;data attributes;interaction techniques;data visualization tools;touch-based devices;touch-based visualization systems;attribute-based visualization recommendations;data visualization tools","","3","","37","","19 Dec 2019","","","IEEE","IEEE Conferences"
"A Coloring Algorithm for Disambiguating Graph and Map Drawings","Y. Hu; L. Shi; Q. Liu","Yahoo Research, Sunnyvale, CA; Chinese Academy of Sciences and UCAS, Beijing, China; Chinese Academy of Sciences and UCAS, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","28 Dec 2018","2019","25","2","1321","1335","Drawings of non-planar graphs always result in edge crossings. When there are many edges crossing at small angles, it is often difficult to follow these edges, because of the multiple visual paths resulted from the crossings that slow down eye movements. In this paper we propose an algorithm that disambiguates the edges with automatic selection of distinctive colors. Our proposed algorithm computes a near optimal color assignment of a dual collision graph, using a novel branch-and-bound procedure applied to a space decomposition of the color gamut. We give examples demonstrating this approach in real world graphs and maps, as well as a user study to establish its effectiveness and limitations.","1941-0506","","10.1109/TVCG.2018.2798631","China National 973(grant numbers:2014CB340301); NSFC(grant numbers:61379088,61772504); Key Research Program of Frontier Sciences, CAS(grant numbers:QYZDY-SSW-JSC041); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269823","Graph drawing;virtual maps;edge coloring;branch-and-bound algorithm;global optimization","Color;Image color analysis;Visualization;Layout;Image edge detection;Task analysis;Optimization","cartography;data visualisation;graph colouring;mathematics computing;optimisation;tree searching","coloring algorithm;map drawings;edge crossings;algorithm computes;dual collision graph;color gamut;color selection;branch-and-bound procedure;nonplanar graph drawings;visual paths;near optimal color assignment;space decomposition","","2","","31","IEEE","25 Jan 2018","","","IEEE","IEEE Journals"
"A Colorization Framework for Monochrome-Color Dual-Lens Systems Using a Deep Convolutional Network","X. Dong; W. Li; X. Hu; X. Wang; Y. Wang","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2022","2022","28","3","1469","1485","In monochrome-color dual-lens systems, the monochrome camera can capture images with higher quality than the color camera. To obtain high quality color images, a better approach is to colorize the gray images from the monochrome camera with the color images from the color camera serving as a reference. In addition, the colorization may fail in some cases, which makes the estimation of the colorization quality a necessary step before outputting the colorization result. To solve these problems, we propose a deep convolutional network based framework. 1) In the colorization module, the proposed colorization CNN uses deep feature representations, attention operation, 3-D regulation and color correction to make use of colors of multiple pixels in the reference image for colorizing each pixel in the input gray image. 2) In the colorization quality estimation module, based on the symmetry property of colorization, we propose to utilize the colorization CNN again to colorize the gray map of the original reference color image using the first-time colorization result from the colorization module as reference. Then, the quality loss of the second-time colorization result can be used for estimating the colorization quality. Experimental results show that our method can largely outperform the state-of-the-art colorization methods and estimate the colorization quality accurately as well.","1941-0506","","10.1109/TVCG.2020.3022480","National Natural Science Foundation of China(grant numbers:61802026,61806016); Fundamental Research Funds for the Central Universities(grant numbers:2019RC39); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188002","Colorization CNN;weight volume;color correction;colorization quality estimation","Image color analysis;Color;Estimation;Cameras;Feature extraction;Lenses;Training","cameras;feature extraction;image colour analysis","high quality color images;gray images;monochrome camera;color camera;deep convolutional network based framework;colorization module;colorization CNN;color correction;reference image;input gray image;colorization quality estimation module;original reference color image;first-time colorization result;second-time colorization result;state-of-the-art colorization methods;colorization framework;monochrome-color dual-lens systems","","2","","38","IEEE","8 Sep 2020","","","IEEE","IEEE Journals"
"Adaptive Sampling for Sound Propagation","C. R. A. Chaitanya; J. M. Snyder; K. Godin; D. Nowrouzezahrai; N. Raghuvanshi",Microsoft Research; Microsoft Research; Microsoft Research; McGill University; Microsoft Research,"IEEE Transactions on Visualization and Computer Graphics","27 Mar 2019","2019","25","5","1846","1854","Precomputed sound propagation samples acoustics at discrete scene probe positions to support dynamic listener locations. An offline 3D numerical simulation is performed at each probe and the resulting field is encoded for runtime rendering with dynamic sources. Prior work place probes on a uniform grid, requiring high density to resolve narrow spaces. Our adaptive sampling approach varies probe density based on a novel “local diameter” measure of the space surrounding a given point, evaluated by stochastically tracing paths in the scene. We apply this measure to layout probes so as to smoothly adapt resolution and eliminate undersampling in corners, narrow corridors and stairways, while coarsening appropriately in more open areas. Coupled with a new runtime interpolator based on radial weights over geodesic paths, we achieve smooth acoustic effects that respect scene boundaries as both the source or listener move, unlike existing visibility-based solutions. We consistently demonstrate quality improvement over prior work at fixed cost.","1941-0506","","10.1109/TVCG.2019.2898765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642450","Diffraction;interpolation;mean free path;radial basis function;ray tracing;reciprocity;room acoustics;wave simulation","Probes;Runtime;Interpolation;Acoustics;Games;Geometry;Three-dimensional displays","acoustic signal processing;acoustic wave propagation;interpolation;rendering (computer graphics);signal resolution;signal sampling","smooth acoustic effects;discrete scene probe positions;dynamic listener locations;offline 3D numerical simulation;runtime rendering;adaptive sampling approach;probe density;runtime interpolator;geodesic paths;local diameter measure;visibility-based solutions;sound propagation samples acoustics","","2","","26","IEEE","14 Feb 2019","","","IEEE","IEEE Journals"
"Auditing the Sensitivity of Graph-based Ranking with Visual Analytics","T. Xie; Y. Ma; H. Tong; M. T. Thai; R. Maciejewski",Arizona State University; Arizona State University; University of Illinois at Urbana-Champaign; University of Florida; Arizona State University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1459","1469","Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.","1941-0506","","10.1109/TVCG.2020.3028958","U.S. Department of Homeland Security(grant numbers:2017-ST-061-QA0001,17STQAC00001-03-03); National Science Foundation Program on Fairness in AI in collaboration with Amazon(grant numbers:1939725); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216512","Graph-based ranking;sensitivity analysis;visual analytics","Sensitivity;Perturbation methods;Blogs;Visual analytics;Task analysis;Layout;Hypertext systems","data analysis;data mining;data visualisation;graph theory;information retrieval;search engines","model developers;graph structure;visual analytics framework;graph mining;e-commerce platform;ranked list;graph-based ranking methods;industrial information retrieval settings;perturbation-based what-if analysis","","2","","51","IEEE","7 Oct 2020","","","IEEE","IEEE Journals"
"Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks","N. Das; H. Park; Z. J. Wang; F. Hohman; R. Firstman; E. Rogers; D. H. P. Chau",Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Tech Research Institute; Georgia Institute of Technology,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","271","275","Deep neural networks (DNNs) are now commonly used in many domains. However, they are vulnerable to adversarial attacks: carefully-crafted perturbations on data inputs that can fool a model into making incorrect predictions. Despite significant research on developing DNN attack and defense techniques, people still lack an understanding of how such attacks penetrate a model's internals. We present Bluff, an interactive system for visualizing, characterizing, and deciphering adversarial attacks on vision-based neural networks. Bluff allows people to flexibly visualize and compare the activation pathways for benign and attacked images, revealing mechanisms that adversarial attacks employ to inflict harm on a model. Bluff is open-sourced and runs in modern web browsers.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331279","Human-centered computing;Visual Analytics","Perturbation methods;Interactive systems;Conferences;Neural networks;Data visualization;Predictive models;Data models","computer vision;data visualisation;deep learning (artificial intelligence);image classification;interactive systems;public domain software","deep neural networks;vision based neural networks;Bluff interactive system;adversarial attack visualization;benign images;attacked images;open sourced system;image classification","","2","","41","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Camera-sampling field and its applications","Ping-Hsien Lin; Tong-Yee Lee","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan; Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","IEEE Transactions on Visualization and Computer Graphics","15 Mar 2004","2004","10","3","241","251","We propose a novel vector field, called a camera-sampling field, to represent the sampling density distribution of a pinhole camera. We give the derivation and discuss some essential properties of the camera-sampling field, including flux, divergence, curl, gradient, level surface, and sampling patterns. This vector field reveals camera-sampling concisely and facilitates camera sampling analysis. The usage for this vector field in several computer graphics applications is introduced, such as determining the splat kernel for image-based rendering, texture filtering, mipmap level selection, level transition criteria for LOD, and LDI-construction.","1941-0506","","10.1109/TVCG.2004.1272724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272724","","Cameras;Image sampling;Rendering (computer graphics);Layout;Sampling methods;Computer graphics;Application software;Filtering;Computer vision;Filters","rendering (computer graphics);image texture;image sampling","camera-sampling field;sampling density distribution;pinhole camera;vector field;computer graphics applications;splat kernel;image-based rendering;texture filtering;mipmap level selection;level transition criteria;layered depth image;level of detail","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Photography;Reproducibility of Results;Sensitivity and Specificity","2","","23","","15 Mar 2004","","","IEEE","IEEE Journals"
"Composite Rectilinear Deformation for Stretch and Squish Navigation","J. Slack; T. Munzner",Department of Computer Science at the University of British Columbia; Department of Computer Science at the University of British Columbia,"IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2006","12","5","901","908","We present the first scalable algorithm that supports the composition of successive rectilinear deformations. Earlier systems that provided stretch and squish navigation could only handle small datasets. More recent work featuring rubber sheet navigation for large datasets has focused on rendering and on application-specific issues. However, no algorithm has yet been presented for carrying out such navigation methods; our paper addresses this problem. For maximum flexibility with large datasets, a stretch and squish navigation algorithm should allow for millions of potentially deformable regions. However, typical usage only changes the extents of a small subset k of these n regions at a time. The challenge is to avoid computations that are linear in n, because a single deformation can affect the absolute screen-space location of every deformable region. We provide an O(klogn) algorithm that supports any application that can lay out a dataset on a generic grid, and show an implementation that allows navigation of trees and gene sequences with millions of items in sub-millisecond time","1941-0506","","10.1109/TVCG.2006.127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015445","Focus+Context;information visualization;real time rendering;navigation.","Navigation;Rubber;Layout;Cameras;Graphics;Pipelines;Computer science;Visualization;Displays;History","data visualisation;rendering (computer graphics)","composite rectilinear deformation;stretch navigation;squish navigation;rubber sheet navigation;real-time rendering;screen-space location;information visualization","","2","","14","","20 Nov 2006","","","IEEE","IEEE Journals"
"DRIL: Descriptive Rules by Interactive Learning","F. Cao; E. T. Brown",DePaul University; DePaul University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","256","260","Analyzing data is increasingly a part of jobs across industry, science and government, but data stakeholders are not necessarily experts in analytics. The human-in-the-loop (HIL) approach includes semantic interaction tools, which leverage machine learning behind the scenes to assist users with their tasks without engaging them directly with algorithms. One widely applicable model for how humans under-stand data is descriptive rules, which can characterize important attributes and simultaneously their crucial values or ranges. In this paper, we introduce an approach to help with data understanding via interactively and automatically generated rules. Our approach makes discerning the behavior of groups of interesting data efficient and simple by bridging the gap between machine learning methods for rule learning and the user experience of sensemaking through visual exploration. We have evaluated our approach with machine learning experiments to confirm an existing rule learning algorithm performs well in this interactive context even with a small amount of user input, and created a prototype system, DRIL (Descriptive Rules by Interactive Learning), to demonstrate its capability through a case study.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331309","human-in-the-loop;data characterization;rule learning","Visualization;Machine learning algorithms;Prototypes;Machine learning;Tools;User experience;Stakeholders","data analysis;knowledge based systems;learning (artificial intelligence);user experience","rule learning;user experience;DRIL;data analysis;human-in-the-loop approach;semantic interaction tools;machine learning;Descriptive Rules by Interactive Learning;sensemaking;visual exploration","","2","","41","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Data Visualization Practitioners’ Perspectives on Chartjunk","P. Parsons; P. Shukla",Purdue University; Purdue University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","211","215","Chartjunk is a popular yet contentious topic. Previous studies have shown that extreme minimalism is not always best, and that visual embellishments can be useful depending on the context. While more knowledge is being developed regarding the effects of embellishments on users, less attention has been given to the perspectives of practitioners regarding how they design with embellishments. We conducted semi-structured interviews with 20 data visualization practitioners, investigating how they understand chartjunk and the factors that influence how and when they make use of embellishments. Our investigation uncovers a broad and pluralistic understanding of chartjunk among practitioners, and foregrounds a variety of personal and situated factors that influence the use of chartjunk beyond context. We highlight the personal nature of design practice, and discuss the need for more practice-led research to better understand the ways in which concepts like chartjunk are interpreted and used by practitioners.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331299","Human-centered computing;Visualization","Visualization;Conferences;Data visualization;Interviews","data visualisation","chartjunk;visual embellishments;data visualization practitioners","","2","","42","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Data-Driven Colormap Optimization for 2D Scalar Field Visualization","Q. Zeng; Y. Wang; J. Zhang; W. Zhang; C. Tu; I. Viola; Y. Wang","Shandong University; Shandong University; Chinese Academy of Sciences,Computer Network Information Center; Shandong University; Shandong University; King Abdullah University of Science and Technology; Shandong University","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","266","270","Colormapping is an effective and popular visual representation to analyze data patterns for 2D scalar fields. Scientists usually adopt a default colormap and adjust it to fit data in a trial-and-error process. Even though a few colormap design rules and measures are proposed, there is no automatic algorithm to directly optimize a default colormap for better revealing spatial patterns hidden in unevenly distributed data, especially the boundary characteristics. To fill this gap, we conduct a pilot study with six domain experts and summarize three requirements for automated colormap adjustment. We formulate the colormap adjustment as a nonlinear constrained optimization problem, and develop an efficient GPU-based implementation accompanying with a few interactions. We demonstrate the usefulness of our method with two case studies.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933764","Scientific visualization;scalar fields;color mapping;visualization optimization","Image color analysis;Data visualization;Oceans;Optimization;Two dimensional displays;Task analysis;Salinity (geophysical)","data visualisation;graphics processing units;nonlinear programming","trial-and-error process;colormap design rules;automatic algorithm;default colormap;spatial patterns;unevenly distributed data;automated colormap adjustment;nonlinear constrained optimization problem;data-driven colormap optimization;2D scalar field;colormapping;visual representation;data patterns","","2","","23","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Data-Driven Indoor Scene Modeling from a Single Color Image with Iterative Object Segmentation and Model Retrieval","M. Liu; K. Zhang; J. Zhu; J. Wang; J. Guo; Y. Guo","National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China","IEEE Transactions on Visualization and Computer Graphics","27 Feb 2020","2020","26","4","1702","1715","We propose a new method for modeling the indoor scene from a single color image. With our system, the user only needs to drag a few semantic bounding boxes surrounding the objects of interest. Our system then automatically finds the most similar 3D models from the ShapeNet model repository and aligns them with the corresponding objects of interest. To achieve this, each 3D model is represented as a group of view-dependent representations generated from a set of synthesized views. We iteratively conduct object segmentation and 3D model retrieval, based on the observation that good segmentation of the objects of interest can significantly improve the accuracy of model retrieval and make it robust to cluttered background and occlusions, and in turn, the retrieved 3D models can be used to assist with object segmentation. Segmentation of all objects of interest is achieved simultaneously under a unified multilabeling framework which fully utilizes the correspondences between the objects of interest and retrieved model images. Besides, we propose a new method to estimate the scene layout of the input image with the segmentation masks, which helps compose the resulting scene and further improves the modeling result remarkably. We verify the effectiveness of our approach through experimenting with a variety of indoor images and comparing against the relevant methods.","1941-0506","","10.1109/TVCG.2018.2880737","National Natural Science Foundation of China(grant numbers:61772257,61672279); Natural Science Foundation of Jiangsu Province(grant numbers:BK20150016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8531721","Indoor scene modeling;data-driven;object segmentation;model retrieval;layout estimation","Solid modeling;Three-dimensional displays;Image segmentation;Object segmentation;Computational modeling;Semantics;Layout","computer vision;image colour analysis;image representation;image retrieval;image segmentation;iterative methods;object detection;stereo image processing","data-driven indoor scene modeling;single color image;iterative object segmentation;ShapeNet model repository;3D models retrieval;indoor images","","2","","48","IEEE","11 Nov 2018","","","IEEE","IEEE Journals"
"Decision Graph Embedding for High-Resolution Manometry Diagnosis","J. Kreiser; A. Hann; E. Zizer; T. Ropinski",Visual Computing GroupUlm University; Department of Internal Medicine IUlm University; Department of Internal Medicine IUlm University; Visual Computing GroupUlm University,"IEEE Transactions on Visualization and Computer Graphics","4 Dec 2017","2018","24","1","873","882","High-resolution manometry is an imaging modality which enables the categorization of esophageal motility disorders. Spatio-temporal pressure data along the esophagus is acquired using a tubular device and multiple test swallows are performed by the patient. Current approaches visualize these swallows as individual instances, despite the fact that aggregated metrics are relevant in the diagnostic process. Based on the current Chicago Classification, which serves as the gold standard in this area, we introduce a visualization supporting an efficient and correct diagnosis. To reach this goal, we propose a novel decision graph representing the Chicago Classification with workflow optimization in mind. Based on this graph, we are further able to prioritize the different metrics used during diagnosis and can exploit this prioritization in the actual data visualization. Thus, different disorders and their related parameters are directly represented and intuitively influence the appearance of our visualization. Within this paper, we introduce our novel visualization, justify the design decisions, and provide the results of a user study we performed with medical students as well as a domain expert. On top of the presented visualization, we further discuss how to derive a visual signature for individual patients that allows us for the first time to perform an intuitive comparison between subjects, in the form of small multiples.","1941-0506","","10.1109/TVCG.2017.2744299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017642","Small multiples;manometry;chicago classification","Data visualization;Medical diagnostic imaging;Medical services;Esophagus;Visualization;Image color analysis;Standards","biological organs;data visualisation;graph theory;image classification;manometers;medical image processing;patient diagnosis;patient treatment;pressure sensors;statistical analysis","Chicago classification;data visualization;visual signature;workflow optimization;diagnostic process;aggregated metrics;multiple test swallows;tubular device;spatio-temporal pressure data;esophageal motility disorders;imaging modality;high-resolution manometry diagnosis;decision graph embedding","Adult;Computer Graphics;Data Visualization;Esophageal Motility Disorders;Esophagus;Female;Humans;Image Interpretation, Computer-Assisted;Male;Manometry;Young Adult","2","","29","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Declutter and Focus: Empirically Evaluating Design Guidelines for Effective Data Communication","K. Ajani; E. Lee; C. Xiong; C. Nussbaumer Knaflic; W. Kemper; S. Franconeri","School of Medicine, Case Western Reserve University, 2546 Cleveland, Ohio, United States, (e-mail: kxa347@case.edu); School of Information, University of Michigan, 1259 Ann Arbor, Michigan, United States, (e-mail: elsie.lee@umich.edu); Psychology, Northwestern University, 3270 Evanston, Illinois, United States, (e-mail: cxiong@u.northwestern.edu); Storytelling with data, Milwaukee, Wisconsin, United States, (e-mail: cole@storytellingwithdata.com); Psychology, Northwestern University, 3270 Evanston, Illinois, United States, (e-mail: wlkemper@gmail.com); Psychology, Northwestern University, Evanston, Illinois, United States, 60208 (e-mail: franconeri@northwestern.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Data visualization design has a powerful effect on which patterns we see as salient and how quickly we see them. The visualization practitioner community prescribes two popular guidelines for creating clear and efficient visualizations: declutter and focus. The declutter guidelines suggest removing non-critical gridlines, excessive labeling of data values, and color variability to improve aesthetics and to maximize the emphasis on the data relative to the design itself. The focus guidelines for explanatory communication recommend including a clear headline that describes the relevant data pattern, highlighting a subset of relevant data values with a unique color, and connecting those values to written annotations that contextualize them in a broader argument. We evaluated how these recommendations impact recall of the depicted information across cluttered, decluttered, and decluttered+focused designs of six graph topics. Undergraduate students were asked to redraw previously seen visualizations, to recall their topics and main conclusions, and to rate the varied designs on aesthetics, clarity, professionalism, and trustworthiness. Decluttering designs led to higher ratings on professionalism, and adding focus to the design led to higher ratings on aesthetics and clarity. They also showed better memory for the highlighted pattern in the data, as reflected across redrawings of the original visualization and typed free-response conclusions, though we do not know whether these results would generalize beyond our memory-based tasks. The results largely empirically validate the intuitions of visualization designers and practitioners. The stimuli, data, analysis code, and Supplementary Materials are available at https://osf.io/wes9u/.","1941-0506","","10.1109/TVCG.2021.3068337","National Science Foundation(grant numbers:IIS-1901485); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385921","data visualization;data communication;data storytelling;empirical evaluation;visualization aesthetics","Data visualization;Guidelines;Image color analysis;Clutter;Task analysis;Bars;Visualization","","","","2","","","IEEE","24 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Deep Colormap Extraction from Visualizations","L. Yuan; W. Zeng; S. Fu; Z. Zeng; H. Li; C. -W. Fu; H. Qu","Computer Science and Engineering, Hong Kong University of Science and Technology, 58207 Kowloon, Hong Kong, Hong Kong, (e-mail: atuanylp@gmail.com); Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences Guangzhou Branch, 53042 Guangzhou, Guangdong, China, 510070 (e-mail: wei.zeng@siat.ac.cn); CSE, HKUST, Hong Kong, Hong Kong, Hong Kong, (e-mail: fusiwei339@gmail.com); Computer Science and Engineering, The Chinese University of Hong Kong, 26451 New Territories, Hong Kong, Hong Kong, (e-mail: zlzeng6@gmail.com); Computer Science and Engineering, The Hong Kong University of Science and Technology, 58207 Kowloon, Hong Kong, Hong Kong, (e-mail: haotian.li@connect.ust.hk); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong, Hong Kong, SIN (e-mail: cwfu@cse.cuhk.edu.hk); The Department of Computer Science and Engineering, he Hong Kong University of Science and Technology, Hong Kong, HK, Hong Kong, (e-mail: huamin@cse.ust.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","This work presents a new approach based on deep learning to automatically extract colormaps from visualizations. After summarizing colors in an input visualization image as a Lab color histogram, we pass the histogram to a pre-trained deep neural network, which learns to predict the colormap that produces the visualization. To train the network, we create a new dataset of ~64K visualizations that cover a wide variety of data distributions, chart types, and colormaps. The network adopts an atrous spatial pyramid pooling module to capture color features at multiple scales in the input color histograms. We then classify the predicted colormap as discrete or continuous, and refine the predicted colormap based on its color histogram. Quantitative comparisons to existing methods show the superior performance of our approach on both synthetic and real-world visualizations. We further demonstrate the utility of our method with two use cases, i.e., color transfer and color remapping.","1941-0506","","10.1109/TVCG.2021.3070876","Shenzhen Institutes of Advanced Technology Innovation Program for Excellent Young Researchers; National Natural Science Foundation of China(grant numbers:61802388); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395231","Color extraction;information visualization;deep learning;color histogram","Image color analysis;Data visualization;Histograms;Neural networks;Deep learning;Data mining;Robustness","","","","2","","","IEEE","5 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Designing Narrative-Focused Role-Playing Games for Visualization Literacy in Young Children","E. Huynh; A. Nyhout; P. Ganea; F. Chevalier","Department of Computer ScienceUniversity of Toronto; Ontario Institute for Studies in Education, University of Toronto; Ontario Institute for Studies in Education, University of Toronto; Department of Computer Science and Statistical SciencesUniversity of Toronto","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","924","934","Building on game design and education research, this paper introduces narrative-focused role-playing games as a way to promote visualization literacy in young children. Visualization literacy skills are vital in understanding the world around us and constructing meaningful visualizations, yet, how to better develop these skills at an early age remains largely overlooked and understudied. Only recently has the visualization community started to fill this gap, resulting in preliminary studies and development of educational tools for use in early education. We add to these efforts through the exploration of gamification to support learning, and identify an opportunity to apply role-playing game-based designs by leveraging the presence of narratives in data-related problems involving visualizations. We study the effects of including narrative elements on learning through a technology probe, grounded in a set of design considerations stemming from visualization, game design and education science. We create two versions of a game - one with narrative elements and one without - and evaluate our instances on 33 child participants between 11- to 13-years old using a between-subjects study design. Despite participants requiring double the amount of time to complete their game due to additional narrative elements, the inclusion of such elements were found to improve engagement without sacrificing learning; our results indicate no significant differences in development of graph-reading skills, but significant differences in engagement and overall enjoyment of the game. We report observations and qualitative feedback collected, and note areas for improvement and room for future work.","1941-0506","","10.1109/TVCG.2020.3030464","NSERC(grant numbers:RGPIN-2018-05072); University of Toronto FA&S Tri-Council Bridge Funding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222251","Visualization Literacy;Educational technology;Gamification;Narrative","Data visualization;Games;Education;Visualization;Computer science;Tools;Probes","computer aided instruction;data visualisation;human computer interaction;serious games (computing)","educational tools;visualization community;meaningful visualizations;visualization literacy skills;education research;young children;designing narrative-focused role-playing games;graph-reading skills;additional narrative elements;between-subjects study design;education science;game design;design considerations;role-playing game-based designs;early education","Adolescent;Child;Child, Preschool;Computer Graphics;Gamification;Humans;Learning;Literacy;Narration;Video Games","2","","92","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Distributed Virtual Reality environments based on rewriting systems","H. Noser; C. Stern; P. Stucki","Dept. of Inf. Technol., Zurich Univ., Switzerland; Dept. of Inf. Technol., Zurich Univ., Switzerland; Dept. of Inf. Technol., Zurich Univ., Switzerland","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2003","2003","9","2","213","225","Ideally, virtual worlds should be dynamic, mutable, and complex in order to be attractive for immersed users. As such worlds can be designed easily by rewriting techniques, we propose a distributed Virtual Reality (VR) system that is based on an interactive animation system using a rewriting technique for geometric and behavioral modeling. The emphasis is on concepts and extensions for the integration of user immersion, user interaction, and networking into a rewriting-based animation system, Finally, the modeling of a ball game with two immersed users, as well as a virtual park, serve as case studies to illustrate the proposed concepts and extensions.","1941-0506","","10.1109/TVCG.2003.1196008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196008","","Virtual reality;Virtual environment;Animation;Layout;Graphics;Geometry;XML;Prototypes;Object oriented modeling;Solid modeling","computer animation;virtual reality;groupware;distributed processing;rewriting systems","virtual worlds;immersed users;rewriting techniques;distributed Virtual Reality system;interactive animation system;geometric modeling;behavioral;user immersion;user interaction;user networking;rewriting-based animation system;ball game;virtual park;mayer-systems;distributed environment;computer animation","","2","","19","","29 Apr 2003","","","IEEE","IEEE Journals"
"Evaluating Balance Recovery Techniques for Users Wearing Head-Mounted Display in VR","C. A. T. Cortes; H. -T. Chen; D. L. Sturnieks; J. Garcia; S. R. Lord; C. -T. Lin","Centre for Artificial Intelligence, University of Technology, Sydney, Ultimo, NSW, Australia; Centre for Artificial Intelligence, University of Technology, Sydney, Ultimo, NSW, Australia; Neuroscience Research Australia, Randwick, NSW, Australia; University of Technology Sydney, Ultimo, NSW, Australia; Neuroscience Research Australia, Randwick, NSW, Australia; Centre for Artificial Intelligence, University of Technology, Sydney, Ultimo, NSW, Australia","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","204","215","Room-scale 3D position tracking enables users to explore a virtual environment by physically walking, which improves comfort and the level of immersion. However, when users walk with their eyesight blocked by a head-mounted display, they may unexpectedly lose their balance and fall if they bump into real-world obstacles or unintentionally shift their center of mass outside the margin of stability. This paper evaluates balance recovery methods and intervention timing during the use of VR with the assumption that the onset of a fall is given. Our experiment followed the tether-release protocol during clinical research and induced a fall while a subject was engaged in a secondary 3D object selection task. The experiment employed a two-by-two design that evaluated two assistive techniques, i.e., video-see-through and auditory warning at two different timings, i.e., at fall onset and 500ms prior to fall onset. The data from 17 subjects showed that video-see-through triggered 500 ms before the onset of fall can effectively help users recover from falls. Surprisingly, video-see-through at fall onset has a significant negative impact on balance recovery and produces similar results to those of the baseline condition (no intervention).","1941-0506","","10.1109/TVCG.2019.2927477","Australian Research Council(grant numbers:DP180100670,DP180100656); NSW Defence Innovation Network; NSW State Government of Australia(grant numbers:DINPP2019 S1-03/09); Office of Naval Research Global(grant numbers:N62909-19-1-2058); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758372","VR;fall;balance","Protocols;Virtual environments;Three-dimensional displays;Australia;Legged locomotion;Timing;Resists","helmet mounted displays;virtual reality","virtual environment;balance recovery methods;intervention timing;VR;tether-release protocol;clinical research;secondary 3D object selection task;balance recovery techniques;head-mounted display;room-scale 3D position tracking;video-see-through","Accidental Falls;Adult;Computer Graphics;Female;Humans;Male;Postural Balance;Smart Glasses;Virtual Reality;Walking;Young Adult","2","","50","IEEE","9 Jul 2019","","","IEEE","IEEE Journals"
"Evaluating Effects of Background Stories on Graph Perception","Y. Zhao; J. Shi; J. Liu; J. Zhao; F. Zhou; W. Zhang; K. Chen; X. Zhao; C. Zhu; W. Chen","School of Information Science & Engineering, Central South University, China, Changsha, Hunan, China, (e-mail: zhaoying@csu.edu.cn); School of Computer Science and Engineering, Central South University, Changsha, Hunan, China, (e-mail: 429433693@qq.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan, China, (e-mail: 870656034@qq.com); School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, N2L 3G1 (e-mail: jianzhao@uwaterloo.ca); School of Computer Science and Engineering, Central South University, China, Changsha, Hunan, China, (e-mail: Zff@csu.edu.cn); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan, China, (e-mail: 1093894600@qq.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan, China, (e-mail: 2500150552@qq.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan, China, (e-mail: 1064253658@qq.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan, China, (e-mail: 240427611@qq.com); Zhejiang University, State Key Lab of CAD&CG, Hangzhou, Zhejiang, China, 310058 (e-mail: chenwei@cad.zju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","A graph is an abstract model that represents relations among entities, for example, the interactions of characters in a novel. Background story endows entities and relations with real-world meanings and describes semantics and contexts of the abstract model, for example, the actual story that the novel presents. Considering practical experience and relevant research, human viewers who know the background story of a graph and those not knowing the story may perform differently when perceiving the same graph. However, there are currently no previous studies to adequately address this problem. This paper presents an evaluation study that investigates the effects of background stories on graph perception. We formulate three hypotheses on different aspects including visual focus areas, graph structure identification, and mental model formation, and design three controlled experiments to test our hypotheses using real-world graphs with background stories. We analyze our experimental data to compare the performance of participants who have read and not read the background stories, and obtain a set of instructive findings. First, our results show that knowing the background stories affects participants focus areas in interactive graph exploration to a certain extent. Second, it significantly affects the performance of identifying community structures but not high degree and bridge structures. Third, it has a significant impact on graph recognition under blurred visual conditions. These findings can bring new considerations to the design of storytelling visualizations and interactive graph explorations.","1941-0506","","10.1109/TVCG.2021.3107297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523761","Graph visualization;node-link diagram;storytelling;evaluation","Visualization;Visual perception;Layout;Shape;Psychology;Bridges;Semantics","","","","2","","","IEEE","26 Aug 2021","","","IEEE","IEEE Early Access Articles"
"Evaluating Gradient Perception in Color-Coded Scalar Fields","K. Reda; M. E. Papka",Indiana University–Purdue University Indianapolis; Argonne National Laboratory & Northern Illinois University,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","271","275","Color mapping is a commonly used technique for visualizing scalar fields. While there exists advice for choosing effective colormaps, it is unclear if current guidelines apply equally across task types. We study the perception of gradients and evaluate the effectiveness of three colormaps at depicting gradient magnitudes. In a crowd-sourced experiment, we determine the just-noticeable differences (JNDs) at which participants can reliably compare and judge variations in gradient between two scalar fields. We find that participants exhibited lower JNDs with a diverging (cool-warm) or a spectral (rainbow) scheme, as compared with a monotonic-luminance colormap (viridis). The results support a hypothesis that apparent discontinuities in the color ramp may help viewers discern subtle structural differences in gradient. We discuss these findings and highlight future research directions for colormap evaluation.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933760","Human-centered computing—Visualization—;Empirical studies in visualization","Task analysis;Image color analysis;Visualization;Guidelines;Color;Meteorology;Sensitivity","data visualisation","gradient perception;color-coded scalar fields;color mapping;task types;gradient magnitudes;crowd-sourced experiment;just-noticeable differences;JNDs;spectral scheme;monotonic-luminance colormap;color ramp;colormap evaluation","","2","","40","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Evaluating the Effects of Non-Isomorphic Rotation on 3D Manipulation Tasks in Mixed Reality Simulation","Z. Gao; H. Wang; H. Lv; M. Wang; Y. Qi","College of Computer Science and Technology, Harbin Engineering University, Harbin, Heilongjiang, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, Heilongjiang, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, Heilongjiang, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, Heilongjiang, China; Peng Cheng Laboratory, Shenzhen, Guangdong, China","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1261","1273","As a hyper-natural interaction technique in 3D user interfaces, non-isomorphic rotation has been considered an effective approach for rotation tasks, where a static or dynamic control-display gain can be applied to amplify or attenuate a rotation. However, it is not clear whether non-isomorphic rotation can benefit 6-degree-of-freedom (6-DOF) manipulation tasks in AR and VR. In this article, we extended the usability studies of non-isomorphic rotation from rotation-only tasks to 6-DOF manipulation tasks and analyzed the collected data using a 2-component model. Using a mixed reality (MR) simulation approach, we also investigated whether environment (AR or VR) had an impact on 3D manipulation tasks. The results reveal that although both static and dynamic non-isomorphic rotation techniques could save time and effort in ballistic phases, only dynamic non-isomorphic rotation was significantly faster than isomorphic rotation. Interestingly, while environment had no significant impact on overall user performance, we found evidence that it could affect fine-tuning in correction phases. We also found that most participants preferred AR over VR, indicating that environmental visual realism could be helpful to improve user experience.","1941-0506","","10.1109/TVCG.2020.3010247","National Natural Science Foundation of China(grant numbers:61872104); Natural Science Foundation of Heilongjiang Province(grant numbers:F2016028); Fundamental Research Funds for the Central Universities(grant numbers:3072020CF0603); PCL Future Greater-Bay Area Network Facilities for Large-scale Experiments and Applications(grant numbers:LZC0019); Tianjin Key Laboratory of Advanced Networking; Tianjin University(grant numbers:300350); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144483","Virtual reality;augmented reality;mixed reality simulation;3D interaction;non-isomorphic rotation","Task analysis;Three-dimensional displays;Virtual reality;Solid modeling;User interfaces;Usability;Manipulator dynamics","augmented reality;computer displays;data visualisation;ergonomics;graphical user interfaces;human computer interaction;human factors;interactive systems;touch sensitive screens","rotation tasks;nonisomorphic rotation techniques;isomorphic rotation;3D user interfaces;hyper-natural interaction technique;mixed reality simulation","","2","","53","IEEE","20 Jul 2020","","","IEEE","IEEE Journals"
"Expressive Authoring of Node-Link Diagrams With Graphies","H. Romat; C. Appert; E. Pietriga","INRIA, Université Paris-Saclay CNRS, Orsay, France; INRIA, Université Paris-Saclay CNRS, Orsay, France; INRIA, Université Paris-Saclay CNRS, Orsay, France","IEEE Transactions on Visualization and Computer Graphics","25 Feb 2021","2021","27","4","2329","2340","Expressive design environments enable visualization designers not only to specify chart types and visual mappings, but also to customize individual graphical marks, as they would in a vector graphics drawing tool. Prior work has mainly investigated how to support the expressive design of a wide range of charts generated from tabular data: bar charts, scatterplots, maps, etc. We focus here on an expressive design environment for node-link diagrams generated from multivariate networks. Such data structures raise specific challenges and opportunities in terms of visual design and interactive authoring. We discuss those specificities and describe the user-centered design process that led to Graphies, a prototype environment for expressive node-link diagram authoring. We then report on a study in which participants successfully reproduced several expressive designs, and created their own designs as well.","1941-0506","","10.1109/TVCG.2019.2950932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889698","Expressive design;node-link diagram;multivariate networks","Visualization;Tools;Data visualization;Layout;Data structures;User centered design","data structures;data visualisation;user centred design","expressive authoring;node-link diagrams;Graphies;expressive design environment;visualization designers;chart types;visual mappings;individual graphical marks;vector graphics;bar charts;visual design;interactive authoring;user-centered design process;prototype environment;expressive node-link diagram authoring","","2","","54","IEEE","1 Nov 2019","","","IEEE","IEEE Journals"
"FeatureLego: Volume Exploration Using Exhaustive Clustering of Super-Voxels","S. Jadhav; S. Nadeem; A. Kaufman","Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, NY, USA; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2019","2019","25","9","2725","2737","We present a volume exploration framework, FeatureLego, that uses a novel voxel clustering approach for efficient selection of semantic features. We partition the input volume into a set of compact super-voxels that represent the finest selection granularity. We then perform an exhaustive clustering of these super-voxels using a graph-based clustering method. Unlike the prevalent brute-force parameter sampling approaches, we propose an efficient algorithm to perform this exhaustive clustering. By computing an exhaustive set of clusters, we aim to capture as many boundaries as possible and ensure that the user has sufficient options for efficiently selecting semantically relevant features. Furthermore, we merge all the computed clusters into a single tree of meta-clusters that can be used for hierarchical exploration. We implement an intuitive user-interface to interactively explore volumes using our clustering approach. Finally, we show the effectiveness of our framework on multiple real-world datasets of different modalities.","1941-0506","","10.1109/TVCG.2018.2856744","National Science Foundation(grant numbers:IIS1527200,NRT1633299,CNS1650499); Billi and Bernie Marcus Foundation; National Institutes of Health(grant numbers:U01HL127522); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412138","Volume visualization;hierarchical exploration;voxel clustering","Clustering algorithms;Feature extraction;Semantics;Histograms;Two dimensional displays;Three-dimensional displays;Visualization","data visualisation;feature selection;graph theory;pattern clustering;user interfaces","exhaustive clustering;volume exploration framework;FeatureLego;compact super-voxels;exhaustive set;computed clusters;meta-clusters;hierarchical exploration;voxel clustering approach;selection granularity;semantic features selection;graph-based clustering method;intuitive user-interface","Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Databases, Factual;Humans;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Anatomic;Semantics;Spinal Cord;Spine;Tooth;User-Computer Interface","2","","40","IEEE","17 Jul 2018","","","IEEE","IEEE Journals"
"Generating Multi-Destination Maps","J. Zhang; J. Fan; Z. Luo","Cognitive Science Department, Mind, Art and Computation Group, Xiamen University, Xiamen, Fujian, P.R. China; Cognitive Science Department, Mind, Art and Computation Group, Xiamen University, Xiamen, Fujian, P.R. China; Cognitive Science Department, Mind, Art and Computation Group, Xiamen University, Xiamen, Fujian, P.R. China","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2017","2017","23","8","1964","1976","Multi-destination maps are a kind of navigation maps aimed to guide visitors to multiple destinations within a region, which can be of great help to urban visitors. However, they have not been developed in the current online map service. To address this issue, we introduce a novel layout model designed especially for generating multi-destination maps, which considers the global and local layout of a multi-destination map. We model the layout problem as a graph drawing that satisfies a set of hard and soft constraints. In the global layout phase, we balance the scale factor between ROIs. In the local layout phase, we make all edges have good visibility and optimize the map layout to preserve the relative length and angle of roads. We also propose a perturbation-based optimization method to find an optimal layout in the complex solution space. The multi-destination maps generated by our system are potential feasible on the modern mobile devices and our result can show an overview and a detail view of the whole map at the same time. In addition, we perform a user study to evaluate the effectiveness of our method, and the results prove that the multi-destination maps achieve our goals well.","1941-0506","","10.1109/TVCG.2016.2597827","National Natural Science Foundation of China(grant numbers:60903129); Fundamental Research Funds for the Central Universities(grant numbers:20720140520); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530932","Multi-destination maps;visualization;layout optimization;urban network;traffic visualization;geographic/geospatial visualization","Roads;Layout;Visualization;Navigation;Trajectory;Optimization methods","cartography;data visualisation;graph theory;mobile computing;optimisation","multidestination maps;online map service;graph drawing;global layout phase;layout optimization;mobile devices;visualization","","2","","27","IEEE","3 Aug 2016","","","IEEE","IEEE Journals"
"GeoBuilder: A Geometric Algorithm Visualization and Debugging System for 2D and 3D Geometric Computing","J. -D. Wei; M. -H. Tsai; G. -C. Lee; J. -H. Huang; D. -T. Lee","Chang Gung University, Taipei; Institute of Information Science, Academia Sinica, Taipei; Institute of Information Science, Academia Sinica, Taipei; Institute of Information Science, Academia Sinica, Taipei; Institute of Information Science, Academia Sinica, Taipei","IEEE Transactions on Visualization and Computer Graphics","20 Jan 2009","2009","15","2","234","248","Algorithm visualization is a unique research topic that integrates engineering skills such as computer graphics, system programming, database management, computer networks, etc., to facilitate algorithmic researchers in testing their ideas, demonstrating new findings, and teaching algorithm design in the classroom. Within the broad applications of algorithm visualization, there still remain performance issues that deserve further research, e.g., system portability, collaboration capability, and animation effect in 3D environments. Using modern technologies of Java programming, we develop an algorithm visualization and debugging system, dubbed GeoBuilder, for geometric computing. The GeoBuilder system features Java's promising portability, engagement of collaboration in algorithm development, and automatic camera positioning for tracking 3D geometric objects. In this paper, we describe the design of the GeoBuilder system and demonstrate its applications.","1941-0506","","10.1109/TVCG.2008.93","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4564451","Visualization techniques and methodologies;Geometric algorithms;languages;and systems;Visualization techniques and methodologies;Geometric algorithms;languages;and systems","Visualization;Debugging;Computer network management;Collaboration;Java;Data engineering;Design engineering;Computer graphics;Spatial databases;Visual databases","computational geometry;data visualisation;groupware;Java;program debugging","GeoBuilder;geometric algorithm visualization;debugging system;2D geometric computing;3D geometric computing;computer graphics;system programming;database management;computer networks;Java programming","Algorithms;Computer Communication Networks;Computer Graphics;Computer Simulation;Database Management Systems;Humans;Image Enhancement;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Programming Languages;Software;User-Computer Interface","2","","55","","15 Jul 2008","","","IEEE","IEEE Journals"
"Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis","Y. Kim; J. Kim; H. Jeon; Y. -H. Kim; H. Song; B. Kim; J. Seo",Seoul National University; Seoul National University; POSTECH; University of Maryland; Soongsil University; Hankuk University of Foreign Studies; Seoul National University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","656","666","Git metadata contains rich information for developers to understand the overall context of a large software development project. Thus it can help new developers, managers, and testers understand the history of development without needing to dig into a large pile of unfamiliar source code. However, the current tools for Git visualization are not adequate to analyze and explore the metadata: They focus mainly on improving the usability of Git commands instead of on helping users understand the development history. Furthermore, they do not scale for large and complex Git commit graphs, which can play an important role in understanding the overall development history. In this paper, we present Githru, an interactive visual analytics system that enables developers to effectively understand the context of development history through the interactive exploration of Git metadata. We design an interactive visual encoding idiom to represent a large Git graph in a scalable manner while preserving the topological structures in the Git graph. To enable scalable exploration of a large Git commit graph, we propose novel techniques (graph reconstruction, clustering, and Context-Preserving Squash Merge (CSM) methods) to abstract a large-scale Git commit graph. Based on these Git commit graph abstraction techniques, Githru provides an interactive summary view to help users gain an overview of the development history and a comparison view in which users can compare different clusters of commits. The efficacy of Githru has been demonstrated by case studies with domain experts using real-world, in-house datasets from a large software development team at a major international IT company. A controlled user study with 12 developers comparing Githru to previous tools also confirms the effectiveness of Githru in terms of task completion time.","1941-0506","","10.1109/TVCG.2020.3030414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222261","git;history;exploration;overview;repository;visualization;cluster;DAG","History;Metadata;Software;Visualization;Interviews;Tools;Complexity theory","data analysis;data visualisation;graph theory;meta data;program visualisation;software engineering","Githru;software development team;software development history;Git metadata;software development project;Git visualization;Git commands;complex Git commit graphs;interactive visual analytics system;interactive visual encoding idiom;Git commit graph abstraction techniques;visual analytics","Computer Graphics;Data Interpretation, Statistical;Metadata;Software","2","","75","CCBY","13 Oct 2020","","","IEEE","IEEE Journals"
"GlyphCreator: Towards Example-based Automatic Generation of Circular Glyphs","L. Ying; T. Tangl; Y. Luo; L. Shen; X. Xie; L. Yu; Y. Wu","State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China; Department of Sport Science, Zhejiang University, Hangrhou, China; Department of Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","400","410","Circular glyphs are used across disparate fields to represent multidimensional data. However, although these glyphs are extremely effective, creating them is often laborious, even for those with professional design skills. This paper presents GlyphCreator, an interactive tool for the example-based generation of circular glyphs. Given an example circular glyph and multidimensional input data, GlyphCreator promptly generates a list of design candidates, any of which can be edited to satisfy the requirements of a particular representation. To develop GlyphCreator, we first derive a design space of circular glyphs by summarizing relationships between different visual elements. With this design space, we build a circular glyph dataset and develop a deep learning model for glyph parsing. The model can deconstruct a circular glyph bitmap into a series of visual elements. Next, we introduce an interface that helps users bind the input data attributes to visual elements and customize visual styles. We evaluate the parsing model through a quantitative experiment, demonstrate the use of GlyphCreator through two use scenarios, and validate its effectiveness through user interviews.","1941-0506","","10.1109/TVCG.2021.3114877","NSFC(grant numbers:62072400); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); Collaborative Innovation Center of Artificial Intelligence; MOE and Zhejiang Provincial Government (ZJU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557223","Glyph-based visualization;machine learning;automatic visualization","Data visualization;Visualization;Layout;Deep learning;Data mining;Tools;Task analysis","data visualisation;deep learning (artificial intelligence);interactive systems","GlyphCreator;example-based automatic generation;multidimensional input data;circular glyph dataset;glyph parsing;circular glyph bitmap;deep learning;visual elements;customize visual styles;interactive tool","","2","","73","IEEE","1 Oct 2021","","","IEEE","IEEE Journals"
"Graph-Assisted Visualization of Microvascular Networks","P. Govyadinov; T. Womack; J. Eriksen; D. Mayerich; G. Chen",University of Houston; University of Houston; University of Houston; University of Houston; University of Houston,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Microvessels are frequent targets for research into tissue development and disease progression. These complex and subtle differences between networks are currently difficult to visualize, making sample comparisons subjective and difficult to quantify. These challenges are due to the structure of microvascular networks, which are sparse but space-filling. This results in a complex and interconnected mesh that is difficult to represent and impractical to interpret using conventional visualization techniques. We develop a bi-modal visualization framework, leveraging graph-based and geometry-based techniques to achieve interactive visualization of microvascular networks. This framework allows researchers to objectively interpret the complex and subtle variations that arise when comparing microvascular networks.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933682","microvascular;graph;network;bi-modal visualization","Visualization;Three-dimensional displays;Layout;Diseases;Rendering (computer graphics);Cameras;Complexity theory","blood vessels;data visualisation;diseases;geometry;graph theory;medical image processing;rendering (computer graphics)","tissue development;microvascular networks;interconnected mesh;bi-modal visualization framework;interactive visualization techniques;graph-assisted visualization;geometry-based techniques;graph-based technique","","2","","41","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Hybrid Graph Visualizations With ChordLink: Algorithms, Experiments, and Applications","L. Angori; W. Didimo; F. Montecchiani; D. Pagliuca; A. Tappini","Dipartimento di Ingegneria, Università degli Studi di Perugia, Perugia, Italy; Dipartimento di Ingegneria, Università degli Studi di Perugia, Perugia, Italy; Dipartimento di Ingegneria, Università degli Studi di Perugia, Perugia, Italy; Agenzia delle Entrate, Arezzo, Italy; Dipartimento di Ingegneria, Università degli Studi di Perugia, Perugia, Italy","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1288","1300","Many real-world networks are globally sparse but locally dense. Typical examples are social networks, biological networks, and information networks. This double structural nature makes it difficult to adopt a homogeneous visualization model that clearly conveys both an overview of the network and the internal structure of its communities at the same time. As a consequence, the use of hybrid visualizations has been proposed. For instance, <sc>NodeTrix</sc> combines node-link and matrix-based representations (Henry <italic>et al.</italic>, 2007). In this article we describe <sc>ChordLink</sc>, a hybrid visualization model that embeds chord diagrams, used to represent dense subgraphs, into a node-link diagram, which shows the global network structure. The visualization makes it possible to interactively highlight the structure of a community while keeping the rest of the layout stable. We discuss the intriguing algorithmic challenges behind the <sc>ChordLink</sc> model, present a prototype system that implements it, and illustrate case studies on real-world networks.","1941-0506","","10.1109/TVCG.2020.3016055","Ministero dell’Istruzione, dell’Università e della Ricerca(grant numbers:20174LF3T8); Dip. di Ingegneria - Università degli Studi di Perugia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165928","Network visualization;graph drawing;hybrid visualization;chord diagrams;optimization algorithms;systems","Visualization;Layout;Task analysis;Semiconductor device modeling;Prototypes;Sparse matrices;Stability analysis","data visualisation;graph theory;social networking (online)","real-world networks;typical examples;social networks;biological networks;information networks;double structural nature;homogeneous visualization model;internal structure;hybrid visualizations;matrix-based representations;hybrid visualization model;chord diagrams;dense subgraphs;node-link diagram;global network structure;intriguing algorithmic challenges;ChordLink model;hybrid graph visualizations","","2","","60","IEEE","12 Aug 2020","","","IEEE","IEEE Journals"
"Hybrid Rendering with Scheduling under Uncertainty","G. Tamm; J. Krüger","DFKI, Saarbrücken, Germany; Intel VCI, SCI, University Duisburg-Essen, Essen, Germany","IEEE Transactions on Visualization and Computer Graphics","17 Mar 2014","2014","20","5","767","780","As scientific data of increasing size is generated by today's simulations and measurements, utilizing dedicated server resources to process the visualization pipeline becomes necessary. In a purely server-based approach, requirements on the client-side are minimal as the client only displays results received from the server. However, the client may have a considerable amount of hardware available, which is left idle. Further, the visualization is put at the whim of possibly unreliable server and network conditions. Server load, bandwidth and latency may substantially affect the response time on the client. In this paper, we describe a hybrid method, where visualization workload is assigned to server and client. A capable client can produce images independently. The goal is to determine a workload schedule that enables a synergy between the two sides to provide rendering results to the user as fast as possible. The schedule is determined based on processing and transfer timings obtained at runtime. Our probabilistic scheduler adapts to changing conditions by shifting workload between server and client, and accounts for the performance variability in the dynamic system.","1941-0506","","10.1109/TVCG.2014.2303092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727579","Remote/hybrid rendering;client/server systems;uncertainty;probabilistic scheduling","Servers;Rendering (computer graphics);Timing;Schedules;Data visualization;Hardware;Probabilistic logic","data visualisation;rendering (computer graphics)","hybrid rendering;visualization pipeline;purely server-based approach;capable client;workload schedule;probabilistic scheduler","","2","","29","IEEE","28 Jan 2014","","","IEEE","IEEE Journals"
"InfoColorizer: Interactive Recommendation of Color Palettes for Infographics","L. Yuan; Z. Zhou; J. Zhao; Y. Guo; F. Du; H. Qu","Computer Science and Engineering, Hong Kong University of Science and Technology, 58207 Kowloon, Hong Kong, Hong Kong, (e-mail: atuanylp@gmail.com); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, N2L 3G1 (e-mail: zzqwaterloo@gmail.com); School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, N2L 3G1 (e-mail: jianzhao@uwaterloo.ca); Software Engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi, China, (e-mail: maxleaf@stu.xjtu.edu.cn); Research, Adobe Systems Inc, 58584 San Jose, California, United States, 95110-2704 (e-mail: fdu@adobe.com); The Department of Computer Science and Engineering, he Hong Kong University of Science and Technology, Hong Kong, HK, Hong Kong, (e-mail: huamin@cse.ust.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","When designing infographics, general users usually struggle with getting desired color palettes using existing infographic authoring tools, which sometimes sacrifice customizability, require design expertise, or neglect the influence of elements? spatial arrangement. We propose a data-driven method that provides flexibility by considering users? preferences, lowers the expertise barrier via automation, and tailors suggested palettes to the spatial layout of elements. We build a recommendation engine by utilizing deep learning techniques to characterize good color design practices from data, and further develop InfoColorizer, a tool that allows users to obtain color palettes for their infographics in an interactive and dynamic manner. To validate our method, we conducted a comprehensive four-part evaluation, including case studies, a controlled user study, a survey study, and an interview study. The results indicate that InfoColorizer can provide compelling palette recommendations with adequate flexibility, allowing users to effectively obtain high-quality color design for input infographics with low effort.","1941-0506","","10.1109/TVCG.2021.3085327","NSERC Discovery Grant; Adobe; Microsoft Research Asia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444798","Color palettes design;infographics;visualization recommendation;machine learning","Image color analysis;Tools;Visualization;Layout;Engines;Deep learning;Data visualization","","","","2","","","IEEE","1 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Interactive Architectural Design with Diverse Solution Exploration","G. Berseth; B. Haworth; M. Usman; D. Schaumann; M. Khayatkhoei; M. Kapadia; P. Faloutsos","Department of Electrical Engineering and Computer Sciences, UC Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, York University, Toronto, ON, Canada; Department of Electrical Engineering and Computer Science, York University, Toronto, ON, Canada; Department of Computer Science, Rutgers University, Piscataway, NJ, USA; Department of Computer Science, Rutgers University, Piscataway, NJ, USA; Department of Computer Science, Rutgers University, Piscataway, NJ, USA; Department of Electrical Engineering and Computer Science, York University, Toronto, ON, Canada","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","111","124","In architectural design, architects explore a vast amount of design options to maximize various performance criteria, while adhering to specific constraints. In an effort to assist architects in such a complex endeavour, we propose IDOME, an interactive system for computer-aided design optimization. Our approach balances automation and control by efficiently exploring, analyzing, and filtering space layouts to inform architects' decision-making better. At each design iteration, IDOME provides a set of alternative building layouts which satisfy user-defined constraints and optimality criteria concerning a user-defined space parametrization. When the user selects a design generated by IDOME, the system performs a similar optimization process with the same (or different) parameters and objectives. A user may iterate this exploration process as many times as needed. In this work, we focus on optimizing built environments using architectural metrics by improving the degree of visibility, accessibility, and information gaining for navigating a proposed space. This approach, however, can be extended to support other kinds of analysis as well. We demonstrate the capabilities of IDOME through a series of examples, performance analysis, user studies, and a usability test. The results indicate that IDOME successfully optimizes the proposed designs concerning the chosen metrics and offers a satisfactory experience for users with minimal training.","1941-0506","","10.1109/TVCG.2019.2938961","ORF/ISSUM; National Science Foundation(grant numbers:IIS-1703883,S&AS-1723869); Murray Postdoctoral Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823048","Design exploration;design optimization;user-in-the-loop","Optimization;Layout;Measurement;Tools;Design automation;Automation;Aerospace electronics","architectural CAD;buildings (structures);decision making;interactive systems;optimisation","IDOME;interactive architectural design;interactive system;space layouts;building layouts;user defined space parametrization;computer aided design optimization;decision making","","2","","71","IEEE","3 Sep 2019","","","IEEE","IEEE Journals"
"Interactive Bicluster Aggregation in Bipartite Graphs","M. Sun; D. Koop; J. Zhao; C. North; N. Ramakrishnan","Northern Illinois University,University of Massachusetts Dartmouth; Northern Illinois University,University of Massachusetts Dartmouth; University of Waterloo,FXPAL; Virginia Tech; Virginia Tech","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","246","250","Exploring coordinated relationships is important for sense making of data in various fields, such as intelligence analysis. To support such investigations, visual analysis tools use biclustering to mine relationships in bipartite graphs and visualize the resulting biclusters with standard graph visualization techniques. Due to overlaps among biclusters, such visualizations can be cluttered (e.g., with many edge crossings), when there are a large number of biclusters. Prior work attempted to resolve this problem by automatically ordering nodes in a bipartite graph. However, visual clutter is still a serious problem, since the number of displayed biclusters remains unchanged. We propose bicluster aggregation as an alternative approach, and have developed two methods of interactively merging biclusters. These interactive bicluster aggregations help organize similar biclusters and reduce the number of displayed biclusters. Initial expert feedback indicates potential usefulness of these techniques in practice.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933546","Bicluster;bipartite graph;visual analytics","Visualization;Bipartite graph;Encoding;Merging;Manuals;Aggregates;Data visualization","data aggregation;data analysis;data visualisation;graph theory;interactive systems;pattern clustering","interactive bicluster aggregation;bipartite graph;coordinated relationships;intelligence analysis;visual analysis tools;relationship mining;standard graph visualization techniques;visual clutter","","2","","23","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Interactive Dendritic Spine Analysis Based on 3D Morphological Features","J. Choi; S. -E. Lee; E. Cho; Y. Kashiwagi; S. Okabe; S. Chang; W. -K. Jeong",Ulsan National Institute of Science and Technology; Seoul National University College of Medicine; Seoul National University College of Medicine; University of Tokyo; University of Tokyo; Seoul National University College of Medicine; Ulsan National Institute of Science and Technology,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","171","175","Dendritic spines are submicron scale protrusions on neuronal dendrites that form the postsynaptic sites of excitatory neuronal inputs. The morphological changes of dendritic spines reflect alterations in physiological conditions and are further indicators of various neuropsychiatric conditions. However, due to the highly dynamic and heterogeneous nature of spines, accurate measurement and object analysis of spine morphology is a major challenge in neuroscience research. Here, we propose an interactive 3D dendritic spine analysis system that displays 3D rendering of spines and plots the high-dimensional features extracted from the 3D mesh of spines in three graph types (parallel coordinate plot, radar plot, and 2D scatter plot with t-Distributed Stochastic Neighbor Embedding). With this system, analysts can effectively explore and analyze the dendritic spine in a 3D manner with high-dimensional features. For the system, we have constructed a set of morphological high-dimensional features from the 3D mesh of dendritic spines.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933795","Biomedical and Medical Visualization;Coordinated and Multiple Views;User Interfaces","Three-dimensional displays;Neck;Head;Image color analysis;Two dimensional displays;Rendering (computer graphics);Shape","biomedical optical imaging;data visualisation;dendrites;feature extraction;medical image processing;neurophysiology;rendering (computer graphics);stochastic processes","interactive dendritic spine analysis;3D morphological features;neuronal dendrites;spine morphology;spine analysis system;high-dimensional features;postsynaptic sites;excitatory neuronal inputs;physiological condition;neuropsychiatric conditions;high-dimensional feature extraction;3D mesh;t-distributed stochastic neighbor embedding;morphological high-dimensional features","","2","","25","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Interactive Simulation of Scattering Effects in Participating Media Using a Neural Network Model","L. Ge; B. Wang; L. Wang; X. Meng; N. Holzschuch","School of Software, Shandong University, Jinan, Shandong, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; School of Software, Shandong University, Jinan, Shandong, China; School of Software, Shandong University, Jinan, Shandong, China; Inria, CNRS, Grenoble INP LJK, University Grenoble Alpes, Grenoble, France","IEEE Transactions on Visualization and Computer Graphics","27 May 2021","2021","27","7","3123","3134","Rendering participating media is important to the creation of photorealistic images. Participating media has a translucent aspect that comes from light being scattered inside the material. For materials with a small mean-free-path (mfp), multiple scattering effects dominate. Simulating these effects is computationally intensive, as it requires tracking a large number of scattering events inside the material. Existing approaches precompute multiple scattering events inside the material and store the results in a table. During rendering time, this table is used to compute the scattering effects. While these methods are faster than explicit scattering computation, they incur higher storage costs. In this paper, we present a new representation for double and multiple scattering effects that uses a neural network model. The scattering response from all homogeneous participating media is encoded into a neural network in a preprocessing step. At run time, the neural network is then used to predict the double and multiple scattering effects. We demonstrate the effects combined with Virtual Ray Lights (VRL), although our approach can be integrated with other rendering algorithms. Our algorithm is implemented on GPU. Double and multiple scattering effects for the entire participating media space are encoded using only 23.6 KB of memory. Our method achieves 50 ms per frame in typical scenes and provides results almost identical to the reference.","1941-0506","","10.1109/TVCG.2019.2963015","National Key Research and Development Program of China(grant numbers:2017YFB0203000); National Natural Science Foundation of China(grant numbers:61802187,61872223); Natural Science Foundation of Jiangsu Province(grant numbers:BK20170857); Fundamental Research Funds for the Central Universities(grant numbers:30918011320); ANR(grant numbers:ANR-15-CE38-0005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945399","Participating media;multiple scattering;real-time;neural network","Scattering;Neural networks;Media;Rendering (computer graphics);Photonics;Computational modeling;Graphics processing units","computer simulation;graphics processing units;interactive systems;neural nets;ray tracing;rendering (computer graphics)","scattering events;ray tracing;participating media space;GPU;VRL;virtual ray lights;storage costs;double scattering effects;mean-free-path;photorealistic images;rendering;interactive simulation;homogeneous participating media;scattering response;neural network;multiple scattering effects","","2","","22","IEEE","30 Dec 2019","","","IEEE","IEEE Journals"
"Joint Graph Layouts for Visualizing Collections of Segmented Meshes","J. Ren; J. Schneider; M. Ovsjanikov; P. Wonka","Visual Computing Center (VCC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Visual Computing Center (VCC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Laboratoire d'Informatique (LIX), École Polytechnique, Palaiseau Cedex, France; Visual Computing Center (VCC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","IEEE Transactions on Visualization and Computer Graphics","30 Jul 2018","2018","24","9","2546","2558","We present a novel and efficient approach for computing joint graph layouts and then use it to visualize collections of segmented meshes. Our joint graph layout algorithm takes as input the adjacency matrices for a set of graphs along with partial, possibly soft, correspondences between nodes of different graphs. We then use a two stage procedure, where in the first step, we extend spectral graph drawing to include a consistency term so that a collection of graphs can be handled jointly. Our second step extends metric multi-dimensional scaling with stress majorization to the joint layout setting, while using the output of the spectral approach as initialization. Further, we discuss a user interface for exploring a collection of graphs. Finally, we show multiple example visualizations of graphs stemming from collections of segmented meshes and we present qualitative and quantitative comparisons with previous work.","1941-0506","","10.1109/TVCG.2017.2751473","École Polytechnique; FUI project TANDEM 2; Google Focused Research Award; King Abdullah University of Science and Technology (KAUST); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031987","Multi-graph layout;spectral graph layout;multi-dimensional scaling;topological exploration","Layout;Approximation algorithms;Three-dimensional displays;Stress;Shape;Algorithm design and analysis;Optimization","data visualisation;graph theory;matrix algebra","spectral graphs;adjacency matrices;spectral graph drawing;multi-dimensional scaling;stress majorization;joint layout setting;joint graph layout algorithm;joint graph layouts;segmented meshes","","2","","32","IEEE","12 Sep 2017","","","IEEE","IEEE Journals"
"LADV: Deep Learning Assisted Authoring of Dashboard Visualizations From Images and Sketches","R. Ma; H. Mei; H. Guan; W. Huang; F. Zhang; C. Xin; W. Dai; X. Wen; W. Chen","Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Senseable City Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2021","2021","27","9","3717","3732","Dashboard visualizations are widely used in data-intensive applications such as business intelligence, operation monitoring, and urban planning. However, existing visualization authoring tools are inefficient in the rapid prototyping of dashboards because visualization expertise and user intention need to be integrated. We propose a novel approach to rapid conceptualization that can construct dashboard templates from exemplars to mitigate the burden of designing, implementing, and evaluating dashboard visualizations. The kernel of our approach is a novel deep learning-based model that can identify and locate charts of various categories and extract colors from an input image or sketch. We design and implement a web-based authoring tool for learning, composing, and customizing dashboard visualizations in a cloud computing environment. Examples, user studies, and user feedback from real scenarios in Alibaba Cloud verify the usability and efficiency of the proposed approach.","1941-0506","","10.1109/TVCG.2020.2980227","National Natural Science Foundation of China(grant numbers:61772456,61761136020,U1609217); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9035622","Dashboard visualization;visual design;stylization;deep learning-based","Tools;Data visualization;Image color analysis;Visualization;Layout;Task analysis;Rapid prototyping","authoring systems;cloud computing;data visualisation;deep learning (artificial intelligence)","deep learning assisted authoring;data-intensive applications;visualization authoring tools;visualization expertise;dashboard templates;dashboard visualizations;user intention;images;sketches;cloud computing;color extraction;LADV","","2","","49","IEEE","13 Mar 2020","","","IEEE","IEEE Journals"
"Mesh Denoising with Facet Graph Convolutions","M. Armando; J. -S. Franco; E. Boyer","Morpheo, Institut National de Recherche en Informatique et en Automatique Centre de Recherche Grenoble Rhone-Alpes, 56521 Montbonnot, Isre, France, 38334 (e-mail: matthieu.armando@inria.fr); INRIA, INRIA, Grenoble, France, France, (e-mail: jean-sebastien.franco@inria.fr); Morpheo, INRIA, Montbonnot, -, France, 38334 (e-mail: edmond.boyer@inria.fr)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","We examine the problem of mesh denoising, which consists of removing noise from corrupted 3D meshes while preserving existing geometric features. Most mesh denoising methods require a lot of mesh-specific parameter fine-tuning, to account for specific features and noise types. In recent years, data-driven methods have demonstrated their robustness and effectiveness with respect to noise and feature properties on a wide variety of geometry and image problems. Most existing mesh denoising methods still use hand-crafted features, and locally denoise facets rather than examine the mesh globally. In this work, we propose the use of a fully end-to-end learning strategy based on graph convolutions, where meaningful features are learned directly by our network. It operates on a graph of facets, directly on the existing topology of the mesh, without resampling, and follows a multi-scale design to extract geometric features at different resolution levels. Similar to most recent pipelines, given a noisy mesh, we first denoise face normals with our novel approach, then update vertex positions accordingly. Our method performs significantly better than the current state-of-the-art learning-based methods. Additionally, we show that it can be trained on noisy data, without explicit correspondence between noisy and ground-truth facets. We also propose a multi-scale denoising strategy, better suited to correct noise with a low spatial frequency.","1941-0506","","10.1109/TVCG.2020.3045490","Microsoft Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9296808","Mesh denoising;normal filtering;graph convolution;feature preserving;geometric deep learning","Noise reduction;Faces;Shape;Noise measurement;Three-dimensional displays;Surface treatment;Optimization","","","","2","","","IEEE","17 Dec 2020","","","IEEE","IEEE Early Access Articles"
"MissBiN: Visual Analysis of Missing Links in Bipartite Networks","J. Zhao; M. Sun; F. Chen; P. Chiu",FX Palo Alto Laboratory; Northern Illinois University; FX Palo Alto Laboratory; FX Palo Alto Laboratory,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","71","75","The analysis of bipartite networks is critical in a variety of application domains, such as exploring entity co-occurrences in intelligence analysis and investigating gene expression in bio-informatics. One important task is missing link prediction, which infers the existence of unseen links based on currently observed ones. In this paper, we propose MissBiN that involves analysts in the loop for making sense of link prediction results. MissBiN combines a novel method for link prediction and an interactive visualization for examining and understanding the algorithm outputs. Further, we conducted quantitative experiments to assess the performance of the proposed link prediction algorithm and a case study to evaluate the overall effectiveness of MissBiN.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933639","Link prediction;bipartite network;visual analytics.","Visualization;Prediction algorithms;Measurement;Task analysis;Network topology;Predictive models;Tools","bioinformatics;data analysis;data visualisation;genetics","MissBiN;visual analysis;missing links;bipartite networks;entity co-occurrences;intelligence analysis;gene expression;bioinformatics;interactive visualization;link prediction algorithm","","2","","41","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Motion Planning for Convertible Indoor Scene Layout Design","G. Xiong; Q. Fu; H. Fu; B. Zhou; G. Luo; Z. Deng","Virtual Reality and Interactive Techniques Institute, East China Jiaotong University, Nanchang, Jiangxi, China; School of Digital Media and Design Arts, Beijing University of Posts and Telecommunications, Beijing, China; School of Creative Media, City University of Hong Kong, Hong Kong, China; School of Computer Science, Beihang University, Beijing, China; Virtual Reality and Interactive Techniques Institute, East China Jiaotong University, Nanchang, Jiangxi, China; Department of Computer Science, University of Houston, Houston, TX, USA","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2021","2021","27","12","4413","4424","We present a system for designing indoor scenes with convertible furniture layouts. Such layouts are useful for scenarios where an indoor scene has multiple purposes and requires layout conversion, such as merging multiple small furniture objects into a larger one or changing the locus of the furniture. We aim at planning the motion for the convertible layouts of a scene with the most efficient conversion process. To achieve this, our system first establishes object-level correspondences between the layout of a given source and that of a reference to compute a target layout, where the objects are re-arranged in the source layout with respect to the reference layout. After that, our system initializes the movement paths of objects between the source and target layouts based on various mechanical constraints. A joint space-time optimization is then performed to program a control stream of object translations, rotations, and stops, under which the movements of all objects are efficient and the potential object collisions are avoided. We demonstrate the effectiveness of our system through various design examples of multi-purpose, indoor scenes with convertible layouts.","1941-0506","","10.1109/TVCG.2020.3005680","National Natural Science Foundation of China(grant numbers:61902032,61962021); National Science Foundation(grant numbers:IIS-1524782); Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:CityU 11237116); Beihang University(grant numbers:VRLAB2019B01); City University of Hong Kong(grant numbers:7004915); Fundamental Research Funds for the Central Universities(grant numbers:2020RC17); China Postdoctoral Science Foundation(grant numbers:2019M662261); Key Research and Development Program of Jiangxi Province(grant numbers:20192BBE50079); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9128027","Indoor scene synthesis;motion planning;convertible layout","Image analysis;Motion planning;Planning;Optimization;Layout","furniture;object detection;optimisation;path planning","motion planning;convertible indoor scene layout design;convertible furniture layouts;layout conversion;object-level correspondences;target layout;source layout;reference layout;object translations;potential object collisions;joint space-time optimization","","2","","39","IEEE","29 Jun 2020","","","IEEE","IEEE Journals"
"Multiscale Snapshots: Visual Analysis of Temporal Summaries in Dynamic Graphs","E. Cakmak; U. Schlegel; D. Jäckle; D. Keim; T. Schreck","University of Konstanz, Germany; University of Konstanz, Germany; Independent Researcher, Munich, Germany; University of Konstanz, Germany; TU Graz, Austria","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","517","527","The overview-driven visual analysis of large-scale dynamic graphs poses a major challenge. We propose Multiscale Snapshots, a visual analytics approach to analyze temporal summaries of dynamic graphs at multiple temporal scales. First, we recursively generate temporal summaries to abstract overlapping sequences of graphs into compact snapshots. Second, we apply graph embeddings to the snapshots to learn low-dimensional representations of each sequence of graphs to speed up specific analytical tasks (e.g., similarity search). Third, we visualize the evolving data from a coarse to fine-granular snapshots to semi-automatically analyze temporal states, trends, and outliers. The approach enables us to discover similar temporal summaries (e.g., reoccurring states), reduces the temporal data to speed up automatic analysis, and to explore both structural and temporal properties of a dynamic graph. We demonstrate the usefulness of our approach by a quantitative evaluation and the application to a real-world dataset.","1941-0506","","10.1109/TVCG.2020.3030398","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy(grant numbers:EXC 2117 - 422037984); European Union's Horizon 2020 research and innovation programme(grant numbers:830892); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222072","Dynamic Graph;Dynamic Network;Unsupervised Graph Learning;Graph Embedding;Multiscale Visualization","Data visualization;Visual analytics;Task analysis;Dimensionality reduction;Animation;Scalability","data analysis;data visualisation;graph theory","data visualization;multiscale snapshots;large-scale dynamic graphs;overview-driven visual analysis;temporal properties;structural properties;automatic analysis;temporal data;similar temporal summaries;temporal states;fine-granular snapshots;graph embeddings;compact snapshots;multiple temporal scales;dynamic graph;visual analytics","","2","","66","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation","S. Hazarika; H. Li; K. -C. Wang; H. -W. Shen; C. -S. Chou",Department of Computer ScienceOhio State University; Department of Computer ScienceOhio State University; Department of Computer ScienceOhio State University; Department of Computer ScienceOhio State University; Department of MathematicsOhio State University,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","34","44","Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.","1941-0506","","10.1109/TVCG.2019.2934591","US Department of Energy; Los Alamos National Laboratory(grant numbers:47145); UT-Battelle LLC(grant numbers:4000159447); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805421","Surrogate modeling;Neural networks;Computational biology;Visual analysis;Parameter analysis","Analytical models;Computational modeling;Visualization;Biological system modeling;Neural networks;Machine learning;Data models","biology computing;computer simulation;data analysis;data visualisation;interactive systems;learning (artificial intelligence);neural nets","interactive exploratory analysis;trained neural network-based surrogate model;neural networks;interactive parameter sensitivity analysis;neural network assisted visual analysis;complex computational models;yeast cell polarization simulation;backend analysis;computational biologists;NNVA","Computational Biology;Computer Graphics;Models, Biological;Neural Networks, Computer;Yeasts","2","","66","IEEE","19 Aug 2019","","","IEEE","IEEE Journals"
"No mark is an island: Precision and category repulsion biases in data reproductions","C. M. McColeman; L. Harrison; M. Feng; S. Franconeri",Northwestern University; Worcester Polytechnic Institute; Worcester Polytechnic Institute; Northwestern University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1063","1072","Data visualization is powerful in large part because it facilitates visual extraction of values. Yet, existing measures of perceptual precision for data channels (e.g., position, length, orientation, etc.) are based largely on verbal reports of ratio judgments between two values (e.g., [7]). Verbal report conflates multiple sources of error beyond actual visual precision, introducing a ratio computation between these values and a requirement to translate that ratio to a verbal number. Here we observe raw measures of precision by eliminating both ratio computations and verbal reports; we simply ask participants to reproduce marks (a single bar or dot) to match a previously seen one. We manipulated whether the mark was initially presented (and later drawn) alone, paired with a reference (e.g. a second `100%' bar also present at test, or a y-axis for the dot), or integrated with the reference (merging that reference bar into a stacked bar graph, or placing the dot directly on the axis). Reproductions of smaller values were overestimated, and larger values were underestimated, suggesting systematic memory biases. Average reproduction error was around 10% of the actual value, regardless of whether the reproduction was done on a common baseline with the original. In the reference and (especially) the integrated conditions, responses were repulsed from an implicit midpoint of the reference mark, such that values above 50% were overestimated, and values below 50% were underestimated. This reproduction paradigm may serve within a new suite of more fundamental measures of the precision of graphical perception.","1941-0506","","10.1109/TVCG.2020.3030345","National Science Foundation(grant numbers:IIS-190); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288884","Cognition and perception;Graphical perception;Perceptual biases;Ratio perception","Bars;Visualization;Data visualization;Task analysis;Particle measurements;Atmospheric measurements;Semantics","cognition;data visualisation;visual perception","category repulsion;data reproductions;data visualization;visual extraction;perceptual precision;data channels;verbal report;ratio judgments;visual precision;ratio computation;verbal number;raw measures;reference bar;stacked bar graph;smaller values;systematic memory biases;average reproduction error;reference mark;reproduction paradigm","","2","","41","IEEE","9 Dec 2020","","","IEEE","IEEE Journals"
"PICO: Procedural Iterative Constrained Optimizer for Geometric Modeling","V. Krs; R. Měch; M. Gaillard; N. Carr; B. Benes","Adobe Research, San Jose, CA, USA; Adobe Research, San Jose, CA, USA; Department of Computer Graphics Technology, Purdue University, West Lafayette, IN, USA; Adobe Research, San Jose, CA, USA; Department of Computer Graphics Technology, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2021","2021","27","10","3968","3981","Procedural modeling has produced amazing results, yet fundamental issues such as controllability and limited user guidance persist. We introduce a novel procedural model called PICO (Procedural Iterative Constrained Optimizer) and PICO-Graph that is the underlying procedural model designed with optimization in mind. The key novelty of PICO is that it enables the exploration of generative designs by combining both user and environmental constraints into a single framework by using optimization without the need to write procedural rules. The PICO-Graph procedural model consists of a set of geometry generating operations and a set of axioms connected in a directed cyclic graph. The forward generation is initiated by a set of axioms that use the connections to send coordinate systems and geometric objects through the PICO-Graph, which in turn generates more objects. This allows for fast generation of complex and varied geometries. Moreover, we combine PICO-Graph with efficient optimization that allows for quick exploration of the generated models and the generation of variants. The user defines the rules, the axioms, and the set of constraints; for example, whether an existing object should be supported by the generated model, whether symmetries exist, whether the object should spin, etc. PICO then generates a class of geometric models and optimizes them so that they fulfill the constraints. The generation and the optimization in our implementation provides interactive user control during model execution providing continuous feedback. For example, the user can sketch the constraints and guide the geometry to meet these specified goals. We show PICO on a variety of examples such as the generation of procedural chairs with multiple supports, generation of support structures for 3D printing, generation of spinning objects, or generation of procedural terrains matching a given input. Our framework could be used as a component in a larger design workflow; its strongest application is in the early rapid ideation and prototyping phases.","1941-0506","","10.1109/TVCG.2020.2995556","National Science Foundation(grant numbers:#10001387); Functional Proceduralization of 3D Geometric Models; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095367","Computational geometry and object modeling;three-dimensional graphics and realism","Optimization;Geometry;Shape;Computational modeling;Grammar;Three-dimensional displays;Solid modeling","computational geometry;directed graphs;graph theory;iterative methods;optimisation;solid modelling","Procedural Iterative Constrained Optimizer;geometry generating operations;axioms;continuous feedback;PICO Graph procedural model;environmental constraints;user constraints;procedural terrains;procedural chairs;execution model;geometric models;forward generation;directed cyclic graph","","2","","70","IEEE","18 May 2020","","","IEEE","IEEE Journals"
"Perceptually Uniform Motion Space","Å. Birkeland; C. Turkay; I. Viola","Department of Informatics, University of Bergen, Bergen, Hordaland, Norway; Department of Computer Science, City University London, Room: A304C, Northampton Square, London EC1V OHB, United Kingdom; Institute of Computer Graphics and Algorithms, Vienna University of Technology, Favoritenstrasse 9-11, E186, Vienna, Austria","IEEE Transactions on Visualization and Computer Graphics","24 Sep 2014","2014","20","11","1542","1554","Flow data is often visualized by animated particles inserted into a flow field. The velocity of a particle on the screen is typically linearly scaled by the velocities in the data. However, the perception of velocity magnitude in animated particles is not necessarily linear. We present a study on how different parameters affect relative motion perception. We have investigated the impact of four parameters. The parameters consist of speed multiplier, direction, contrast type and the global velocity scale. In addition, we investigated if multiple motion cues, and point distribution, affect the speed estimation. Several studies were executed to investigate the impact of each parameter. In the initial results, we noticed trends in scale and multiplier. Using the trends for the significant parameters, we designed a compensation model, which adjusts the particle speed to compensate for the effect of the parameters. We then performed a second study to investigate the performance of the compensation model. From the second study we detected a constant estimation error, which we adjusted for in the last study. In addition, we connect our work to established theories in psychophysics by comparing our model to a model based on Stevens' Power Law.","1941-0506","","10.1109/TVCG.2014.2322363","VERDIKT(grant numbers:# 193170); MedViz network(grant numbers:PK1760-5897-Project 11); Vienna Science and Technology(grant numbers:VRG11-010); EC Marie Curie Career Integration(grant numbers:PCIG13-GA-2013-618680); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6811168","Motion visualization;motion perception;animation;evaluation;perceptual model","Data visualization;Image color analysis;Brain modeling;Data visualization;Motion detection;Particle measurements","computational fluid dynamics;computer animation;flow visualisation","Stevens power law;psychophysics;constant estimation error;compensation model;speed estimation;point distribution;multiple motion cues;global velocity scale;contrast type;speed multiplier;relative motion perception;velocity magnitude;particle velocity;flow field;animated particles;flow data;perceptually uniform motion space","","2","","31","CCBY","7 May 2014","","","IEEE","IEEE Journals"
"Periphery Plots for Contextualizing Heterogeneous Time-Based Charts","B. Morrow; T. Manz; A. E. Chung; N. Gehlenborg; D. Gotz",UNC-Chapel Hill; Harvard University; UNC-Chapel Hill; Harvard University; UNC-Chapel Hill,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Patterns in temporal data can often be found across different scales, such as days, weeks, and months, making effective visualization of time-based data challenging. Here we propose a new approach for providing focus and context in time-based charts to enable interpretation of patterns across time scales. Our approach employs a focus zone with a time and a second axis, that can either represent quantities or categories, as well as a set of adjacent periphery plots that can aggregate data along the time, value, or both dimensions. We present a framework for periphery plots and describe two use cases that demonstrate the utility of our approach.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933582","Time-based data;Focus + context techniques;Health informatics;mHealth;Patient-generated health data","Data visualization;Visualization;Encoding;Time series analysis;Meteorology;Medical diagnostic imaging;Data models","data visualisation","temporal data;time scales;periphery plots;heterogeneous time-based chart contextualization;time-based data visualization","","2","","20","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Persistent Homology Guided Force-Directed Graph Layouts","A. Suh; M. Hajij; B. Wang; C. Scheidegger; P. Rosen","University of South Florida, Tufts University; Ohio State University; University of Utah; University of Arizona; University of South Florida","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","697","707","Graphs are commonly used to encode relationships among entities, yet their abstractness makes them difficult to analyze. Node-link diagrams are popular for drawing graphs, and force-directed layouts provide a flexible method for node arrangements that use local relationships in an attempt to reveal the global shape of the graph. However, clutter and overlap of unrelated structures can lead to confusing graph visualizations. This paper leverages the persistent homology features of an undirected graph as derived information for interactive manipulation of force-directed layouts. We first discuss how to efficiently extract 0-dimensional persistent homology features from both weighted and unweighted undirected graphs. We then introduce the interactive persistence barcode used to manipulate the force-directed graph layout. In particular, the user adds and removes contracting and repulsing forces generated by the persistent homology features, eventually selecting the set of persistent homology features that most improve the layout. Finally, we demonstrate the utility of our approach across a variety of synthetic and real datasets.","1941-0506","","10.1109/TVCG.2019.2934802","National Science Foundation(grant numbers:IIS-1513616,DBI-1661375); CRA-W Collaborative Research Experiences for Undergraduates (CREU)(grant numbers:DARPA CHESS FA8750-19-C-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807379","Graph drawing;force-directed layout;Topological Data Analysis;persistent homology","Layout;Feature extraction;Visualization;Extraterrestrial measurements;Clutter;Data visualization","data visualisation;directed graphs;interactive systems","unweighted undirected graphs;interactive persistence barcode;persistent homology;node-link diagrams;force-directed layouts;0-dimensional persistent homology features;weighted undirected graphs","","2","","91","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Real-Time View Planning for Unstructured Lumigraph Modeling","O. Erat; M. Hoell; K. Haubenwallner; C. Pirchheim; D. Schmalstieg",Graz University of Technology; Graz University of Technology; Graz University of Technology; Graz University of Technology; Graz University of Technology,"IEEE Transactions on Visualization and Computer Graphics","2 Oct 2019","2019","25","11","3063","3072","We propose an algorithm for generating an unstructured lumigraph in real-time from an image stream. This problem has important applications in mixed reality, such as telepresence, interior design or as-built documentation. Unlike conventional texture optimization in structure from motion, our method must choose views from the input stream in a strictly incremental manner, since only a small number of views can be stored or transmitted. This requires formulating an online variant of the well-known view-planning problem, which must take into account what parts of the scene have already been seen and how the lumigraph sample distribution could improve in the future. We address this highly unconstrained problem by regularizing the scene structure using a regular grid structure. Upon the grid structure, we define a coverage metric describing how well the lumigraph samples cover the grid in terms of spatial and angular resolution, and we greedily keep incoming views if they improve the coverage. We evaluate the performance of our algorithm quantitatively and qualitatively on a variety of synthetic and real scenes, and demonstrate visually appealing results obtained at real-time frame rates (in the range of 3Hz-100Hz per incoming image, depending on configuration).","1941-0506","","10.1109/TVCG.2019.2932237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794622","Lumigraph;virtual reality;rendering;real-time;view planning;keyframe selection;multi-view","Planning;Image reconstruction;Real-time systems;Geometry;Rendering (computer graphics);Computational modeling;Image color analysis","graph theory;image resolution;image texture;interactive systems;rendering (computer graphics);virtual reality","time view planning;unstructured lumigraph modeling;image stream;mixed reality;telepresence;interior design;conventional texture optimization;strictly incremental manner;online variant;well-known view-planning problem;lumigraph sample distribution;highly unconstrained problem;scene structure;regular grid structure;lumigraph samples;spatial resolution;angular resolution;incoming views;synthetic scenes;real scenes;real-time frame rates","","2","","51","IEEE","12 Aug 2019","","","IEEE","IEEE Journals"
"Reducing Photon-Mapping Bandwidth by Query Reordering","J. Steinhurst; G. Coombe; A. Lastra","Department of Computer Science, Bucknell University, Lewisburg, PA; Google Inc., Mountain View, CA; Department of Computer Science, University of North Carolina at Chapel Hill, Sitterson Hall, Chapel Hill, NC","IEEE Transactions on Visualization and Computer Graphics","19 Nov 2007","2008","14","1","13","24","Photon mapping places an enormous burden on the memory hierarchy. Rendering a 512 x 512 image of a simple scene can require more than 196 Gbytes of raw bandwidth to the photon map data structure. This bandwidth is a major obstacle to real-time photon mapping. This paper investigates two approaches for reducing the required bandwidth: 1) reordering the <i>k</i>NN searches and 2) cache conscious data structures. Using a Hilbert curve reordering, we demonstrate an experimental lower bound of 15 Mbytes of bandwidth for the same scene. Unfortunately, this improvement of four orders of magnitude requires a prohibitive amount of intermediate storage. We introduce two novel cost-effective algorithms that reduce the bandwidth by one order of magnitude. Scenes of different complexities are shown to exhibit similar reductions in bandwidth. We explain why the choice of data structure does not achieve similar reductions. We also examine the interaction of query reordering with two photon map acceleration techniques, importance sampling, and the irradiance cache. Query reordering exploits the additional coherence that arises from the use of importance sampling in scenes with glossy surfaces. Irradiance caching also benefits from query reordering, even when complex surface geometry reduces the effectiveness of the irradiance cache.","1941-0506","","10.1109/TVCG.2007.70413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359492","Global Illumination;Photon Mapping;Importance Sampling;Irradiance Caching;Graphics Hardware;Global Illumination;Photon Mapping;Importance Sampling;Irradiance Caching;Graphics Hardware","Bandwidth;Layout;Data structures;Lighting;Casting;Monte Carlo methods;Geometry;Hardware;Rendering (computer graphics);Acceleration","cache storage;data structures;image sampling;rendering (computer graphics)","photon-mapping bandwidth;query reordering;image rendering;photon map data structure;kNN search;Hilbert curve reordering;irradiance cache;importance sampling","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Light;Lighting;Numerical Analysis, Computer-Assisted;Photometry;Photons;Radiation Dosage;Radiometry;Signal Processing, Computer-Assisted;User-Computer Interface","2","3","37","","19 Nov 2007","","","IEEE","IEEE Journals"
"Representing Real-Time Multi-User Collaboration in Visualizations","R. Neogy; J. Zong; A. Satyanarayan",MIT CSAIL; MIT CSAIL; MIT CSAIL,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","146","150","Establishing common ground and maintaining shared awareness amongst participants is a key challenge in collaborative visualization. For real-time collaboration, existing work has primarily focused on synchronizing constituent visualizations - an approach that makes it difficult for users to work independently, or selectively attend to their collaborators' activity. To address this gap, we introduce a design space for representing synchronous multi-user collaboration in visualizations defined by two orthogonal axes: situatedness, or whether collaborators' interactions are overlaid on or shown outside of a user's view, and specificity, or whether collaborators are depicted through abstract, generic representations or through specific means customized for the given visualization. We populate this de-sign space with a variety of examples including generic and custom synchronized cursors, and user legends that collect these cursors together or reproduce collaborators' views as thumbnails. To build common ground, users can interact with these representations by peeking to take a quick look at a collaborator's view, tracking to follow along with a collaborator in real-time, and forking to independently explore the visualization based on a collaborator's work. We present a reference implementation of a wrapper library that converts interactive Vega-Lite charts into collaborative visualizations. We find that our approach affords synchronous collaboration across an expressive range of visual designs and interaction techniques.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331317","Human-centered computing;Visualization;Visualization systems and tools","Visualization;Collaboration;Prototypes;Switches;Tools;Real-time systems;Synchronization","data visualisation;groupware","shared awareness;collaborative visualization;real-time collaboration;constituent visualizations;collaborators;design space;synchronous multiuser collaboration;abstract representations;generic representations;given visualization;generic cursors;custom synchronized cursors;user legends;visual designs;interaction techniques;real-time multiuser collaboration","","2","","25","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Responsive Matrix Cells: A Focus+Context Approach for Exploring and Editing Multivariate Graphs","T. Horak; P. Berger; H. Schumann; R. Dachselt; C. Tominski","Interactive Media LabTechnische Universitat Dresden; Inst. for Visual & Analytic Computing, University of Rostock; Inst. for Visual & Analytic Computing, University of Rostock; Interactive Media LabTechnische Universitat Dresden; Inst. for Visual & Analytic Computing, University of Rostock","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1644","1654","Matrix visualizations are a useful tool to provide a general overview of a graph's structure. For multivariate graphs, a remaining challenge is to cope with the attributes that are associated with nodes and edges. Addressing this challenge, we propose responsive matrix cells as a focus+context approach for embedding additional interactive views into a matrix. Responsive matrix cells are local zoomable regions of interest that provide auxiliary data exploration and editing facilities for multivariate graphs. They behave responsively by adapting their visual contents to the cell location, the available display space, and the user task. Responsive matrix cells enable users to reveal details about the graph, compare node and edge attributes, and edit data values directly in a matrix without resorting to external views or tools. We report the general design considerations for responsive matrix cells covering the visual and interactive means necessary to support a seamless data exploration and editing. Responsive matrix cells have been implemented in a web-based prototype based on which we demonstrate the utility of our approach. We describe a walk-through for the use case of analyzing a graph of soccer players and report on insights from a preliminary user feedback session.","1941-0506","","10.1109/TVCG.2020.3030371","DFG(grant numbers:214484876,389792660); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226461","Multivariate graph visualization;matrix visualization;focus+context;embedded visualizations;responsive visualization;graph editing","Data visualization;Visualization;Task analysis;Layout;Lenses;Tools;Encoding","data visualisation;graph theory;interactive systems;Internet;matrix algebra","Web-based prototype;interactive views;visual contents;auxiliary data exploration;matrix visualizations;editing multivariate graphs;focus+context approach;responsive matrix cells","","2","","83","CCBY","16 Oct 2020","","","IEEE","IEEE Journals"
"Retrieve-Then-Adapt: Example-based Automatic Generation for Proportion-related Infographics","C. Qian; S. Sun; W. Cui; J. -G. Lou; H. Zhang; D. Zhang",Microsoft Research AsiaPeking University; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","443","452","Infographic is a data visualization technique which combines graphic and textual descriptions in an aesthetic and effective manner. Creating infographics is a difficult and time-consuming process which often requires significant attempts and adjustments even for experienced designers, not to mention novice users with limited design expertise. Recently, a few approaches have been proposed to automate the creation process by applying predefined blueprints to user information. However, predefined blueprints are often hard to create, hence limited in volume and diversity. In contrast, good infogrpahics have been created by professionals and accumulated on the Internet rapidly. These online examples often represent a wide variety of design styles, and serve as exemplars or inspiration to people who like to create their own infographics. Based on these observations, we propose to generate infographics by automatically imitating examples. We present a two-stage approach, namely retrieve-then-adapt. In the retrieval stage, we index online examples by their visual elements. For a given user information, we transform it to a concrete query by sampling from a learned distribution about visual elements, and then find appropriate examples in our example library based on the similarity between example indexes and the query. For a retrieved example, we generate an initial drafts by replacing its content with user information. However, in many cases, user information cannot be perfectly fitted to retrieved examples. Therefore, we further introduce an adaption stage. Specifically, we propose a MCMC-like approach and leverage recursive neural networks to help adjust the initial draft and improve its visual appearance iteratively, until a satisfactory result is obtained. We implement our approach on widely-used proportion-related infographics, and demonstrate its effectiveness by sample results and expert reviews.","1941-0506","","10.1109/TVCG.2020.3030448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233469","Infographics;automatic visualization","Visualization;Layout;Libraries;Tools;Internet;Indexes;Neural networks","data visualisation;image retrieval;Internet;learning (artificial intelligence);neural nets","example-based automatic generation;data visualization technique;graphic descriptions;textual descriptions;aesthetics;experienced designers;design expertise;creation process;predefined blueprints;online examples;design styles;two-stage approach;retrieval stage;visual elements;user information;example library;example indexes;adaption stage;visual appearance;proportion-related infographics;initial draft generation;retrieve-then-adapt;Internet;MCMC-like approach;recursive neural networks","","2","","38","IEEE","20 Oct 2020","","","IEEE","IEEE Journals"
"SANVis: Visual Analytics for Understanding Self-Attention Networks","C. Park; I. Na; Y. Jo; S. Shin; J. Yoo; B. C. Kwon; J. Zhao; H. Noh; Y. Lee; J. Choo","Korea University; Korea University; Korea University; University of Maryland; Korea University; IBM Research; University of Waterloo; NCSOFT Co., LTD.; NCSOFT Co., LTD.; Korea University","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","146","150","Attention networks, a deep neural network architecture inspired by humans' attention mechanism, have seen significant success in image captioning, machine translation, and many other applications. Recently, they have been further evolved into an advanced approach called multi-head self-attention networks, which can encode a set of input vectors, e.g., word vectors in a sentence, into another set of vectors. Such encoding aims at simultaneously capturing diverse syntactic and semantic features within a set, each of which corresponds to a particular attention head, forming altogether multi-head attention. Meanwhile, the increased model complexity prevents users from easily understanding and manipulating the inner workings of models. To tackle the challenges, we present a visual analytics system called SANVis, which helps users understand the behaviors and the characteristics of multi-head self-attention networks. Using a state-of-the-art self-attention model called Transformer, we demonstrate usage scenarios of SANVis in machine translation tasks. Our system is available at http://short.sanvis.org.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933677","Deep neural networks;visual analytics;natural language processing;interpretability;self-attention networks","Visual analytics;Magnetic heads;Decoding;Task analysis;Analytical models;Entropy","data analysis;data visualisation;language translation;learning (artificial intelligence);natural language processing;neural nets","deep neural network architecture;human attention mechanism;multihead self-attention networks;visual analytics system;SANVis;image captioning;syntactic features;semantic features;model complexity;machine translation tasks","","2","","35","","19 Dec 2019","","","IEEE","IEEE Conferences"
"SSR-TVD: Spatial Super-Resolution for Time-Varying Data Analysis and Visualization","J. Han; C. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana, United States, (e-mail: jhan5@nd.edu); Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana, United States, (e-mail: chaoli.wang@nd.edu)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","We present SSR-TVD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of time-varying data (TVD) using adversarial learning. In scientific visualization, SSR-TVD is the first work that applies the generative adversarial network (GAN) to generate high-resolution volumes for three-dimensional time-varying data sets. The design of SSR-TVD includes a generator and two discriminators (spatial and temporal discriminators). The generator takes a low-resolution volume as input and outputs a synthesized high-resolution volume. To capture spatial and temporal coherence in the volume sequence, the two discriminators take the synthesized high-resolution volume(s) as input and produce a score indicating the realness of the volume(s). Our method can work in the in situ visualization setting by downscaling volumetric data from selected time steps as the simulation runs and upscaling downsampled volumes to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-TVD, we show quantitative and qualitative results with several time-varying data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation and a solution solely based on CNN.","1941-0506","","10.1109/TVCG.2020.3032123","National Science Foundation(grant numbers:CNS-1629914,DUE-1833129,IIS-1455886,IIS-1955395); Nvidia(grant numbers:GPU Grant Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229162","Time-varying data visualization;deep learning;super-resolution;generative adversarial network","Data visualization;Coherence;Deep learning;Generative adversarial networks;Training;Gallium nitride","","","","2","","","IEEE","19 Oct 2020","","","IEEE","IEEE Early Access Articles"
"ShapeWordle: Tailoring Wordles using Shape-aware Archimedean Spirals","Y. Wang; X. Chu; K. Zhang; C. Bao; X. Li; J. Zhang; C. -W. Fu; C. Hurter; O. Deussen; B. Lee","Shandong University; Shandong University; Shandong University; Shandong University; Shandong University; CNIC, CAS; Chinese University of Hong Kong; ENAC, France; Konstanz University, Germany; Microsoft Research","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","991","1000","We present a new technique to enable the creation of shape-bounded Wordles, we call ShapeWordle, in which we fit words to form a given shape. To guide word placement within a shape, we extend the traditional Archimedean spirals to be shape-aware by formulating the spirals in a differential form using the distance field of the shape. To handle non-convex shapes, we introduce a multi-centric Wordle layout method that segments the shape into parts for our shape-aware spirals to adaptively fill the space and generate word placements. In addition, we offer a set of editing interactions to facilitate the creation of semantically-meaningful Wordles. Lastly, we present three evaluations: a comprehensive comparison of our results against the state-of-the-art technique (WordArt), case studies with 14 users, and a gallery to showcase the coverage of our technique.","1941-0506","","10.1109/TVCG.2019.2934783","National Key Research & Development Plan of China(grant numbers:2016YFB1001404); National Natural Science Foundation of China(grant numbers:61772315,61861136012); NSFC-Guangdong Joint Fund(grant numbers:U1501255); Leading Talents of Guangdong Program(grant numbers:00201509); CAS(grant numbers:GJHZ1862); DFG Center of Excellence 2117 “Centre for the advanced Study of Collective Behaviour”(grant numbers:422037984); Research Grants Council of the Hong Kong Special Administrative Region(grant numbers:CUHK 14203416); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807355","Wordle;Archimedean spiral;shape","Shape;Layout;Spirals;Tag clouds;Image color analysis;Tools;Semantics","art;computational geometry;data analysis;data visualisation","ShapeWordle;shape-aware Archimedean spirals;shape-bounded Wordles;word placement;traditional Archimedean spirals;differential form;nonconvex shapes;multicentric Wordle layout method;shape-aware spirals;semantically-meaningful Wordles","","2","","42","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"Sketch-Based Fast and Accurate Querying of Time Series Using Parameter-Sharing LSTM Networks","C. Fan; K. Matković; H. Hauser","University of Bergen, Bergen, Norway; VRVis Research Center, Wien, Austria; University of Bergen, Bergen, Norway","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2021","2021","27","12","4495","4506","Sketching is one common approach to query time series data for patterns of interest. Most existing solutions for matching the data with the interaction are based on an empirically modeled similarity function between the user’s sketch and the time series data with limited efficiency and accuracy. In this article, we introduce a machine learning based solution for fast and accurate querying of time series data based on a swift sketching interaction. We build on existing LSTM technology (long short-term memory) to encode both the sketch and the time series data in a network with shared parameters. We use data from a user study to let the network learn a proper similarity function. We focus our approach on perceived similarities and achieve that the learned model also includes a user-side aspect. To the best of our knowledge, this is the first data-driven solution for querying time series data in visual analytics. Besides evaluating the accuracy and efficiency directly in a quantitative way, we also compare our solution to the recently published Qetch algorithm as well as the commonly used dynamic time warping (DTW) algorithm.","1941-0506","","10.1109/TVCG.2020.3002950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9119141","Machine learning;sketch-based interaction;visual analytics;time series data","Time series analysis;Machine learning;Time series analysis;Data visualization;Data models;Heuristic algorithms","data visualisation;learning (artificial intelligence);query processing;time series","sketch-based fast;accurate querying;parameter-sharing LSTM networks;sketching;time series data;data-driven solution","","2","","46","IEEE","16 Jun 2020","","","IEEE","IEEE Journals"
"Slope-Dependent Rendering of Parallel Coordinates to Reduce Density Distortion and Ghost Clusters","D. Pomerenke; F. L. Dennig; D. A. Keim; J. Fuchs; M. Blumenschein","University of Konstanz,Germany; University of Konstanz,Germany; University of Konstanz,Germany; University of Konstanz,Germany; University of Konstanz,Germany","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","86","90","Parallel coordinates are a popular technique to visualize multidimensional data. However, they face a significant problem influencing the perception and interpretation of patterns. The distance between two parallel lines differs based on their slope. Vertical lines are rendered longer and closer to each other than horizontal lines. This problem is inherent in the technique and has two main consequences: (1) clusters which have a steep slope between two axes are visually more prominent than horizontal clusters. (2) Noise and clutter can be perceived as clusters, as a few parallel vertical lines visually emerge as a ghost cluster. Our paper makes two contributions: First, we formalize the problem and show its impact. Second, we present a novel technique to reduce the effects by rendering the polylines of the parallel coordinates based on their slope: horizontal lines are rendered with the default width, lines with a steep slope with a thinner line. Our technique avoids density distortions of clusters, can be computed in linear time, and can be added on top of most parallel coordinate variations. To demonstrate the usefulness, we show examples and compare them to the classical rendering.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933706","Parallel coordinates;rendering;density distortion.","Rendering (computer graphics);Distortion;Clutter;Visualization;Distributed databases;Data visualization;Geometry","computational geometry;data visualisation;pattern clustering;rendering (computer graphics)","parallel coordinates;multidimensional data visualization;horizontal lines;ghost cluster;density distortion;slope-dependent rendering;pattern interpretation;vertical lines;polyline rendering","","2","","20","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Structured penumbral irradiance computation","G. Drettakis; E. L. Flume","Inst. Nat. de Recherche en Inf. et Autom., Grenoble, France; NA","IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","1996","2","4","299","312","A definitive understanding of irradiance behavior in penumbral regions has been hard to come by, mainly due to the computational expense of determining the visible parts of an area light source. Consequently, sampling strategies have been mostly ad hoc, and evaluation of the resulting approximations has been difficult. In this paper, the structure of penumbral irradiance is investigated empirically and numerically. This study has been made feasible by the use of the discontinuity mesh and the backprojection, an efficient data structure representing visibility in regions of partial occlusion. Regions of penumbrae in which irradiance varies nonmonotonically are characterized empirically, and numerical tests are performed to determine the frequency of their occurrence. This study inspired the development of two algorithms for the construction of interpolating approximations to irradiance: one algorithm reduces the number of edges in the mesh defining the interpolant domain; and the other algorithm chooses among linear, quadratic, and mixed interpolants based on irradiance monotonicity. Results from numerical tests and images are presented that demonstrate good performance of the new algorithms for various realistic test configurations.","1941-0506","","10.1109/2945.556499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556499","","Lighting;Light sources;Testing;Layout;Sampling methods;Data structures;Frequency;Image sampling;Performance evaluation;Interpolation","brightness;rendering (computer graphics);computational geometry;data structures;interpolation;mesh generation","structured penumbral irradiance computation;computational expense;area light source;sampling strategies;approximations;discontinuity mesh;backprojection;data structure;partial occlusion;numerical tests;interpolating approximations;mixed interpolants;linear interpolants;quadratic interpolants;irradiance monotonicity;performance;rendering;illumination;radiosity","","2","","34","","6 Aug 2002","","","IEEE","IEEE Journals"
"<italic>TaxThemis</italic>: Interactive Mining and Exploration of Suspicious Tax Evasion Groups","Y. Lin; K. Wong; Y. Wang; R. Zhang; B. Dong; H. Qu; Q. Zheng","MOEKLINNS LabXi 'an Jiaotong University; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; National Engineering Lab of Big Data Analytics, Xi'an Jiaotong University; Hong Kong University of Science and Technology; MOEKLINNS LabXi 'an Jiaotong University","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","849","859","Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.","1941-0506","","10.1109/TVCG.2020.3030370","National Key Research and Development Program of China(grant numbers:2016YFB1000903); MOE Innovation Research(grant numbers:IRT_17R86); National Science Foundation of China(grant numbers:61721002,61532015); HK RGC GRF(grant numbers:16213317); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222068","Visual Analytics;Tax Network;Tax Evasion Detection;Anomaly detection;Multidimensional data","Finance;Data visualization;Visual analytics;Bars;Network topology;Investment","data analysis;data mining;data visualisation;profitability;taxation","TaxThemis;interactive mining;government;unfair business competition environment;data analytics;related party transaction tax evasion;interactive visual analytics system;heterogeneous tax-related data;taxpayer network;suspicious RPTTE groups;suspicious transactions;related taxpayers;related party transactions;real-world tax-related data;suspicious tax evasion group mining","","2","","41","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"The Anatomical Edutainer","M. Schindler; H. -Y. Wu; R. G. Raidou","TU Wien,Austria; TU Wien,Austria; TU Wien,Austria","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","1","5","Physical visualizations (i.e., data representations by means of physical objects) have been used for many centuries in medical and anatomical education. Recently, 3D printing techniques started also to emerge. Still, other medical physicalizations that rely on affordable and easy-to-find materials are limited, while smart strategies that take advantage of the optical properties of our physical world have not been thoroughly investigated. We propose the Anatomical Edutainer, a workflow to guide the easy, accessible, and affordable generation of physicalizations for tangible, interactive anatomical edutainment. The Anatomical Edutainer supports 2D printable and 3D foldable physicalizations that change their visual properties (i.e., hues of the visible spectrum) under colored lenses or colored lights, to reveal distinct anatomical structures through user interaction.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331275","Human-centered computing;Visualization;Visualization application domains;Scientific visualization;Applied computing;Life and medical sciences","Visualization;Three-dimensional displays;Two dimensional displays;Education;Three-dimensional printing;Optical materials;Lenses","biomedical education;computer aided instruction;data visualisation;entertainment;interactive systems;medical computing;solid modelling;three-dimensional printing;virtual reality","interactive anatomical edutainment;3D foldable physicalizations;visual properties;distinct anatomical structures;physical visualizations;data representations;physical objects;medical education;anatomical education;3D printing;medical physicalizations;physical world;tangible anatomical edutainment;anatomical edutainer;optical properties","","2","","31","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Thumbnails for Data Stories: A Survey of Current Practices","H. Kim; J. Oh; Y. Han; S. Ko; M. Brehmer; B. C. Kwon",UNIST; UNIST; UNIST; UNIST; UNIST; IBM Research,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","116","120","When people browse online news, small thumbnail images accompanying links to articles attract their attention and help them to decide which articles to read. As an increasing proportion of online news can be construed as data journalism, we have witnessed a corresponding increase in the incorporation of visualization in article thumbnails. However, there is little research to support alternative design choices for visualization thumbnails, which include resizing, cropping, simplifying, and embellishing charts appearing within the body of the associated article. We therefore sought to better understand these design choices and determine what makes a visualization thumbnail inviting and interpretable. This paper presents our findings from a survey of visualization thumbnails collected online and from conversations with data journalists and news graphics designers. Our study reveals that there exists an uncharted design space, one that is in need of further empirical study. Our work can thus be seen as a first step toward providing structured guidance on how to design thumbnails for data stories.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933773","Human-centered computing;Visualization","Data visualization;Journalism;Media;Bars;Organizations;Visualization","data visualisation;human computer interaction;journalism","visualization thumbnail;data journalists;news graphics designers;data stories;thumbnail images;data journalism;article thumbnails","","2","","37","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Time Varying Predominance Tag Maps","M. Reckziegel; S. Jänicke",Leipzig University; Southern University of Denmark,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","231","235","Visually conveying time-dependent changes in tag maps is insufficiently addressed by current approaches. Typically, for each time range a tag map is determined, and the change between tag maps of subsequent time ranges is progressively visualized. Our method compares tag maps locally in order to enable a continuous display of geographical topic changes among subsequent time ranges. We further provide an alternate tag map variant focusing on frequency changes instead of relative frequency values to visualize the geospatial-temporal rise and fall of topics.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933654","visualization;geo-spatial;time-dependent;point-based data;data aggregation","Visualization;Data visualization;Tag clouds;Market research;Animation;Histograms;Geospatial analysis","data aggregation;data visualisation;geographic information systems","time varying predominance tag maps;geographical topic changes","","2","","30","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Toward Perception-Based Evaluation of Clustering Techniques for Visual Analytics","M. Aupetit; M. Sedlmair; M. M. Abbas; A. Baggag; H. Bensmail","HBKU,QCRI,Doha; University of Stuttgart,VISUS; HBKU,QCRI,Doha; HBKU,QCRI,Doha; HBKU,QCRI,Doha","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","141","145","Automatic clustering techniques play a central role in Visual Analytics by helping analysts to discover interesting patterns in high-dimensional data. Evaluating these clustering techniques, however, is difficult due to the lack of universal ground truth. Instead, clustering approaches are usually evaluated based on a subjective visual judgment of low-dimensional scatterplots of different datasets. As clustering is an inherent human-in-the-loop task, we propose a more systematic way of evaluating clustering algorithms based on quantification of human perception of clusters in 2D scatterplots. The core question we are asking is in how far existing clustering techniques align with clusters perceived by humans. To do so, we build on a dataset from a previous study [1], in which 34 human subjects la-beled 1000 synthetic scatterplots in terms of whether they could see one or more than one cluster. Here, we use this dataset to benchmark state-of-the-art clustering techniques in terms of how far they agree with these human judgments. More specifically, we assess 1437 variants of K-means, Gaussian Mixture Models, CLIQUE, DBSCAN, and Agglomerative Clustering techniques on these benchmarks data. We get unexpected results. For instance, CLIQUE and DBSCAN are at best in slight agreement on this basic cluster counting task, while model-agnostic Agglomerative clustering can be up to a substantial agreement with human subjects depending on the variants. We discuss how to extend this perception-based clustering benchmark approach, and how it could lead to the design of perception-based clustering techniques that would better support more trustworthy and explainable models of cluster patterns.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933620","H.1.2 [User/Machine Systems]: Human factors;I.5.3 [Clustering]: Algorithms;I.5.2 [Design Methodology]: Pattern analysis","Benchmark testing;Task analysis;Data models;Two dimensional displays;Merging;Visualization;Gaussian mixture model","data analysis;data mining;data visualisation;Gaussian processes;pattern clustering","agglomerative clustering techniques;basic cluster counting task;perception-based clustering;visual analytics;clustering approaches;subjective visual judgment;human-in-the-loop task;clustering algorithms;human perception;perception-based evaluation;model-agnostic agglomerative clustering;k-means clustering;Gaussian mixture models;CLIQUE clustering;DBSCAN clustering","","2","","38","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Towards Enhancing RadViz Analysis and Interpretation","M. Angelini; G. Blasilli; S. Lenti; A. Palleschi; G. Santucci",Sapienza University of Rome; Sapienza University of Rome; Sapienza University of Rome; Sapienza University of Rome; Sapienza University of Rome,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","226","230","RadViz plots are commonly used to represent multidimensional data because they use the familiar notion of 2D points for encoding data elements, displaying the original data dimensions that act as springs for setting the x andy coordinates. However, this intuitive approach implies several drawbacks and produces misleading visualizations that can confuse the user, even while analyzing a single data point. The paper attacks this problem following the well known idea of changing the order of the dimensions and introducing ancillary visualizations to mitigate some of RadViz drawbacks. In particular, the paper defines the notion of point optimal disposition of the dimensions for a single data point, generalizes this concept to a set of data points, and proposes effective heuristics for dealing with the intractable problem of exploring all the (n-1)!/2 dispositions of the dimensions along the RadViz circumference. Additional views, visual quality metrics, and a circular grid superimposed on the RadViz complement the attribute reordering strategy and provide abetter understanding of the actual plot of the data elements.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933775","RadViz;dimension arrangement;multiple views","Data visualization;Visualization;Distortion;Springs;Proposals;Task analysis;Layout","data visualisation","ancillary visualizations;data elements encoding;RadViz analysis enhancement;visual quality metrics;RadViz circumference;data points;point optimal disposition;RadViz drawbacks;data dimensions;2D points;multidimensional data representation;RadViz plots;data elements","","2","","28","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Trrack: A Library for Provenance-Tracking in Web-Based Visualizations","Z. Cutler; K. Gadhave; A. Lex",University of Utah; University of Utah; University of Utah,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","116","120","Provenance-tracking is widely acknowledged as an important feature of visualization systems. By tracking provenance data, visualization designers can provide a wide variety of functionality, ranging from action recovery (undo/redo), reproducibility, collaboration and sharing, to logging in support of quantitative and longitudinal evaluation. However, no widely used library that can provide that functionality is current available. As a consequence, visualization designers either develop ad hoc solutions that are rarely comprehensive, or do not track provenance at all. In this paper, we introduce a web-based software library - Trrack - that is designed for easy integration in existing or future visualization systems. Trrack supports a wide range of use cases, from simple action recovery, to capturing intent and reasoning, and can be used to share states with collaborators and store provenance on a server. Trrack also includes an optional provenance visualization component that supports annotation of states and aggregation of events.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00030","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331264","Human-centered computing;Visualization;Visualization systems and tools","Visualization;Software libraries;Annotations;Data visualization;Collaboration;Tools;Servers","data integrity;data visualisation;Internet;software libraries","Web based visualization;Trrack;provenance visualization;Web based software library;provenance data tracking","","2","","20","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Visual Analytics of a Computer-Aided Diagnosis System for Pancreatic Lesions","K. Dmitriev; J. Marino; K. Baker; A. E. Kaufman","Computer Science Department, Stony Brook University, Stony Brook, NY, USA; Computer Science Department, Stony Brook University, Stony Brook, NY, USA; Radiology Department, Stony Brook Medicine, Stony Brook, NY, USA; Computer Science Department, Stony Brook University, Stony Brook, NY, USA","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","3","2174","2185","Machine learning is a powerful and effective tool for medical image analysis to perform computer-aided diagnosis (CAD). Having great potential in improving the accuracy of a diagnosis, CAD systems are often analyzed in terms of the final accuracy, leading to a limited understanding of the internal decision process, impossibility to gain insights, and ultimately to skepticism from clinicians. We present a visual analytics approach to uncover the decision-making process of a CAD system for classifying pancreatic cystic lesions. This CAD algorithm consists of two distinct components: random forest (RF), which classifies a set of predefined features, including demographic features, and a convolutional neural network (CNN), which analyzes radiological (imaging) features of the lesions. We study the class probabilities generated by the RF and the semantical meaning of the features learned by the CNN. We also use an eye tracker to better understand which radiological features are particularly useful for a radiologist to make a diagnosis and to quantitatively compare with the features that lead the CNN to its final classification decision. Additionally, we evaluate the effects and benefits of supplying the CAD system with a case-based visual aid in a second-reader setting.","1941-0506","","10.1109/TVCG.2019.2947037","National Science Foundation(grant numbers:NRT1633299,CNS1650499,OAC1919752); Marcus Foundation; NIH NHLBI(grant numbers:U01HL127522); NY State Center for Biotechnology; Cold Spring Harbor Laboratory; Brookhaven National Laboratory; Feinstein Institute for Medical Research; NY State Dept. of Economic Development(grant numbers:C14051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868209","Radiomics;pancreas;abdominal imaging;machine learning;computer-aided diagnosis;cancer","Lesions;Visualization;Solid modeling;Machine learning;Analytical models;Computed tomography;Cancer","convolutional neural nets;data visualisation;decision making;feature extraction;image classification;medical image processing;probability;random forests","computer-aided diagnosis system;pancreatic lesions;machine learning;medical image analysis;CAD system;internal decision process;visual analytics approach;decision-making process;pancreatic cystic lesions;RF;predefined features;demographic features;CNN;radiological features;case-based visual aid","Adult;Algorithms;Female;Humans;Image Interpretation, Computer-Assisted;Machine Learning;Male;Neural Networks, Computer;Pancreas;Pancreatic Neoplasms;Radiography, Abdominal;Young Adult","2","","65","IEEE","14 Oct 2019","","","IEEE","IEEE Journals"
"Visual Cues in Estimation of Part-To-Whole Comparisons","S. Redmond","Accenture plc,National College of Ireland","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Pie charts were first published in 1801 by William Playfair and have caused some controversy since. Despite the suggestions of many experts against their use, several empirical studies have shown that pie charts are at least as good as alternatives. From Brinton to Few on one side and Eells to Kosara on the other, there appears to have been a hundred-year war waged on the humble pie. In this paper a set of experiments are reported that compare the performance of pie charts and horizontal bar charts with various visual cues. Amazon's Mechanical Turk service was employed to perform the tasks of estimating segments in various part-to-whole charts. The results lead to recommendations for data visualization professionals in developing dashboards.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933718","Human-centered computing;Visualization;Empirical studies in visualization;Visualization design and evaluation methods","Bars;Visualization;Estimation;Data visualization;Task analysis;Indexes;Human computer interaction","bar charts;data visualisation","pie charts;horizontal bar charts;visual cues;part-to-whole charts;data visualization professionals;humble pie;part-to-whole comparisons;Amazon Mechanical Turk service","","2","","18","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visualization of Morse Connection Graphs for Topologically Rich 2D Vector Fields","A. Szymczak; L. Sipeki",Colorado School of Mines; Colorado School of Mines,"IEEE Transactions on Visualization and Computer Graphics","16 Oct 2013","2013","19","12","2763","2772","Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.","1941-0506","","10.1109/TVCG.2013.229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634162","Trajectory;Computer graphics;Topology;Corporate acquisitions;Two dimensional displays;Morse connection graph;Vector field topology","Trajectory;Computer graphics;Topology;Corporate acquisitions;Two dimensional displays","data visualisation;graph theory;vectors","Morse connection graph visualization;multiscale graph representations;Morse sets;stationary points;periodic trajectories;topologically rich 2D vector fields;MCG visual representation;MCG arcs;MCG nodes;PC vector field;piecewise constant vector field;topological skeletons","Algorithms;Computer Simulation;Image Enhancement;Imaging, Three-Dimensional;Models, Theoretical","2","","34","","16 Oct 2013","","","IEEE","IEEE Journals"
"Visualizing Hierarchical Performance Profiles of Parallel Codes Using <sc>CallFlow</sc>","H. T. Nguyen; A. Bhatele; N. Jain; S. P. Kesavan; H. Bhatia; T. Gamblin; K. -L. Ma; P. -T. Bremer","Department of Computer Science, University of California, Davis, CA, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; NVIDIA, Inc, Santa Clara, CA; Department of Computer Science, University of California, Davis, CA, USA; Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA; Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA; Department of Computer Science, University of California, Davis, CA, USA; Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA","IEEE Transactions on Visualization and Computer Graphics","25 Feb 2021","2021","27","4","2455","2468","Calling context trees (CCTs) couple performance metrics with call paths, helping understand the execution and performance of parallel programs. To identify performance bottlenecks, programmers and performance analysts visually explore CCTs to form and validate hypotheses regarding degraded performance. However, due to the complexity of parallel programs, existing visual representations do not scale to applications running on a large number of processors. We present CallFlow, an interactive visual analysis tool that provides a high-level overview of CCTs together with semantic refinement operations to progressively explore CCTs. Using a flow-based metaphor, we visualize a CCT by treating execution time as a resource spent during the call chain, and demonstrate the effectiveness of our design with case studies on large-scale, production simulation codes.","1941-0506","","10.1109/TVCG.2019.2953746","U.S. Department of Energy(grant numbers:DE-AC52-07NA27344); U.S. Department of Energy(grant numbers:DE-SC0014917. LLNL-JRNL-797378); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901998","Performance analysis;software visualization;visual analytics;hierarchical data;coordinated and multiple views","Data visualization;Tools;Visualization;Layout;Vegetation;Histograms;Measurement","data visualisation;parallel programming;query processing;trees (mathematics);very large databases","parallel codes;CallFlow;calling context trees;CCT;parallel programs;degraded performance;visual representations;interactive visual analysis tool;high-level overview;semantic refinement operations;execution time;production simulation codes;hierarchical performance profiles","","2","","59","IEEE","15 Nov 2019","","","IEEE","IEEE Journals"
"Visualizing Information on Watch Faces: A Survey with Smartwatch Users","A. Islam; A. Bezerianos; B. Lee; T. Blascheck; P. Isenberg","Université Paris-Saclay,CNRS, Inria, LRI; Université Paris-Saclay,CNRS, Inria, LRI; Microsoft Research; University of Stuttgart; Université Paris-Saclay,CNRS, Inria, LRI","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","156","160","People increasingly wear smartwatches that can track a wide variety of data. However, it is currently unknown which data people consume and how it is visualized. To better ground research on smartwatch visualization, it is important to understand the current use of these representation types on smartwatches, and to identify missed visualization opportunities. We present the findings of a survey with 237 smartwatch wearers, and assess the types of data and representations commonly displayed on watch faces. We found a predominant display of health & fitness data, with icons accompanied by text being the most frequent representation type. Combining these results with a further analysis of online searches of watch faces and the data tracked on smartwatches that are not commonly visualized, we discuss opportunities for visualization research. Supplementary material is available at https://osf.io/nwy2r/.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331267","Human-centered computing;Visualization;Empirical studies in visualization;Mobile devices","Conferences;Data visualization;Faces","data visualisation;mobile computing;watches","information visualization;watch faces;data people;smartwatch visualization;representation types;frequent representation type;visualization research;health and fitness data;smartwatch wearers;visualization opportunities","","2","","29","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Visualizing RNN States with Predictive Semantic Encodings","L. Sawatzky; S. Bergner; F. Popowich","Simon Fraser University,School of Computing Science; Simon Fraser University,School of Computing Science; Simon Fraser University,School of Computing Science","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","156","160","Recurrent Neural Networks are an effective and prevalent tool used to model sequential data such as natural language text. However, their deep nature and massive number of parameters pose a challenge for those intending to study precisely how they work. We present a visual technique that gives a high level intuition behind the semantics of the hidden states within Recurrent Neural Networks. This semantic encoding allows for hidden states to be compared throughout the model independent of their internal details. The proposed technique is displayed in a proof of concept visualization tool which is demonstrated to visualize the natural language processing task of language modelling.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933744","Human-centered computing;Visualization;Visualization techniques","Visualization;Semantics;Task analysis;Encoding;Image color analysis;Probability distribution;Recurrent neural networks","data visualisation;natural language processing;recurrent neural nets;text analysis","recurrent neural networks;semantic encoding;concept visualization tool;natural language processing task;language modelling;predictive semantic encodings;sequential data;natural language text;RNN states visualization","","2","","19","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Vortex Boundary Identification using Convolutional Neural Network","M. Berenjkoub; G. Chen; T. Günther",University of Houston and Nvidia Inc.; University of Houston; FAU Erlangen-Nürnberg,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","261","265","Feature extraction is an integral component of scientific visualization, and specifically in situations in which features are difficult to formalize, deep learning has great potential to aid in data analysis. In this paper, we develop a deep neural network that is capable of finding vortex boundaries. For training data generation, we employ a parametric flow model that generates thousands of vector field patches with known ground truth. Compared to previous methods, our approach does not require the manual setting of a threshold in order to generate the training data or to extract the vortices. After supervised learning, we apply the method to numerical fluid flow simulations, demonstrating its applicability in practice. Our results show that the vortices extracted using the proposed method can capture more accurate behavior of the vortices in the flow.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00059","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331265","Vortex boundary;convolutional neural network","Neural networks;Supervised learning;Training data;Manuals;Fluid flow;Feature extraction;Numerical models","computational fluid dynamics;computational geometry;convolutional neural nets;data analysis;data visualisation;deep learning (artificial intelligence);feature extraction;flow simulation;supervised learning;vortices","fluid dynamics;feature extraction;convolutional neural network;vortex boundary identification;numerical fluid flow simulations;supervised learning;parametric flow model;training data generation;vortex boundaries;deep neural network;data analysis;deep learning;scientific visualization","","2","","43","","1 Feb 2021","","","IEEE","IEEE Conferences"
"3D Talking Face with Personalized Pose Dynamics","C. Zhang; S. Ni; Z. Fan; H. Li; M. Zeng; M. Budagavi; X. Guo","Computer Science, The University of Texas at Dallas, 12335 DALLAS, Texas, United States, 75252 (e-mail: chenxu.zhang@utdallas.edu); Standards and Mobility Innovation Lab, Samsung Research America, 497524 Mountain View, California, United States, (e-mail: saifeng.ni@samsung.com); Electrical and Computer Engineering, New York University, 5894 New York, New York, United States, (e-mail: zf606@nyu.edu); Computer Science, The University of Texas at Dallas, 12335 Richardson, Texas, United States, (e-mail: hongbo.li@utdallas.edu); Software School, Xiamen University, 12466 Xiamen, Fujian, China, (e-mail: zengming@xmu.edu.cn); Standards and Mobility Innovation Lab, Samsung Research America, 497524 Plano, Texas, United States, (e-mail: m.budagavi@samsung.com); Computer Science, The University of Texas at Dallas, 12335 Richardson, Texas, United States, (e-mail: xguo@utdallas.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Recently, we have witnessed a boom in applications for 3D talking face generation. However, most existing 3D face generation methods can only generate 3D faces with a static head pose, which is inconsistent with how humans perceive faces. Only a few papers focus on head pose generation, but even these ignore the attribute of personality. In this paper, we propose a unified audio-driven approach to endow 3D talking faces with personalized pose dynamics. To achieve this goal, we establish an original person-specific dataset, providing corresponding head poses and face shapes for each video. Our framework is composed of two separate modules: PoseGAN and PGFace. Given an input audio, PoseGAN first produces a head pose sequence for the 3D head, and then, PGFace utilizes the audio and pose information to generate natural face models. With the combination of these two parts, a 3D talking head with dynamic head movement can be constructed. Experimental evidence indicates that our method can generate person-specific head pose sequences that are in sync with the input audio and that best match with the human experience of talking heads.","1941-0506","","10.1109/TVCG.2021.3117484","National Natural Science Foundation of China(grant numbers:62072382); National Science Foundation(grant numbers:2007661); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557828","Audio-driven generation;3D talking face;personalized pose;generative adversarial network","Faces;Three-dimensional displays;Head;Shape;Solid modeling;Hidden Markov models;Dynamics","","","","1","","","IEEE","4 Oct 2021","","","IEEE","IEEE Early Access Articles"
"A Comparison of Radial and Linear Charts for Visualizing Daily Patterns","M. Waldner; A. Diehl; D. Gračanin; R. Splechtna; C. Delrieux; K. Matković",TU Wien; University of Zurich; Virginia Tech; VRVis Research Center; Electric and Computer Eng. Dept.Universidad Nacional del SUR and CONICET; VRVis Research Center,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","1033","1042","Radial charts are generally considered less effective than linear charts. Perhaps the only exception is in visualizing periodical time-dependent data, which is believed to be naturally supported by the radial layout. It has been demonstrated that the drawbacks of radial charts outweigh the benefits of this natural mapping. Visualization of daily patterns, as a special case, has not been systematically evaluated using radial charts. In contrast to yearly or weekly recurrent trends, the analysis of daily patterns on a radial chart may benefit from our trained skill on reading radial clocks that are ubiquitous in our culture. In a crowd-sourced experiment with 92 non-expert users, we evaluated the accuracy, efficiency, and subjective ratings of radial and linear charts for visualizing daily traffic accident patterns. We systematically compared juxtaposed 12-hours variants and single 24-hours variants for both layouts in four low-level tasks and one high-level interpretation task. Our results show that over all tasks, the most elementary 24-hours linear bar chart is most accurate and efficient and is also preferred by the users. This provides strong evidence for the use of linear layouts - even for visualizing periodical daily patterns.","1941-0506","","10.1109/TVCG.2019.2934784","Austrian Science Fund(grant numbers:T 752-N30); PGI(grant numbers:24/K061); Universidad Nacional del Sur; VRVis(grant numbers:854174); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807238","Radial charts;time series series data;daily patterns;crowd-sourced experiment","Bars;Data visualization;Layout;Clocks;Task analysis;Time series analysis;Encoding","bar charts;crowdsourcing;data analysis;data visualisation;pattern recognition;road accidents;road traffic;traffic engineering computing","linear charts;radial chart;bar chart;daily traffic accident pattern visualization;daily pattern analysis","","1","","54","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"A Visual Analytics Approach to Scheduling Customized Shuttle Buses via Perceiving Passengers’ Travel Demands","Q. Liu; Q. Li; C. Tang; H. Lin; X. Ma; T. Chen","WeBank,AI Group,Shenzhen,China; WeBank,AI Group,Shenzhen,China; WeBank,AI Group,Shenzhen,China; WeBank,AI Group,Shenzhen,China; The Hong Kong University of Science and Technology,Hong Kong; WeBank,AI Group,Shenzhen,China","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","76","80","Shuttle buses have been a popular means to move commuters sharing similar origins and destinations during periods of high travel demand. However, planning and deploying reasonable, customized service bus systems becomes challenging when the commute demand is rather dynamic. It is difficult, if not impossible to form a reliable, unbiased estimation of user needs in such a case using traditional modeling methods. We propose a visual analytics approach to facilitating assessment of actual, varying travel demands and planning of night customized shuttle systems. A preliminary case study verifies the efficacy of our approach.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331263","Human-centered computing;Visualization;Visualization design and evaluation methods","Processor scheduling;Visual analytics;Design methodology;Conferences;Estimation;Planning;Reliability","data analysis;data visualisation;intelligent transportation systems;public transport;traffic engineering computing","visual analytics approach;scheduling;passengers travel demands;commute demand;shuttle buses;service bus systems;travel planning","","1","","36","","1 Feb 2021","","","IEEE","IEEE Conferences"
"A Visual Analytics Based Decision Making Environment for COVID-19 Modeling and Visualization","S. Afzal; S. Ghani; H. C. Jenkins-Smith; D. S. Ebert; M. Hadwiger; I. Hoteit",KAUST; KAUST; University of Oklahoma; Purdue University; KAUST; KAUST,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","86","90","Public health officials dealing with pandemics like COVID-19 have to evaluate and prepare response plans. This planning phase requires not only looking into the spatiotemporal dynamics and impact of the pandemic using simulation models, but they also need to plan and ensure the availability of resources under different spread scenarios. To this end, we have developed a visual analytics environment that enables public health officials to model, simulate, and explore the spread of COVID-19 by supplying county-level information such as population, demographics, and hospital beds. This environment facilitates users to explore spatiotemporal model simulation data relevant to COVID-19 through a geospatial map with linked statistical views, apply different decision measures at different points in time, and understand their potential impact. Users can drill-down to county-level details such as the number of sicknesses, deaths, needs for hospitalization, and variations in these statistics over time. We demonstrate the usefulness of this environment through a use case study and also provide feedback from domain experts. We also provide details about future extensions and potential applications of this work.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331307","Human-centered computing;Visualization;Visualization application domains;Visual analytics","COVID-19;Analytical models;Pandemics;Visual analytics;Data models;Spatiotemporal phenomena;Public healthcare","data analysis;data visualisation;decision making;decision support systems;diseases;geographic information systems;hospitals;medical computing;planning","public health officials;COVID-19;county-level information;hospital beds;spatiotemporal model simulation data;linked statistical views;decision measures;county-level details;response plans;planning phase;spatiotemporal dynamics;simulation models;spread scenarios;visual analytics environment","","1","","32","","1 Feb 2021","","","IEEE","IEEE Conferences"
"An Exploration And Validation of Visual Factors in Understanding Classification Rule Sets","J. Yuan; O. Nov; E. Bertini",New York University; New York University; New York University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","6","10","Rule sets are often used in Machine Learning (ML) as a way to communicate the model logic in settings where transparency and intelligibility are necessary. Rule sets are typically presented as a text-based list of logical statements (rules). Surprisingly, to date there has been limited work on exploring visual alternatives for presenting rules. In this paper, we explore the idea of designing alternative representations of rules, focusing on a number of visual factors we believe have a positive impact on rule readability and understanding. We then presents a user study exploring their impact. The results show that some design factors have a strong impact on how efficiently readers can process the rules while having minimal impact on accuracy. This work can help practitioners employ more effective solutions when using rules as a communication strategy to understand ML models.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623303","Ruman-centered computing;Visualization;Empirical studies in visualization","Visualization;Conferences;Computational modeling;Focusing;Machine learning","data mining;data visualisation;knowledge based systems;learning (artificial intelligence);pattern classification","visual factors;rule readability;design factors;ML models;classification rule;rule sets;model logic;text-based list;logical statements;visual alternatives","","1","","27","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Assigning Rated Items to Locations in Non-List Display Layouts","S. Santini","Escuela Politécnica Superior, Universidad Autónoma de Madrid, Madrid, Spain","IEEE Transactions on Visualization and Computer Graphics","31 Dec 2019","2020","26","2","1278","1291","One of the most common ways in which results are displayed by an information retrieval system is in the form of a list, in which the most relevant results appear in the first positions. Today's large screens, however, allow one to create more complex displays of results, especially in cases such as image retrieval, in which each unit returned is fairly compact. For these layouts the simple list model is no longer valid, since the relations between the slots in which the results are placed do not form a sequence, that is, the relation among them is no longer that of a total order. In this paper we model these layouts as partial orders and show that a “stalwart display” property (a layout in which items' relevance is unambiguously conveyed by their display position) can be obtained only in the case of lists. For the other layouts, we define two classes of representation functions: “safe” functions (which display results without adding spurious structure) and “rich” functions (which do not drop any structure from the result set), as well as an algorithm to optimally display fully ordered result sets in arbitrary display layouts.","1941-0506","","10.1109/TVCG.2018.2870164","Ministerio de Educación de la Nación(grant numbers:TIN2016-80630-P); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464300","Display layout;prominence determination;attention fixation;computational complexity;display functions;query results display","Layout;Information retrieval;Data models;Standards;Computational modeling;Image retrieval","data visualisation;image retrieval;query processing","information retrieval system;complex displays;image retrieval;simple list model;total order;partial orders;stalwart display property;display position;arbitrary display layouts;rated items;nonlist display layouts","","1","","40","IEEE","13 Sep 2018","","","IEEE","IEEE Journals"
"Augmenting Parallel Coordinates Plots with Color-coded Stacked Histograms","J. Bok; B. Kim; J. Seo","Department of Computer Science and Engineering, Seoul National University, 26725 Seoul, Seoul Korea (the Republic of) (e-mail: bok@hcil.snu.ac.kr); Division of Biomedical Engineering, Hankuk University of Foreign Studies - Global Campus, 65466 Yongin, Gyeonggi-do Korea (the Republic of) (e-mail: bkim@hufs.ac.kr); Department of Computer Science and Engineering, Seoul National University, 26725 Gwanak-gu, Seoul Korea (the Republic of) (e-mail: jseo@snu.ac.kr)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","We introduce Parallel Histogram Plot (PHP), a technique that overcomes the innate limitations of parallel coordinates plot (PCP) by attaching stacked-bar histograms with discrete color schemes to PCP. The color-coded histograms enable users to see an overview of the whole data without cluttering or scalability issues. Each rectangle in the PHP histograms is color coded according to the data ranking by a selected attribute. This color-coding scheme allows users to visually examine relationships between attributes, even between those that are displayed far apart, without repositioning or reordering axes. We adopt the Visual Information Seeking Mantra so that the polylines of the original PCP can be used to show details of a small number of selected items when the cluttering problem subsides. We also design interactions, such as a focus+context technique, to help users investigate small regions of interest in a space-efficient manner. We provide a real-world example in which PHP is effectively utilized compared with other visualizations, and we perform a controlled user study to evaluate the performance of PHP in helping users estimate the correlation between attributes. The results demonstrate that the performance of PHP was consistent in the estimation of correlations between two attributes regardless of the distance between them.","1941-0506","","10.1109/TVCG.2020.3038446","National Research Foundation of Korea(grant numbers:NRF- 2019R1A2C1088900,NRF-2019R1A2C2089062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262081","Parallel Coordinates Plots;Parallel Histogram Plots;Color-coded Stacked Histogram","Histograms;Image color analysis;Visualization;Bars;Data visualization;Correlation;Layout","","","","1","","","CCBY","17 Nov 2020","","","IEEE","IEEE Early Access Articles"
"COVIs: Supporting Temporal Visual Analysis of Covid-19 Events Usable in Data-Driven Journalism","R. A. Leite; V. Schetinger; D. Ceneda; B. Henz; S. Miksch",TU Wien; TU Wien; TU Wien; IFFar; TU Wien,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","56","60","Caused by a newly discovered coronavirus, COVID-19 is an infectious disease easily transmitted between people through close contacts that had exponential global growth in 2020 and became, in a very short time, a major health, and economic global issue. Real-world data concerning the spread of the disease was quickly made available by different global institutions and resulted in many works involving data visualizations and prediction models. In this paper, (1) we discuss the problem, data aspects, and challenges of COVID-19 data analysis; (2) We propose a Visual Analytics approach (called COVis) combining different temporal aspects of COVID-19 data with the output of a predictive model. This combination supports the estimation of the spread of the disease in different scenarios and allows correlating and monitoring the virus development in relation to different government response events; (3) We evaluate the approach with two domain experts to support the understanding of how our system can facilitate journalistic investigation tasks and (4) we discuss future works and a possible generalization of our solution.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00018","Austrian Science Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331018","COVID-19;Visual Analytics;Data Visualization;Prediction ModelEventsTime-oriented Analysis","COVID-19;Visual analytics;Data visualization;Predictive models;Task analysis;Viruses (medical);Monitoring","data analysis;data visualisation;diseases;journalism;medical computing","COVis approach;government response events;data visualizations;economic global issue;exponential global growth;infectious disease;coronavirus;data-driven journalism;covid-19 events;temporal visual analysis;predictive model;visual analytics approach;COVID-19 data analysis;data aspects;prediction models","","1","","32","","1 Feb 2021","","","IEEE","IEEE Conferences"
"ChartStory: Automated Partitioning, Layout, and Captioning of Charts into Comic-Style Narratives","J. Zhao; S. Xu; S. Chandrasegaran; C. J. Bryan; F. Du; A. Mishra; X. Qian; Y. Li; K. -L. Ma","School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, N2L 3G1 (e-mail: jianzhao@uwaterloo.ca); School of Interactive Computing, Georgia Institute of Technology, 1372 Atlanta, Georgia, United States, (e-mail: shenyuxu@gatech.edu); Department of Computer Science, University of California Davis, 8789 Davis, California, United States, 95616-5270 (e-mail: senthil.kumaran@gmail.com); Computer Science, Arizona State University, 7864 Tempe, Arizona, United States, 85287-1004 (e-mail: cbryan16@asu.edu); Research, Adobe Systems Inc, 58584 San Jose, California, United States, 95110-2704 (e-mail: fdu@adobe.com); School of Computing, Informatics, & Decision Systems, Arizona State University, 7864 Tempe, Arizona, United States, (e-mail: amishr45@asu.edu); College of Information Studies, University of Maryland at College Park, 1068 College Park, Maryland, United States, (e-mail: xinq@umd.edu); Computer Science, University of California Davis, 8789 Davis, California, United States, (e-mail: ranli@ucdavis.edu); Computer Science, University of California at Davis, Davis, California, United States, 95616-8562 (e-mail: ma@cs.ucdavis.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Visual data storytelling is gaining importance as a means of presenting data-driven information or analysis results, especially to the general public. This has resulted in design principles being proposed for data-driven storytelling, and new authoring tools being created to aid such storytelling. However, data analysts typically lack sufficient background in design and storytelling to make effective use of these principles and authoring tools. To assist this process, we present ChartStory for crafting data stories from a collection of user-created charts, using a style akin to comic panels to imply the underlying sequence and logic of data-driven narratives. Our approach is to operationalize established design principles into an advanced pipeline which characterizes charts by their properties and similarity, and recommends ways to partition, layout, and caption story pieces to serve a narrative. ChartStory also augments this pipeline with intuitive user interactions for visual refinement of generated data comics. We extensively and holistically evaluate ChartStory via a trio of studies. We first assess how the tool supports data comic creation in comparison to a manual baseline tool. Data comics from this study are subsequently compared and evaluated to ChartStorys automated recommendations by a team of narrative visualization practitioners. This is followed by a pair of interview studies with data scientists using their own datasets and charts who provide an additional assessment of the system. We find that ChartStory provides cogent recommendations for narrative generation, resulting in data comics that compare favorably to manually-created ones.","1941-0506","","10.1109/TVCG.2021.3114211","National Science Foundation(grant numbers:OAC-1934766); Natural Sciences and Engineering Research Council of Canada; Adobe Systems; Division of Information and Intelligent Systems(grant numbers:IIS-1741536, IIS-1528203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9547737","Data story generation;narrative visualization;data-driven storytelling;data comics","Layout;Data visualization;Visualization;Tools;Pipelines;Authoring systems;Annotations","","","","1","","","IEEE","24 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Comparative Layouts Revisited: Design Space, Guidelines, and Future Directions","S. LYi; J. Jo; J. Seo",Harvard Medical School; Sungkyunkwan University; Seoul National University,"IEEE Transactions on Visualization and Computer Graphics","1 Feb 2021","2021","27","2","1525","1535","We present a systematic review on three comparative layouts-juxtaposition, superposition, and explicit-encoding-which are information visualization (InfoVis) layouts designed to support comparison tasks. For the last decade, these layouts have served as fundamental idioms in designing many visualization systems. However, we found that the layouts have been used with inconsistent terms and confusion, and the lessons from previous studies are fragmented. The goal of our research is to distill the results from previous studies into a consistent and reusable framework. We review 127 research papers, including 15 papers with quantitative user studies, which employed comparative layouts. We first alleviate the ambiguous boundaries in the design space of comparative layouts by suggesting lucid terminology (e.g., chart-wise and item-wise juxtaposition). We then identify the diverse aspects of comparative layouts, such as the advantages and concerns of using each layout in the real-world scenarios and researchers' approaches to overcome the concerns. Building our knowledge on top of the initial insights gained from the Gleicher et al.'s survey [19], we elaborate on relevant empirical evidence that we distilled from our survey (e.g., the actual effectiveness of the layouts in different study settings) and identify novel facets that the original work did not cover (e.g., the familiarity of the layouts to people). Finally, we show the consistent and contradictory results on the performance of comparative layouts and offer practical implications for using the layouts by suggesting trade-offs and seven actionable guidelines.","1941-0506","","10.1109/TVCG.2020.3030419","National Research Foundation of Korea (NRF); Korea government (MSIT)(grant numbers:NRF-2019R1A2C2089062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9223736","Comparative layout;visual comparison;literature review;juxtaposition;superposition;explicit-encoding","Layout;Visualization;Task analysis;Bars;Heating systems;Data visualization;Guidelines","data visualisation","comparative layouts;design space;juxtaposition;explicit-encoding;information visualization layouts;InfoVis layouts;visualization systems;actionable guidelines","","1","","74","IEEE","14 Oct 2020","","","IEEE","IEEE Journals"
"CrowdTrace: Visualizing Provenance in Distributed Sensemaking","T. Li; Y. Belghith; C. North; K. Luther",Loyola University Chicago; Virginia Tech; Virginia Tech; Virginia Tech,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","191","195","Capturing analytic provenance is important for refining sensemaking analysis. However, understanding this provenance can be difficult. First, making sense of the reasoning in intermediate steps is time-consuming. Especially in distributed sensemaking, the provenance is less cohesive because each analyst only sees a small portion of the data without an understanding of the overall collaboration workflow. Second, analysis errors from one step can propagate to later steps. Furthermore, in exploratory sensemaking, it is difficult to define what an error is since there are no correct answers to reference. In this paper, we explore provenance analysis for distributed sense-making in the context of crowdsourcing, where distributed analysis contributions are captured in microtasks. We propose crowd auditing as a way to help individual analysts visualize and trace provenance to debug distributed sensemaking. To evaluate this concept, we implemented a crowd auditing tool, CrowdTrace. Our user study-based evaluation demonstrates that CrowdTrace offers an effective mechanism to audit and refine multi-step crowd sensemaking.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331303","Crowdsourcing;sensemaking;crowd auditing","Crowdsourcing;Conferences;Refining;Distributed databases;Collaboration;Tools;Cognition","data analysis;data visualisation;inference mechanisms","crowd auditing;reasoning;provenance analysis;exploratory sensemaking;sensemaking analysis;distributed sensemaking;provenance visualization;CrowdTrace","","1","","33","","1 Feb 2021","","","IEEE","IEEE Conferences"
"DRGraph: An Efficient Graph Layout Algorithm for Large-scale Graphs by Dimensionality Reduction","M. Zhu; W. Chen; Y. Hu; Y. Hou; L. Liu; K. Zhang","State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1666","1676","Efficient layout of large-scale graphs remains a challenging problem: the force-directed and dimensionality reduction-based methods suffer from high overhead for graph distance and gradient computation. In this paper, we present a new graph layout algorithm, called DRGraph, that enhances the nonlinear dimensionality reduction process with three schemes: approximating graph distances by means of a sparse distance matrix, estimating the gradient by using the negative sampling technique, and accelerating the optimization process through a multi-level layout scheme. DRGraph achieves a linear complexity for the computation and memory consumption, and scales up to large-scale graphs with millions of nodes. Experimental results and comparisons with state-of-the-art graph layout methods demonstrate that DRGraph can generate visually comparable layouts with a faster running time and a lower memory requirement.","1941-0506","","10.1109/TVCG.2020.3030447","National Natural Science Foundation of China(grant numbers:61772456,61761136020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282195","graph visualization;graph layout;dimensionality reduction;force-directed layout","Layout;Dimensionality reduction;Computational complexity;Optimization;Acceleration;Memory management;Principal component analysis","computational complexity;data visualisation;graph theory;optimisation","graph layout methods;optimization process;negative sampling technique;sparse distance matrix;nonlinear dimensionality reduction process;DRGraph;graph distance;dimensionality reduction-based methods;graph layout algorithm;visually comparable layouts;large-scale graphs;multilevel layout scheme","","1","","68","IEEE","4 Dec 2020","","","IEEE","IEEE Journals"
"Distinction of 3D Objects and Scenes via Classification Network and Markov Random Field","R. Song; Y. Liu; P. L. Rosin","Centre for Secure, Intelligent and Usable Systems, School of Computing, Engineering and Mathematics, University of Brighton, Brighton, United Kingdom; Department of Computer Science, Edge Hill University, Ormskirk, United Kingdom; School of Computer Science and Informatics, Cardiff University, Cardiff, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","30 Apr 2020","2020","26","6","2204","2218","An importance measure of 3D objects inspired by human perception has a range of applications since people want computers to behave like humans in many tasks. This paper revisits a well-defined measure, distinction of 3D surface mesh, which indicates how important a region of a mesh is with respect to classification. We develop a method to compute it based on a classification network and a Markov Random Field (MRF). The classification network learns view-based distinction by handling multiple views of a 3D object. Using a classification network has an advantage of avoiding the training data problem which has become a major obstacle of applying deep learning to 3D object understanding tasks. The MRF estimates the parameters of a linear model for combining the view-based distinction maps. The experiments using several publicly accessible datasets show that the distinctive regions detected by our method are not just significantly different from those detected by methods based on handcrafted features, but more consistent with human perception. We also compare it with other perceptual measures and quantitatively evaluate its performance in the context of two applications. Furthermore, due to the view-based nature of our method, we are able to easily extend mesh distinction to 3D scenes containing multiple objects.","1941-0506","","10.1109/TVCG.2018.2885750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567954","3D mesh;distinction;neural network;Markov random field","Three-dimensional displays;Task analysis;Shape;Two dimensional displays;Feature extraction;Training;Markov random fields","feature extraction;image classification;image representation;learning (artificial intelligence);Markov processes;neural nets;object detection;object recognition","multiple objects;mesh distinction;view-based nature;distinctive regions;view-based distinction maps;3D object understanding tasks;Markov Random Field;classification network;3D surface mesh;human perception","","1","","65","IEEE","7 Dec 2018","","","IEEE","IEEE Journals"
"Eiffel: Evolutionary Flow Map for Influence Graph Visualization","Y. Huang; L. Shi; Y. Su; Y. Hu; H. Tong; C. Wang; T. Yang; D. Wang; S. Liang","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences and UCAS, Beijing, China; Yahoo Labs, New York, NY, USA; School of Computing, Informatics, Decision Systems Engineering, Arizona State University, Tempe, AZ, USA; Department of Computer Science & Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science, Peking University, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences and UCAS, Beijing, China; Academy of Arts & Design, Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2020","2020","26","10","2944","2960","The visualization of evolutionary influence graphs is important for performing many real-life tasks such as citation analysis and social influence analysis. The main challenges include how to summarize large-scale, complex, and time-evolving influence graphs, and how to design effective visual metaphors and dynamic representation methods to illustrate influence patterns over time. In this work, we present Eiffel, an integrated visual analytics system that applies triple summarizations on evolutionary influence graphs in the nodal, relational, and temporal dimensions. In numerical experiments, Eiffel summarization results outperformed those of traditional clustering algorithms with respect to the influence-flow-based objective. Moreover, a flow map representation is proposed and adapted to the case of influence graph summarization, which supports two modes of evolutionary visualization (i.e., flip-book and movie) to expedite the analysis of influence graph dynamics. We conducted two controlled user experiments to evaluate our technique on influence graph summarization and visualization respectively. We also showcased the system in the evolutionary influence analysis of two typical scenarios, the citation influence of scientific papers and the social influence of emerging online events. The evaluation results demonstrate the value of Eiffel in the visual analysis of evolutionary influence graphs.","1941-0506","","10.1109/TVCG.2019.2906900","National Natural Science Foundation of China(grant numbers:61772504,61672061); National Science Foundation(grant numbers:IIS-1456763,IIS-1455886,IIS-1651203,IIS-1715385,DUE-1833129); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673661","Influence graph;dynamic visualization;citation analysis","Visualization;Task analysis;Data visualization;Citation analysis;Layout;Twitter;Clutter","citation analysis;data visualisation;evolutionary computation;graph theory;pattern clustering","influence-flow-based objective;flow map representation;influence graph summarization;evolutionary visualization;influence graph dynamics;evolutionary influence analysis;citation influence;Eiffel summarization results;integrated visual analytics system;influence patterns;effective visual metaphors;time-evolving influence graphs;social influence analysis;influence graph visualization;evolutionary flow map;evolutionary influence graphs;visual analysis","","1","","58","IEEE","25 Mar 2019","","","IEEE","IEEE Journals"
"Encodable: Configurable Grammar for Visualization Components","K. Wongsuphasawat","Airbnb, Inc.","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","131","135","There are so many Libraries of visualization components nowadays with their APIs often different from one another. Could these components be more similar, both in terms of the APIs and common functionalities? For someone who is developing a new visualization component, how should the API look like? This work drew inspiration from visualization grammar, decoupled the grammar from its rendering engine and adapted it into a configurable grammar for individual components called Encodable. Encodable helps component authors define grammar for their components, and parse encoding specifications from users into utility functions for the implementation. This paper explains the grammar design and demonstrates how to build components with it.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331312","Information visualization;systems;toolkits;API design;reusable visualization;visualization component","Visualization;Conferences;Rendering (computer graphics);Libraries;Encoding;Grammar;Engines","application program interfaces;grammars;rendering (computer graphics)","API look;visualization grammar;configurable grammar;component authors;parse encoding specifications;grammar design;visualization component","","1","","37","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Evaluating Animated Transitions between Contiguous Visualizations for Streaming Big Data","T. Pereira; J. Moreira; D. Mendes; D. Gonçalves","Universidade de Lisboa,INESC-ID Lisboa, Instituto Superior Técnico; Universidade de Lisboa,INESC-ID Lisboa, Instituto Superior Técnico; Universidade de Lisboa,INESC-ID Lisboa, Instituto Superior Técnico; Universidade de Lisboa,INESC-ID Lisboa, Instituto Superior Técnico","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","161","165","An approach to analyzing Streaming Big Data as it comes in while maintaining the proper context of past events is to employ contiguous visualizations with an increasingly aggressive aggregation degree. This allows for the most recent data to be displayed in detail, while older data is shown in an aggregated form according to how long ago it was received. However, the transitions applied between visualizations with different aggregations must not compromise the understandability of the data flow. Particularly, new data should be perceived considering the context established by older data, and the visualizations should not be perceived as independent or un-connected. In this paper, we present the first study on transitions between two contiguous visualizations, focusing on time series data. We developed several animated transitions between a scatter plot, where all data points are individually represented as they arrive, and other visualizations where data is displayed in an aggregated form. We then conducted a user evaluation to assess the most appealing and effective transitions that allow for the best comprehension of the displayed data for each visualization pair.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331296","Human-centered computing;Visualization;Visualization Techniques;Empirical Studies in visualization","Conferences;Time series analysis;Data visualization;Focusing;Big Data","Big Data;computer animation;data analysis;data visualisation;time series","aggregated form;data flow;contiguous visualizations;time series data;animated transitions;appealing transitions;effective transitions;displayed data;visualization pair;Big Data streaming","","1","","18","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Evaluating Ordering Strategies of Star Glyph Axes","M. Miller; X. Zhang; J. Fuchs; M. Blumenschein",University of Konstanz; RWTH Aachen University; University of Konstanz; University of Konstanz,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","91","95","Star glyphs are a well-researched visualization technique to represent multi-dimensional data. They are often used in small multiple settings for a visual comparison of many data points. However, their overall visual appearance is strongly influenced by the ordering of dimensions. To this end, two orthogonal categories of layout strategies are proposed in the literature: order dimensions by similarity to get homogeneously shaped glyphs vs. order by dissimilarity to emphasize spikes and salient shapes. While there is evidence that salient shapes support clustering tasks, evaluation, and direct comparison of data-driven ordering strategies has not received much research attention. We contribute an empirical user study to evaluate the efficiency, effectiveness, and user confidence in visual clustering tasks using star glyphs. In comparison to similarity-based ordering, our results indicate that dissimilarity-based star glyph layouts support users better in clustering tasks, especially when clutter is present.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933656","Star glyph;axes ordering;quantitative evaluation","Task analysis;Shape;Visualization;Clutter;Data visualization;Benchmark testing;Data analysis","data analysis;data visualisation;pattern clustering","ordering strategies;star glyph axes;star glyphs;visualization technique;multi-dimensional data;multiple settings;visual comparison;data points;visual appearance;orthogonal categories;layout strategies;order dimensions;salient shapes;visual clustering tasks;similarity-based ordering;dissimilarity-based star glyph","","1","","38","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Explainable Spatial Clustering: Leveraging Spatial Data in Radiation Oncology","A. Wentzel; G. Canahuate; L. V. van Dijk; A. S. R. Mohamed; C. D. Fuller; G. E. Marai",University of Illinois at Chicago; University of Iowa; University of Texas; University of Texas; University of Texas; University of Illinois at Chicago,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","281","285","Advances in data collection in radiation therapy have led to an abundance of opportunities for applying data mining and machine learning techniques to promote new data-driven insights. In light of these advances, supporting collaboration between machine learning experts and clinicians is important for facilitating better development and adoption of these models. Although many medical use-cases rely on spatial data, where understanding and visualizing the underlying structure of the data is important, little is known about the interpretability of spatial clustering results by clinical audiences. In this work, we reflect on the design of visualizations for explaining novel approaches to clustering complex anatomical data from head and neck cancer patients. These visualizations were developed, through participatory design, for clinical audiences during a multi-year collaboration with radiation oncologists and statisticians. We distill this collaboration into a set of lessons learned for creating visual and explainable spatial clustering for clinical users.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331305","Data Clustering and Aggregation;Life Sciences;Collaboration;Mixed Initiative Human-Machine Analysis;Guidelines","Visualization;Data visualization;Collaboration;Machine learning;Oncology;Spatial databases;Cancer","cancer;data analysis;data mining;data visualisation;learning (artificial intelligence);medical computing;pattern clustering;radiation therapy;tumours","complex anatomical data;radiation oncologists;spatial clustering;spatial data;data collection;radiation therapy;data mining;data-driven insights;machine learning experts","","1","","35","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Facilitating Exploration with Interaction Snapshots under High Latency","Y. Wu; R. Chang; J. M. Hellerstein; E. Wu",UC Berkeley; Tufts University; UC Berkeley; Columbia University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","136","140","Latency is, unfortunately, a reality when working with large data sets. Guaranteeing imperceptible latency for interactivity is often prohibitively expensive: the application developer may be forced to migrate data processing engines or deal with complex error bounds on samples, and to limit the application to users with high network bandwidth. Instead of relying on the backend, we propose a simple UX design-interaction snapshots. Responses of requests from the interactions are asynchronously loaded in ""snapshots"". With interaction snapshots, users can interact concurrently while the snapshots load. Our user study participants found it useful not to have to wait for each result and easily navigate to prior snapshots. For latency up to 5 seconds, participants were able to complete extrema, threshold, and trend identification tasks with little negative impact.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00034","3M; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331306","Interaction design;history;asynchrony;latency","Navigation;Conferences;Bandwidth;Market research;Data processing;Task analysis;Engines","data visualisation;human computer interaction;user experience","data processing engines;high network bandwidth;interaction snapshots;snapshots load;high latency;UX design;complex error bounds;interactive data visualization systems","","1","","30","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Fast and Flexible Overlap Detection for Chart Labeling with Occupancy Bitmap","C. Kittivorawong; D. Moritz; K. Wongsuphasawat; J. Heer",University of Washington; Apple Inc; University of Washington; University of Washington,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","101","105","Legible labels should not overlap with other marks in a chart. The state-of-the-art labeling algorithm detects overlaps using a set of points to approximate each mark's shape. This approach is inefficient for large marks or many marks as it requires too many points to detect overlaps. In response, we present a Bitmap-Based label placement algorithm, which leverages occupancy bitmap to accelerate overlap detection. To create an occupancy bitmap, we rasterize marks onto a bitmap based on the area they occupy in the chart. With the bitmap, we can efficiently place labels without overlapping existing marks, regardless of the number and geometric complexity of the marks. This Bitmap-Based algorithm offers significant performance improvements over the state-of-the-art approach while placing a similar number of labels.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00027","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331274","Human-centered computing;Visualization;Visualization techniques;Information Visualization","Visualization;Shape;Conferences;Approximation algorithms;Complexity theory;Labeling;Acceleration","computational geometry;data visualisation","occupancy bitmap;legible labels;overlap detection;chart labeling;bitmap-based label placement algorithm;mark shape;mark rasterization;geometric complexity","","1","","14","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Further Towards Unambiguous Edge Bundling: Investigating Power-Confluent Drawings for Network Visualization","J. X. Zheng; S. Pawar; D. F. M. Goodman","Imperial College London, London, United Kingdom; Imperial College London, London, United Kingdom; Imperial College London, London, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","3","2244","2249","Bach et al. [1] recently presented an algorithm for constructing confluent drawings, by leveraging power graph decomposition to generate an auxiliary routing graph. We identify two issues with their method which we call the node split and short-circuit problems, and solve both by modifying the routing graph to retain the hierarchical structure of power groups. We also classify the exact type of confluent drawings that the algorithm can produce as `power-confluent', and prove that it is a subclass of the previously studied `strict confluent' drawing. A description and source code of our implementation is also provided, which additionally includes an improved method for power graph construction.","1941-0506","","10.1109/TVCG.2019.2944619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852738","Graph drawing;power graph decomposition;edge bundling;confluent drawing;optimization","Splines (mathematics);Routing;Junctions;Visualization;Classification algorithms;Standards;Merging","graph drawing;graph theory;network theory (graphs);pattern classification","network visualization;power graph decomposition;auxiliary routing graph;power groups;unambiguous edge bundling;power confluent drawings;confluent drawing classification;graph drawing","","1","","18","IEEE","30 Sep 2019","","","IEEE","IEEE Journals"
"GPU Parallel Computation of Morse-Smale Complexes","V. Subhash; K. Pandey; V. Natarajan","Indian Institute of Science,Department of Computer Science and Automation,Bangalore; Indian Institute of Science,Department of Computer Science and Automation,Bangalore; Indian Institute of Science,Department of Computer Science and Automation,Bangalore","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","36","40","The Morse-Smale complex is a well studied topological structure that represents the gradient flow behavior of a scalar function. It supports multi-scale topological analysis and visualization of large scientific data. Its computation poses significant algorithmic challenges when considering large scale data and increased feature complexity. Several parallel algorithms have been proposed towards the fast computation of the 3D Morse-Smale complex. The non-trivial structure of the saddle-saddle connections are not amenable to parallel computation. This paper describes a fine grained parallel method for computing the Morse-Smale complex that is implemented on a GPU. The saddle-saddle reachability is first determined via a transformation into a sequence of vector operations followed by the path traversal, which is achieved via a sequence of matrix operations. Computational experiments show that the method achieves up to 7 × speedup over current shared memory implementations.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331295","Human-centered computing;Visualization;Visualization techniques;Computing methodologies;Parallel computing methodologies;Parallel algorithms;Shared memory algorithms","Three-dimensional displays;Conferences;Graphics processing units;Data visualization;Synchronization;Parallel algorithms;Task analysis","computational complexity;computational geometry;data analysis;data visualisation;graphics processing units;mathematics computing;matrix algebra;parallel algorithms;reachability analysis;vectors","matrix operations;saddle-saddle reachability;vector operations;3D Morse-Smale complex;scalar function;gradient flow behavior;topological structure;GPU parallel computation;parallel algorithms;feature complexity;scientific data visualization","","1","","25","","1 Feb 2021","","","IEEE","IEEE Conferences"
"GalStamps: Analyzing Real and Simulated Galaxy Observations","N. McCurdy; M. Meyer",University of Utah; University of Utah,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","276","280","One way astronomers and astrophysicists study galaxy formation and evolution is by analyzing and comparing real galaxy observations, captured by telescopes, and simulated galaxy observations, generated from theoretical models. They approach this through a combination of statistical and visual analysis, conducted either independently or sequentially. During the first year of an ongoing design study with astronomers and astrophysicists, we explored approaches to integrating statistical and visual analysis to enhance understanding of these data. Contributions from this stage of the study include a data and task abstraction for statistically and visually analyzing real and simulated galaxy observations, as well as an initial design, implemented in a prototype called GalStamps, and evaluated through two case studies with domain experts.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933671","Visualization;Design study;Astronomy","Data visualization;Visualization;Two dimensional displays;Task analysis;Telescopes;Prototypes;Extraterrestrial measurements","astronomy computing;data analysis;data visualisation;galaxies","simulated galaxy observations;way astronomers;galaxy formation;visual analysis;statistical analysis;astrophysicists;data understanding;GalStamps","","1","","42","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Geometry-Driven Detection, Tracking and Visual Analysis of Viscous and Gravitational Fingers","J. Xu; S. Dutta; W. He; J. Moortgat; H. -W. Shen","Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA; Data Science at Scale Team, Los Alamos National Laboratory, Los Alamos, NM, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA; School of Earth Sciences, The Ohio State University, Columbus, OH, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2022","2022","28","3","1514","1528","Viscous and gravitational flow instabilities cause a displacement front to break up into finger-like fluids. The detection and evolutionary analysis of these fingering instabilities are critical in multiple scientific disciplines such as fluid mechanics and hydrogeology. However, previous detection methods of the viscous and gravitational fingers are based on density thresholding, which provides limited geometric information of the fingers. The geometric structures of fingers and their evolution are important yet little studied in the literature. In this article, we explore the geometric detection and evolution of the fingers in detail to elucidate the dynamics of the instability. We propose a ridge voxel detection method to guide the extraction of finger cores from three-dimensional (3D) scalar fields. After skeletonizing finger cores into skeletons, we design a spanning tree based approach to capture how fingers branch spatially from the finger skeletons. Finally, we devise a novel geometric-glyph augmented tracking graph to study how the fingers and their branches grow, merge, and split over time. Feedback from earth scientists demonstrates the usefulness of our approach to performing spatio-temporal geometric analyses of fingers.","1941-0506","","10.1109/TVCG.2020.3017568","UT-Battelle(grant numbers:LLC 4000159557); Los Alamos National Laboratory(grant numbers:471415); National Science Foundation(grant numbers:SBE-1738502); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170853","Viscous and gravitational fingering;topological and geometric data analysis;ridge detection;spatio-temporal visualization;tracking graph","Visualization;Earth;Three-dimensional displays;Skeleton;Feature extraction;Fingers;Computer science","computational geometry;data analysis;data visualisation;feature extraction;flow instability;geometry;graph theory;image recognition;medical image processing;spatiotemporal phenomena;trees (mathematics)","viscous flow instabilities;gravitational flow instabilities;finger-like fluids;evolutionary analysis;fingering instabilities;previous detection methods;viscous fingers;gravitational fingers;geometric detection;ridge voxel detection method;finger cores;fingers branch;finger skeletons;geometry-driven detection","","1","","50","IEEE","18 Aug 2020","","","IEEE","IEEE Journals"
"GlassViz: Visualizing Automatically-Extracted Entry Points for Exploring Scientific Corpora in Problem-Driven Visualization Research","A. Benito-Santos; R. Therón","Universidad de Salamanca,VisUSAL Research Group,Spain; Universidad de Salamanca,VisUSAL Research Group,Spain","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","226","230","In this paper, we report the development of a model and a proof-of-concept visual text analytics (VTA) tool to enhance document discovery in a problem-driven visualization research (PDVR) context. The proposed model captures the cognitive model followed by domain and visualization experts by analyzing the interdisciplinary communication channel as represented by keywords found in two disjoint collections of research papers. High distributional intercollection similarities are employed to build informative keyword associations that serve as entry points to drive the exploration of a large document corpus. Our approach is demonstrated in the context of research on visualization for the digital humanities.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00052","Ministry of Economic Affairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331261","visual text analytics;literature-based discovery;visualization of scientific corpora;distributional similarity;sensemaking;methodology transfer;digital humanities","Visualization;Analytical models;Conferences;Communication channels;Tools;Drives;Context modeling","data visualisation;humanities;text analysis","automatically-extracted entry points;scientific corpora;document discovery;problem-driven visualization research;cognitive model;interdisciplinary communication channel;informative keyword associations;GlassViz;visual text analytics tool;intercollection similarities;PDVR;TVA;digital humanities","","1","","33","","1 Feb 2021","","","IEEE","IEEE Conferences"
"High Fidelity Visualization of Large Scale Digitally Reconstructed Brain Circuitry with Signed Distance Functions","J. Karlsson; M. Abdellah; S. Speierer; A. Foni; S. Lapere; F. Schürmann","Ecole Polytehnique Fédérale de Lausanne (EPFL),Blue Brain Project (BBP),Switzerland; Ecole Polytehnique Fédérale de Lausanne (EPFL),Blue Brain Project (BBP),Switzerland; Ecole Polytehnique Fédérale de Lausanne (EPFL),Blue Brain Project (BBP),Switzerland; Ecole Polytehnique Fédérale de Lausanne (EPFL),Blue Brain Project (BBP),Switzerland; Ecole Polytehnique Fédérale de Lausanne (EPFL),Blue Brain Project (BBP),Switzerland; Ecole Polytehnique Fédérale de Lausanne (EPFL),Blue Brain Project (BBP),Switzerland","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","176","180","We explore a first proof-of-concept application for visualizing large scale digitally reconstructed brain circuitry using signed distance functions. The significance of our method is demonstrated in comparison with using implicit geometry that is limited to provide the natural look of neurons or explicit geometry that requires huge amounts of memory and has limited scalability with larger circuits.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933693","Signed distance function;Neuron;Ray-marching;Visualization","Geometry;Neurons;Rendering (computer graphics);Visualization;Shape;Memory management;Digital circuits","brain;geometry;image reconstruction;medical image processing;neurophysiology","high fidelity visualization;signed distance functions;implicit geometry;large scale digitally reconstructed brain circuitry","","1","","27","","19 Dec 2019","","","IEEE","IEEE Conferences"
"HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine Learning Models","Q. Wang; W. Alexander; J. Pegg; H. Qu; M. Chen","Hong Kong University of Science and Technology, China; University of Oxford, UK; University of Oxford, UK; Hong Kong University of Science and Technology, China; University of Oxford, UK","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1417","1426","In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a “concept” or “feature” may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have applied HypoML to a number of hypothesized concepts, demonstrating the intuitive and explainable nature of the visual analysis.","1941-0506","","10.1109/TVCG.2020.3030449","European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie(grant numbers:822214); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222284","Visual analytics;model-developmental visualization;machine learning;neural network;hypothesis test;HypoML","Analytical models;Testing;Data models;Computational modeling;Tools;Visualization;Neurons","data analysis;data visualisation;inference mechanisms;learning (artificial intelligence);multi-threading;program testing","HypoML;hypothesis-based evaluation;machine learning models;visual analytics tool;statistical hypothesis testing;logical reasoning;statistical inferences;logical inferences;visual representation;logical flow;ML-testing framework;multithread testing","","1","","44","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"InstanceFlow: Visualizing the Evolution of Classifier Confusion at the Instance Level","M. Pühringer; A. Hinterreiter; M. Streit","Johannes Kepler University Linz; Johannes Kepler University Linz Imperial College,London; Johannes Kepler University Linz","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","291","295","Classification is one of the most important supervised machine learning tasks. During the training of a classification model, the training instances are fed to the model multiple times (during multiple epochs) in order to iteratively improve classification performance. The increasing complexity of models has led to a growing demand to make them interpretable through visualization. Existing approaches mostly focus on the visual analysis of the final model performance after training and are often limited to aggregate performance measures. In this paper, we introduce InstanceFlow, a novel dual-view visualization tool that allows users to analyze the learning behavior of classifiers over time at the instance-level. A Sankey diagram visualizes the flow of instances throughout epochs, with on-demand detailed glyphs and traces for individual instances. A tabular view allows users to locate interesting instances by ranking and filtering. Thus, InstanceFlow bridges the gap between class-level and instance-level performance evaluation while enabling users to perform a full temporal analysis of the training process.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00065","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331302","Classification;Performance analysis;Time series visualization","Training;Performance evaluation;Visualization;Filtering;Machine learning;Tools;Task analysis","data visualisation;learning (artificial intelligence);pattern classification","on-demand detailed glyphs;instance-level performance evaluation;classifier confusion;instance level;supervised machine learning tasks;classification model;classification performance;visual analysis;class-level performance evaluation;InstanceFlow;dual-view visualization tool;Sankey diagram","","1","","24","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Interactive Graph Construction for Graph-Based Semi-Supervised Learning","C. Chen; Z. Wang; J. Wu; X. Wang; L. -Z. Guo; Y. -F. Li; S. Liu","School of Software, BNRist, Tsinghua University, Beijing, China; School of Software, BNRist, Tsinghua University, Beijing, China; Cardiff University, Cardiff, U.K.; Microsoft Research Asia, Beijing, China; Nanjing University, Nanjing, Jiangsu, China; Nanjing University, Nanjing, Jiangsu, China; School of Software, BNRist, Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2021","2021","27","9","3701","3716","Semi-supervised learning (SSL) provides a way to improve the performance of prediction models (e.g., classifier) via the usage of unlabeled samples. An effective and widely used method is to construct a graph that describes the relationship between labeled and unlabeled samples. Practical experience indicates that graph quality significantly affects the model performance. In this paper, we present a visual analysis method that interactively constructs a high-quality graph for better model performance. In particular, we propose an interactive graph construction method based on the large margin principle. We have developed a river visualization and a hybrid visualization that combines a scatterplot, a node-link diagram, and a bar chart to convey the label propagation of graph-based SSL. Based on the understanding of the propagation, a user can select regions of interest to inspect and modify the graph. We conducted two case studies to showcase how our method facilitates the exploitation of labeled and unlabeled samples for improving model performance.","1941-0506","","10.1109/TVCG.2021.3084694","National Key Research and Development Program of China(grant numbers:2020YFB2104100); National Natural Science Foundation of China(grant numbers:61936002); Institute Guo Qiang; Institute for Brain and Cognitive Science, Tsinghua University; Tsinghua-Kuaishou Institute of Future Media Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444198","Semi-supervised learning;unlabeled samples;graph quality","Dogs;Visualization;Image edge detection;Noise measurement;Labeling;Data visualization;Uncertainty","data visualisation;graph theory;learning (artificial intelligence)","graph-based semisupervised;semisupervised learning;prediction models;unlabeled samples;graph quality;visual analysis method;high-quality graph;interactive graph construction method;river visualization;hybrid visualization;label propagation;graph-based SSL","","1","","67","IEEE","28 May 2021","","","IEEE","IEEE Journals"
"Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images","X. Huang; S. Jamonnak; Y. Zhao; B. Wang; M. Hoai; K. Yager; W. Xu",Kent State University; Kent State University; Kent State University; Stony Brook University; Stony Brook University; Brookhaven National Laboratory; Brookhaven National Laboratory,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1312","1321","Existing interactive visualization tools for deep learning are mostly applied to the training, debugging, and refinement of neural network models working on natural images. However, visual analytics tools are lacking for the specific application of x-ray image classification with multiple structural attributes. In this paper, we present an interactive system for domain scientists to visually study the multiple attributes learning models applied to x-ray scattering images. It allows domain scientists to interactively explore this important type of scientific images in embedded spaces that are defined on the model prediction output, the actual labels, and the discovered feature space of neural networks. Users are allowed to flexibly select instance images, their clusters, and compare them regarding the specified visual representation of attributes. The exploration is guided by the manifestation of model performance related to mutual relationships among attributes, which often affect the learning accuracy and effectiveness. The system thus supports domain scientists to improve the training dataset and model, find questionable attributes labels, and identify outlier images or spurious data clusters. Case studies and scientists feedback demonstrate its functionalities and usefulness.","1941-0506","","10.1109/TVCG.2020.3030384","KSU graduate assistantship; BNL LDRD(grant numbers:18-009); ECP CODAR(grant numbers:17-SC-20-SC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240062","","X-ray scattering;Deep learning;Visualization;Tools;Computational modeling;X-ray imaging;Aerospace electronics","data visualisation;image classification;interactive systems;learning (artificial intelligence);neural nets;pattern clustering","specified visual representation;neural networks;model prediction output;scientific images;interactive system;multiple structural attributes;X-ray image classification;visual analytics tools;natural images;neural network models;deep learning;interactive visualization tools;X-ray scattering images;multiple attributes;interactive visual study;outlier images;domain scientists;learning accuracy","","1","","41","IEEE","26 Oct 2020","","","IEEE","IEEE Journals"
"Investigating Direct Manipulation of Graphical Encodings as a Method for User Interaction","B. Saket; S. Huron; C. Perin; A. Endert",Georgia Tech; University Paris Saclay; University of Victoria; Georgia Tech,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","482","491","We investigate direct manipulation of graphical encodings as a method for interacting with visualizations. There is an increasing interest in developing visualization tools that enable users to perform operations by directly manipulating graphical encodings rather than external widgets such as checkboxes and sliders. Designers of such tools must decide which direct manipulation operations should be supported, and identify how each operation can be invoked. However, we lack empirical guidelines for how people convey their intended operations using direct manipulation of graphical encodings. We address this issue by conducting a qualitative study that examines how participants perform 15 operations using direct manipulation of standard graphical encodings. From this study, we 1) identify a list of strategies people employ to perform each operation, 2) observe commonalities in strategies across operations, and 3) derive implications to help designers leverage direct manipulation of graphical encoding as a method for user interaction.","1941-0506","","10.1109/TVCG.2019.2934534","NSF(grant numbers:IIS-1750474); NSERC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809678","Direct Manipulation;Data Visualization","Bars;Data visualization;Encoding;Visualization;Image color analysis;Tools;Instruments","data visualisation;graph theory;human computer interaction;user interfaces","user interaction;direct manipulation operations;graphical encodings;visualization tools","","1","","47","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"Jurassic Mark: Inattentional Blindness for a Datasaurus Reveals that Visualizations are Explored, not Seen","T. Boger; S. B. Most; S. L. Franconeri",Yale University; UNSW Sydney; Northwestern University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","71","75","Graphs effectively communicate data because they capitalize on the visual system’s ability to rapidly extract patterns. Yet, this pattern extraction does not occur in a single glance. Instead, research on visual attention suggests that the visual system iteratively applies a sequence of filtering operations on an image, extracting patterns from subsets of visual information over time, while selectively inhibiting other information at each of these moments. To demonstrate that this powerful series of filtering operations also occurs during the perception of visualized data, we designed a task where participants made judgments from one class of marks on a scatterplot, presumably incentivizing them to relatively ignore other classes of marks. Participants consistently missed a conspicuous dinosaur in the ignored collection of marks (93% for a 1s presentation, and 61% for 2.5s), but not in a control condition where the incentive to ignore that collection was removed (25% for a 1s presentation, and 11% for 2.5s), revealing that data visualizations are not “seen” in a single glance, and instead require an active process of exploration.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623273","perception & cognition;attention;communcation/presentation","Dinosaurs;Visualization;Filtration;Data visualization;Process control;Blindness;Visual systems","data visualisation;feature extraction;image processing;visual perception","data visualizations;jurassic mark;inattentional blindness;datasaurus;visual system;pattern extraction","","1","","37","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Knowing what to look for: A Fact-Evidence Reasoning Framework for Decoding Communicative Visualization","S. Vaidya; A. Dasgupta",NJIT; NJIT,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","231","235","Despite the widespread use of charts as a medium for communicating data in science domains, we lack a systematic understanding of the goals and principles of effective visual communication. Existing research mostly focuses on the means, i.e. the encoding principles, and not the end, i.e. the key takeaway of a chart. To address this gap, we start from the first principles and aim to answer the fundamental question: how can we describe the message of a scientific chart? We contribute a fact-evidence reasoning framework (FaEvR) by augmenting the conventional visualization pipeline with the stages of gathering and associating evidence for decoding the facts presented in a chart. We apply the resulting classification scheme of fact and evidence on a collection of 500 charts collected from publications in multiple science domains. We demonstrate the practical applications of FaEvR in calibrating task complexity and detecting barriers towards chart interpretability.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331031","Visual communication;scientific communication;graphical reasoning;chart interpretation","Visualization;Systematics;Visual communication;Tools;Cognition;Decoding;Task analysis","calibration;data analysis;data visualisation;inference mechanisms;pattern classification","fact-evidence reasoning framework;communicative visualization;visual communication;encoding principles;conventional visualization pipeline;chart interpretability;FaEvR framework;classification scheme","","1","","39","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Kyrix-S: Authoring Scalable Scatterplot Visualizations of Big Data","W. Tao; X. Hou; A. Sah; L. Battle; R. Chang; M. Stonebraker",Massachusetts Institute of Technology; Zhejiang University; Zhejiang University; University of Maryland; Tufts University; Massachusetts Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","401","411","Static scatterplots often suffer from the overdraw problem on big datasets where object overlap causes undesirable visual clutter. The use of zooming in scatterplots can help alleviate this problem. With multiple zoom levels, more screen real estate is available, allowing objects to be placed in a less crowded way. We call this type of visualization scalable scatterplot visualizations, or SSV for short. Despite the potential of SSVs, existing systems and toolkits fall short in supporting the authoring of SSVs due to three limitations. First, many systems have limited scalability, assuming that data fits in the memory of one computer. Second, too much developer work, e.g., using custom code to generate mark layouts or render objects, is required. Third, many systems focus on only a small subset of the SSV design space (e.g. supporting a specific type of visual marks). To address these limitations, we have developed Kyrix-S, a system for easy authoring of SSVs at scale. Kyrix-S derives a declarative grammar that enables specification of a variety of SSVs in a few tens of lines of code, based on an existing survey of scatterplot tasks and designs. The declarative grammar is supported by a distributed layout algorithm which automatically places visual marks onto zoom levels. We store data in a multi-node database and use multi-node spatial indexes to achieve interactive browsing of large SSVs. Extensive experiments show that 1) Kyrix-S enables interactive browsing of SSVs of billions of objects, with response times under 500ms and 2) Kyrix-S achieves 4X-9X reduction in specification compared to a state-of-the-art authoring system.","1941-0506","","10.1109/TVCG.2020.3030372","NSF(grant numbers:OAC-1940175,OAC-1939945,IIS-1452977,DGE-1855886,IIS-1850115); Defense Advanced Research Projects Agency(grant numbers:FA8750-17-2-0107); Data Systems and AI Lab initiative(grant numbers:3882825); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222038","pan/zoom visualization;declarative grammar;scalability;performance optimization","Visualization;Data visualization;Layout;Grammar;Scalability;Semantics;Heating systems","authoring systems;Big Data;data visualisation;grammars;real-time systems;rendering (computer graphics)","Kyrix-S;authoring scalable scatterplot visualizations;static scatterplots;overdraw problem;big datasets;object overlap causes undesirable visual clutter;multiple zoom levels;screen real estate;visualization scalable scatterplot visualizations;developer work;custom code;mark layouts;render objects;systems focus;SSV design space;visual marks;easy authoring;declarative grammar;scatterplot tasks;state-of-the-art authoring system;SSV","","1","","54","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Learning Adaptive Sampling and Reconstruction for Volume Visualization","S. Weiss; M. Isik; J. Thies; R. Westermann","Computer Science, Technical University of Munich, 9184 Munchen, Bavaria, Germany, (e-mail: sebastian.weiss@in.tum.de); Computer Science, Technical University of Munich, 9184 Munchen, Bavaria, Germany, (e-mail: m.isik@tum.de); Computer Science, Technical University of Munich, 9184 Munchen, Bavaria, Germany, (e-mail: justus.thies@tum.de); Informatik 15 (Computer Graphik & Visualisierung), Technische Universitt Mnchen, Garching bei Mnchen, Bavaria, Germany, 85748 (e-mail: westermann@tum.de)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","A central challenge in data visualization is to understand which data samples are required to generate an image of a data set in which the relevant information is encoded. In this work, we make a first step towards answering the question of whether an artificial neural network can predict where to sample the data with higher or lower density, by learning of correspondences between the data, the sampling patterns and the generated images. We introduce a novel neural rendering pipeline, which is trained end-to-end to generate a sparse adaptive sampling structure from a given low-resolution input image, and reconstructs a high-resolution image from the sparse set of samples. For the first time, to the best of our knowledge, we demonstrate that the selection of structures that are relevant for the final visual representation can be jointly learned together with the reconstruction of this representation from these structures. Therefore, we introduce differentiable sampling and reconstruction stages, which can leverage back-propagation based on supervised losses solely on the final image. We shed light on the adaptive sampling patterns generated by the network pipeline and analyze its use for volume visualization including isosurface and direct volume rendering.","1941-0506","","10.1109/TVCG.2020.3039340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264699","Volume visualization;adaptive sampling;deep learning","Image reconstruction;Data visualization;Pipelines;Image resolution;Visualization;Rendering (computer graphics);Neural networks","","","","1","","","IEEE","19 Nov 2020","","","IEEE","IEEE Early Access Articles"
"Let’s Gamble: How a Poor Visualization Can Elicit Risky Behavior","M. Bancilhon; Z. Liu; A. Ottley",Washington University in St. Louis; Washington University in St. Louis; Washington University in St. Louis,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","196","200","Data visualizations are standard tools for assessing and communicating risks. However, it is not always clear which designs are optimal or how encoding choices might influence risk perception and decision-making. In this paper, we report the findings of a large-scale gambling game that immersed participants in an environment where their actions impacted their bonuses. Participants chose to either enter a lottery or receive guaranteed monetary gains based on five visualization designs. By measuring risk perception and observing decision-making, we present suggestive evidence that people were more likely to gamble when presented area proportioned triangle and circle designs. Using our results, we model risk perception and discuss how our findings can improve visualization selection.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00046","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331315","Human-centered computing;Visualization;Decision Theory;Risk Behavior;Evaluation methods","Decision making;Data visualization;Tools;Probability;Particle measurements;Standards;Incentive schemes","data visualisation;decision making;game theory;risk management","data visualizations;encoding choices;large-scale gambling game;monetary gains;visualization designs;risk perception;visualization selection;risk decision-making;area proportioned triangle design;circle design","","1","","23","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Modeling Repetitive Motions Using Structured Light","Y. Xu; D. G. Aliaga","Purdue University, West Lafayette; Purdue University, West Lafayette","IEEE Transactions on Visualization and Computer Graphics","18 May 2010","2010","16","4","676","689","Obtaining models of dynamic 3D objects is an important part of content generation for computer graphics. Numerous methods have been extended from static scenarios to model dynamic scenes. If the states or poses of the dynamic object repeat often during a sequence (but not necessarily periodically), we call such a repetitive motion. There are many objects, such as toys, machines, and humans, undergoing repetitive motions. Our key observation is that when a motion-state repeats, we can sample the scene under the same motion state again but using a different set of parameters; thus, providing more information of each motion state. This enables robustly acquiring dense 3D information difficult for objects with repetitive motions using only simple hardware. After the motion sequence, we group temporally disjoint observations of the same motion state together and produce a smooth space-time reconstruction of the scene. Effectively, the dynamic scene modeling problem is converted to a series of static scene reconstructions, which are easier to tackle. The varying sampling parameters can be, for example, structured-light patterns, illumination directions, and viewpoints resulting in different modeling techniques. Based on this observation, we present an image-based motion-state framework and demonstrate our paradigm using either a synchronized or an unsynchronized structured-light acquisition method.","1941-0506","","10.1109/TVCG.2009.207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332229","Three-dimensional graphics and realism;digitization and image capture;geometric modeling.","Layout;Image reconstruction;Robustness;Humans;Image converters;Cameras;Computer graphics;Hardware;Image sampling;Lighting","computer graphics;image motion analysis;image reconstruction;image sequences","repetitive motion modelling;dynamic 3D object model;computer graphics;motion sequence;space-time reconstruction;dynamic scene modeling problem;static scene reconstructions;structured-light patterns;image-based motion-state framework;unsynchronized structured-light acquisition method;synchronized structured-light acquisition method","Algorithms;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Lighting;Models, Theoretical;Motion","1","","41","","13 Nov 2009","","","IEEE","IEEE Journals"
"Multi-Perspective, Simultaneous Embedding","M. I. Hossain; V. Huroyan; S. Kobourov; R. Navarrete",Computer Science DepartmentThe University of Arizona; Department of MathematicsThe University of Arizona; Computer Science DepartmentThe University of Arizona; Department of MathematicsThe University of Arizona,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1569","1579","We describe MPSE: a Multi-Perspective Simultaneous Embedding method for visualizing high-dimensional data, based on multiple pairwise distances between the data points. Specifically, MPSE computes positions for the points in 3D and provides different views into the data by means of 2D projections (planes) that preserve each of the given distance matrices. We consider two versions of the problem: fixed projections and variable projections. MPSE with fixed projections takes as input a set of pairwise distance matrices defined on the data points, along with the same number of projections and embeds the points in 3D so that the pairwise distances are preserved in the given projections. MPSE with variable projections takes as input a set of pairwise distance matrices and embeds the points in 3D while also computing the appropriate projections that preserve the pairwise distances. The proposed approach can be useful in multiple scenarios: from creating simultaneous embedding of multiple graphs on the same set of vertices, to reconstructing a 3D object from multiple 2D snapshots, to analyzing data from multiple points of view. We provide a functional prototype of MPSE that is based on an adaptive and stochastic generalization of multi-dimensional scaling to multiple distances and multiple variable projections. We provide an extensive quantitative evaluation with datasets of different sizes and using different number of projections, as well as several examples that illustrate the quality of the resulting solutions.","1941-0506","","10.1109/TVCG.2020.3030373","National Science Foundation(grant numbers:CCF-1740858,CCF-1712119,DMS-1839274); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241407","Graph visualization;Dimensionality reduction;Multidimensional scaling;Mental map preservation","Three-dimensional displays;Data visualization;Layout;Two dimensional displays;Visualization;Dimensionality reduction;Optimization","data visualisation;graph theory;matrix algebra","multiple variable projections;MPSE;MultiPerspective Simultaneous Embedding method;high-dimensional data;multiple pairwise distances;data points;distance matrices;fixed projections;pairwise distance matrices;multiple graphs;multiple 2D snapshots;multidimensional scaling;multiple distances","","1","","51","IEEE","27 Oct 2020","","","IEEE","IEEE Journals"
"Natural Language to Visualization by Neural Machine Translation","Y. Luo; N. Tang; G. Li; J. Tang; C. Chai; X. Qin","Department of Computer Science, Tsinghua University, China; QCRI, Hamad Bin Khalifa University, Qatar; Department of Computer Science, Tsinghua University, China; American School of Doha, Doha, Qatar; Department of Computer Science, Tsinghua University, China; Department of Computer Science, Tsinghua University, China","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","217","226","Supporting the translation from natural language (NL) query to visualization (NL2VIS) can simplify the creation of data visualizations because if successful, anyone can generate visualizations by their natural language from the tabular data. The state-of-the-art NL2VIS approaches (<italic>e.g.</italic>, NL4DV and FlowSense) are based on semantic parsers and heuristic algorithms, which are not end-to-end and are not designed for supporting (possibly) complex data transformations. Deep neural network powered neural machine translation models have made great strides in many machine translation tasks, which suggests that they might be viable for NL2VIS as well. In this paper, we present <bold>ncNet</bold>, a Transformer-based sequence-to-sequence model for supporting NL2VIS, with several novel visualization-aware optimizations, including using attention-forcing to optimize the learning process, and visualization-aware rendering to produce better visualization results. To enhance the capability of machine to comprehend natural language queries, <bold>ncNet</bold> is also designed to take an optional chart template (<italic>e.g.</italic>, a pie chart or a scatter plot) as an additional input, where the chart template will be served as a constraint to limit what could be visualized. We conducted both quantitative evaluation and user study, showing that <bold>ncNet</bold> achieves good accuracy in the <bold>nvBench</bold> benchmark and is easy-to-use.","1941-0506","","10.1109/TVCG.2021.3114848","NSF of China(grant numbers:61925205,61632016); Beijing National Research Center for Information Science and Technology; Huawei; TAL Education; China National Postdoctoral Program for Innovative Talents(grant numbers:BX2021155); China Postdoctoral Science Foundation(grant numbers:2021M691784); Zhejiang Lab's International Talent Fund for Young Professionals; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617561","Natural language interface;data visualization;neural machine translation;chart template","Data visualization;Natural languages;Bars;Deep learning;Machine translation;Visualization;Transformers","charts;data visualisation;grammars;language translation;learning (artificial intelligence);natural language processing;neural nets;rendering (computer graphics)","natural language query;data visualizations;tabular data;state-of-the-art NL2VIS approaches;supporting complex data transformations;neural network;neural machine translation models;machine translation tasks;Transformer-based sequence-to-sequence model;novel visualization-aware optimizations;visualization-aware rendering;visualization results","","1","","58","IEEE","16 Nov 2021","","","IEEE","IEEE Journals"
"OCTVis: Ontology-Based Comparison of Topic Models","A. Ge; H. Jang; G. Carenini; K. Ho; Y. J. Lee","University of British Columbia,Department of Computer Science; University of British Columbia,Department of Computer Science; University of British Columbia,Department of Computer Science; University of British Columbia,Department of Emergency Medicine; University of Pittsburgh,School of Nursing","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","66","70","Evaluating topic modeling results requires communication between domain and NLP experts. OCTVis is a visual interface to compare the quality of two topic models when mapped against a domain ontology. Its design is based on detailed data and task models, and was tested in a case study in the healthcare domain.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933646","Human-centered computing;Visualization;Visualization design and evaluation methods","Ontologies;Computational modeling;Task analysis;Data models;Measurement;Analytical models;Semantics","data visualisation;health care;medical computing;natural language processing;ontologies (artificial intelligence)","NLP experts;OCTVis;visual interface;domain ontology;healthcare domain;ontology-based comparison;topic modeling","","1","","24","","19 Dec 2019","","","IEEE","IEEE Conferences"
"OD Morphing: Balancing Simplicity with Faithfulness for OD Bundling","Y. Lyu; X. Liu; H. Chen; A. Mangal; K. Liu; C. Chen; B. Lim","National University of Singapore; Southeast University, China; Zhejiang University, China; Indian Institute of Technology, Delhi; Chongqing University, China; Chongqing University, China; National University of Singapore","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","811","821","OD bundling is a promising method to identify key origin-destination (OD) patterns, but the bundling can mislead the interpretation of actual trajectories traveled. We present OD Morphing, an interactive OD bundling technique that improves geographical faithfulness to actual trajectories while preserving visual simplicity for OD patterns. OD Morphing iteratively identifies critical waypoints from the actual trajectory network with a min-cut algorithm and transitions OD bundles to pass through the identified waypoints with a smooth morphing method. Furthermore, we extend OD Morphing to support bundling at interaction speeds to enable users to interactively transition between degrees of faithfulness to aid sensemaking. We introduce metrics for faithfulness and simplicity to evaluate their trade-off achieved by OD morphed bundling. We demonstrate OD Morphing on real-world city-scale taxi trajectory and USA domestic planned flight datasets.","1941-0506","","10.1109/TVCG.2019.2934657","Ministry of Education; National Natural Science Foundation of China(grant numbers:61872049); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809845","OD Visualization;Edge Bundling;Trajectory","Trajectory;Data visualization;Roads;Public transportation;Visualization;Image edge detection","data visualisation;graph theory;interactive systems;pattern clustering","OD Morphing;faithfulness;origin-destination patterns;interactive OD bundling technique;OD patterns;min-cut algorithm;balancing simplicity;OD visualization;smooth morphing method","","1","","59","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"On the Readability of Abstract Set Visualizations","M. Wallinger; B. Jacobsen; S. Kobourov; M. Nöllenburg","Algorithms and Complexity Group, TU Wien, Vienna, Austria; Dept. of Computer Science, University of Arizona, Tucson, AZ, USA; Dept. of Computer Science, University of Arizona, Tucson, AZ, USA; Algorithms and Complexity Group, TU Wien, Vienna, Austria","IEEE Transactions on Visualization and Computer Graphics","12 May 2021","2021","27","6","2821","2832","Set systems are used to model data that naturally arises in many contexts: social networks have communities, musicians have genres, and patients have symptoms. Visualizations that accurately reflect the information in the underlying set system make it possible to identify the set elements, the sets themselves, and the relationships between the sets. In static contexts, such as print media or infographics, it is necessary to capture this information without the help of interactions. With this in mind, we consider three different systems for medium-sized set data, LineSets, EulerView, and MetroSets, and report the results of a controlled human-subjects experiment comparing their effectiveness. Specifically, we evaluate the performance, in terms of time and error, on tasks that cover the spectrum of static set-based tasks. We also collect and analyze qualitative data about the three different visualization systems. Our results include statistically significant differences, suggesting that MetroSets performs and scales better.","1941-0506","","10.1109/TVCG.2021.3074615","NSF(grant numbers:CCF-1740858,CCF-1712119,DMS-1839274); Vienna Science and Technology Fund (WWTF)(grant numbers:ICT19-035); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418624","set visualization;usability study;quantitative evaluation","Task analysis;Data visualization;Social networking (online);Transmission line matrix methods;Shape;Bipartite graph;Taxonomy","data visualisation;directed graphs;set theory;statistical analysis","genres;underlying set system;set elements;static contexts;print media;medium-sized set data;controlled human-subjects;static set-based tasks;qualitative data;different visualization systems;readability;abstract set visualizations;set systems;social networks;musicians","","1","","50","IEEE","29 Apr 2021","","","IEEE","IEEE Journals"
"Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality","A. Choudhry; M. Sharma; P. Chundury; T. Kapler; D. W. S. Gray; N. Ramakrishnan; N. Elmqvist","Virginia Tech, Arlington, VA, USA; Virginia Tech, Arlington, VA, USA; University of Maryland, College Park, MD, USA; Uncharted Software, Toronto, Canada; Uncharted Software, Toronto, Canada; Virginia Tech, Arlington, VA, USA; University of Maryland, College Park, MD, USA","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1332","1342","Causality visualization can help people understand temporal chains of events, such as messages sent in a distributed system, cause and effect in a historical conflict, or the interplay between political actors over time. However, as the scale and complexity of these event sequences grows, even these visualizations can become overwhelming to use. In this paper, we propose the use of textual narratives as a data-driven storytelling method to augment causality visualization. We first propose a design space for how textual narratives can be used to describe causal data. We then present results from a crowdsourced user study where participants were asked to recover causality information from two causality visualizations-causal graphs and Hasse diagrams-with and without an associated textual narrative. Finally, we describe Causeworks, a causality visualization system for understanding how specific interventions influence a causal model. The system incorporates an automatic textual narrative mechanism based on our design space. We validate Causeworks through interviews with experts who used the system for understanding complex events.","1941-0506","","10.1109/TVCG.2020.3030358","Defense Advanced Research Projects Agency (DARPA)(grant numbers:FA8650-17-C-7720); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222357","Causality visualization;natural language generation;data-driven storytelling;temporal data;quantitative studies","Data visualization;Visualization;Natural languages;Pipelines;Task analysis;Correlation;Tools","causality;data visualisation;graph theory;social networking (online)","textual narratives;distributed system;event sequences;data-driven storytelling method;design space;causal data;causality information;causality visualizations-causal graphs;causality visualization system;automatic textual narrative mechanism;complex events","","1","","68","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Output-Sensitive Avatar Representations for Immersive Telepresence","A. Kreskowski; S. Beck; B. Froehlich","Virtual Reality and Visualization Research Group, Bauhaus-Universitt Weimar, 26597 Weimar, Thuringia, Germany, 99423 (e-mail: adrian.kreskowski@uni-weimar.de); Virtual Reality Systems Group, Bauhaus-Universitt Weimar, Weimar, Thringen, Germany, (e-mail: stephan.beck@uni-weimar.de); Faculty of Media, Bauhaus-Universitaet Weimar, Weimar, Thuringia, Germany, 99423 (e-mail: bernd.froehlich@uni-weimar.de)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","In this paper, we propose a system design and implementation for output-sensitive reconstruction, transmission and rendering of 3D video avatars in distributed virtual environments. In our immersive telepresence system, users are captured by multiple RGBD sensors connected to a server that performs geometry reconstruction based on viewing feedback from remote telepresence parties. This feedback and reconstruction loop enables visibility-aware level-of-detail reconstruction of video avatars regarding geometry and texture data, and considers individual and groups of collocated users. Our evaluation reveals that our approach leads to a significant reduction of reconstruction times, network bandwidth requirements and round-trip times as well as rendering costs in many situations.","1941-0506","","10.1109/TVCG.2020.3037360","Thringer Ministerium fr Wirtschaft Wissenschaft und Digitale Gesellschaft(grant numbers:5575/10-5 (MetaReal)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257094","Immersive telepresence;avatars;output-sensitive rendering;distributed virtual environments","Three-dimensional displays;Avatars;Telepresence;Rendering (computer graphics);Streaming media;Geometry;Image reconstruction","","","","1","","","IEEE","11 Nov 2020","","","IEEE","IEEE Early Access Articles"
"Popup-Plots: Warping Temporal Data Visualization","J. Schmidt; D. Fleischmann; B. Preim; N. Brändle; G. Mistelbauer","AIT Austrian Institute of Technology, Vienna, Austria; Stanford University, Stanford, CA; Otto-von-Guericke University, Magdeburg, Germany; AIT Austrian Institute of Technology, Vienna, Austria; Otto-von-Guericke University, Magdeburg, Germany","IEEE Transactions on Visualization and Computer Graphics","27 May 2019","2019","25","7","2443","2457","Temporal data visualization is used to analyze dependent variables that vary over time, with time being an independent variable. Visualizing temporal data is inherently difficult, due to the many aspects that need to be communicated to the users (e.g., time and variable changes). This is an important topic in visualization, and a wide range of visualization techniques dealing with different tasks have already been designed. In this paper we propose popup-plots, a novel concept where the common interaction of 3D rotation is used to navigate through the data. This allows the users to view the data from different perspectives without having to learn and adapt to new interaction concepts. Popup-plots are therefore a novel method for visualizing and interacting with dependent variables over time. We extend 2D plots with the temporal information by bending the space according to the time. The bending is calculated based on a spherical coordinates approach, which is continuously influenced by the viewing direction towards the plot. Hence, the plot can be viewed from various angles with seamless transitions in between, offering the possibility to analyze different aspects of the represented data. As the current viewing direction is inherently depicted by the shape of the data, the users are able to deduce which part of the data is currently viewed. The temporal information is encoded into the visualization itself, resembling annual rings of a tree. We demonstrate our method by applying it to data from two different domains, comprising measurements at spatial positions over time, and we also evaluated the usability of our solution.","1941-0506","","10.1109/TVCG.2018.2841385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8368315","Temporal data;time-dependent visualization;3D plots;ellipsoidal coordinate system","Data visualization;Three-dimensional displays;Two dimensional displays;Temperature measurement;Time measurement;Layout","data visualisation","popup-plots;temporal data visualization;dependent variables;interaction concepts;3D rotation;spherical coordinates","","1","","55","IEEE","29 May 2018","","","IEEE","IEEE Journals"
"PyramidTags: Context-, Time- and Word Order-Aware Tag Maps to Explore Large Document Collections","J. Knittel; S. Koch; T. Ertl","Institute of Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany; Institute of Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany; Institute of Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2021","2021","27","12","4455","4468","It is difficult to explore large text collections if no or little information is available on the contained documents. Hence, starting analytic tasks on such corpora is challenging for many stakeholders from various domains. As a remedy, recent visualization research suggests to use visual spatializations of representative text documents or tags to explore text collections. With PyramidTags, we introduce a novel approach for summarizing large text collections visually. In contrast to previous work, PyramidTags in particular aims at creating an improved representation that incorporates both temporal evolution and semantic relationship of visualized tags within the summarized document collection. As a result, it equips analysts with a visual starting point for interactive exploration to not only get an overview of the main terms and phrases of the corpus, but also to grasp important ideas and stories. Analysts can hover and select multiple tags to explore relationships and retrieve the most relevant documents. In this work, we apply PyramidTags to hundreds of thousands of web-crawled news reports. Our benchmarks suggest that PyramidTags creates time- and context-aware layouts, while preserving the inherent word order of important pairs.","1941-0506","","10.1109/TVCG.2020.3010095","German Science Foundation DFG(grant numbers:392087235); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143452","Visual analytics;information retrieval;text analysis;layout","Tag clouds;Layout;Data visualization;Text mining;Semantics","","","","1","","57","IEEE","17 Jul 2020","","","IEEE","IEEE Journals"
"Quality of Service Impact on Edge Physics Simulations for VR","S. Friston; E. Griffith; D. Swapp; C. Lrondi; F. Jjunju; R. Ward; A. Marshall; A. Steed",Department of Computer ScienceUniversity College London; Department of Electrical Engineering and ElectronicsUniversity of Liverpool; Department of Computer ScienceUniversity College London; Department of Electrical Engineering and ElectronicsUniversity of Liverpool; Department of Electrical Engineering and ElectronicsUniversity of Liverpool; Department of Electrical Engineering and ElectronicsUniversity of Liverpool; Department of Electrical Engineering and ElectronicsUniversity of Liverpool; Department of Computer ScienceUniversity College London,"IEEE Transactions on Visualization and Computer Graphics","16 Apr 2021","2021","27","5","2691","2701","Mobile HMDs must sacrifice compute performance to achieve ergonomic and power requirements for extended use. Consequently, applications must either reduce rendering and simulation complexity - along with the richness of the experience - or offload complexity to a server. Within the context of edge-computing, a popular way to do this is through render streaming. Render streaming has been demonstrated for desktops and consoles. It has also been explored for HMDs. However, the latency requirements of head tracking make this application much more challenging. While mobile GPUs are not yet as capable as their desktop counterparts, we note that they are becoming more powerful and efficient. With the hard requirements of VR, it is worth continuing to investigate what schemes could optimally balance load, latency and quality. We propose an alternative we call edge-physics: streaming at the scene-graph level from a simulation running on edge-resources, analogous to cluster rendering. Scene streaming is not only straightforward, but compute and bandwidth efficient. The most demanding loops run locally. Jobs that hit the power-wall of mobile CPUs are off-loaded, while improving GPUs are leveraged, maximising compute utilisation. In this paper we create a prototypical implementation and evaluate its potential in terms of fidelity, bandwidth and performance. We show that an effective system which maintains high consistencies on typical edge-links can be easily built, but that some traditional concepts are not applicable, and a better understanding of the perception of motion is required to evaluate such a system comprehensively.","1941-0506","","10.1109/TVCG.2021.3067757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382921","virtual reality;streaming;edge-computing","Streaming media;Physics;Bandwidth;Quality of service;Servers;Visualization;Rendering (computer graphics)","graph theory;graphics processing units;mobile computing;power aware computing;rendering (computer graphics);virtual reality","edge physics simulations;VR;mobile HMDs;power requirements;offload complexity;edge-computing;render streaming;latency requirements;head tracking;mobile GPUs;desktop counterparts;hard requirements;scene-graph level;edge-resources;cluster rendering;scene streaming;power-wall;mobile CPUs;typical edge-links;quality of service impact;simulation complexity;motion perception","","1","","55","IEEE","22 Mar 2021","","","IEEE","IEEE Journals"
"Real-Time External Labeling of Ghosted Views","L. Čmolík; J. Bittner","Czech Technical University in Prague, Prague 6, Czech Republic; Czech Technical University in Prague, Prague 6, Czech Republic","IEEE Transactions on Visualization and Computer Graphics","27 May 2019","2019","25","7","2458","2470","We present a new algorithm for calculating the external labeling of ghosted views of moderately complex 3D models. The algorithm uses multiple criteria decision making, based on fuzzy logic, to optimize positions of the labels associated with different parts of the input model. The proposed method can be used with various existing algorithms for creating ghosted views from 3D models. The method operates in real-time, which allows the user to acquire a good understanding of the structure of the input model by studying the model and its labels from different viewpoints. We have conducted a user study to evaluate label layouts produced by our algorithm and those created by humans. The results show that the proposed method can significantly improve user understanding of labeled ghosted views of complicated 3D models, and its label layouts are comparable with label layouts created by humans.","1941-0506","","10.1109/TVCG.2018.2833479","MSMT(grant numbers:7AMB17AT021); MOBILITY(grant numbers:MSMT-539/2017-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355684","External labeling;ghosted views;illustrative visualization;empirical evaluation;visualization for the masses","Labeling;Three-dimensional displays;Solid modeling;Layout;Real-time systems;Computational modeling;Rendering (computer graphics)","data visualisation;decision making;fuzzy logic;stereo image processing","fuzzy logic;label layouts;labeled ghosted views;complicated 3D models;multiple criteria decision making;complex 3D models;real time external labeling","","1","","40","IEEE","7 May 2018","","","IEEE","IEEE Journals"
"Refocusable Gigapixel Panoramas for Immersive VR Experiences","W. Lyu; P. Ding; Y. Zhang; A. Chen; M. Wu; S. Yin; J. Yu","VRVC Lab, ShanghaiTech University, Pudong, China; VRVC Lab, ShanghaiTech University, Pudong, China; VRVC Lab, ShanghaiTech University, Pudong, China; VRVC Lab, ShanghaiTech University, Pudong, China; VRVC Lab, ShanghaiTech University, Pudong, China; LION Lab, ShanghaiTech University, Pudong, China; VRVC Lab, ShanghaiTech University, Pudong, China","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","3","2028","2040","There have been significant advances in capturing gigapixel panoramas (GPP). However, solutions for viewing GPPs on head-mounted displays (HMDs) are lagging: an immersive experience requires ultra-fast rendering while directly loading a GPP onto the GPU is infeasible due to limited texture memory capacity. In this paper, we present a novel out-of-core rendering technique that supports not only classic panning, tilting, and zooming but also dynamic refocusing for viewing a GPP on HMD. Inspired by the network package transmission mechanisms in distributed visualization, our approach employs hierarchical image tiling and on-demand data updates across the main and the GPU memory. We further present a multi-resolution rendering scheme and a refocused light field rendering technique based on RGBD GPPs with minimal memory overhead. Comprehensive experiments demonstrate that our technique is highly efficient and reliable, able to achieve ultra-high frame rates (> 50 fps) even on low-end GPUs. With an embedded gaze tracker, our technique enables immersive panorama viewing experiences with unprecedented resolutions, field-of-view, and focus variations while maintaining smooth spatial, angular, and focal transitions.","1941-0506","","10.1109/TVCG.2019.2940444","Science and Technology Commission of Shanghai Municipality(grant numbers:17XD1402900,17JC1403800,17511108201,17511105805,2015F0203-000-06); SHMEC(grant numbers:2019-01-07-00-01-E00003); Shanghai Municipal Commission of Economy and Informatization(grant numbers:2018-RGZN-01011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827949","Gigapixel panoramas;dynamic refocusing;memory management;I/O scheduling;virtual reality","Rendering (computer graphics);Cameras;Headphones;Graphics processing units;Image resolution;Resists;Engines","data visualisation;helmet mounted displays;image resolution;image texture;rendering (computer graphics);virtual reality","head-mounted displays;HMD;immersive experience;GPP;texture memory capacity;out-of-core rendering technique;classic panning;dynamic refocusing;network package transmission mechanisms;distributed visualization;hierarchical image tiling;on-demand data updates;GPU memory;multiresolution rendering scheme;refocused light field;minimal memory;comprehensive experiments;ultra-high frame rates;immersive panorama;field-of-view;refocusable gigapixel panoramas;immersive VR experiences;RGBD GPP","","1","","57","IEEE","10 Sep 2019","","","IEEE","IEEE Journals"
"Scalable Mesh Refinement for Canonical Polygonal Schemas of Extremely High Genus Shapes","M. Livesu","CNR IMATI, Genova, Liguria, Italy","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","254","260","Any closed manifold of genus g can be cut open to form a topological disk and then mapped to a regular polygon with 4g sides. This construction is called the canonical polygonal schema of the manifold, and is a key ingredient for many applications in graphics and engineering, where a parameterization between two shapes with same topology is often needed. The sides of the 4g-gon define on the manifold a system of loops, which all intersect at a single point and are disjoint elsewhere. Computing a shortest system of loops of this kind is NP-hard. A computationally tractable alternative consists of computing a set of shortest loops that are not fully disjoint in polynomial time using the greedy homotopy basis algorithm proposed by Erickson and Whittlesey and then detach them in post processing via mesh refinement. Despite this operation is conceptually simple, known refinement strategies do not scale well for high genus shapes, triggering a mesh growth that may exceed the amount of memory available in modern computers, leading to failures. In this article we study various local refinement operators to detach cycles in a system of loops, and show that there are important differences between them, both in terms of mesh complexity and preservation of the original surface. We ultimately propose two novel refinement approaches: the former greatly reduces the number of new elements in the mesh, possibly at the cost of a deviation from the input geometry. The latter allows to trade mesh complexity for geometric accuracy, bounding deviation from the input surface. Both strategies are trivial to implement, and experiments confirm that they allow to realize canonical polygonal schemas even for extremely high genus shapes where previous methods fail.","1941-0506","","10.1109/TVCG.2020.3010736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145719","Topology;polygonal schema;cut graph;homology;homotopy","Manifolds;Shape;Basis algorithms;Geometry;Complexity theory;Topology;Robustness","computational complexity;computational geometry;geometry;mesh generation;polynomials;solid modelling","greedy homotopy basis algorithm;mesh growth;local refinement operators;mesh complexity;canonical polygonal schema;scalable mesh refinement;polygonal schemas;topological disk;genus shapes","","1","","24","IEEE","21 Jul 2020","","","IEEE","IEEE Journals"
"Scalable Topological Data Analysis and Visualization for Evaluating Data-Driven Models in Scientific Applications","S. Liu; D. Wang; D. Maljovec; R. Anirudh; J. J. Thiagarajan; S. A. Jacobs; B. C. Van Essen; D. Hysom; J. -S. Yeom; J. Gaffney; L. Peterson; P. B. Robinson; H. Bhatia; V. Pascucci; B. K. Spears; P. -T. Bremer","Lawrence Livermore National Laboratory; SCI Institute, University of Utah; SCI Institute, University of Utah; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; SCI Institute, University of Utah; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","291","300","With the rapid adoption of machine learning techniques for large-scale applications in science and engineering comes the convergence of two grand challenges in visualization. First, the utilization of black box models (e.g., deep neural networks) calls for advanced techniques in exploring and interpreting model behaviors. Second, the rapid growth in computing has produced enormous datasets that require techniques that can handle millions or more samples. Although some solutions to these interpretability challenges have been proposed, they typically do not scale beyond thousands of samples, nor do they provide the high-level intuition scientists are looking for. Here, we present the first scalable solution to explore and analyze high-dimensional functions often encountered in the scientific data analysis pipeline. By combining a new streaming neighborhood graph construction, the corresponding topology computation, and a novel data aggregation scheme, namely topology aware datacubes, we enable interactive exploration of both the topological and the geometric aspect of high-dimensional data. Following two use cases from high-energy-density (HED) physics and computational biology, we demonstrate how these capabilities have led to crucial new insights in both applications.","1941-0506","","10.1109/TVCG.2019.2934594","U.S. Department of Energy; Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344); NSF(grant numbers:1602127); CGV(grant numbers:1314896); ACI(grant numbers:1649923); DOE/SciDAC(grant numbers:DESC0007446); PSAAP; CCMSC(grant numbers:DE-NA0002375); OAC(grant numbers:1842042); Intel Graphics and Visualization; Institutes of XeLLENCE program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820172","Model Evaluation;Deep Learning;High-Dimensional Space;Topological Data Analysis;Inertial Confinement Fusion","Computational modeling;Data visualization;Data analysis;Analytical models;Topology;Physics;Predictive models","biology computing;data aggregation;data analysis;data visualisation;graph theory;high energy physics instrumentation computing;learning (artificial intelligence);neural nets","black box models;deep neural networks;high-level intuition scientists;high-dimensional functions;scientific data analysis pipeline;topology computation;topology aware datacubes;interactive exploration;high-dimensional data;high-energy-density physics;computational biology;scalable topological data analysis;data-driven models;scientific applications;large-scale applications;data visualization;machine learning techniques;neighborhood graph construction;data aggregation scheme","","1","","38","IEEE","30 Aug 2019","","","IEEE","IEEE Journals"
"Sentifiers: Interpreting Vague Intent Modifiers in Visual Analysis using Word Co-occurrence and Sentiment Analysis","V. Setlur; A. Kumar",Tableau Software; Tableau Software,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","216","220","Natural language interaction with data visualization tools often involves the use of vague subjective modifiers in utterances such as ""show me the sectors that are performing"" and ""where is a good neighborhood to buy a house?."" Interpreting these modifiers is often difficult for these tools because their meanings lack clear semantics and are in part defined by context and personal user preferences. This paper presents a system called Sentifiers that makes a first step in better understanding these vague predicates. The algorithm employs word co-occurrence and sentiment analysis to determine which data attributes and filters ranges to associate with the vague predicates. The provenance results from the algorithm are exposed to the user as interactive text that can be repaired and refined. We conduct a qualitative evaluation of the Sentifiers that indicates the usefulness of the interface as well as opportunities for better supporting subjective utterances in visual analysis tasks through natural language.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331269","vague and subjective modifiers;natural language interaction;sentiment analysis;visual analysis","Visualization;Sentiment analysis;Natural languages;Semantics;Data visualization;Tools;Task analysis","data visualisation;interactive systems;natural language processing;sentiment analysis;text analysis","word co-occurrence;sentiment analysis;data attributes;vague predicates;interactive text;Sentifiers;visual analysis tasks;vague intent modifiers;natural language interaction;data visualization tools;personal user preferences;subjective modifiers;subjective utterances","","1","","43","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Shedding Light on Cast Shadows: An Investigation of Perceived Ground Contact in AR and VR","H. Adams; J. Stefanucci; S. H. Creem-Regehr; G. Pointon; W. B. Thompson; B. Bodenheimer","Electrical Engineering and Computer Science, Vanderbilt University, 5718 Nashville, Tennessee, United States, 37240-0002 (e-mail: haley.a.adams@vanderbilt.edu); Psychology, University of Utah, Salt Lake City, Utah, United States, 84112 (e-mail: jeanine.stefanucci@psych.utah.edu); Psychology, University of Utah, Salt Lake City, Utah, United States, (e-mail: sarah.creem@psych.utah.edu); Psychology, University of Utah, Salt Lake City, Utah, United States, (e-mail: grant.pointon@psych.utah.edu); Computer Science, University of Utah, Salt Lake City, Utah, United States, (e-mail: thompson@cs.utah.edu); Electrical Engineering and Computer Science, Vanderbilt University School of Engineering, 541729 Nashville, Tennessee, United States, (e-mail: bobbyb@vuse.vanderbilt.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Virtual objects in augmented reality (AR) often appear to float atop real world surfaces, which makes it difficult to determine where they are positioned in space. This is problematic as many applications for AR require accurate spatial perception. In the current study, we examine how the way we render cast shadows--which act as an important monocular depth cue for creating a sense of contact between an object and the surface beneath it--impacts spatial perception. Over two experiments, we evaluate people's sense of surface contact given both traditional and non-traditional shadow shading methods in optical see-through augmented reality (OST AR), video see-through augmented reality (VST AR), and virtual reality (VR) head-mounted displays. Our results provide evidence that nontraditional shading techniques for rendering shadows in AR displays may enhance the accuracy of one's perception of surface contact. This finding implies a possible tradeoff between photorealism and accuracy of depth perception, especially in OST AR displays. However, it also supports the use of more stylized graphics like non-traditional cast shadows to improve perception and interaction in AR applications.","1941-0506","","10.1109/TVCG.2021.3097978","Office of Naval Research(grant numbers:N00014-18-1-2964); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9490310","Augmented Reality;OST AR;VST AR;VR;Perception;Ground Contact;Shadows;Contrast","Visualization;Rendering (computer graphics);Optical imaging;Optical sensors;Lighting;Layout;Image color analysis","","","","1","","","IEEE","19 Jul 2021","","","IEEE","IEEE Early Access Articles"
"SineStream: Improving the Readability of Streamgraphs by Minimizing Sine Illusion Effects","C. Bu; Q. Zhang; Q. Wang; J. Zhang; M. Sedlmair; O. Deussen; Y. Wang","Shandong University, Qingdao, China; Shandong University, Qingdao, China; HongKong University of Science and Technology, Hong Kong, China; CNIC, CAS; VISUS, University of Stuttgart, Germany; SIAT, Konstanz University, Germany and Shenzhen VisuCA Key Lab, China; Shandong University, Qingdao, China","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1634","1643","In this paper, we propose SineStream, a new variant of streamgraphs that improves their readability by minimizing sine illusion effects. Such effects reflect the tendency of humans to take the orthogonal rather than the vertical distance between two curves as their distance. In SineStream, we connect the readability of streamgraphs with minimizing sine illusions and by doing so provide a perceptual foundation for their design. As the geometry of a streamgraph is controlled by its baseline (the bottom-most curve) and the ordering of the layers, we re-interpret baseline computation and layer ordering algorithms in terms of reducing sine illusion effects. For baseline computation, we improve previous methods by introducing a Gaussian weight to penalize layers with large thickness changes. For layer ordering, three design requirements are proposed and implemented through a hierarchical clustering algorithm. Quantitative experiments and user studies demonstrate that SineStream improves the readability and aesthetics of streamgraphs compared to state-of-the-art methods.","1941-0506","","10.1109/TVCG.2020.3030404","National Natural Science Foundation of China(grant numbers:61772315,61861136012); Deutsche Forschungsgemeinschaft(grant numbers:DE 620/26-1); TRR 161 Quantitative methods for visual computing(grant numbers:251654672); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222035","Streamgraphs;Sine Illusion;Readability","Distortion;Optimization;Task analysis;Visualization;Distortion measurement;Clustering algorithms;Motion pictures","data analysis;data visualisation;Gaussian processes;graph theory;pattern clustering","readability;streamgraph;baseline computation;layer ordering;sine illusion effects;SineStream;hierarchical clustering algorithm","","1","","35","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Sketch Augmentation-Driven Shape Retrieval Learning Framework Based on Convolutional Neural Networks","W. Zhou; J. Jia; W. Jiang; C. Huang","School of Computer and Information, Anhui Normal University, Wuhu, Anhui, China; School of Software Engineering, Tongji University, Shanghai, China; School of Computer and Information, Anhui Normal University, Wuhu, China; Department of Computer Science, Xiamen University, Xiamen, Fujian, China","IEEE Transactions on Visualization and Computer Graphics","30 Jun 2021","2021","27","8","3558","3570","In this article, we present a deep learning approach to sketch-based shape retrieval that incorporates a few novel techniques to improve the quality of the retrieval results. First, to address the problem of scarcity of training sketch data, we present a sketch augmentation method that more closely mimics human sketches compared to simple image transformation. Our method generates more sketches from the existing training data by (i) removing a stroke, (ii) adjusting a stroke, and (iii) rotating the sketch. As such, we generate a large number of sketch samples for training our neural network. Second, we obtain the 2D renderings of each 3D model in the shape database by determining the view positions that best depict the 3D shape: i.e., avoiding self-occlusion, showing the most salient features, and following how a human would normally sketch the model. We use a convolutional neural network (CNN) to learn the best viewing positions of each 3D model and generates their 2D images for the next step. Third, our method uses a cross-domain learning strategy based on two Siamese CNNs that pair up sketches and the 2D shape images. A joint Bayesian measure is used to measure the output similarity from these CNNs to maximize inter-class similarity and minimize intra-class similarity. Extensive experiments show that our proposed approach comprehensively outperforms many existing state-of-the-art methods.","1941-0506","","10.1109/TVCG.2020.2975504","National Natural Science Foundation of China(grant numbers:61902003,61976006); National Natural Science Foundation of China(grant numbers:U19A2063); Doctoral Scientific Research Foundation of Anhui Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9007505","Sketch-based shape retrieval;convolutional neural network;learning framework;sketch augmentation;best view;joint Bayesian fusion","Shape;Three-dimensional displays;Two dimensional displays;Solid modeling;Training;Task analysis;Neural networks","Bayes methods;feature extraction;image classification;image representation;image retrieval;learning (artificial intelligence);neural nets","sketch augmentation-driven shape retrieval learning framework;convolutional neural network;deep learning approach;retrieval results;training sketch data;sketch augmentation method;closely mimics human sketches;simple image transformation;existing training data;stroke;sketch samples;shape database;view positions;viewing positions;cross-domain learning strategy;2D shape images","","1","","44","IEEE","24 Feb 2020","","","IEEE","IEEE Journals"
"SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays","H. Subramonyam; E. Adar",School of InformationUniversity of Michigan; School of InformationUniversity of Michigan,"IEEE Transactions on Visualization and Computer Graphics","7 Dec 2018","2019","25","1","597","607","Details-on-demand is a crucial feature in the visual information-seeking process but is often only implemented in highly constrained settings. The most common solution, hover queries (i.e., tooltips), are fast and expressive but are usually limited to single mark (e.g., a bar in a bar chart). `Queries' to retrieve details for more complex sets of objects (e.g., comparisons between pairs of elements, averages across multiple items, trend lines, etc.) are difficult for end-users to invoke explicitly. Further, the output of these queries require complex annotations and overlays which need to be displayed and dismissed on demand to avoid clutter. In this work we introduce SmartCues, a library to support details-on-demand through dynamically computed overlays. For end-users, SmartCues provides multitouch interactions to construct complex queries for a variety of details. For designers, SmartCues offers an interaction library that can be used out-of-the-box, and can be extended for new charts and detail types. We demonstrate how SmartCues can be implemented across a wide array of visualization types and, through a lab study, show that end users can effectively use SmartCues.","1941-0506","","10.1109/TVCG.2018.2865231","NSF(grant numbers:IIS-1421438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440833","Graphical overlays;details-on-demand;graph comprehension","Bars;US Department of Defense;Task analysis;Visualization;Data visualization;Libraries;Color","data visualisation;interactive systems;query processing","multitouch query approach;details-on-demand;dynamically computed overlays;visual information-seeking process;highly constrained settings;complex annotations;multitouch interactions;complex queries;end users;smartcues","","1","","73","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Spanning Trees as Approximation of Data Structures","D. Alcaide; J. Aerts","ESAT/STADIUS, Faculty of Engineering, KU Leuven, Leuven, Belgium; UHasselt, I-BioStat and Data Science Institute, Hasselt, Belgium","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2021","2021","27","10","3994","4008","The connections in a graph generate a structure that is independent of a coordinate system. This visual metaphor allows creating a more flexible representation of data than a two-dimensional scatterplot. In this article, we present STAD (Simplified Topological Abstraction of Data), a parameter-free dimensionality reduction method that projects high-dimensional data into a graph. STAD generates an abstract representation of high-dimensional data by giving each data point a location in a graph which preserves the approximate distances in the original high-dimensional space. The STAD graph is built upon the Minimum Spanning Tree (MST) to which new edges are added until the correlation between the distances from the graph and the original dataset is maximized. Additionally, STAD supports the inclusion of additional functions to focus the exploration and allow the analysis of data from new perspectives, emphasizing traits in data which otherwise would remain hidden. We demonstrate the effectiveness of our method by applying it to two real-world datasets: traffic density in Barcelona and temporal measurements of air quality in Castile and León in Spain.","1941-0506","","10.1109/TVCG.2020.2995465","IWT/SBO(grant numbers:150056); Flanders AI Impulse Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096616","Visual analytics;networks;dimensionality reduction;data transformation","Dimensionality reduction;Data visualization;Visualization;Three-dimensional displays;Shape;Matrix converters;Correlation","data structures;data visualisation;graph theory;telecommunication network topology;trees (mathematics)","high-dimensional space;STAD graph;Minimum Spanning Tree;Spanning trees;coordinate system;visual metaphor;flexible representation;two-dimensional scatterplot;Simplified Topological Abstraction;parameter-free dimensionality reduction method;projects high-dimensional data;abstract representation;approximate distances","","1","","62","CCBY","19 May 2020","","","IEEE","IEEE Journals"
"SplitStreams: A Visual Metaphor for Evolving Hierarchies","F. Bolte; M. Nourani; E. D. Ragan; S. Bruckner","Department of Informatics, University of Bergen, Bergen, Norway; Department of Computer & Information Science & Engineering, University of Florida, Gainesville, FL, USA; Department of Computer & Information Science & Engineering, University of Florida, Gainesville, FL, USA; Department of Informatics, University of Bergen, Bergen, Norway","IEEE Transactions on Visualization and Computer Graphics","30 Jun 2021","2021","27","8","3571","3584","The visualization of hierarchically structured data over time is an ongoing challenge and several approaches exist trying to solve it. Techniques such as animated or juxtaposed tree visualizations are not capable of providing a good overview of the time series and lack expressiveness in conveying changes over time. Nested streamgraphs provide a better understanding of the data evolution, but lack the clear outline of hierarchical structures at a given timestep. Furthermore, these approaches are often limited to static hierarchies or exclude complex hierarchical changes in the data, limiting their use cases. We propose a novel visual metaphor capable of providing a static overview of all hierarchical changes over time, as well as clearly outlining the hierarchical structure at each individual time step. Our method allows for smooth transitions between treemaps and nested streamgraphs, enabling the exploration of the trade-off between dynamic behavior and hierarchical structure. As our technique handles topological changes of all types, it is suitable for a wide range of applications. We demonstrate the utility of our method on several use cases, evaluate it with a user study, and provide its full source code.","1941-0506","","10.1109/TVCG.2020.2973564","MetaVis project(grant numbers:#250133); Norges Forskningsråd; National Science Foundation(grant numbers:1565725); DARPA XAI(grant numbers:N66001-17-2-4032); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998355","Visualization;hierarchy data;time-varying data;streamgraphs;treemaps","Data visualization;Visualization;Layout;Sociology;Statistics;Image color analysis;Encoding","data analysis;data visualisation;graph theory;tree data structures;trees (mathematics)","hierarchically structured data;animated tree visualizations;juxtaposed tree visualizations;good overview;time series;lack expressiveness;nested streamgraphs;data evolution;clear outline;hierarchical structure;static hierarchies;complex hierarchical changes;novel visual metaphor;static overview;individual time step;topological changes","","1","","39","IEEE","13 Feb 2020","","","IEEE","IEEE Journals"
"StructGraphics: Flexible Visualization Design through Data-Agnostic and Reusable Graphical Structures","T. Tsandilas","Inria & CNRS, Université Paris-Saclay, France","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","315","325","Information visualization research has developed powerful systems that enable users to author custom data visualizations without textual programming. These systems can support graphics-driven practices by bridging lazy data-binding mechanisms with vector-graphics editing tools. Yet, despite their expressive power, visualization authoring systems often assume that users want to generate visual representations that they already have in mind rather than explore designs. They also impose a data-to-graphics workflow, where binding data dimensions to graphical properties is a necessary step for generating visualization layouts. In this paper, we introduce StructGraphics, an approach for creating data-agnostic and fully reusable visualization designs. StructGraphics enables designers to construct visualization designs by drawing graphics on a canvas and then structuring their visual properties without relying on a concrete dataset or data schema. In StructGraphics, tabular data structures are derived directly from the structure of the graphics. Later, designers can link these structures with real datasets through a spreadsheet user interface. StructGraphics supports the design and reuse of complex data visualizations by combining graphical property sharing, by-example design specification, and persistent layout constraints. We demonstrate the power of the approach through a gallery of visualization examples and reflect on its strengths and limitations in interaction with graphic designers and data visualization experts.","1941-0506","","10.1109/TVCG.2020.3030476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222091","Visualization design;graphical structures;visualization grammars;layout constraints;infographics;flexible data binding","Data visualization;Layout;Visualization;Tools;Programming;Task analysis","authoring systems;computer graphics;data structures;data visualisation;interactive systems;spreadsheet programs;user interfaces","fully reusable visualization designs;StructGraphics;visual properties;concrete dataset;tabular data structures;spreadsheet user interface;complex data visualizations;graphical property sharing;by-example design specification;visualization examples;graphic designers;data visualization experts;flexible visualization design;reusable graphical structures;information visualization research;powerful systems;author custom data visualizations;textual programming;graphics-driven practices;lazy data-binding mechanisms;vector-graphics editing tools;expressive power;visualization authoring systems;visual representations;explore designs;data-to-graphics workflow;binding data dimensions;visualization layouts;data-agnostic structures","","1","","59","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"TIVEE: Visual Exploration and Explanation of Badminton Tactics in Immersive Visualizations","X. Chu; X. Xie; S. Ye; H. Lu; H. Xiao; Z. Yuan; Z. Chen; H. Zhang; Y. Wu","State Key Lab of CAD&CG, Zhejiang University, China; Department of Sport Science, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; Department of Cognitive Science and Design Lab, University of California San Diego, United States; Department of Sport Science, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","118","128","Tactic analysis is a major issue in badminton as the effective usage of tactics is the key to win. The tactic in badminton is defined as a sequence of consecutive strokes. Most existing methods use statistical models to find sequential patterns of strokes and apply 2D visualizations such as glyphs and statistical charts to explore and analyze the discovered patterns. However, in badminton, spatial information like the shuttle trajectory, which is inherently 3D, is the core of a tactic. The lack of sufficient spatial awareness in 2D visualizations largely limited the tactic analysis of badminton. In this work, we collaborate with domain experts to study the tactic analysis of badminton in a 3D environment and propose an immersive visual analytics system, TIVEE, to assist users in exploring and explaining badminton tactics from multi-levels. Users can first explore various tactics from the third-person perspective using an unfolded visual presentation of stroke sequences. By selecting a tactic of interest, users can turn to the first-person perspective to perceive the detailed kinematic characteristics and explain its effects on the game result. The effectiveness and usefulness of TIVEE are demonstrated by case studies and an expert interview.","1941-0506","","10.1109/TVCG.2021.3114861","National Key Research and Development Program of China(grant numbers:2018YFB1004300); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); Collaborative Innovation Center of Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557225","Tactic analysis;stroke sequence visualization;immersive visualization","Trajectory;Sports;Three-dimensional displays;Data visualization;Visualization;Games;Layout","biomechanics;data analysis;data mining;data visualisation;pattern recognition;sport;statistical analysis","immersive visualizations;tactic analysis;immersive visual analytics system;TIVEE;unfolded visual presentation;badminton tactics;visual exploration;visual explanation;consecutive strokes;statistical models;stroke sequential patterns;2D visualizations;glyphs;statistical charts;pattern discovery;spatial information;shuttle trajectory;spatial awareness;3D environment;third-person perspective;stroke sequence;kinematic characteristics","Biomechanical Phenomena;Computer Graphics;Humans;Racquet Sports","1","","62","IEEE","1 Oct 2021","","","IEEE","IEEE Journals"
"TempoCave: Visualizing Dynamic Connectome Datasets to Support Cognitive Behavioral Therapy","R. Xu; M. M. Thomas; A. Leow; O. A. Ajilore; A. G. Forbes","University of California,Department of Computational Media,Santa Cruz; University of California,Department of Computational Media,Santa Cruz; University of Illinois at Chicago,Department of Psychiatry; University of Illinois at Chicago,Department of Psychiatry; University of California,Department of Computational Media,Santa Cruz","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","186","190","We introduce TempoCave, a novel visualization application for analyzing dynamic brain networks, or connectomes. TempoCave provides a range of functionality to explore metrics related to the activity patterns and modular affiliations of different regions in the brain. These patterns are calculated by processing raw data retrieved functional magnetic resonance imaging (fMRI) scans, which creates a network of weighted edges between each brain region, where the weight indicates how likely these regions are to activate synchronously. TempoCave supports the analysis needs of clinical psychologists, who examine these modular affiliations and weighted edges and their temporal dynamics, utilizing them to understand relationships between neurological disorders and brain activity, which could have significant impact on how patients are diagnosed and treated. In addition to summarizing the main functionality of TempoCave, we present a real world use case that analyzes pre- and post-treatment connectome datasets from 27 subjects in a clinical study investigating the use of cognitive behavior therapy to treat major depression disorder, indicating that TempoCave can provide new insight into the dynamic behavior of the human brain.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933544","Connectome visualization;dynamic graph comparison","Task analysis;Visualization;Tools;Data visualization;Measurement;Functional magnetic resonance imaging;Inspection","biomedical MRI;brain;cognition;data visualisation;medical disorders;medical image processing;neurophysiology;patient treatment;psychology","cognitive behavioral therapy;TempoCave;novel visualization application;dynamic brain networks;modular affiliations;functional magnetic resonance imaging scans;weighted edges;brain region;post-treatment connectome datasets;cognitive behavior therapy;dynamic behavior;human brain;visualizing dynamic connectome datasets;fMRI scans","","1","","38","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Text Entry in Virtual Environments using Speech and a Midair Keyboard","J. Adhikary; K. Vertanen","Department of Computer Science, Michigan Technological University, USA; Department of Computer Science, Michigan Technological University, USA","IEEE Transactions on Visualization and Computer Graphics","15 Apr 2021","2021","27","5","2648","2658","Entering text in virtual environments can be challenging, especially without auxiliary input devices. We investigate text input in virtual reality using hand-tracking and speech. Our system visualizes users' hands in the virtual environment, allowing typing on an auto-correcting midair keyboard. It also supports speaking a sentence and then correcting errors by selecting alternative words proposed by a speech recognizer. We conducted a user study in which participants wrote sentences with and without speech. Using only the keyboard, users wrote at 11 words-per-minute at a 1.2% error rate. Speaking and correcting sentences was faster and more accurate at 28 words-per-minute and a 0.5% error rate. Participants achieved this performance despite half of sentences containing an uncommon out-of-vocabulary word (e.g. proper name). For sentences with only in-vocabulary words, performance using speech and midair keyboard corrections was faster at 36 words-per-minute with a low 0.3% error rate.","1941-0506","","10.1109/TVCG.2021.3067776","NSF(grant numbers:IIS-1750193); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382836","Text Entry;Speech Recognition;Virtual Reality (VR);Head Mounted Display (HMD);Midair Gestures","Keyboards;Speech recognition;Virtual environments;Resists;Visualization;Error analysis;Layout","human computer interaction;keyboards;speech recognition;virtual reality","speech recognizer;out-of-vocabulary word;in-vocabulary words;midair keyboard corrections;text entry;virtual environment;auxiliary input devices;text input;virtual reality;hand-tracking;auto-correcting midair keyboard;error rate","Adolescent;Adult;Aged;Female;Gestures;Hand;Humans;Male;Middle Aged;Smart Glasses;Speech Recognition Software;Text Messaging;Virtual Reality;Young Adult","1","","57","IEEE","22 Mar 2021","","","IEEE","IEEE Journals"
"The Effectiveness of Interactive Visualization Techniques for Time Navigation of Dynamic Graphs on Large Displays","A. Lee; D. Archambault; M. A. Nacenta","Dept. of Computer Science, Swansea University, Swansea University Medical School, UK; Dept. of Computer Science, Swansea University, UK; Dept. of Computer Science, University of Victoria, Canada","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","528","538","Dynamic networks can be challenging to analyze visually, especially if they span a large time range during which new nodes and edges can appear and disappear. Although it is straightforward to provide interfaces for visualization that represent multiple states of the network (i.e., multiple timeslices) either simultaneously (e.g., through small multiples) or interactively (e.g., through interactive animation), these interfaces might not support tasks in which disjoint timeslices need to be compared. Since these tasks are key for understanding the dynamic aspects of the network, understanding which interactive visualizations best support these tasks is important. We present the results of a series of laboratory experiments comparing two traditional approaches (small multiples and interactive animation), with a more recent approach based on interactive timeslicing. The tasks were performed on a large display through a touch interface. Participants completed 24 trials of three tasks with all techniques. The results show that interactive timeslicing brings benefit when comparing distant points in time, but less benefits when analyzing contiguous intervals of time.","1941-0506","","10.1109/TVCG.2020.3030446","EPSRC(grant numbers:EP/N509553/1); Microsoft Surface Hub award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222301","Dynamic networks;Information visualization;Large displays","Animation;Data visualization;Navigation;Task analysis;Microsoft Windows;Visualization;Computer science","computer animation;data visualisation;graph theory;interactive systems","interactive visualization techniques;time navigation;dynamic graphs;dynamic networks;multiple timeslices;interactive animation;interactive visualizations;interactive timeslicing;touch interface","","1","","66","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"The Mixture Graph-A Data Structure for Compressing, Rendering, and Querying Segmentation Histograms","K. Al-Thelaya; M. Agus; J. Schneider","Hamad Bin Khalifa University (HBKU), College of Science and Engineering (CSE), Education City, Doha, Qatar; Hamad Bin Khalifa University (HBKU), College of Science and Engineering (CSE), Education City, Doha, Qatar; Hamad Bin Khalifa University (HBKU), College of Science and Engineering (CSE), Education City, Doha, Qatar","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","645","655","In this paper, we present a novel data structure, called the Mixture Graph. This data structure allows us to compress, render, and query segmentation histograms. Such histograms arise when building a mipmap of a volume containing segmentation IDs. Each voxel in the histogram mipmap contains a convex combination (mixture) of segmentation IDs. Each mixture represents the distribution of IDs in the respective voxel's children. Our method factorizes these mixtures into a series of linear interpolations between exactly two segmentation IDs. The result is represented as a directed acyclic graph (DAG) whose nodes are topologically ordered. Pruning replicate nodes in the tree followed by compression allows us to store the resulting data structure efficiently. During rendering, transfer functions are propagated from sources (leafs) through the DAG to allow for efficient, pre-filtered rendering at interactive frame rates. Assembly of histogram contributions across the footprint of a given volume allows us to efficiently query partial histograms, achieving up to 178 x speed-up over naive parallelized range queries. Additionally, we apply the Mixture Graph to compute correctly pre-filtered volume lighting and to interactively explore segments based on shape, geometry, and orientation using multi-dimensional transfer functions.","1941-0506","","10.1109/TVCG.2020.3030451","College of Science and Engineering (CSE); Hamad Bin Khalifa University (HBKU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224646","Segmented Volumes;Data Structures;Sparse Data","Rendering (computer graphics);Histograms;Data structures;Semantics;Encoding;Transfer functions;Interpolation","data structures;directed graphs;image segmentation;interpolation;query processing;rendering (computer graphics);transfer functions;trees (mathematics)","mixture graph;segmentation IDs;histogram mipmap;respective voxel;directed acyclic graph;data structure;histogram contributions;partial histograms;naive parallelized range queries;segmentation histogram compression;querying segmentation rendering;segmentation histogram querying;multidimensional transfer functions;linear interpolations","","1","","56","IEEE","15 Oct 2020","","","IEEE","IEEE Journals"
"TopoMap: A 0-dimensional Homology Preserving Projection of High-Dimensional Data","H. Doraiswamy; J. Tierny; P. J. S. Silva; L. G. Nonato; C. Silva","New York University; CNRS and Sorbonne Université; University of Campinas; University of Sao Paulo, Sao Carlos; New York University","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","561","571","Multidimensional Projection is a fundamental tool for high-dimensional data analytics and visualization. With very few exceptions, projection techniques are designed to map data from a high-dimensional space to a visual space so as to preserve some dissimilarity (similarity) measure, such as the Euclidean distance for example. In fact, although adopting distinct mathematical formulations designed to favor different aspects of the data, most multidimensional projection methods strive to preserve dissimilarity measures that encapsulate geometric properties such as distances or the proximity relation between data objects. However, geometric relations are not the only interesting property to be preserved in a projection. For instance, the analysis of particular structures such as clusters and outliers could be more reliably performed if the mapping process gives some guarantee as to topological invariants such as connected components and loops. This paper introduces TopoMap, a novel projection technique which provides topological guarantees during the mapping process. In particular, the proposed method performs the mapping from a high-dimensional space to a visual space, while preserving the 0-dimensional persistence diagram of the Rips filtration of the high-dimensional data, ensuring that the filtrations generate the same connected components when applied to the original as well as projected data. The presented case studies show that the topological guarantee provided by TopoMap not only brings confidence to the visual analytic process but also can be used to assist in the assessment of other projection methods.","1941-0506","","10.1109/TVCG.2020.3030441","DARPA D3M program; Moore Sloan Data Science Environment at NYU; NSF(grant numbers:CNS-1229185,CCF-1533564,CNS-1544753,CNS-1730396,CNS-1828576); European Commission(grant numbers:ERC-2019-COG); “TORI”(grant numbers:863464); CNPq-Brazil(grant numbers:303552/2017-4,304301/2019-1); Sao Paulo Research Foundation (FAPESP) - Brazil(grant numbers:2013/07375-0,2016/04190-7,2018/07551-6,2018/24293-0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222271","Topological data analysis;computational topology;high-dimensional data;projection","Three-dimensional displays;Data visualization;Two dimensional displays;Data analysis;Layout;Visualization;Topology","computational geometry;data analysis;data visualisation;graph theory;solid modelling;topology","visual analytic process;projected data;0-dimensional persistence diagram;topological guarantee;novel projection technique;mapping process;data objects;encapsulate geometric properties;multidimensional projection methods;dissimilarity measure;visual space;high-dimensional space;map data;projection techniques;visualization;high-dimensional data analytics;0-dimensional homology preserving projection;TopoMap","","1","","79","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Topological Analysis of Magnetic Reconnection in Kinetic Plasma Simulations","D. Banesh; L. -T. Lo; P. Kilian; F. Guo; B. Hamann",University of California Davis; Los Alamos National Lab; Los Alamos National Lab; Los Alamos National Lab; University of California Davis,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","6","10","Magnetic reconnection is a ubiquitous plasma process in which oppositely directed magnetic field lines break and rejoin, resulting in a change of the magnetic field topology. Reconnection generates magnetic islands: regions enclosed by magnetic field lines and separated by reconnection points. Proper identification of these features is important to understand particle acceleration and overall behavior of plasma. We present a contour-tree based visualization for robust and objective identification of islands and reconnection points in two-dimensional (2D) magnetic reconnection simulations. The application of this visualization to a simple simulation has revealed a physical phenomenon previously not reported, resulting in a more comprehensive understanding of magnetic reconnection.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331301","Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods","Magnetic reconnection;Visualization;Plasma simulation;Two dimensional displays;Data visualization;Tools;Topology","magnetic reconnection;plasma kinetic theory;plasma simulation;trees (mathematics)","topological analysis;kinetic plasma simulations;plasma process;magnetic field lines break;magnetic field topology;magnetic islands;reconnection points;two-dimensional magnetic reconnection simulations;contour-tree based visualization","","1","","37","","1 Feb 2021","","","IEEE","IEEE Conferences"
"TradAO: A Visual Analytics System for Trading Algorithm Optimization","K. W. Tsang; H. Li; F. M. Lam; Y. Mu; Y. Wang; H. Qu",HKUST; HKUST; ALGOGENE; HKUST; HKUST; HKUST,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","61","65","With the wide applications of algorithmic trading, it has become critical for traders to build a winning trading algorithm to beat the market. However, due to the lack of efficient tools, traders mainly rely on their memory to manually compare the algorithm instances of a trading algorithm and further select the best trading algorithm instance for the real trading deployment. We work closely with industry practitioners to discover and consolidate user requirements and develop an interactive visual analytics system for trading algorithm optimization. Structured expert interviews are conducted to evaluate TradAO and a representative case study is documented for illustrating the system effectiveness. To the best of our knowledge, previous financial data visual analyses have mainly aimed to assist investment managers in investment portfolio analysis but have neglected the need of traders in developing trading algorithms for portfolio execution. TradAO is the first visual analytics system that assists users in comprehensively exploring the performances of a trading algorithm with different parameter settings.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331281","Human-centered computing;Visualization;Visualization design and evaluation methods","Visual analytics;Tools;Interviews;Usability;Portfolios;Optimization;Investment","data analysis;data visualisation;financial data processing;interactive systems;investment;stock markets","traders;winning trading algorithm;interactive visual analytics system;trading algorithm optimization;TradAO;financial data visual analyses;investment managers;investment portfolio analysis;financial market","","1","","33","","1 Feb 2021","","","IEEE","IEEE Conferences"
"UNOC: Understanding Occlusion for Embodied Presence in Virtual Reality","M. Parger; C. Tang; Y. Xu; C. D. Twigg; L. Tao; Y. Li; R. Wang; M. Steinberger","Institute of Computer Graphics and Vision, Graz University of Technology, 27253 Graz, Styria, Austria, 8010 (e-mail: mathias.parger@icg.tugraz.at); Facebook Reality Labs Research, Facebook Inc, 342996 Menlo Park, California, United States, 94025-1452 (e-mail: chengcheng.tang@kaust.edu.sa); Facebook Reality Labs, Facebook Inc, 342996 Menlo Park, California, United States, 94025 (e-mail: merayxu@gmail.com); Facebook Reality Labs Research, Facebook Inc, 342996 Menlo Park, California, United States, 94025-1452 (e-mail: cdtwigg@gmail.com); Center of Imaging Science, Johns Hopkins University, 1466 Baltimore, Maryland, United States, 21218 (e-mail: taolingling06@gmail.com); Oculus Reality Labs, Facebook Inc, 342996 Menlo Park, California, United States, 94025-1452 (e-mail: yijingli@fb.com); Facebook Reality Labs, Facebook Inc, 342996 Menlo Park, California, United States, 94025-1452 (e-mail: rywang@csail.mit.edu); Institut for Computer Graphics and Vision, Graz University of Technology, Graz, Styria, Austria, (e-mail: steinberger@icg.tugraz.at)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Tracking body and hand motions in 3D space is essential for social and self-presence in augmented and virtual environments. Unlike the popular 3D pose estimation setting, the problem is often formulated as egocentric tracking based on embodied perception (e.g., egocentric cameras, handheld sensors). In this paper, we propose a new data-driven framework for egocentric body tracking, targeting challenges of omnipresent occlusions in optimization-based methods (e.g., inverse kinematics solvers). We first collect a large-scale motion capture dataset with both body and finger motions using optical markers and inertial sensors. This dataset focuses on social scenarios and captures ground truth poses under self-occlusions and body-hand interactions. We then simulate the occlusion patterns in head-mounted camera views on the captured ground truth using a ray casting algorithm and learn a deep neural network to infer the occluded body parts. Our experiments show that our method is able to generate high-fidelity embodied poses by applying the proposed method to the task of real-time egocentric body tracking, finger motion synthesis, and 3-point inverse kinematics.","1941-0506","","10.1109/TVCG.2021.3085407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444887","Motion capture;machine learning;body tracking;embodied presence;virtual reality","Tracking;Cameras;Three-dimensional displays;Headphones;Kinematics;Videos;Optical sensors","","","","1","","","IEEE","1 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Understanding Missing Links in Bipartite Networks with MissBiN","J. Zhao; M. Sun; F. Chen; P. Chui","School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: jianzhao@uwaterloo.ca); Department of Computer Science, Northern Illinois University, 2848 DeKalb, Illinois, United States, (e-mail: smaoyuan@niu.edu); Research, FXPAL, Palo Alto, California, United States, (e-mail: chen@fxpal.com); Research, FXPAL, Palo Alto, California, United States, (e-mail: chiu@fxpal.com)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","The analysis of bipartite networks is critical in a variety of application domains, such as exploring entity co-occurrences in intelligence analysis and investigating gene expression in bio-informatics. One important task is missing link prediction, which infers the existence of unseen links based on currently observed ones. In this paper, we propose a visual analysis system, MissBiN, to involve analysts in the loop for making sense of link prediction results. MissBiN equips a novel method for link prediction in a bipartite network by leveraging the information of bi-cliques in the network. It also provides an interactive visualization for understanding the algorithm outputs. The design of MissBiN is based on three high-level analysis questions (what, why, and how) regarding missing links, which are distilled from the literature and expert interviews. We conducted quantitative experiments to assess the performance of the proposed link prediction algorithm, and interviewed two experts from different domains to demonstrate the effectiveness of MissBiN as a whole. We also provide a comprehensive usage scenario to illustrate the usefulness of the tool in an application of intelligence analysis.","1941-0506","","10.1109/TVCG.2020.3032984","Natural Sciences and Engineering Research Council of Canada(grant numbers:Discovery Grant); Division of Information and Intelligent Systems(grant numbers:IIS-1850036 and IIS-2002082); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237128","Missing link prediction;bipartite network;bi-clique;interactive visualization;visual analytics","Visualization;Prediction algorithms;Task analysis;Measurement;Interviews;Tools;Feature extraction","","","","1","","","IEEE","22 Oct 2020","","","IEEE","IEEE Early Access Articles"
"Unsteady Flow Visualization via Physics Based Pathline Exploration","D. B. Nguyen; L. Zhang; R. S. Laramee; D. Thompson; R. O. Monico; G. Chen",University of Houston; University of Houston; Swansea University; Mississippi State University; University of Houston; University of Houston,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","286","290","This work proposes to analyze the time-dependent characteristics of the physical attributes measured along pathlines derived from unsteady flows, which can be represented as a series of time activity curves (TAC). A new TAC-based unsteady flow visualization and analysis framework is proposed. The center of this framework is a new event-based distance metric (EDM) that compares the similarity of two TACs, from which a new spatio-temporal, hierarchical clustering of pathlines based on their physical attributes and an attribute-based pathline exploration are proposed. These techniques are integrated into a visual analytics system, which has been applied to a number of unsteady flow in 2D and 3D to demonstrate its utility.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933578","Flow visualization;Time activity curves;Clustering","Measurement;Market research;Correlation;Two dimensional displays;Data visualization;Kernel;Physics","computational fluid dynamics;data analysis;data visualisation;flow instability;flow visualisation;pattern clustering;physics computing","physics based pathline exploration;time activity curves;TAC-based unsteady flow visualization;event-based distance metric;hierarchical clustering;attribute-based pathline exploration;visual analytics system","","1","","32","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visual Analysis of Collective Anomalies Using Faceted High-Order Correlation Graphs","J. Yan; L. Shi; J. Tao; X. Yu; Z. Zhuang; C. Huang; R. Yu; P. Su; C. Wang; Y. Chen","TCA/SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China; School of Computer Science, Beihang University, Beijing, China; Department of Computer Science & Engineering, University of Notre Dame, Notre Dame, IN, USA; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China; SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China; TCA/SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Computer Science & Engineering, University of Notre Dame, Notre Dame, IN, USA; School of Computer Science, Fudan University, Shanghai, China","IEEE Transactions on Visualization and Computer Graphics","28 May 2020","2020","26","7","2517","2534","Successfully detecting, analyzing, and reasoning about collective anomalies is important for many real-life application domains (e.g., intrusion detection, fraud analysis, software security). The primary challenges to achieving this goal include the overwhelming number of low-risk events and their multimodal relationships, the diversity of collective anomalies by various data and anomaly types, and the difficulty in incorporating the domain knowledge of experts. In this paper, we propose the novel concept of the faceted High-Order Correlation Graph (HOCG). Compared with previous, low-order correlation graphs, HOCG achieves better user interactivity, computational scalability, and domain generality through synthesizing heterogeneous types of objects, their anomalies, and the multimodal relationships, all in a single graph. We design elaborate visual metaphors, interaction models, and the coordinated multiple view based interface to allow users to fully unleash the visual analytics power of the HOCG. We conduct case studies for three application domains and collect feedback from domain experts who apply our method to these scenarios. The results demonstrate the effectiveness of the HOCG in the overview of point anomalies, the detection of collective anomalies, and the reasoning process of root cause analyses.","1941-0506","","10.1109/TVCG.2018.2889470","National Natural Science Foundation of China(grant numbers:61772504,U1836117,U1736209,61572483,61602122,71731004); U.S. NSF(grant numbers:IIS-1455886,DUE-1833129); NSF(grant numbers:16ZR1402200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8587186","Correlation graph visualization;collective anomaly","Anomaly detection;Correlation;Visual analytics;Data visualization;Software;Feature extraction","data analysis;data visualisation;fraud;graph theory;inference mechanisms;security of data","HOCG;point anomalies;collective anomalies;visual analysis;real-life application domains;intrusion detection;fraud analysis;low-risk events;multimodal relationships;anomaly types;high-order correlation graph;previous order correlation graphs;low-order correlation graphs;domain generality;single graph;domain experts;faceted high-order correlation graphs","","1","","47","IEEE","23 Dec 2018","","","IEEE","IEEE Journals"
"Visual Analysis of the Time Management of Learning Multiple Courses in Online Learning Environment","H. He; B. Dong; Q. Zheng; D. Di; Y. Lin","Xi’an Jiaotong University,Shaanxi Province Key Laboratory of Satellite and Terrestrial Network Tech. R&D; Xi’an Jiaotong University,School of Continuing Education; Xi’an Jiaotong University,Shaanxi Province Key Laboratory of Satellite and Terrestrial Network Tech. R&D; Xi’an Jiaotong University,School of Management; Xi’an Jiaotong University,Shaanxi Province Key Laboratory of Satellite and Terrestrial Network Tech. R&D","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","56","60","Self-paced online learning not only provides the opportunities of learning anytime but also chanllenges students' time management, especially in the context of learning multiple courses at same time. The inappropriate scheduling of multiple courses may affect student engagement and learning performance, thus how to arrange the study time of multiple courses is a concern of both instructors and students. Existing studies related to student engagement and time management in online learning mainly focus on providing self-regulated learning strategies and evaluating learning performance. However, these methods have limited abilities to gain intuitive understanding of the time management of multi-course learning. To address this issue, we present LearnerVis to help users analyze how students schedule their multi-course learning. LearnerVis visualize the temporal features of learning process, and it enables users to customize student groups to compare the differences in student engagement and time management. A case study is conducted to demonstrate the usefulness of the system with real-word dataset.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933778","Human-centered computing;Visualization;Visual analytics; Applied computing;E-learning","Task analysis;Color;Schedules;Time measurement;Visual analytics;Tools","data visualisation;educational courses;Internet;learning management systems","time management;student engagement;study time;self-regulated learning strategies;multicourse learning;learning performance evaluation;visual analysis;self-paced online learning;LearnerVis","","1","","22","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visual Analytics for RNN-Based Deep Reinforcement Learning","J. Wang; W. Zhang; H. Yang; C. -C. M. Yeh; L. Wang","Data Analytics Team, Visa Research, Palo Alto, California, United States, (e-mail: junpeng.wang.nk@gmail.com); Data Analytics Team, Visa Research, Palo Alto, California, United States, (e-mail: wzhan@visa.com); Data Analytics Team, Visa Research, Palo Alto, California, United States, (e-mail: haoyang@visa.com); Data Analytics Team, Visa Research, Palo Alto, California, United States, (e-mail: miyeh@visa.com); Data Analytics Team, Visa Research, Palo Alto, California, United States, (e-mail: liawang@visa.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Deep reinforcement learning (DRL) targets to train an autonomous agent to interact with a pre-defined environment and strives to achieve specific goals through deep neural networks (DNN). Recurrent neural network (RNN) based DRL has demonstrated superior performance, as RNNs can effectively capture the temporal evolution of the environment and respond with proper agent actions. However, apart from the outstanding performance, little is known about how RNNs understand the environment internally and what has been memorized over time. Revealing these details is extremely important for deep learning experts to understand and improve DRLs, which in contrast, is also challenging due to the complicated data transformations inside these models. In this paper, we propose Deep Reinforcement Learning Interactive Visual Explorer (DRLIVE), a visual analytics system to effectively explore, interpret, and diagnose RNN-based DRLs. Focused on DRL agents trained for different Atari games, DRLIVE targets to accomplish three tasks: game episode exploration, RNN hidden/cell state examination, and interactive model perturbation. Using the system, one can flexibly explore a DRL agent through interactive visualizations, discover interpretable RNN cells by prioritizing RNN hidden/cell states with a set of metrics, and further diagnose the DRL model by interactively perturbing its inputs. Through concrete studies with multiple deep learning experts, we validated the efficacy of DRLIVE.","1941-0506","","10.1109/TVCG.2021.3076749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420254","Deep reinforcement learning (DRL);recurrent neural network (RNN);model interpretation;visual analytics","Games;Visual analytics;Analytical models;Reinforcement learning;Recurrent neural networks;Perturbation methods;Data models","","","","1","","","IEEE","30 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Visual Neural Decomposition to Explain Multivariate Data Sets","J. Knittel; A. Lalama; S. Koch; T. Ertl",University of Stuttgart; University of Stuttgart; University of Stuttgart; University of Stuttgart,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1374","1384","Investigating relationships between variables in multi-dimensional data sets is a common task for data analysts and engineers. More specifically, it is often valuable to understand which ranges of which input variables lead to particular values of a given target variable. Unfortunately, with an increasing number of independent variables, this process may become cumbersome and time-consuming due to the many possible combinations that have to be explored. In this paper, we propose a novel approach to visualize correlations between input variables and a target output variable that scales to hundreds of variables. We developed a visual model based on neural networks that can be explored in a guided way to help analysts find and understand such correlations. First, we train a neural network to predict the target from the input variables. Then, we visualize the inner workings of the resulting model to help understand relations within the data set. We further introduce a new regularization term for the backpropagation algorithm that encourages the neural network to learn representations that are easier to interpret visually. We apply our method to artificial and real-world data sets to show its utility.","1941-0506","","10.1109/TVCG.2020.3030420","University of Stuttgart; German Science Foundation (DFG)(grant numbers:392087235); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222060","Visual Analytics;Multivariate Data Analysis;Machine Learning","Data visualization;Visualization;Correlation;Analytical models;Input variables;Neural networks;Semiconductor device measurement","backpropagation;data analysis;data visualisation;neural nets","backpropagation algorithm;visual model;data analysts;multidimensional data sets;multivariate data sets;visual neural decomposition;neural network","Algorithms;Computer Graphics;Neural Networks, Computer","1","","64","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Visualization of Symmetries in Fourth-Order Stiffness Tensors","C. Hergl; T. Nagel; O. Kolditz; G. Scheuermann","Leipzig University,Institute of Computer Science,Germany; Institute of Geotechnics Technische Universitat Bergakademie Freiberg,Chair of Soil Mechanics and Foundation Engineering,Germany; Helmholtz Center for Environmental Research,Department of Environmental Informatics,Leipzig,Germany; Leipzig University,Institute of Computer Science,Germany","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","291","295","Many materials like wood, biological tissue, composites or rock have anisotropic mechanical properties. They become increasingly important in modern material, earth, and life sciences. The stress-strain response of such materials can be characterized (to first-order) by the three-dimensional fourth-order stiffness tensor. There are different anisotropy classes, i.e. material symmetries, that differ in the number and orientation of symmetry planes characteristic of the material. A three-dimensional fourth-order stiffness tensor of a hyperelastic material has up to 21 independent coefficients representing both moduli and orientation information which challenges any visualization method. Therefore, we use a fourth-order tensor decomposition to compute the anisotropy classes and the position of the corresponding symmetry planes. To facilitate judgment of the significance of the amount of anisotropy, we construct an isotropic material. Based on these computations, we design a glyph that represents the stiffness tensor. We demonstrate our method in a finite deformation setting of an initially isotropic hyperelastic material of Ogden class which is often modeling biological tissue. Upon deformation, the stiffness tensor can evolve along with its symmetry creating an inhomogeneous, unsteady fourth-order tensor field in three dimensions.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933592","Stiffness Tensor;Deviatoric Decomposition;Hyper-elastic Material;Tensor Field Visualization","Anisotropic magnetoresistance;Mirrors;Visualization;Strain;Young's modulus;Image color analysis","biological tissues;decomposition;deformation;elastic moduli;elasticity;stress-strain relations;tensors","fourth-order tensor decomposition;isotropic hyperelastic material;biological tissue;stress-strain response;three-dimensional fourth-order stiffness tensor;elastic moduli;deformation","","1","","17","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visualizing a Thinker's Life","P. Riehmann; D. Kiesel; M. Kohlhaas; B. Froehlich","Bauhaus-Universität Weimar, Weimar, Germany; Bauhaus-Universität Weimar, Weimar, Germany; Kohlhaas & Kohlhaas Agency in Weimar, Weimar, Germany; Bauhaus-Universität Weimar, Weimar, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Feb 2019","2019","25","4","1803","1816","This paper presents a visualization framework that aids readers in understanding and analyzing the contents of medium-sized text collections that are typical for the opus of a single or few authors. We contribute several document-based visualization techniques to facilitate the exploration of the work of the German author Bazon Brock by depicting various aspects of its texts, such as the TextGenetics that shows the structure of the collection along with its chronology. The ConceptCircuit augments the TextGenetics with entities - persons and locations that were crucial to his work. All visualizations are sensitive to a wildcard-based phrase search that allows complex requests towards the author's work. Further development, as well as expert reviews and discussions with the author Bazon Brock, focused on the assessment and comparison of visualizations based on automatic topic extraction against ones that are based on expert knowledge.","1941-0506","","10.1109/TVCG.2018.2824822","German Federal Ministry of Education and Research (BMBF)(grant numbers:03IP704,03IPT704X,03PSIPT5A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334579","Glyph-based techniques;text and document data;coordinated and multiple views","Visualization;Data visualization;Tag clouds;Layout;Periodic structures;Tools;Focusing","cognition;data visualisation;text analysis","thinker;visualization framework;readers;medium-sized text collections;document-based visualization techniques;TextGenetics;persons;locations;wildcard-based phrase search;German author;ConceptCircuit","","1","","58","IEEE","10 Apr 2018","","","IEEE","IEEE Journals"
"Visually Analyzing and Steering Zero Shot Learning","S. Sahoo; M. Berger",Vanderbilt University; Vanderbilt University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","251","255","We propose a visual analytics system to help a user analyze and steer zero-shot learning models. Zero-shot learning has emerged as a viable scenario for categorizing data that consists of no labeled examples, and thus a promising approach to minimize data annotation from humans. However, it is challenging to understand where zero-shot learning fails, the cause of such failures, and how a user can modify the model to prevent such failures. Our visualization system is designed to help users diagnose and understand mispredictions in such models, so that they may gain insight on the behavior of a model when applied to data associated with categories not seen during training. Through usage scenarios, we highlight how our system can help a user improve performance in zero-shot learning.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331297","Zero-shot learning;Visualization;Visual Analytics;Model Steering","Training;Analytical models;Annotations;Visual analytics;Conferences;Data visualization;Data models","data analysis;data visualisation;learning (artificial intelligence)","visualization system;steering zero shot learning;visual analytics;data categorization","","1","","31","","1 Feb 2021","","","IEEE","IEEE Conferences"
"What are Data Insights to Professional Visualization Users?","P. -M. Law; A. Endert; J. Stasko",Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","181","185","While many visualization researchers have attempted to define data insights, little is known about how visualization users perceive them. We interviewed 23 professional users of end-user visualization platforms (e.g., Tableau and Power BI) about their experiences with data insights. We report on seven characteristics of data insights based on interviewees' descriptions. Grounded in these characteristics, we propose practical implications for creating tools that aim to automatically communicate data insights to users.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331294","Human-centered computing;Visualization;Visualization theory;concepts and paradigms","Conferences;Data visualization;Tools;Interviews","data visualisation","data insights;professional visualization users;visualization researchers;end-user visualization platforms;Tableau platform;Power BI platform","","1","","41","","1 Feb 2021","","","IEEE","IEEE Conferences"
"3D Objects Clouds: Viewing Virtual Objects in Interactive Clouds","X. Hong; S. Brooks","Faculty of Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada; Faculty of Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2020","2020","26","3","1442","1453","Given the expanding use of 3D Objects in a variety of fields such as animation, gaming, virtual worlds, commerce, augmented reality and 3D printing, we present a novel system for object browsing and searching. Specifically, the system packs objects into an interactive 3D cloud for browsing and searching. It was designed with the aim of increasing search efficiency in a variety of active environments, while providing a visually engaging layout, and we evaluated this by conducting a comparative user study. We show that our system can significantly decrease search times compared to the classic grid-based layout, and it has been suggested by subjects that cloud-based searching is more interesting and visually-engaging.","1941-0506","","10.1109/TVCG.2018.2873724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481362","Computer graphics;visualization;graphical user interfaces;human computer interaction","Three-dimensional displays;Layout;Solid modeling;Tag clouds;Search problems;Visualization;Cloud computing","cloud computing;data visualisation;human computer interaction;interactive systems","cloud-based searching;3D objects clouds;visually engaging layout;interactive 3D cloud;object browsing;virtual objects","","","","29","IEEE","4 Oct 2018","","","IEEE","IEEE Journals"
"3D-CariGAN: An End-to-End Solution to 3D Caricature Generation from Normal Face Photos","Z. Ye; M. Xia; Y. Sun; R. Yi; M. Yu; J. Zhang; Y. -K. Lai; Y. -J. Liu","Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: yezp17@mails.tsinghua.edu.cn); Computer Science, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: xmf20@mails.tsinghua.edu.cn); Computer Science, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: sunyn20@mails.tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: ranyi@sjtu.edu.cn); College of Intelligence and Computing, Tianjin University, 12605 Tianjin, Tianjin, China, (e-mail: minjingyu@tju.edu.cn); Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China, (e-mail: juyong@ustc.edu.cn); School of Computer Science and Informatics, Cardiff University, 2112 Cardiff, South Glamorgan, United Kingdom of Great Britain and Northern Ireland, (e-mail: laiy4@cardiff.ac.uk); Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, 100084 (e-mail: liuyongjin@tsinghua.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Caricature is a kind of artistic style of human faces that attracts considerable attention in entertainment industry. So far a few 3D caricature generation methods exist and all of them require some caricature information (e.g., a caricature sketch or 2D caricature) as input. This kind of input, however, is difficult to provide by non-professional users. In this paper, we propose an end-to-end deep neural network model that generates high-quality 3D caricature directly from a simple normal face photo. The most challenging issue in our system is that the source domain of face photos (characterized by 2D normal faces) is significantly different from the target domain of 3D caricatures (characterized by 3D exaggerated face shapes and texture). To address this challenge, we (1) build a large dataset of 6,100 3D caricature meshes and use it to establish a PCA model in the 3D caricature shape space, (2) reconstruct a 3D normal full head from the input face photo and use its PCA representation in the 3D caricature shape space to set up correspondence between the input photo and 3D caricature shape, and (3) propose a novel character loss and a novel caricature loss based on previous psychological studies on caricatures. Experiments including a novel two-level user study show that our system can generate high-quality 3D caricatures directly from normal face photos.","1941-0506","","10.1109/TVCG.2021.3126659","National Natural Science Foundation of China(grant numbers:61725204); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609545","Face reconstruction;3D caricature;PCA representation;caricature shape space","Three-dimensional displays;Faces;Solid modeling;Shape;Principal component analysis;Image reconstruction;Parametric statistics","","","","","","","IEEE","9 Nov 2021","","","IEEE","IEEE Early Access Articles"
"A Deep Generative Model for Reordering Adjacency Matrices","O. -H. Kwon; C. -H. Kao; C. -H. Chen; K. -L. Ma","Computer Science, University of California, Davis, Davis, California, United States, 95616; Department of Statistics, Tamkang University, 34886 Taipei, Taiwan, Taiwan; Academia Sinica, Institute of Statistical Science, Taipei, Taiwan, Taiwan; Computer Science, University of California at Davis, Davis, California, United States, 95616-8562","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Depending on the node ordering, an adjacency matrix can highlight distinct characteristics of a graph. Deriving a ""proper"" node ordering is thus a critical step in visualizing a graph as an adjacency matrix. Users often try multiple matrix reorderings using different methods until they find one that meets the analysis goal. However, this trial-and-error approach is laborious and disorganized, which is especially challenging for novices. This paper presents a technique that enables users to effortlessly find a matrix reordering they want. Specifically, we design a generative model that learns a latent space of diverse matrix reorderings of the given graph. We also construct an intuitive user interface from the learned latent space by creating a map of various matrix reorderings. We demonstrate our approach through quantitative and qualitative evaluations of the generated reorderings and learned latent spaces. The results show that our model is capable of learning a latent space of diverse matrix reorderings. Most existing research in this area generally focused on developing algorithms that can compute ""better"" matrix reorderings for particular circumstances. This paper introduces a fundamentally new approach to matrix visualization of a graph, where a machine learning model learns to generate diverse matrix reorderings of a graph.","1941-0506","","10.1109/TVCG.2022.3153838","Division of Information and Intelligent Systems(grant numbers:IIS-1741536); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721695","Graph visualization;matrix visualization;machine learning;deep generative model;visualization interface","Sorting;Data visualization;Neural networks;Computational modeling;Training;Computer architecture;Stochastic processes","","","","","","","IEEE","25 Feb 2022","","","IEEE","IEEE Early Access Articles"
"A Didactic Methodology for Crafting Information Visualizations","M. Keck; R. Groh; Z. Vosough","Technische Universität,Dresden,Germany; Technische Universität,Dresden,Germany; SAP Labs,Palo Alto,USA","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","186","190","Finding or creating the right information visualization solution that meets design goals can be a very challenging task, not only for students but also for visualization experts. In this paper, we introduce a didactic methodology for designing interactive visualizations through hands-on activities. Our approach can assist students and anyone interested in crafting, ranking, and improving new visualization solutions. The suggested approach follows divergent and convergent thinking that motivates designing several low-fidelity prototypes, discussing pros and cons of each in groups, and improving the final solution by incorporating visual and perceptual principles. The methodology is described with teaching course examples for undergraduate and graduate students. We also list observations made when applying the methodology online and offline along with gathered student feedback.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331272","Didactic Methodology;Creativity Method;Construction Kit;Visual Encodings;Gestalt Principles","Visualization;Conferences;Education;Prototypes;Task analysis","data visualisation;interactive systems;user interfaces","didactic methodology;information visualizations;interactive visualizations;hands-on activities;visual principles;perceptual principles","","","","32","","1 Feb 2021","","","IEEE","IEEE Conferences"
"A Domain-Oblivious Approach for Learning Concise Representations of Filtered Topological Spaces for Clustering","Y. Qin; B. T. Fasy; C. Wenk; B. Summa","Tulane University, United States; Montana State University, United States; Tulane University, United States; Tulane University, United States","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2021","2022","28","1","302","312","Persistence diagrams have been widely used to quantify the underlying features of filtered topological spaces in data visualization. In many applications, computing distances between diagrams is essential; however, computing these distances has been challenging due to the computational cost. In this paper, we propose a persistence diagram hashing framework that learns a binary code representation of persistence diagrams, which allows for fast computation of distances. This framework is built upon a generative adversarial network (GAN) with a diagram distance loss function to steer the learning process. Instead of using standard representations, we hash diagrams into binary codes, which have natural advantages in large-scale tasks. The training of this model is domain-oblivious in that it can be computed purely from synthetic, randomly created diagrams. As a consequence, our proposed method is directly applicable to various datasets without the need for retraining the model. These binary codes, when compared using fast Hamming distance, better maintain topological similarity properties between datasets than other vectorized representations. To evaluate this method, we apply our framework to the problem of diagram clustering and we compare the quality and performance of our approach to the state-of-the-art. In addition, we show the scalability of our approach on a dataset with 10k persistence diagrams, which is not possible with current techniques. Moreover, our experimental results demonstrate that our method is significantly faster with the potential of less memory usage, while retaining comparable or better quality comparisons.","1941-0506","","10.1109/TVCG.2021.3114872","National Science Foundation and the National Institutes of Health(grant numbers:1664848,1664858); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552880","Topological data analysis;Persistence diagrams;Persistence diagram distances;Learned hashing;Clustering","Binary codes;Training;Propagation losses;Histograms;Generative adversarial networks;Hash functions;Water resources","binary codes;data visualisation;file organisation;learning (artificial intelligence);neural nets;pattern clustering;topology","filtered topological spaces;computational cost;binary code representation;diagram distance loss function;standard representations;Hamming distance;diagram clustering;domain-oblivious approach;data visualization;persistence diagram hashing;generative adversarial network;GAN;learning;topological similarity properties;datasets;vectorized representations;memory usage","","","","84","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"A Mixed-Initiative Visual Analytics Approach for Qualitative Causal Modeling","F. Husain; P. Proulx; M. -W. Chang; R. Romero-Gómez; H. Vasquez",Uncharted Software Inc.; Uncharted Software Inc.; Uncharted Software Inc.; Uncharted Software Inc.; Uncharted Software Inc.,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","121","125","Modeling complex systems is a time-consuming, difficult and fragmented task, often requiring the analyst to work with disparate data, a variety of models, and expert knowledge across a diverse set of domains. Applying a user-centered design process, we developed a mixed-initiative visual analytics approach, a subset of the Causemos platform, that allows analysts to rapidly assemble qualitative causal models of complex socio-natural systems. Our approach facilitates the construction, exploration, and curation of qualitative models bringing together data across disparate domains. Referencing a recent user evaluation, we demonstrate our approach’s ability to interactively enrich user mental models and accelerate qualitative model building.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623318","Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods","Analytical models;Computational modeling;Visual analytics;Conferences;User centered design;Data visualization;Data models","data analysis;data visualisation;user centred design","mixed-initiative visual analytics approach;qualitative causal modeling;modeling complex systems;fragmented task;disparate data;user-centered design process;qualitative causal models;complex socio-natural systems;qualitative models;disparate domains;interactively enrich user mental models;qualitative model building","","","","27","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"A Music-driven Deep Generative Adversarial Model for Guzheng Playing Animation","J. Chen; C. Fan; Z. Zhang; G. Li; Z. Zhao; Z. Deng; Y. Ding","FUXI AI lab, Netease Inc, 485092 Hangzhou, Zhejiang, China, 310052 (e-mail: chenjiali02@corp.netease.com); Netease Inc, Netease Inc, 485092 Hangzhou, Zhejiang, China, (e-mail: fanchangjie@corp.netease.com); FUXI AI lab, Netease Inc, 485092 Hangzhou, Zhejiang, China, 310052 (e-mail: zhangzhimeng@corp.netease.com); Netease Fuxi AI Lab, Netease Inc, 485092 Hangzhou, Zhejiang, China, 310052 (e-mail: ligongzheng@corp.netease.com); Netease Fuxi AI Lab, Netease Inc., Hangzhou, Zhejiang, China, (e-mail: hzzhaozeng@corp.netease.com); Computer Science, University of Houston, Houston, Texas, United States, (e-mail: zdeng4@uh.edu); Netease Fuxi AI Lab, Netease Inc, 485092 Hangzhou, Zhejiang, China, 77204 (e-mail: dingyu9528@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","To date relatively few efforts have been made on the automatic generation of musical instrument playing animations. This problem is challenging due to the intrinsically complex, temporal relationship between music and human motion as well as the lacking of high quality music-playing motion datasets. In this paper, we propose a fully automatic, deep learning based framework to synthesize realistic upper body animations based on novel guzheng music input. Specifically, based on a recorded audiovisual motion capture dataset, we delicately design a generative adversarial network (GAN) based approach to capture the temporal relationship between the music and the human motion data. In this process, data augmentation is employed to improve the generalization of our approach to handle a variety of guzheng music inputs. Through extensive objective and subjective experiments, we show that our method can generate visually plausible guzheng-playing animations that are well synchronized with the input guzheng music, and it can significantly outperform \uline{the state-of-the-art} methods. In addition, through an ablation study, we validate the contributions of the carefully-designed modules in our framework.","1941-0506","","10.1109/TVCG.2021.3115902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551755","deep learning;generative adversarial networks;motion capture;guzheng animation;music-driven;data augmentation","Animation;Generative adversarial networks;Instruments;Motion segmentation;Hidden Markov models;Facial animation;Deep learning","","","","","","","IEEE","28 Sep 2021","","","IEEE","IEEE Early Access Articles"
"A Partially-Sorted Concentric Layout for Efficient Label Localization in Augmented Reality","Z. Zhou; L. Wang; V. Popescu","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Purdue University, U.S.","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2021","2021","27","11","4087","4096","A common approach for Augmented Reality labeling is to display the label text on a flag planted into the real world element at a 3D anchor point. When there are more than just a few labels, the efficiency of the interface decreases as the user has to search for a given label sequentially. The search can be accelerated by sorting the labels alphabetically, but sorting all labels results in long and intersecting leader lines from the anchor points to the labels. This paper proposes a partially-sorted concentric label layout that leverages the search efficiency of sorting while avoiding the label display problems of long or intersecting leader lines. The labels are partitioned into a small number of sorted sequences displayed on circles of increasing radii. Since the labels on a circle are sorted, the user can quickly search each circle. A tight upper bound derived from circular permutation theory limits the number of circles and thereby the complexity of the label layout. For example, 12 labels require at most three circles. When the application allows it, the labels are presorted to further reduce the number of circles in the layout. The layout was tested in a user study where it significantly reduced the label searching time compared to a conventional single-circle layout.","1941-0506","","10.1109/TVCG.2021.3106492","National Natural Science Foundation of China through Projects(grant numbers:61932003,61772051); National Key RD plan(grant numbers:2019YFC1521102); Beijing Natural Science Foundation(grant numbers:L182016); Beijing Program for International ST Cooperation Project(grant numbers:Z191100001619003); Shenzhen Research Institute of Big Data(Shenzhen)(grant numbers:518000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523830","Augmented Reality;Label layout;Fast label finding","Layout;Sorting;Annotations;Search problems;Labeling;Gaze tracking;Augmented reality","augmented reality;computational complexity;data visualisation;sorting;text analysis","efficient label localization;Augmented Reality labeling;label text;given label;labels results;partially-sorted concentric label layout;label display problems;circle;partially-sorted concentric layout","","","","49","IEEE","27 Aug 2021","","","IEEE","IEEE Journals"
"A Review of Geospatial Content in IEEE Visualization Publications","A. Yoshizumi; M. M. Coffer; E. L. Collins; M. D. Gaines; X. Gao; K. Jones; I. R. McGregor; K. A. McQuillan; V. Perin; L. M. Tomkins; T. Worm; L. Tateosian","North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics; North Carolina State University,Center for Geospatial Analytics","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","51","55","Geospatial analysis is crucial for addressing many of the world's most pressing challenges. Given this, there is immense value in improving and expanding the visualization techniques used to communicate geospatial data. In this work, we explore this important intersection - between geospatial analytics and visualization - by examining a set of recent IEEE VIS Conference papers (a selection from 2017-2019) to assess the inclusion of geospatial data and geospatial analyses within these papers. After removing the papers with no geospatial data, we organize the remaining literature into geospatial data domain categories and provide insight into how these categories relate to VIS Conference paper types. We also contextualize our results by investigating the use of geospatial terms in IEEE Visualization publications over the last 30 years. Our work provides an understanding of the quantity and role of geospatial subject matter in recent IEEE VIS publications and supplies a foundation for future meta-analytical work around geospatial analytics and geovisualization that may shed light on opportunities for innovation.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331291","Human-centered computing;Visualization;Visualization application domains;Geographic visualization","Technological innovation;Conferences;Text categorization;Data visualization;Tools;Geospatial analysis;Task analysis","data analysis;data visualisation;electronic publishing;geographic information systems","IEEE visualization publications;geospatial analysis;geospatial analytics;IEEE VIS conference papers;geospatial data domain categories;geospatial content review","","","","39","","1 Feb 2021","","","IEEE","IEEE Conferences"
"A Rotation-Invariant Framework for Deep Point Cloud Analysis","X. Li; R. Li; G. Chen; C. -W. Fu; D. Cohen-Or; P. -A. Heng","Computer Science and Engineering, Chinese University of Hong Kong, 26451 Hong Kong, Hong Kong, Hong Kong, (e-mail: xzli@cse.cuhk.edu.hk); Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 Hong Kong, Hong Kong, Hong Kong, (e-mail: ruihuili.lee@gmail.com); Institute of Advanced Integration Technology, Shenzhen Institutes of Advanced Technology Chinese Academy of Sciences, 85411 Shenzhen, Guangdong, China, (e-mail: gy.chen@siat.ac.cn); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong, Hong Kong, SIN (e-mail: cwfu@cse.cuhk.edu.hk); computer science, Tel-Aviv University, Tel-Aviv, Israel, Israel, 69778 (e-mail: cohenor@gmail.com); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong, Hong Kong, (e-mail: pheng@cse.cuhk.edu.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Recently, many deep neural networks were designed to process 3D point clouds, but a common drawback is that rotation invariance is not ensured, leading to poor generalization to arbitrary orientations. In this paper, we introduce a new low-level purely rotation-invariant representation to replace common 3D Cartesian coordinates as the network inputs. Also, we present a network architecture to embed these representations into features, encoding local relations between points and their neighbors, and the global shape structure. To alleviate inevitable global information loss caused by the rotation-invariant representations, we further introduce a region relation convolution to encode local and non-local information. We evaluate our method on multiple point cloud analysis tasks, including (i) shape classification, (ii) part segmentation, and (iii) shape retrieval. Extensive experimental results show that our method achieves consistent, and also the best performance, on inputs at arbitrary orientations, compared with all the state-of-the-art methods.","1941-0506","","10.1109/TVCG.2021.3092570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465688","Point cloud analysis;rotation-invariant representation;deep neural network","Three-dimensional displays;Shape;Feature extraction;Convolution;Neural networks;Task analysis;Network architecture","","","","","","","IEEE","25 Jun 2021","","","IEEE","IEEE Early Access Articles"
"A Study of Opacity Ranges for Transparent Overlays in 3D Landscapes","J. Hombeck; L. Ji; K. Lawonn; C. Perin",University of Koblenz; LlamaZOO Interactive Inc.; University of Jena; University of Victoria,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","66","70","When visualizing data in a realistically rendered 3D virtual environment, it is often important to represent not only the 3D scene but also overlaid information about additional, abstract data. These overlays must be usefully visible, i.e. be readable enough to convey the information they represent, but remain unobtrusive to avoid cluttering the view. We take a step toward establishing guidelines for designing such overlays by studying the relationship between three different patterns (filled, striped and dotted patterns), two pattern densities, the presence or not of a solid outline, two types of background (blank and with trees), and the opacity of the overlay. For each combination of factors, participants set the faintest and the strongest acceptable opacity values. Results from this first study suggest that i) ranges of acceptable opacities are around 20-70%, that ii) ranges can be extended by 5% by using an outline, and that iii) ranges shift based on features like pattern and density.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331259","Overlays;Opacity;Visualization","Visualization;Three-dimensional displays;Data visualization;Virtual environments;Solids;Rendering (computer graphics);Junctions","data visualisation;rendering (computer graphics);solid modelling;virtual reality","opacity ranges;transparent overlays;data visualization;pattern densities;3D landscapes;3D virtual environment rendering","","","","26","","1 Feb 2021","","","IEEE","IEEE Conferences"
"A Virtual Frame Buffer Abstraction for Parallel Rendering of Large Tiled Display Walls","M. Han; I. Wald; W. Usher; N. Morrical; A. Knoll; V. Pascucci; C. R. Johnson","University of Utah,SCI Institute; NVIDIA Corp; University of Utah,SCI Institute; University of Utah,SCI Institute; Intel Corp.; University of Utah,SCI Institute; University of Utah,SCI Institute","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","11","15","We present dw2, a flexible and easy-to-use software infrastructure for interactive rendering of large tiled display walls. Our library represents the tiled display wall as a single virtual screen through a display ""service"", which renderers connect to and send image tiles to be displayed, either from an on-site or remote cluster. The display service can be easily configured to support a range of typical network and display hardware configurations; the client library provides a straightforward interface for easy integration into existing renderers. We evaluate the performance of our display wall service in different configurations using a CPU and GPU ray tracer, in both on-site and remote rendering scenarios using multiple display walls.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00009","National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331308","Tiled Display Walls;Distributed Display Frameworks","Visualization;Conferences;Graphics processing units;Rendering (computer graphics);Libraries;Software;Hardware","buffer storage;computer displays;data visualisation;graphics processing units;interactive devices;microprocessor chips;parallel processing;pattern clustering;ray tracing;rendering (computer graphics)","virtual frame buffer abstraction;parallel rendering;tiled display wall;software infrastructure;interactive rendering;image tiles;display wall service;multiple display walls;GPU ray tracer;CPU ray tracer","","","","21","","1 Feb 2021","","","IEEE","IEEE Conferences"
"A Visual Analytics Approach for Ecosystem Dynamics based on Empirical Dynamic Modeling","H. Natsukawa; E. R. Deyle; G. M. Pao; K. Koyamada; G. Sugihara","Kyoto University; Boston University; Salk Institution for Biological Sciences; Kyoto University; Scripps Institution of Oceanography, University of California, San Diego","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","506","516","An important approach for scientific inquiry across many disciplines involves using observational time series data to understand the relationships between key variables to gain mechanistic insights into the underlying rules that govern the given system. In real systems, such as those found in ecology, the relationships between time series variables are generally not static; instead, these relationships are dynamical and change in a nonlinear or state-dependent manner. To further understand such systems, we investigate integrating methods that appropriately characterize these dynamics (i.e., methods that measure interactions as they change with time-varying system states) with visualization techniques that can help analyze the behavior of the system. Here, we focus on empirical dynamic modeling (EDM) as a state-of-the-art method that specifically identifies causal variables and measures changing state-dependent relationships between time series variables. Instead of using approaches centered on parametric equations, EDM is an equation-free approach that studies systems based on their dynamic attractors. We propose a visual analytics system to support the identification and mechanistic interpretation of system states using an EDM-constructed dynamic graph. This work, as detailed in four analysis tasks and demonstrated with a GUI, provides a novel synthesis of EDM and visualization techniques such as brush-link visualization and visual summarization to interpret dynamic graphs representing ecosystem dynamics. We applied our proposed system to ecological simulation data and real data from a marine mesocosm study as two key use cases. Our case studies show that our visual analytics tools support the identification and interpretation of the system state by the user, and enable us to discover both confirmatory and new findings in ecosystem dynamics. Overall, we demonstrated that our system can facilitate an understanding of how systems function beyond the intuitive analysis of high-dimensional information based on specific domain knowledge.","1941-0506","","10.1109/TVCG.2020.3028956","Keihanshin Consortium for Fostering the Next Generation of Global Leaders in Research (K-CONNEX); Ministry of Education, Culture, Sports, Science and Technology; JSPS KAKENHI(grant numbers:19K20278); JST CREST(grant numbers:JP-MJCR1511); Lenfest Ocean Program award(grant numbers:00028335); Department of Defense Strategic Environmental Research and Development Program(grant numbers:15 RC-2509); EPA-STAR Fellowship Program; National Science Foundation ABI-Innovation(grant numbers:DBI-1667584); National Science Foundation(grant numbers:DEB-1020372); U.S. Department of the Interior(grant numbers:NPS-P20AC00527); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216532","Visual analytics;empirical dynamic modeling;dynamic network;exploratory data analysis","Visual analytics;Time series analysis;Data visualization;Ecosystems;Task analysis;Time measurement;Ecology","biology computing;data analysis;data visualisation;ecology;graph theory;graphical user interfaces","GUI;time-varying system states;state-dependent manner;time series variables;mechanistic insights;observational time series data;empirical dynamic modeling;visual analytics approach;visual analytics tools;ecological simulation data;ecosystem dynamics;dynamic graphs;visual summarization;brush-link visualization;visualization techniques;EDM-constructed dynamic graph;visual analytics system;equation-free approach","","","","58","IEEE","7 Oct 2020","","","IEEE","IEEE Journals"
"A Visual Analytics System for Water Distribution System Optimization","Y. Li; E. Musabandesu; T. Fujiwara; F. J. Loge; K. -L. Ma","University of California,Davis; University of California,Davis; University of California,Davis; University of California,Davis; University of California,Davis","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","126","130","The optimization of water distribution systems (WDSs) is vital to minimize energy costs required for their operations. A principal approach taken by researchers is identifying an optimal scheme for water pump controls through examining computational simulations of WDSs. However, due to a large number of possible control combinations and the complexity of WDS simulations, it remains non-trivial to identify the best pump controls by reviewing the simulation results. To address this problem, we design a visual analytics system that helps understand relationships between simulation inputs and outputs towards better optimization. Our system incorporates interpretable machine learning as well as multiple linked visualizations to capture essential input-output relationships from complex WDS simulations. We demonstrate our system’s effectiveness through a practical case study and evaluate its usability through expert reviews. Our results show that our system can lessen the burden of analysis and assist in determining optimal operating schemes.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623272","National Science Foundation; California Energy Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623272","","Costs;Visual analytics;Computational modeling;Simulation;Conferences;Machine learning;Water pumps","data visualisation;learning (artificial intelligence);optimisation;pumps;water supply","possible control combinations;pump controls;visual analytics system;simulation inputs;multiple linked visualizations;essential input-output relationships;complex WDS simulations;optimal operating schemes;water distribution system optimization;water distribution systems;WDSs;energy costs;principal approach;water pump;computational simulations","","","","27","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"A local graph-based structure for processing gigantic aggregated 3D point clouds","A. Bletterer; F. Payan; M. Antonini","Université Cõte d’Azur, CNRS, I3S, Sophia Antipolis, France, (e-mail: bletterer@i3s.unice.fr); Université Cõte d’Azur, CNRS, I3S, Sophia Antipolis, France, (e-mail: fpayan@i3s.unice.fr); Université Cõte d’Azur, CNRS, I3S, Sophia Antipolis, France, (e-mail: am@i3s.unice.fr)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","We present an original workflow for structuring a point cloud generated from several scans. Our representation is based on a set of local graphs. Each graph is constructed from the depth map provided by each scan. The graphs are then connected together via the overlapping areas, and careful consideration of the redundant points in these regions leads to a piecewise and globally consistent structure for the underlying surface sampled by the point cloud. The proposed workflow allows structuring aggregated point clouds, scan after scan, whatever the number of acquisitions and the number of points per acquisition, even on computers with very limited memory capacities. To show that our structure can be highly relevant for the community, where the gigantic amount of data represents a real scientific challenge per se, we present an algorithm based on this structure capable of resampling billions of points on standard computers. This application is particularly attractive for simplifying and visualizing gigantic point clouds representing very large-scale scenes (buildings, urban scenes, historical sites舰), which often require a prohibitive number of points to describe them accurately.","1941-0506","","10.1109/TVCG.2020.3042588","Region SUD France; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282203","Computational Geometry and Object Modeling;Three-Dimensional Graphics and Realism;3D Point Clouds;Data Structure;Graphs;Out-Of-Core Algorithms;Poisson-disk sampling","Three-dimensional displays;Surface morphology;Random access memory;Surface treatment;Solid modeling;Sensors;Two dimensional displays","","","","","","","IEEE","4 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Accelerating Force-Directed Graph Drawing with RT Cores","S. Zellmann; M. Weier; I. Wald",University of Cologne; Hochschule Bonn-Rhein-Sieg; NVIDIA,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","96","100","Graph drawing with spring embedders employs a V ×V computation phase over the graph's vertex set to compute repulsive forces. Here, the efficacy of forces diminishes with distance: a vertex can effectively only influence other vertices in a certain radius around its position. Therefore, the algorithm lends itself to an implementation using search data structures to reduce the runtime complexity. NVIDIA RT cores implement hierarchical tree traversal in hard-ware. We show how to map the problem of finding graph layouts with force-directed methods to a ray tracing problem that can subsequently be implemented with dedicated ray tracing hardware. With that, we observe speedups of 4× to 13× over a CUDA software implementation.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331321","Human-centered computing;Visualization;Visualization techniques;Graph drawings;Computing methodologies;Computer graphics;Rendering;Ray tracing","Runtime;Software algorithms;Ray tracing;Data structures;Hardware;Software;Springs","computational geometry;computer graphics;data structures;directed graphs;graph theory;parallel architectures;ray tracing;trees (mathematics)","force-directed graph drawing;spring embedders;vertex;repulsive forces;search data structures;hierarchical tree traversal;graph layouts;CUDA software implementation;ray tracing hardware;NVIDIA RT cores","","","","40","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Accurate Dynamic SLAM Using CRF-Based Long-Term Consistency","Z. -J. Du; S. -S. Huang; T. -J. Mu; Q. Zhao; R. R. Martin; K. Xu","Department of Computer Technology and Application, Qinghai University, Xining, China; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; DeepBlue Technology, Shanghai, Co.,Ltd, Shanghai, China; School of Computer Science and Informatics, Cardiff University, Cardiff, U.K; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","25 Feb 2022","2022","28","4","1745","1757","Accurate camera pose estimation is essential and challenging for real world dynamic 3D reconstruction and augmented reality applications. In this article, we present a novel RGB-D SLAM approach for accurate camera pose tracking in dynamic environments. Previous methods detect dynamic components only across a short time-span of consecutive frames. Instead, we provide a more accurate dynamic 3D landmark detection method, followed by the use of long-term consistency via conditional random fields, which leverages long-term observations from multiple frames. Specifically, we first introduce an efficient initial camera pose estimation method based on distinguishing dynamic from static points using graph-cut RANSAC. These static/dynamic labels are used as priors for the unary potential in the conditional random fields, which further improves the accuracy of dynamic 3D landmark detection. Evaluation using the TUM and Bonn RGB-D dynamic datasets shows that our approach significantly outperforms state-of-the-art methods, providing much more accurate camera trajectory estimation in a variety of highly dynamic environments. We also show that dynamic 3D reconstruction can benefit from the camera poses estimated by our RGB-D SLAM approach.","1941-0506","","10.1109/TVCG.2020.3028218","National Natural Science Foundation of China(grant numbers:61863031,61902210,61521002); China Postdoctoral Science Foundation(grant numbers:2019M660646); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210559","RGB-D SLAM;dynamic SLAM;long-term consistency;conditional random fields,graph-cut RANSAC","Cameras;Simultaneous localization and mapping;Three-dimensional displays;Visualization;Pose estimation;Dynamics;Robustness","augmented reality;cameras;feature extraction;graph theory;image reconstruction;image sequences;motion estimation;pose estimation;SLAM (robots)","efficient initial camera;estimation method;distinguishing dynamic;conditional random fields;accurate camera trajectory estimation;highly dynamic environments;accurate dynamic SLAM;CRF-based long-term consistency;world dynamic 3D reconstruction;reality applications;novel RGB-D SLAM approach;dynamic components;short time-span;consecutive frames;accurate dynamic 3D landmark detection method;long-term observations","","","","52","IEEE","1 Oct 2020","","","IEEE","IEEE Journals"
"ActFloor-GAN: Activity-Guided Adversarial Networks for Human-Centric Floorplan Design","S. Wang; W. Zeng; X. Chen; Y. Ye; Y. Qiao; C. -W. Fu","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences Guangzhou Branch, 53042 Shenzhen, Guangdong, China, (e-mail: sdwang96@gmail.com); Computational Media and Arts, The Hong Kong University of Science and Technology, 58207 Guangzhou, Guangdong, China, (e-mail: weizeng@ust.hk); Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences Guangzhou Branch, 53042 Shenzhen, Guangdong, China, (e-mail: xi.chen2@siat.ac.cn); College of Architecture and Urban Planning, Tongji University, 12476 Shanghai, Shanghai, China, (e-mail: yye@tongji.edu.cn); Multimedia, SIAT, Shenzhen, Guangdong, China, (e-mail: yu.qiao@siat.ac.cn); Department of Computer Science and Engineering, The Chinese University of Hong Kong, 26451 Hong Kong, Hong Kong, Hong Kong, (e-mail: cwfu@cse.cuhk.edu.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We present a novel two-stage approach for automated floorplan design in residential buildings with a given exterior wall boundary. Our approach has the unique advantage of being human-centric, that is, the generated floorplans can be geometrically plausible, as well as topologically reasonable to enhance resident interaction with the environment. From the input boundary, we first synthesize a human-activity map that reflects both the spatial configuration and human-environment interaction in an architectural space. We propose to produce the human-activity map either automatically by a pre-trained generative adversarial network (GAN) model, or semi-automatically by synthesizing it with user manipulation of the furniture. Second, we feed the human-activity map into our deep framework ActFloor-GAN to guide a pixel-wise prediction of room types. We adopt a re-formulated cycle-consistency constraint in ActFloor-GAN to maximize the overall prediction performance, so that we can produce high-quality room layouts that are readily convertible to vectorized floorplans. Experimental results show several benefits of our approach. First, a quantitative analysis of ablated techniques shows superior performance of leveraging the human-activity map in predicting piecewise room types. Second, a subjective evaluation by architects shows that our results have compelling quality as professionally-designed floorplans and much better than those generated by existing methods in terms of the room layout topology. Last, our approach allows manipulating the furniture placement, considers the human activities in the environment, and enables the incorporation of user-design preferences.","1941-0506","","10.1109/TVCG.2021.3126478","The Research Grants Council of the Hong Kong Special Administrative Region(grant numbers:CUHK 14206320); The Fundamental Research Funds for the Central Uni- versitie(grant numbers:22120210540); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609576","Floorplan design;room layout;human-centric;GAN","Layout;Generative adversarial networks;Buildings;Predictive models;Computer architecture;Topology;Optimization","","","","","","","IEEE","9 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Active Arrangement of Small Objects in 3D Indoor Scenes","S. Zhang; Z. Han; Y. -K. Lai; M. Zwicker; H. Zhang","School of Software, Tsinghua University, Beijing, China; Department of Computer Science, University of Maryland, College Park, MD, USA; School of Computer Science & Informatics, Cardiff University, Cardiff, United Kingdom; Department of Computer Science, University of Maryland, College Park, MD, USA; School of Software, Tsinghua University, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","25 Feb 2021","2021","27","4","2250","2264","Small object arrangement is very important for creating detailed and realistic 3D indoor scenes. In this article, we present an interactive framework based on active learning to help users create customized arrangements for small objects according to their preferences. To achieve this with minimal user effort, we first learn the prior knowledge about small object arrangement from a 3D indoor scene dataset through a probability mining method, which forms the initial guidance for arranging small objects. Then, users are able to express their preferences on a few small object categories, which are automatically propagated to all the other categories via a novel active learning approach. In the propagation process, we introduce a novel metric to obtain the propagation weights, which measures the degree of interchangeability between two small object categories, and is calculated based on a spatial embedding model learned from the small object neighborhood information extracted from the 3D indoor scene dataset. Experiments show that our framework is able to help users effectively create customized small object arrangements with little effort.","1941-0506","","10.1109/TVCG.2019.2949295","National Natural Science Foundation of China(grant numbers:61373070); National Science Foundation(grant numbers:1813583); Tsinghua-Kuaishou Institute of Future Media Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883084","3D object layout;active learning;scene enrichment;computer-aided aesthetic design;human computer interaction","Three-dimensional displays;Shape;Solid modeling;Learning systems;Computer graphics;Data mining;Neural networks","data mining;learning (artificial intelligence);probability;realistic images","active arrangement;object arrangement;detailed D indoor scenes;realistic 3D indoor scenes;customized arrangements;minimal user effort;3D indoor scene dataset;object categories;active learning approach;object neighborhood information","","","","40","IEEE","25 Oct 2019","","","IEEE","IEEE Journals"
"AdViCE: Aggregated Visual Counterfactual Explanations for Machine Learning Model Validation","O. Gomez; S. Holter; J. Yuan; E. Bertini",NA; NA; NA; NA,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","31","35","Rapid improvements in the performance of machine learning models have pushed them to the forefront of data-driven decision-making. Meanwhile, the increased integration of these models into various application domains has further highlighted the need for greater interpretability and transparency. To identify problems such as bias, overfitting, and incorrect correlations, data scientists require tools that explain the mechanisms with which these model decisions are made. In this paper we introduce AdViCE, a visual analytics tool that aims to guide users in black-box model debugging and validation. The solution rests on two main visual user interface innovations: (1) an interactive visualization design that enables the comparison of decisions on user-defined data subsets; (2) an algorithm and visual design to compute and visualize counterfactual explanations - explanations that depict model outcomes when data features are perturbed from their original values. We provide a demonstration of the tool through a use case that showcases the capabilities and potential limitations of the proposed approach.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623271","Machine learning;interpretability;explainability;counterfactual explanations;data visualization","Technological innovation;Machine learning algorithms;Computational modeling;Visual analytics;Decision making;Data visualization;Machine learning","data analysis;data visualisation;decision making;learning (artificial intelligence);program debugging;program verification;user interfaces","data-driven decision-making;application domains;data scientists;visual analytics tool;black-box model debugging;main visual user interface innovations;interactive visualization design;user-defined data subsets;visual design;data features;aggregated visual counterfactual explanations;machine learning model validation;AdViCE","","","","34","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Adaptive Light Estimation using Dynamic Filtering for Diverse Lighting Conditions","J. Zhao; A. Chalmers; T. Rhee","Computational Media Innovation Centre (CMIC), Victoria University of Wellington, New Zealand; Computational Media Innovation Centre (CMIC), Victoria University of Wellington, New Zealand; Computational Media Innovation Centre (CMIC), Victoria University of Wellington, New Zealand","IEEE Transactions on Visualization and Computer Graphics","27 Oct 2021","2021","27","11","4097","4106","High dynamic range (HDR) panoramic environment maps are widely used to illuminate virtual objects to blend with real-world scenes. However, in common applications for augmented and mixed-reality (AR/MR), capturing 360° surroundings to obtain an HDR environment map is often not possible using consumer-level devices. We present a novel light estimation method to predict 360° HDR environment maps from a single photograph with a limited field-of-view (FOV). We introduce the Dynamic Lighting network (DLNet), a convolutional neural network that dynamically generates the convolution filters based on the input photograph sample to adaptively learn the lighting cues within each photograph. We propose novel Spherical Multi-Scale Dynamic (SMD) convolutional modules to dynamically generate sample-specific kernels for decoding features in the spherical domain to predict 360° environment maps. Using DLNet and data augmentations with respect to FOV, an exposure multiplier, and color temperature, our model shows the capability of estimating lighting under diverse input variations. Compared with prior work that fixes the network filters once trained, our method maintains lighting consistency across different exposure multipliers and color temperature, and maintains robust light estimation accuracy as FOV increases. The surrounding lighting information estimated by our method ensures coherent illumination of 3D objects blended with the input photograph, enabling high fidelity augmented and mixed reality supporting a wide range of environmental lighting conditions and device sensors.","1941-0506","","10.1109/TVCG.2021.3106497","MBIE; TEC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523888","Augmented reality;mixed reality;lighting;light estimation;deep learning","Lighting;Feature extraction;Estimation;Convolution;Image color analysis;Decoding;Adaptation models","augmented reality;convolutional neural nets;estimation theory;filtering theory;image colour analysis;lighting;rendering (computer graphics);virtual reality","data augmentations;FOV;color temperature;diverse input variations;network filters;lighting consistency;mixed reality;environmental lighting conditions;device sensors;adaptive light estimation;dynamic filtering;diverse lighting conditions;high dynamic range panoramic environment maps;mixed-reality;HDR environment map;consumer-level devices;light estimation method;single photograph;DLNet;convolutional neural network;input photograph sample;sample-specific kernels;illuminate virtual objects;AR-MR;augmented reality;spherical multiscale dynamic convolutional modules;SMD;limited field-of-view;dynamic lighting network","","","","44","IEEE","27 Aug 2021","","","IEEE","IEEE Journals"
"Adaptive Optimization Algorithm for Resetting Techniques in Obstacle-ridden Environments","S. -H. Zhang; C. -H. Chen; Z. Fu; Y. Yang; S. -M. Hu","Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, (e-mail: shz@tsinghua.edu.cn); Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: accplusjh@gmail.com); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: gynyfyt2012@hotmail.com); Department of Computer Science, University of Bath, 1555 Bath, Somerset, United Kingdom of Great Britain and Northern Ireland, (e-mail: y.yang@cs.bath.ac.uk); Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, 100084 (e-mail: shimin@tsinghua.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Redirected Walking (RDW) algorithms aim to impose several types of gains on users immersed in Virtual Reality and distort their walking paths in the real world, thus enabling them to explore a larger space. Since collision with physical boundaries is inevitable, a reset strategy needs to be provided to allow users to reset when they hit the boundary. However, most reset strategies are based on simple heuristics by choosing a seemingly suitable solution, which may not perform well in practice. In this paper, we propose a novel optimization-based reset algorithm adaptive to different RDW algorithms. Inspired by the approach of finite element analysis, our algorithm splits the boundary of the physical world by a set of endpoints. Each endpoint is assigned a reset vector to represent the optimized reset direction when hitting the boundary. The reset vectors on the edge will be determined by the interpolation between two neighbouring endpoints. We conduct simulation-based experiments for three RDW algorithms with commonly used reset algorithms to compare with. The results demonstrate that the proposed algorithm significantly reduces the number of resets.","1941-0506","","10.1109/TVCG.2021.3139990","National Key Technology RD Program(grant numbers:2017YFB1002604); National Natural Science Foundation of China(grant numbers:61521002,62132012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669131","Redirected walking;Resetting;Adaptive optimization;Obstacle-ridden area;Redirection","Legged locomotion;Optimization;Heuristic algorithms;Navigation;Space vehicles;Layout;Space exploration","","","","","","","IEEE","4 Jan 2022","","","IEEE","IEEE Early Access Articles"
"AiR: An Augmented Reality Application for Visualizing Air Pollution","N. S. Mathews; S. Chimalakonda; S. Jain","IIT,Department of Chemical Engineering,Tirupati; IIT,Department of Computer Science and Engineering,Tirupati; IIT,Department of Civil and Environmental Engineering,Tirupati","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","146","150","In order to effectively combat Air Pollution, it is necessary for the government and the community to work together. Easily comprehensible visualizations can play a major role in drawing public attention and spreading awareness about seemingly intangible air pollution. Considering the widespread usage of Android-based devices, in this paper, we propose an Augmented Reality based application called AiR, to help users to visualize pollutants in the air and to create an immersive user experience. It aims to interactively engage a wide variety of users and create awareness without overwhelming them with data. AiR visualizes 12 pollutants $[PM _{10}$, $PM _{2.5}$, NO, NO<inf>2</inf>, $NO _{x}$, CO, SO<inf>2</inf>, O<inf>3</inf>, NH<inf>3</inf>, C<inf>6</inf> H<inf>6</inf>, (CH<inf>3</inf>)C<inf>6</inf> H<inf>5</inf> and (CH<inf>3</inf>)<inf>2</inf> C<inf>6</inf> H<inf>5</inf>] through unique models. We demonstrate our application on pollution data by CPCB from various weather stations across India collected over the initial lockdown period due to COVID-19 in India.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623287","Human-centered computing;Visualization;Visualization systems and tools;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Applied computing;Physical sciences and engineering;Earth and atmospheric sciences","Conferences;Urban areas;Government;Data visualization;Air pollution;User experience;Mobile applications","air pollution;Android (operating system);augmented reality;data visualisation;environmental science computing;organic compounds","comprehensible visualizations;Android-based devices;augmented reality based application;user experience;CPCB;combat air pollution;immersive user experience;COVID-19","","","","32","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"An Evaluation-Focused Framework for Visualization Recommendation Algorithms","Z. Zeng; P. Moh; F. Du; J. Hoffswell; T. Y. Lee; S. Malik; E. Koh; L. Battle","University of Maryland, United States; University of Maryland, United States; Adobe Research, United States; Adobe Research, United States; Adobe Research, United States; Adobe Research, United States; Adobe Research, United States; University of Maryland, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","346","356","Although we have seen a proliferation of algorithms for recommending visualizations, these algorithms are rarely compared with one another, making it difficult to ascertain which algorithm is best for a given visual analysis scenario. Though several formal frameworks have been proposed in response, we believe this issue persists because visualization recommendation algorithms are inadequately specified from an <italic>evaluation</italic> perspective. In this paper, we propose an evaluation-focused framework to contextualize and compare a broad range of visualization recommendation algorithms. We present the structure of our framework, where algorithms are specified using three components: (1) a graph representing the full space of possible visualization designs, (2) the method used to traverse the graph for potential candidates for recommendation, and (3) an oracle used to rank candidate designs. To demonstrate how our framework guides the formal comparison of algorithmic performance, we not only theoretically compare five existing representative recommendation algorithms, but also empirically compare four new algorithms generated based on our findings from the theoretical comparison. Our results show that these algorithms behave similarly in terms of user performance, highlighting the need for more rigorous formal comparisons of recommendation algorithms to further clarify their benefits in various analysis scenarios.","1941-0506","","10.1109/TVCG.2021.3114814","NSF(grant numbers:IIS-1850115); Adobe Research Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552925","Visualization Tools;Visualization Recommendation Algorithms","Data visualization;Visualization;Machine learning algorithms;Approximation algorithms;Task analysis;Encoding;Clustering algorithms","data visualisation;formal specification;formal verification;graph theory;recommender systems;software quality","evaluation-focused framework;visualization recommendation algorithms;recommending visualizations;given visual analysis scenario;formal frameworks;possible visualization designs;algorithmic performance;existing representative recommendation algorithms","","","","38","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Analyzing Time Attributes in Temporal Event Sequences","J. Magallanes; L. van Gemeren; S. Wood; M. -C. Villa-Uriol","University of Sheffield,Department of Computer Science,Sheffield,United Kingdom; University of Sheffield,Sheffield Teaching Hospitals NHS Foundation Trust,Sheffield,United Kingdom; University of Sheffield,Sheffield Teaching Hospitals NHS Foundation Trust,Sheffield,United Kingdom; University of Sheffield,Department of Computer Science,Sheffield,United Kingdom","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Event data is present in a variety of domains such as electronic health records, daily living activities and web clickstream records. Current visualization methods to explore event data focus on discovering sequential patterns but present limitations when studying time attributes in event sequences. Time attributes are especially important when studying waiting times or lengths of visit in patient flow analysis. We propose a visual analytics methodology that allows the identification of trends and outliers in respect of duration and time of occurrence in event sequences. The proposed method presents event data using a single Sequential and Time Patterns overview. User-driven alignment by multiple events, sorting by sequence similarity and a novel visual encoding of events allows the comparison of time trends across and within sequences. The proposed visualization allows the derivation of findings that otherwise could not be obtained using traditional visualizations. The proposed methodology has been applied to a real-world dataset provided by Sheffield Teaching Hospitals NHS Foundation Trust, for which four classes of conclusions were derived.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933770","Human-centered computing—Visualization—Visualization techniques;Human-centered computing—Visual analytics;Applied computing—Health care information systems","Encoding;Data visualization;Market research;Visual analytics;Aggregates;Education","data analysis;data visualisation;electronic health records;health care;hospitals;medical computing;patient care","patient flow analysis;visual analytics methodology;temporal event sequences;electronic health records;daily living activities;web clickstream records;visualization methods;event data focus;time attribute analysis;Sheffield teaching hospitals NHS foundation trust","","","","23","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Atlas: Grammar-based Procedural Generation of Data Visualizations","Z. Liu; C. Chen; F. Morales; Y. Zhao","University of Maryland,Department of Computer Science,College Park; University of Maryland,Department of Computer Science,College Park; University of Maryland,Department of Computer Science,College Park; University of Maryland,Department of Computer Science,College Park","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","171","175","We present Atlas, a procedural grammar for constructing data visualizations. Unlike most visualization grammars which use declarative specifications to describe visualization components, Atlas exposes the generative process of a visualization through a set of concatenated high-level production rules. Each of these rules describes how an input graphical object is created, transformed, or joined with abstract data to derive an output object. The visualization state can thus be inspected throughout the generative process. We demonstrate Atlas’ expressivity through a catalog of visualization designs, and discuss the trade-offs in its design by comparing it to state-of-the-art grammars.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623315","Human-centered computing;Visualization;Visualization systems and tools;Visualization toolkits","Conferences;Data visualization;Production;Grammar","data visualisation;grammars;interactive systems","grammar-based procedural generation;data visualizations;procedural grammar;visualization grammars;declarative specifications;visualization components;generative process;input graphical object;visualization state;Atlas;visualization designs;high-level production rules","","","","25","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Automatic Narrative Summarization for Visualizing Cyber Security Logs and Incident Reports","R. Gove","Two Six Technologies, United States","IEEE Transactions on Visualization and Computer Graphics","31 Dec 2021","2022","28","1","1182","1190","Cyber security logs and incident reports describe a narrative, but in practice analysts view the data in tables where it can be difficult to follow the narrative. Narrative visualizations are useful, but common examples use a summarized narrative instead of the full story's narrative; it is unclear how to automatically generate these summaries. This paper presents (1) a narrative summarization algorithm to reduce the size and complexity of cyber security narratives with a user-customizable summarization level, and (2) a narrative visualization tailored for incident reports and network logs. An evaluation on real incident reports shows that the summarization algorithm reduces false positives and improves average precision by 41% while reducing average incident report size up to 79%. Together, the visualization and summarization algorithm generate compact representations of cyber narratives that earned praise from a SOC analyst. We further demonstrate that the summarization algorithm can apply to other types of dynamic graphs by automatically generating a summary of the Les Misérables character interaction graph. We find that the list of main characters in the automatically generated summary has substantial agreement with human-generated summaries. A version of this paper, data, and code is freely available at <uri>https://osf.io/ekzbp/</uri>.","1941-0506","","10.1109/TVCG.2021.3114843","Defense Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552186","Summarization;incident reports;dynamic graphs;cyber security","Data visualization;Tools;Task analysis;Computer crime;Schedules;Heuristic algorithms;Security","data visualisation;graph theory;security of data","automatic narrative summarization;incident reports;narrative visualization;narrative summarization algorithm;cyber security narratives;user-customizable summarization level;network logs;automatically generated summary;cyber security logs visualization;SOC analyst;human-generated summaries","","","","38","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Automatic Polygon Layout for Primal-Dual Visualization of Hypergraphs","B. Qu; E. Zhang; Y. Zhang","School of Electrical Engineering and Computer Science, Oregon State University, United States; School of Electrical Engineering and Computer Science, Oregon State University, United States; School of Electrical Engineering and Computer Science, Oregon State University, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","633","642","N-ary relationships, which relate $N$ entities where $N$ is not necessarily two, can be visually represented as polygons whose vertices are the entities of the relationships. Manually generating a high-quality layout using this representation is labor-intensive. In this paper, we provide an automatic polygon layout generation algorithm for the visualization of N-ary relationships. At the core of our algorithm is a set of objective functions motivated by a number of design principles that we have identified. These objective functions are then used in an optimization framework that we develop to achieve high-quality layouts. Recognizing the duality between entities and relationships in the data, we provide a second visualization in which the roles of entities and relationships in the original data are reversed. This can lead to additional insight about the data. Furthermore, we enhance our framework for a joint optimization on the primal layout (original data) and the dual layout (where the roles of entities and relationships are reversed). This allows users to inspect their data using two complementary views. We apply our visualization approach to a number of datasets that include co-authorship data and social contact pattern data.","1941-0506","","10.1109/TVCG.2021.3114759","NSF(grant numbers:# 1619383); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552233","Hypergraph visualization;N-ary relationships;optimization;polygon layout;duality;primal-dual visualization","Layout;Data visualization;Optimization;Visualization;Manuals;Linear programming;Electrical engineering","data visualisation;graph theory;optimisation","high-quality layout;automatic polygon layout generation algorithm;N-ary relationships;objective functions;optimization framework;primal layout;dual layout;co-authorship data;social contact pattern data;primal-dual visualization;hypergraphs","","","","48","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Automatic Schelling Points Detection from Meshes","G. Chen; H. Dai; T. Zhou; J. Shen; L. Shao","IIAI, Inception Institute of Artificial Intelligence, Abu Dhabi, Abu Dhabi, United Arab Emirates, (e-mail: geng.chen.cs@gmail.com); MBZUAI, MBZUAI, Abu Dhabi, Abu Dhabi, United Arab Emirates, (e-mail: hang.dai@mbzuai.ac.ae); IIAI, Inception Institute of Artificial Intelligence, Abu Dhabi, Abu Dhabi, United Arab Emirates, (e-mail: taozhou.ai@gmail.com); Department of Information Technology and Electrical Engineering, ETH Zurich, Zurich, Zurich, Switzerland, CH-8092 (e-mail: shenjianbingcv@gmail.com); IIAI, Inception Institute of Artificial Intelligence, Abu Dhabi, Abu Dhabi, United Arab Emirates, (e-mail: ling.shao@inceptioniai.org)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Mesh Schelling points explain how humans focus on specific regions of a 3D object. They have a large number of important applications in computer graphics and provide valuable information for perceptual psychology studies. However, detecting mesh Schelling points is time-consuming and expensive since the existing techniques are mostly based on participant observation studies. To overcome these limitations, we propose to employ powerful deep learning techniques to detect mesh Schelling points in an automatic manner, free from participant observation studies. Specifically, we utilize the mesh convolution and pooling operations to extract informative features from mesh objects, and then predict the 3D heat map of Schelling points in an end-to-end manner. In addition, we propose a Deep Schelling Network (DS-Net) to automatically detect the Schelling points, including a multi-scale fusion component and a novel region-specific loss function to improve our network for a better regression of heat maps. To the best of our knowledge, DS-Net is the first deep neural network for detecting Schelling points from 3D meshes. We evaluate DS-Net on a mesh Schelling point dataset obtained from participant observation studies. The experimental results demonstrate that DS-Net is capable of detecting mesh Schelling points effectively and outperforms various state-of-the-art mesh saliency methods and deep learning models, both qualitatively and quantitatively.","1941-0506","","10.1109/TVCG.2022.3144143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684948","Deep Neural Network;Mesh Schelling Points;Geometric Deep Learning;Heat Map Regression","Three-dimensional displays;Deep learning;Heating systems;Feature extraction;Shape;Point cloud compression;Image edge detection","","","","","","","IEEE","19 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Automatic Y-axis Rescaling in Dynamic Visualizations","J. Fisher; R. Chang; E. Wu",Columbia University; Tufts University; Columbia University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","116","120","Animated and interactive data visualizations dynamically change the data rendered in a visualization (e.g., bar chart). As the data changes, the y-axis may need to be rescaled as the domain of the data changes. Each axis rescaling potentially improves the readability of the current chart, but may also disorient the user. In contrast to static visualizations, where there is considerable literature to help choose the appropriate y-axis scale, there is a lack of guidance about how and when rescaling should be used in dynamic visualizations. Existing visualization systems and libraries adapt a fixed global y-axis, or rescale every time the data changes. Yet, professional visualizations, such as in data journalism, do not adopt either strategy. They instead carefully and manually choose when to rescale based on the analysis task and data. To this end, we conduct a series of Mechanical Turk experiments to study the potential of dynamic axis rescaling and the factors that affect its effectiveness. We find that the appropriate rescaling policy is both task- and data-dependent, and we do not find one clear policy choice for all situations.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623319","Human-centered computing;Visualization;Empirical studies in visualization; Human-centered computing;Visualization theory, concepts and paradigms","Conferences;Data visualization;Journalism;Libraries;Task analysis;Bars","computer animation;data visualisation","dynamic visualizations;visualization systems;fixed global y-axis;data changes;professional visualizations;data journalism;dynamic axis rescaling;automatic y-axis rescaling;animated data visualizations;interactive data visualizations;bar chart;static visualizations;rescaling policy","","","","14","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Balance-Aware Grid Collage for Small Image Collections","Y. Song; F. Tang; W. Dong; F. Huang; T. -Y. Lee; C. Xu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Science, Beijing, Beijing, China, (e-mail: songyu2017@ia.ac.cn); School of Artifical Intelligence, Jilin University, 12510 Changchun, Jilin, China, (e-mail: tfan.108@gmail.com); National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Science, Beijing, Beijing, China, (e-mail: Weiming.Dong@ia.ac.cn); YouTu Lab, Tencent, Shanghai, Shanghai, China, (e-mail: garyhuang@tencent.com); Dept. of Computer Science and Information Engineering, National Cheng-Kung University, Tainan, Taiwan, Taiwan, 7001 (e-mail: tonylee@mail.ncku.edu.tw); National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, Beijing, China, (e-mail: csxu@nlpr.ia.ac.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Grid collages (GClg) of small image collections are popular and useful in many applications, such as personal album management, online photo posting, and graphic design. In this study, we focus on how visual effects influence individual preferences through various arrangements of multiple images under such scenarios. A novel balance-aware metric is proposed to bridge the gap between multi-image joint presentation and visual pleasure. The metric merges psychological achievements into the field of grid collage. To capture user preference, a bonus mechanism related to a user-specified special location in the grid and uniqueness values of the subimages is integrated into the metric. An end-to-end reinforcement learning mechanism empowers the model without tedious manual annotations. Experiments demonstrate that our metric can evaluate the GClg visual balance in line with human subjective perception, and the model can generate visually pleasant GClg results, which is comparable to manual designs.","1941-0506","","10.1109/TVCG.2021.3113031","National Natural Science Foundation of China(grant numbers:61832016,U20B2070); National Key RD Program of China(grant numbers:2020AAA0106200); Ministry of Science and Technology Taiwan(grant numbers:110-2221-E-006-135-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540348","Grid collage;visual balance;reinforcement learning","Layout;Measurement;Social networking (online);Reinforcement learning;Visual effects;Psychology;Task analysis","","","","","","","IEEE","16 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Bayesian Modelling of Alluvial Diagram Complexity","A. Arunkumar; S. Ginjpalli; C. Bryan",Arizona State University; Arizona State University; Arizona State University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","51","55","Alluvial diagrams are a popular technique for visualizing flow and relational data. However, successfully reading and interpreting the data shown in an alluvial diagram is likely influenced by factors such as data volume, complexity, and chart layout. To understand how alluvial diagram consumption is impacted by its visual features, we conduct two crowdsourced user studies with a set of alluvial diagrams of varying complexity, and examine (i) participant performance on analysis tasks, and (ii) the perceived complexity of the charts. Using the study results, we employ Bayesian modelling to predict participant classification of diagram complexity. We find that, while multiple visual features are important in contributing to alluvial diagram complexity, interestingly the importance of features seems to depend on the type of complexity being modeled, i.e. task complexity vs. perceived complexity.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623282","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623282","Human-centered computing;Visualization;Visualization techniques;Empirical studies in visualization","Visualization;Analytical models;Conferences;Computational modeling;Layout;Data visualization;Predictive models","Bayes methods;computational complexity;data visualisation;diagrams;flowcharting;relational databases","alluvial diagram complexity;task complexity;perceived complexity;Bayesian modelling;relational data;data volume;multiple visual features;chart layout","","","","34","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Bidirectional Hybrid LSTM Based Recurrent Neural Network for Multi-view Stereo","Z. Wei; Q. Zhu; C. Min; Y. Chen; G. Wang","Graphics &amp; Interaction Lab, Peking University, 12465 Beijing, Beijing, China, 100871; Dept. of EECS, Peking University, 12465 Beijing, Beijing, China; Dept. of EECS, Peking University, 12465 Beijing, Beijing, China; Dept. of EECS, Peking University, 12465 Beijing, Beijing, China; of Computer Science, Peking University, 12465 Beijing, Beijing, China, 100871","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Recently, deep learning based multi-view stereo (MVS) networks have demonstrated their excellent performance on various benchmarks. In this paper, we present an effective and efficient recurrent neural network (RNN) for accurate and complete dense point cloud reconstruction. Instead of regularizing the cost volume via conventional 3D CNN or unidirectional RNN like previous attempts, we adopt a bidirectional hybrid Long Short-Term Memory (LSTM) based structure for cost volume regularization. The proposed bidirectional recurrent regularization is able to perceive full-space context information comparable to 3D CNNs while saving runtime memory. For post-processing, we introduce a visibility based approach for depth map refinement to obtain more accurate dense point clouds. Extensive experiments on DTU, Tanks and Temples and ETH3D datasets demonstrate that our method outperforms previous state-of-the-art MVS methods and exhibits high memory efficiency at runtime.","1941-0506","","10.1109/TVCG.2022.3165860","National Natural Science Foundation of China NSFC(grant numbers:61632003); National Key Technology Research and Development Program of China(grant numbers:2017YFB1002601); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754239","3D reconstruction;deep learning;multi-view stereo;recurrent neural network;point clouds","Costs;Feature extraction;Three-dimensional displays;Runtime;Point cloud compression;Image reconstruction;Recurrent neural networks","","","","","","","IEEE","8 Apr 2022","","","IEEE","IEEE Early Access Articles"
"Binary-space-partitioned images for resolving image-based visibility","C. . -W. Fu; Tien-Tsin Wong; Wai-Shun Tong; Chi-Keung Tang; A. J. Hanson","Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","14 Jun 2004","2004","10","1","58","71","We propose a novel 2D representation for 3D visibility sorting, the binary-space-partitioned image (BSPI), to accelerate real-time image-based rendering. BSPI is an efficient 2D realization of a 3D BSP tree, which is commonly used in computer graphics for time-critical visibility sorting. Since the overall structure of a BSP tree is encoded in a BSPI, traversing a BSPI is comparable to traversing the corresponding BSP tree. BSPI performs visibility sorting efficiently and accurately in the 2D image space by warping the reference image triangle-by-triangle instead of pixel-by-pixel. Multiple BSPIs can be combined to solve ""disocclusion,"" when an occluded portion of the scene becomes visible at a novel viewpoint. Our method is highly automatic, including a tensor voting preprocessing step that generates candidate image partition lines for BSPIs, filters the noisy input data by rejecting outliers, and interpolates missing information. Our system has been applied to a variety of real data, including stereo, motion, and range images.","1941-0506","","10.1109/TVCG.2004.1260758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260758","","Image resolution;Sorting;Tree graphs;Acceleration;Rendering (computer graphics);Computer graphics;Time factors;Pixel;Layout;Tensile stress","rendering (computer graphics);computational geometry;image segmentation;image representation","binary-space-partitioned image;image-based visibility;visibility sorting;image-based rendering;disocclusion;image segmentation","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Online Systems;Pattern Recognition, Automated;Signal Processing, Computer-Assisted;User-Computer Interface;Vision","","","66","IEEE","14 Jun 2004","","","IEEE","IEEE Journals"
"C.DOT - Convolutional Deep Object Tracker for Augmented Reality Based Purely on Synthetic Data","K. K. Thiel; F. Naumann; E. Jundt; S. Guennemann; G. J. Klinker","Group IT, Volkswagen AG, 15053 Wolfsburg, Niedersachsen, Germany, 38436 (e-mail: kevin.thiel@volkswagen.de); Group Innovation, Volkswagen AG, 15053 Wolfsburg, Niedersachsen, Germany, (e-mail: florian.naumann@volkswagen.de); Technical Development VWN, Volkswagen, Wolfsburg, Niedersachsen, Germany, (e-mail: eduard.jundt@volkswagen.de); Fachbereich fr Informatik, Technische Universitt Mnchen, Garching bei Mnchen, Bavaria, Germany, (e-mail: guennemann@in.tum.de); Fachbereich fr Informatik, Technische Universitt Mnchen, Garching bei Mnchen, Bavaria, Germany, D-85748 (e-mail: klinker@in.tum.de)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Augmented reality applications use object tracking to estimate the pose of a camera and to superimpose virtual content onto the observed object. Today, a number of tracking systems are available, ready to be used in industrial applications. However, such systems are hard to handle for a service maintenance engineer, due to obscure configuration procedures. In this paper, we investigate options towards replacing the manual configuration process with a machine learning approach based on automatically synthesized data. We present an automated process of creating object tracker facilities exclusively from synthetic data. The data is highly enhanced to train a convolutional neural network, while still being able to receive reliable and robust results during real world applications only from simple RGB cameras. Comparison against related work using the LINEMOD dataset showed that we are able to outperform similar approaches. For our intended industrial applications with high accuracy demands, its performance is still lower than common object tracking methods with manual configuration. Yet, it can greatly support those as an add-on during initialization, due to its higher reliability.","1941-0506","","10.1109/TVCG.2021.3089096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454303","object tracking;deep learning;industry 40;neural network;synthetic data;augmented reality;computer vision","Cameras;Target tracking;Optical imaging;Training;Neural networks;Tuning;Task analysis","","","","","","","CCBY","14 Jun 2021","","","IEEE","IEEE Early Access Articles"
"CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs","D. Cashman; S. Xu; S. Das; F. Heimerl; C. Liu; S. R. Humayoun; M. Gleicher; A. Endert; R. Chang","Tufts University; Georgia Tech.; Georgia Tech.; University of Wisconsin, Madison; Tufts University; San Francisco State University; University of Wisconsin, Madison; Georgia Tech.; Tufts University","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1731","1741","Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.","1941-0506","","10.1109/TVCG.2020.3030443","National Science Foundation(grant numbers:IIS-1452977,OAC-1940175,OAC-1939945,DGE-1855886,1841349); Defense Advanced Research Projects Agency(grant numbers:FA8750-17-2-0107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222249","Visual Analytics;Information Foraging;Data Augmentation","Task analysis;Visual analytics;Machine learning;Data models;Data visualization;Google;Training","data analysis;data visualisation;query processing","data foraging;complex data combinations;external data;human knowledge;data exploration;data curation;data analysis tasks;foraging loop;data construction;data attributes;analytics process;knowledge graph;exploratory columnar data augmentation;visual analytics system;CAVA","","","","76","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"CellProfiler Analyst Web (CPAW) - Exploration, analysis, and classification of biological images on the web","B. Baidak; Y. Hussain; E. Kelminson; T. R. Jones; L. Franke; D. Haehn",University of Massachusetts Boston; University of Massachusetts Boston; University of Massachusetts Boston; The Broad Institute of MIT and Harvard; University of Massachusetts Boston; University of Massachusetts Boston,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","131","135","CellProfiler Analyst (CPA) has enabled the scientific research community to explore image-based data and classify complex biological phenotypes through an interactive user interface since its release in 2008. This paper describes CellProfiler Analyst Web (CPAW), a newly redesigned and web-based version of the software, allowing for greater accessibility, quicker setup, and facilitating a simple workflow for users. Installation and managing new versions has been challenging and time-consuming, historically. CPAW is an alternative that ensures installation and future updates are not a hassle to the user. CPAW ports the core iteration loop of CPA to a pure server-less browser environment using modern web-development technologies, allowing computationally heavy activities, like machine learning, to occur without freezing the user interface (UI). With a setup as simple as navigating to a website, CPAW presents a clean UI to the user to refine their classifier and explore pheno-typic data easily. We evaluated both the old and the new version of the software in an extensive domain expert study. We found that users could complete the essential classification tasks in CPAW and CPA 3.0 with the same efficiency. Additionally, users completed the tasks 20 percent faster using CPAW compared to CPA 3.0. The code of CellProfiler Analyst Web is open-source and available at https://mpsych.github.io/CellProfilerAnalystWeb/.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623317","Biological Images;Visualization;Machine Learning Classification;Evaluation Methods","Ports (computers);Codes;Navigation;Conferences;Machine learning;User interfaces;Browsers","biology computing;data analysis;data mining;data visualisation;image classification;Internet;learning (artificial intelligence)","biological images;scientific research community;image-based data;biological phenotypes;interactive user interface;CPAW ports;web-development technologies;CellProfiler analyst web;efficiency 20.0 percent","","","","18","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"ClaimViz: Visual Analytics for Identifying and Verifying Factual Claims","M. M. Uddin Rony; E. Hoque; N. Hassan",University of Maryland; York University; University of Maryland,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","246","250","Verifying a factual claim made by public figures, aka fact-checking, is a common task of the journalists in the newsrooms. One critical challenge that fact-checkers face is-they have to swift through a large amount of text to find claims that are check-worthy. While there exist some computational methods for automating the fact-checking process, little research has been done on how a system should combine such techniques with visualizations to assist fact-checkers. ClaimViz is a visual analytic system that integrates natural language processing and machine learning methods with interactive visualizations to facilitate the fact-checking process. The design of ClaimViz is based on analyzing the requirements of real fact-checkers and our case studies demonstrate how the system can help users to effectively spot and verify claims.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331280","Human-centered computing;Visualization;Visualization design and evaluation methods","Visual analytics;Design methodology;Conferences;Machine learning;Natural language processing;Task analysis;Faces","data analysis;data visualisation;interactive systems;journalism;learning (artificial intelligence);natural language processing","public figures;fact-checking process;ClaimViz;visual analytic system;natural language processing;interactive visualizations;factual claim identification;factual claim verification;machine learning;journalists","","","","40","","1 Feb 2021","","","IEEE","IEEE Conferences"
"CloudFindr: A Deep Learning Cloud Artifact Masker for Satellite DEM Data","K. Borkiewicz; V. Shah; J. P. Naiman; C. Shen; S. Levy; J. Carpenter",University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","1","5","Artifact removal is an integral component of cinematic scientific visualization, and is especially challenging with big datasets in which artifacts are difficult to define. In this paper, we describe a method for creating cloud artifact masks which can be used to remove artifacts from satellite imagery using a combination of traditional image processing together with deep learning based on U-Net. Compared to previous methods, our approach does not require multi-channel spectral imagery but performs successfully on single-channel Digital Elevation Models (DEMs). DEMs are a representation of the topography of the Earth and have a variety applications including planetary science, geology, flood modeling, and city planning.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623327","National Science Foundation; National Geospatial-Intelligence Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623327","cinematic scientific visualization;science communication;public outreach;broad impact;data visualization;data processing;machine learning;deep learning;u net;image processing;data preparation","Deep learning;Earth;Satellites;Image processing;Geology;Urban planning;Data visualization","clouds;data visualisation;digital elevation models;floods;geophysical image processing;image processing;learning (artificial intelligence);remote sensing;terrain mapping;topography (Earth)","CloudFindr;cloud artifact masker;satellite DEM data;artifact removal;integral component;cinematic scientific visualization;big datasets;cloud artifact masks;satellite imagery;traditional image processing;deep learning;multichannel spectral imagery;single-channel Digital Elevation Models;DEMs","","","","23","","30 Nov 2021","","","IEEE","IEEE Conferences"
"Co-Visualization of Air Temperature and Urban Data for Visual Exploration","J. Gautier; M. Brédif; S. Christophe","Univ Gustave Eiffel, ENSG, IGN,LASTIG,Saint-Mande,France,F-94160; Univ Gustave Eiffel, ENSG, IGN,LASTIG,Saint-Mande,France,F-94160; Univ Gustave Eiffel, ENSG, IGN,LASTIG,Saint-Mande,France,F-94160","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","71","75","Urban climate data remain complex to analyze regarding their spatial distribution. The co-visualization of simulated air temperature into urban models could help experts to analyze horizontal and vertical spatial distributions. We design a co-visualization framework enabling simulated air temperature data exploration, based on the graphic representation of three types of geometric proxies, and their co-visualization with a 3D urban model with various possible rendering styles. Through this framework, we aim at allowing meteorological researchers to visually analyze and interpret the relationships between simulated air temperature data and urban morphology.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331273","Human-centered computing;Visualization;Geographic visualization;Visualization design and evaluation methods;Visualization techniques","Temperature distribution;Visualization;Graphical models;Three-dimensional displays;Urban planning;Data visualization;Distribution functions","atmospheric temperature;data visualisation;geographic information systems;geophysics computing","visual exploration;urban climate data;spatial distribution;horizontal distributions;vertical spatial distributions;co-visualization framework;simulated air temperature data exploration;3D urban model;urban morphology","","","","29","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Cognitive Path Planning with Spatial Memory Distortion","R. K. Dubey; S. S. Sohn; T. Thrash; C. Holscher; M. Kapadia; A. Borrmann","Computational Modeling and Simulation, Technical University of Munich, 9184 Munchen, Baveria, Germany; Computer Science, Rutgers University, 242612 New Brunswick, New Jersey, United States; DGESS, ETH Zurich, 27219 Zurich, Zrich, Switzerland; DGESS, ETH Zurich, 27219 Zurich, Zrich, Switzerland; Computer Science, Rutgers University, Piscataway, New Jersey, United States, 08854; Computation Modeling and Simulation, Technical University of Munich, Munich, Baveria, Germany","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Human path-planning operates differently from deterministic AI-based path-planning algorithms due to the decay and distortion in a human's spatial memory and the lack of complete scene knowledge. Here, we present a cognitive model of path-planning that simulates human-like learning of unfamiliar environments, supports systematic degradation in spatial memory, and distorts spatial recall during path-planning. We propose a Dynamic Hierarchical Cognitive Graph (DHCG) representation to encode the environment structure by incorporating two critical spatial memory biases during exploration: categorical adjustment and \sequence order effect. We then extend the ‘`Fine-To-Coarse’' (FTC), the most prevalent path-planning heuristic, to incorporate spatial uncertainty during recall through the DHCG. We conducted a lab-based Virtual Reality (VR) experiment to validate the proposed cognitive path-planning model and made three observations: (1) a statistically significant impact of sequence order effect on participants' route-choices, (2) approximately three hierarchical levels in the DHCG according to participants' recall data, and (3) similar trajectories and significantly similar wayfinding performances between participants and simulated cognitive agents on identical path-planning tasks. Furthermore, we performed two detailed simulation experiments with different FTC variants on a Manhattan-style grid. Experimental results demonstrate that the proposed cognitive path-planning model successfully produces human-like paths and can capture human wayfinding's complex and dynamic nature, which traditional AI-based path-planning algorithms cannot capture.","1941-0506","","10.1109/TVCG.2022.3163794","NSF Awards(grant numbers:IIS-1703883,IIS-1955365,IIS-1955404); Singapore-ETH Centre(grant numbers:FI 370074016); Leonhard Obermeyer Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745822","Cognitive Path-Planning;Human Wayfinding;Fine-To-Course;Spatial Memory;Agglomerative Hierarchical Clustering","Solid modeling;Computational modeling;Navigation;Distortion;Games;Data models;Task analysis","","","","","","","CCBY","31 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Compass: Towards Better Causal Analysis of Urban Time Series","Z. Deng; D. Weng; X. Xie; J. Bao; Y. Zheng; M. Xu; W. Chen; Y. Wu","State Key Lab of CAD & CG, Zhejiang University, Hangzhou and Zhejiang Lab, Hangzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou and Zhejiang Lab, Hangzhou, China; Department of Sport Science, Zhejiang University, Hangzhou, China; JD Intelligent Cities Research, JD Tech, Beijing, China; JD Intelligent Cities Research, JD Tech, Beijing, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou and Zhejiang Lab, Hangzhou, China; State Key Lab of CAD & CG, Zhejiang University, Hangzhou and Zhejiang Lab, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","1051","1061","The spatial time series generated by city sensors allow us to observe urban phenomena like environmental pollution and traffic congestion at an unprecedented scale. However, recovering causal relations from these observations to explain the sources of urban phenomena remains a challenging task because these causal relations tend to be time-varying and demand proper time series partitioning for effective analyses. The prior approaches extract one causal graph given long-time observations, which cannot be directly applied to capturing, interpreting, and validating dynamic urban causality. This paper presents Compass, a novel visual analytics approach for in-depth analyses of the dynamic causality in urban time series. To develop Compass, we identify and address three challenges: detecting urban causality, interpreting dynamic causal relations, and unveiling suspicious causal relations. First, multiple causal graphs over time among urban time series are obtained with a causal detection framework extended from the Granger causality test. Then, a dynamic causal graph visualization is designed to reveal the time-varying causal relations across these causal graphs and facilitate the exploration of the graphs along the time. Finally, a tailored multi-dimensional visualization is developed to support the identification of spurious causal relations, thereby improving the reliability of causal analyses. The effectiveness of Compass is evaluated with two case studies conducted on the real-world urban datasets, including the air pollution and traffic speed datasets, and positive feedback was received from domain experts.","1941-0506","","10.1109/TVCG.2021.3114875","NSFC(grant numbers:62072400); Zhejiang Provincial Natural Science Foundation(grant numbers:LR18F020001); Collaborative Innovation Center of Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557222","Visual causal analysis;urban time series;causal graph analysis","Time series analysis;Visual analytics;Compass;Air pollution;Correlation;Urban planning;Indexes","air pollution;causality;data analysis;data visualisation;environmental science computing;graph theory;time series;traffic information systems","causal analyses;compass;real-world urban datasets;causal analysis;urban time series;spatial time series;urban phenomena;time series partitioning;long-time observations;dynamic urban causality;dynamic causality;interpreting dynamic causal relations;multiple causal graphs;causal detection framework;Granger causality test;dynamic causal graph visualization;time-varying causal relations;spurious causal relations;suspicious causal relations","","","","89","IEEE","1 Oct 2021","","","IEEE","IEEE Journals"
"ConVIScope: Visual Analytics for Exploring Patient Conversations","R. Li; E. Hoque; G. Carenini; R. Lester; R. Chau","University of British,Department of Computer Science,Columbia; York University,School of Information Technology; University of British,Department of Computer Science,Columbia; University of British,Department of Medicine,Columbia; University of British,Department of Medicine,Columbia","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","151","155","The proliferation of text messaging for mobile health is generating a large amount of patient-doctor conversations that can be extremely valuable to health care professionals. We present ConVIScope, a visual text analytic system that tightly integrates interactive visualization with natural language processing in analyzing patient-doctor conversations. ConVIScope was developed in collaboration with healthcare professionals following a user-centered iterative design. Case studies with six domain experts suggest the potential utility of ConVIScope and reveal lessons for further developments.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623269","Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623269","Human-centered computing;Visualization;Visualization design and evaluation methods","Visual analytics;Design methodology;Conferences;Collaboration;Medical services;Natural language processing;Electronic messaging","data visualisation;health care;interactive systems;medical information systems;mobile computing;natural language interfaces;natural language processing;text analysis","visual text analytic system;interactive visualization;natural language processing;patient-doctor conversations;ConVIScope;healthcare professionals;mobile health;text messaging","","","","44","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Conceptual Metaphor and Graphical Convention Influence the Interpretation of Line Graphs","G. Woodin; B. Winter; L. Padilla","Department of English Language and Linguistics, University of Birmingham, Birmingham, U.K.; Department of English Language and Linguistics, University of Birmingham, Birmingham, U.K.; Spatial Perception, Applied Cognition & Education Lab, University of California Merced, Merced, CA, USA","IEEE Transactions on Visualization and Computer Graphics","4 Jan 2022","2022","28","2","1209","1221","Many metaphors in language reflect conceptual metaphors that structure thought. In line with metaphorical expressions such as ‘high number’, experiments show that people associate larger numbers with upward space. Consistent with this metaphor, high numbers are conventionally depicted in high positions on the <inline-formula><tex-math notation=""LaTeX"">$y$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href=""woodin-ieq1-3088343.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-axis of line graphs. People also associate good and bad (emotional valence) with upward and downward locations, in line with metaphorical expressions such as ‘uplifting’ and ‘down in the dumps’. Graphs depicting good quantities (e.g., vacation days) are consistent with graphical convention and the valence metaphor, because ‘more’ of the good quantity is represented by higher <inline-formula><tex-math notation=""LaTeX"">$y$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href=""woodin-ieq2-3088343.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-axis positions. In contrast, graphs depicting bad quantities (e.g., murders) are consistent with graphical convention, but not the valence metaphor, because more of the bad quantity is represented by higher (rather than lower) <inline-formula><tex-math notation=""LaTeX"">$y$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href=""woodin-ieq3-3088343.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-axis positions. We conducted two experiments (<italic>N</italic> = 300 per experiment) where participants answered questions about line graphs depicting good and bad quantities. For some graphs, we inverted the conventional axis ordering of numbers. Line graphs that aligned (versus misaligned) with valence metaphors (up = good) were easier to interpret, but this beneficial effect did not outweigh the adverse effect of inverting the axis numbering. Line graphs depicting good (versus bad) quantities were easier to interpret, as were graphs that depicted quantity using the <inline-formula><tex-math notation=""LaTeX"">$x$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi>x</mml:mi></mml:math><inline-graphic xlink:href=""woodin-ieq4-3088343.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-axis (versus <inline-formula><tex-math notation=""LaTeX"">$y$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href=""woodin-ieq5-3088343.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-axis). Our results suggest that conceptual metaphors matter for the interpretation of line graphs. However, designers of line graphs are warned against subverting graphical convention to align with conceptual metaphors.","1941-0506","","10.1109/TVCG.2021.3088343","Economic and Social Research Council(grant numbers:ES/P000711/1); UKRI Future Leaders Fellowship(grant numbers:MR/T040505/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451590","Conceptual metaphor theory;more is up;mental number line;cognition;linguistics;emotional valence;line graph;axis reversal;handedness;empirical evaluation","Data visualization;Linguistics;Cognitive science;Visualization;Psychology;Market research;Random sequences","graph theory","conceptual metaphor;graphical convention influence;line graphs;metaphorical expressions;valence metaphor;yy-axis positions;emotional valence","","","","80","IEEE","10 Jun 2021","","","IEEE","IEEE Journals"
"Conceptualizing Visual Analytic Interventions for Content Moderation","S. Vaidya; J. Cai; S. Basu; A. Naderi; D. Y. Wohn; A. Dasgupta",NJIT; NJIT; NJIT; NJIT; NJIT; NJIT,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","191","195","Modern social media platforms like Twitch, YouTube, etc., embody an open space for content creation and consumption. However, an unintended consequence of such content democratization is the proliferation of toxicity and abuse that content creators get subjected to. Commercial and volunteer content moderators play an indispensable role in identifying bad actors and minimizing the scale and degree of harmful content. Moderation tasks are often laborious, complex, and even if semi-automated, they involve high-consequence human decisions that affect the safety and popular perception of the platforms. In this paper, through an interdisciplinary collaboration among researchers from social science, human-computer interaction, and visualization, we present a systematic understanding of how visual analytics can help in human-in-the-loop content moderation. We contribute a characterization of the data-driven problems and needs for proactive moderation and present a mapping between the needs and visual analytic tasks through a task abstraction framework. We discuss how the task abstraction framework can be used for transparent moderation, design interventions for moderators’ well-being, and ultimately, for creating futuristic human-machine interfaces for data-driven content moderation.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623288","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623288","Content Moderation;Social Media;Task Abstractions;Real-time Decision-Making","Human computer interaction;Toxicology;Systematics;Social networking (online);Visual analytics;Social sciences;Decision making","data analysis;data visualisation;social networking (online)","visual analytic interventions;modern social media platforms;open space;content creation;content democratization;content creators;commercial volunteer content moderators;popular perception;social science;human-computer interaction;visual analytics;human-in-the-loop content moderation;proactive moderation;visual analytic tasks;task abstraction framework;transparent moderation;design interventions;human-machine interfaces;data-driven content moderation;social media platforms;Twitch;YouTube","","","","43","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Consistent Two-Flow Network for Tele-Registration of Point Clouds","Z. Yan; Z. Yi; R. Hu; N. J. Mitra; D. Cohen-Or; H. Huang","Visual Computing Research Center, Shenzhen University, 47890 Shenzhen, Guangdong, China, (e-mail: mr.salingo@gmail.com); Visual Computing Research Center, Shenzhen University, 47890 Shenzhen, Guangdong, China, (e-mail: yizimu@gmail.com); College of Computer Science & Software Engineering, Shenzhen University, 47890 Shenzhen, Guangdong, China, 518060 (e-mail: ruizhen.hu@gmail.com); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, and Adobe Research (e-mail: niloym@gmail.com; nimitra@adobe.com); Computer Science, Tel Aviv University, 26745 Tel Aviv, IL, Israel, (e-mail: cohenor@gmail.com); Visual Computing Research Center, Shenzhen University, 47890 Shenzhen, Guangdong, China, 518060 (e-mail: hhzhiyan@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Rigid registration of partial observations is a fundamental problem in various applied fields. In computer graphics, special attention has been given to the registration between two partial point clouds generated by scanning devices. State-of-the-art registration techniques still struggle when the overlap region between the two point clouds is small, and completely fail if there is no overlap between the scan pairs. In this paper, we present a learning-based technique that alleviates this problem, and allows registration between point clouds, presented in arbitrary poses, and having little or even no overlap, a setting that has been referred to as tele-registration. Our technique is based on a novel neural network design that learns a prior of a class of shapes and can complete a partial shape. The key idea is combining the registration and completion tasks in a way that reinforces each other. In particular, we simultaneously train the registration network and completion network using two coupled flows, one that register-and-complete, and one that complete-and-register, and encourage the two flows to produce a consistent result. We show that, compared with each separate flow, this two-flow training leads to robust and reliable tele-registration, and hence to a better point cloud prediction that completes the registered scans. It is also worth mentioning that each of the components in our neural network outperforms state-of-the-art methods in both completion and registration. We further analyze our network with several ablation studies and demonstrate its performance on a large number of partial point clouds.","1941-0506","","10.1109/TVCG.2021.3086113","National Natural Science Foundation of China(grant numbers:U2001206, 61872250); Royal Society(grant numbers:NAF\R1\180099); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9445585","","Shape;Training;Automobiles;Three-dimensional displays;Computational modeling;Timing;Gold","","","","","","","IEEE","2 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Context Matters: A Theory of Semantic Discriminability for Perceptual Encoding Systems","K. Mukherjee; B. Yin; B. E. Sherman; L. Lessard; K. B. Schloss","Psychology and Wisconsin Institute for Discovery University of Wisconsin_Madison, United States; Cognitive Science University of California, Berkeley; Neurobiology and Wisconsin Institute for Discovery University of Wisconsin-Madison, United States; Mechanical and Industrial Engineering Northeastern University, United States; Psychology and Wisconsin Institute for Discovery University of Wisconsin-Madison, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","697","706","People's associations between colors and concepts influence their ability to interpret the meanings of colors in information visualizations. Previous work has suggested such effects are limited to concepts that have strong, specific associations with colors. However, although a concept may not be strongly associated with any colors, its mapping can be disambiguated in the context of other concepts in an encoding system. We articulate this view in semantic discriminability theory, a general framework for understanding conditions determining when people can infer meaning from perceptual features. Semantic discriminability is the degree to which observers can infer a unique mapping between visual features and concepts. Semantic discriminability theory posits that the capacity for semantic discriminability for a set of concepts is constrained by the difference between the feature-concept association distributions across the concepts in the set. We define formal properties of this theory and test its implications in two experiments. The results show that the capacity to produce semantically discriminable colors for sets of concepts was indeed constrained by the statistical distance between color-concept association distributions (Experiment 1). Moreover, people could interpret meanings of colors in bar graphs insofar as the colors were semantically discriminable, even for concepts previously considered “non-colorable” (Experiment 2). The results suggest that colors are more robust for visual communication than previously thought.","1941-0506","","10.1109/TVCG.2021.3114780","Rob Nowak, Melissa Schoenlein, Kevin Lande, Tim Rogers, Chris Thorstenson, Anna Bartel, and Maureen Stone for helpful discussions(grant numbers:BCS-1945303); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552216","Visual Reasoning;Information Visualization;Visual Communication;Visual Encoding;Color Cognition","Color;Semantics;Visualization;Image color analysis;Encoding;Plastics;Visual communication","data visualisation;feature extraction;graph theory;image colour analysis;statistical analysis;statistical testing;visual perception","perceptual encoding systems;specific associations;encoding system;perceptual features;semantic discriminability theory posits;feature-concept association distributions;semantically discriminable colors;color-concept association distributions;bar graphs;visual communication","","","","41","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Context-Consistent Generation of Indoor Virtual Environments based on Geometry Constraints","Y. He; Y. Liu; Y. Jin; S. -H. Zhang; Y. -K. Lai; S. -M. Hu","Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, 100084 (e-mail: hooyeeevan2511@gmail.com); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, 100084 (e-mail: liuyingt20@mails.tsinghua.edu.cn); School of computer science and Engineering, Tianjin University of Technology, Tianjin, Tianjin, China, (e-mail: 1127703753@qq.com); Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, (e-mail: shz@tsinghua.edu.cn); Computer Science and Informatics, Cardiff University, Cardiff, Wales, United Kingdom of Great Britain and Northern Ireland, CF24 3AA (e-mail: Yukun.Lai@cs.cardiff.ac.uk); Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, 100084 (e-mail: shimin@tsinghua.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","In this paper, we propose a system that can automatically generate immersive and interactive virtual reality (VR) scenes by taking real-world geometric constraints into account. Our system can not only help users avoid real-world obstacles in virtual reality experiences, but also provide context-consistent contents to preserve their sense of presence. To do so, our system first identifies the positions and bounding boxes of scene objects as well as a set of interactive planes from 3D scans. Then context-compatible virtual objects that have similar geometric properties to the real ones can be automatically selected and placed into the virtual scene, based on learned object association relations and layout patterns from large amounts of indoor scene configurations. We regard virtual object replacement as a combinatorial optimization problem, considering both geometric and contextual consistency constraints. Quantitative and qualitative results show that our system can generate plausible interactive virtual scenes that highly resemble real environments, and have the ability to keep the sense of presence for users in their VR experiences.","1941-0506","","10.1109/TVCG.2021.3111729","National Key Technology RD Program(grant numbers:2017YFB1002604); National Natural Science Foundation of China(grant numbers:61521002,61772298); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535226","Virtual Reality;Obstacle Awareness;User Interaction;Scene Generation;Geometric Constraints;Contextual Relation;Layout Patterns","Solid modeling;Sensors;Layout;Computational modeling;Virtual environments;Valves;Upper bound","","","","","","","IEEE","10 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Contrastive Identification of Covariate Shift in Image Data","M. L. Olson; T. -V. Nguyen; G. Dixit; N. Ratzlaff; W. -K. Wong; M. Kahng",Oregon State University; Oregon State University; Oregon State University; Oregon State University; Oregon State University; Oregon State University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","36","40","Identifying covariate shift is crucial for making machine learning systems robust in the real world and for detecting training data biases that are not reflected in test data. However, detecting covariate shift is challenging, especially when the data consists of high-dimensional images, and when multiple types of localized covariate shift affect different subspaces of the data. Although automated techniques can be used to detect the existence of covariate shift, our goal is to help human users characterize the extent of covariate shift in large image datasets with interfaces that seamlessly integrate information obtained from the detection algorithms. In this paper, we design and evaluate a new visual interface that facilitates the comparison of the local distributions of training and test data. We conduct a quantitative user study on multi-attribute facial data to compare two different learned low-dimensional latent representations (pretrained ImageNet CNN vs. density ratio) and two user analytic workflows (nearest-neighbor vs. cluster-to-cluster). Our results indicate that the latent representation of our density ratio model, combined with a nearest-neighbor comparison, is the most effective at helping humans identify covariate shift.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623289","","Training;Visualization;Conferences;Training data;Data visualization;Machine learning;Detection algorithms","face recognition;image representation;learning (artificial intelligence);nearest neighbour methods","multiattribute facial data;image data;training data biases;localized covariate shift;contrastive identification;low-dimensional latent representation;machine learning;nearest-neighbor comparison","","","","21","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"DIEL: Interactive Visualization Beyond the Here and Now","Y. Wu; R. Chang; J. M. Hellerstein; A. Satyanarayan; E. Wu","University of California, Berkeley, United States; Tufts University, United States; University of California, Berkeley, United States; MIT CSAIL, United States; Columbia University, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","737","746","Interactive visualization design and research have primarily focused on local data and synchronous events. However, for more complex use cases-e.g., remote database access and streaming data sources-developers must grapple with distributed data and asynchronous events. Currently, constructing these use cases is difficult and time-consuming; developers are forced to operationally program low-level details like asynchronous database querying and reactive event handling. This approach is in stark contrast to modern methods for browser-based interactive visualization, which feature high-level declarative specifications. In response, we present DIEL, a declarative framework that supports asynchronous events over distributed data. As in many declarative languages, DIEL developers specify only what data they want, rather than procedural steps for how to assemble it. Uniquely, DIEL models asynchronous events (e.g., user interactions, server responses) as streams of data that are captured in event logs. To specify the state of a visualization at any time, developers write declarative queries over the data and event logs; DIEL compiles and optimizes a corresponding dataflow graph, and automatically generates necessary low-level distributed systems details. We demonstrate DIEL'S performance and expressivity through example interactive visualizations that make diverse use of remote data and asynchronous events. We further evaluate DIEL'S usability using the Cognitive Dimensions of Notations framework, revealing wins such as ease of change, and compromises such as premature commitments.","1941-0506","","10.1109/TVCG.2021.3114796","NSF(grant numbers:1564049,1564351,1942659,1845638,2106197,1452977,1939945,1940175,CCF-1730628); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552893","Interactive Visualization Toolkit/Library;Scalability;Asynchrony","Data visualization;Distributed databases;Databases;Programming;Libraries;Visual databases;Servers","data flow graphs;data visualisation;formal specification;interactive systems;program compilers;query processing;user interfaces","event logs;declarative queries;low-level distributed systems details;remote data;browser-based interactive visualization;high-level declarative specifications;declarative framework;declarative languages;DIEL usability;dataflow graph","","","","64","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific Visualization","C. Wang; J. Han","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana, United States; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana, United States","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Since 2016, we have witnessed the tremendous growth of artificial intelligence+visualization (AI+VIS) research. However, existing survey papers on AI+VIS focus on visual analytics and information visualization, not scientific visualization (SciVis). In this paper, we survey related deep learning (DL) works in SciVis, specifically in the direction of DL4SciVis: designing DL solutions for solving SciVis problems. To stay focused, we primarily consider works that handle scalar and vector field data but exclude mesh data. We classify and discuss these works along six dimensions: domain setting, research task, learning type, network architecture, loss function, and evaluation metric. The paper concludes with a discussion of the remaining gaps to fill along the discussed dimensions and the grand challenges we need to tackle as a community. This state-of-the-art survey guides SciVis researchers in gaining an overview of this emerging topic and points out future directions to grow this research.","1941-0506","","10.1109/TVCG.2022.3167896","Division of Undergraduate Education(grant numbers:1833129); Office of Cyberinfrastructure(grant numbers:2104158); Division of Information and Intelligent Systems(grant numbers:1455886,1955395,2101696); Division of Computer and Network Systems(grant numbers:1629914); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760126","Scientific visualization;deep learning;survey","Task analysis;Generative adversarial networks;Neural networks;Measurement;Deep learning;Convolutional neural networks;Three-dimensional displays","","","","","","","IEEE","19 Apr 2022","","","IEEE","IEEE Early Access Articles"
"DRUID<inf>JS</inf> — A JavaScript Library for Dimensionality Reduction","R. Cutura; C. Kralj; M. Sedlmair","TU Wien, University of Stuttgart; University of Vienna; University of Stuttgart","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","111","115","Dimensionality reduction (DR) is a widely used technique for visualization. Nowadays, many of these visualizations are developed for the web, most commonly using JavaScript as the underlying programming language. So far, only few DR methods have a JavaScript implementation though, necessitating developers to write wrappers around implementations in other languages. In addition, those DR methods that exist in JavaScript libraries, such as PCA, t-SNE, and UMAP, do not offer consistent programming interfaces, hampering the quick integration of different methods. Toward a coherent and comprehensive DR programming framework, we developed an open source JavaScript library named DRUID<sub>JS</sub>. Our library contains implementations of ten different DR algorithms, as well as the required linear algebra techniques, tools, and utilities.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331283","Software and its engineering;Software notations and tools;Software libraries and repositories;Human-centered computing;Visualization;Visualization systems and tools;Visualization toolkits","Dimensionality reduction;Linear algebra;Programming;Tools;Libraries;Software;Principal component analysis","data visualisation;Java;linear algebra;public domain software;software libraries","open source JavaScript library;JS;linear algebra;dimensionality reduction;underlying programming language;JavaScript implementation;programming interfaces;DR programming framework;visualization;JavaScript libraries;DRUIDJS","","","","41","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Data Visualization for Transgender Voice Training","A. A. Ahmed; M. A. Borkin",Northeastern University; Northeastern University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","221","225","Social and political factors structure how data are collected, analyzed, and visually presented. Visualization researchers are increasingly discussing these issues, and calling for feminist approaches that allow not only for the interrogation of unspoken assumptions and power imbalances in how visualizations are designed and deployed, but also for the creation of new systems by and for marginalized groups. This paper describes the motivation, ideation, and prototyping of a novel visualization tool to support voice training for transgender people. We centered our design around user needs and lived experiences, in order to support self-determination of gender expression. In so doing, we make novel inroads into how to visualize speech data, and open possibilities for future work in the design of visualizations that prioritize user agency within social and political contexts.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00051","National Science Foundation; National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331270","Human-centered computing—Visualization—Visualization systems and tools;Social and professional topics—Gender;Applied computing—Sound and music computing","Training;Affordances;Visual analytics;Veins;Data visualization;Tools;Gender issues","computer based training;data visualisation;gender issues;social aspects of automation;speech processing","marginalized groups;visualization tool;transgender people;data visualization;transgender voice training;political factors;feminist approach;power imbalance;social factors;gender expression;speech data visualization;user agency;political context;social context","","","","28","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Data-driven Colormap Adjustment for Exploring Spatial Variations in Scalar Fields","Q. Zeng; Y. Zhao; Y. Wang; J. Zhang; Y. Cao; C. Tu; I. Viola; Y. Wang","School of Computer Science and Technology, Shandong University, 12589 Qingdao, Shandong, China, (e-mail: qiong.zn@gmail.com); computer science and technology, Shandong University, 12589 jinan, shandong province, China, 250100 (e-mail: yongwei_zhao@163.com); school of computer science and technology, Shandong University, 12589 Jinan, Shandong, China, 250100 (e-mail: yinqiaowong@gmail.com); SuperComputing Center, Computer Network Information, Chinese Academy of Science, Beijing, Beijing, China, (e-mail: zhangjian@sccas.cn); High performance computing center, Institute of Applied Physics and Computational Mathematics, 71037 Beijing, Beijing, China, (e-mail: caoywill@hotmail.com); School of Computer Science and Technology, Shandong University, 12589 Jinan, Shandong, China, (e-mail: chtu@sdu.edu.cn); Visual Computing Center, King Abdullah University of Science and Technology, 127355 Thuwal, Makkah, Saudi Arabia, 23955-6900 (e-mail: ivan.viola@kaust.edu.sa); Computer Science and Technology, Shandong University, 12589 Jinan, Shandong, China, 250100 (e-mail: cloudseawang@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Colormapping is an effective and popular visualization technique for analyzing patterns in scalar fields. Scientists usually adjust a default colormap to show hidden patterns by shifting the colors in a trial-and-error process. To improve efficiency, efforts have been made to automate the colormap adjustment process based on data properties (e.g., statistical data value or distribution). However, as the data properties have no direct correlation to the spatial variations, previous methods may be insufficient to reveal the dynamic range of spatial variations hidden in the data. To address the above issues, we conduct a pilot analysis with domain experts and summarize three requirements for the colormap adjustment process. Based on the requirements, we formulate colormap adjustment as an objective function, composed of a boundary term and a fidelity term, which is flexible enough to support interactive functionalities. We compare our approach with alternative methods under a quantitative measure and a qualitative user study (25 participants), based on a set of data with broad distribution diversity. We further evaluate our approach via three case studies with six domain experts. Our method is not necessarily more optimal than alternative methods of revealing patterns, but rather is an additional color adjustment option for exploring data with a dynamic range of spatial variations.","1941-0506","","10.1109/TVCG.2021.3109014","The funding from King Abdullah University of Science and Technology KAUST(grant numbers:BAS/1/1680-01-01); National Natural Science Foundation of China(grant numbers:61602273,61772315,61772318,61861136012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527154","Colormapping;Scientific visualization","Image color analysis;Data visualization;Task analysis;Tools;Histograms;Extremities;Encoding","","","","","","","IEEE","1 Sep 2021","","","IEEE","IEEE Early Access Articles"
"DeHumor: Visual Analytics for Decomposing Humor","X. Wang; Y. Ming; T. Wu; H. Zeng; Y. Wang; H. Qu","CSE, HKUST, 58207 Kowloon, Hong Kong, Hong Kong, (e-mail: xingbo.wang@connect.ust.hk); AI ENG, Bloomberg LP, 50421 New York, New York, United States, 10022-1331 (e-mail: yao.ming@connect.ust.hk); Paul G. Allen School of Computer Science and Engineering, University of Washington, 7284 Seattle, Washington, United States, (e-mail: wtshuang@cs.washington.edu); Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, Hong Kong, Hong Kong, (e-mail: hzengac@connect.ust.hk); Department of Computer Science and Engineering, Hong Kong University of Science and Technology, 58207 Hong Kong, Hong Kong, Hong Kong, 99999 (e-mail: ywangct@connect.ust.hk); The Department of Computer Science and Engineering, he Hong Kong University of Science and Technology, Hong Kong, HK, Hong Kong, (e-mail: huamin@cse.ust.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Despite being a critical communication skill, grasping humor is challenginga successful use of humor requires a mixture of both engaging content build-up and an appropriate vocal delivery (e.g., pause). Prior studies on computational humor emphasize the textual and audio features immediately next to the punchline, yet overlooking longer-term context setup. Moreover, the theories are usually too abstract for understanding each concrete humor snippet. To fill in the gap, we develop DeHumor, a visual analytical system for analyzing humorous behaviors in public speaking. To intuitively reveal the building blocks of each concrete example, DeHumor decomposes each humorous video into multimodal features and provides inline annotations of them on the video script. In particular, to better capture the build-ups, we introduce content repetition as a complement to features introduced in theories of computational humor and visualize them in a context linking graph. To help users locate the punchlines that have the desired features to learn, we summarize the content (with keywords) and humor feature statistics on an augmented time matrix. With case studies on stand-up comedy shows and TED talks, we show that DeHumor is able to highlight various building blocks of humor examples. In addition, expert interviews with communication coaches and humor researchers demonstrate the effectiveness of DeHumor for multimodal humor analysis of speech content and vocal delivery.","1941-0506","","10.1109/TVCG.2021.3097709","ITF UICP(grant numbers:UIT/142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9488285","Humor;Context;Multimodal Features;Visualization","Interviews;Public speaking;Speech;Semantics;Phonetics;Feature extraction;Visual analytics","","","","","","","IEEE","16 Jul 2021","","","IEEE","IEEE Early Access Articles"
"DebateVis: Visualizing Political Debates for Non-Expert Users","L. South; M. Schwab; N. Beauchamp; L. Wang; J. Wihbey; M. A. Borkin",Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","241","245","Political debates provide an important opportunity for voters to observe candidate behavior, learn about issues, and make voting decisions. However, debates are generally broadcast late at night and last more than ninety minutes, so watching debates live can be inconvenient, if not impossible, for many potential viewers. Even voters who do watch debates may find themselves overwhelmed by a deluge of information in a substantive, issue-driven debate. Media outlets produce short summaries of debates, but these are not always effective as a method of deeply comprehending the policies candidates propose or the debate techniques they employ. In this paper we contribute reflections and results of an 18-month design study through an interdisciplinary collaboration with journalism and political science researchers. We characterize task and data abstractions for visualizing political debate transcripts for the casual user, and present a novel tool (DebateVis) to help non-expert users explore and analyze debate transcripts.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00055","Northeastern University; National Science Foundation; Northeastern University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331282","Human-centered computing;Visualization;Visualization design and evaluation methods","Data visualization;Collaboration;Tools;Media;Journalism;Reflection;Task analysis","data visualisation;politics;social sciences computing","DebateVis;political debates;voters;candidate behavior;substantive issue-driven debate;debate techniques;journalism;political science researchers;political debate transcripts;data abstractions;task abstractions","","","","29","","1 Feb 2021","","","IEEE","IEEE Conferences"
"DecorIn: An Automatic Method for Plane-Based Decorating","Y. Liang; L. Fan; P. Ren; X. Xie; X. -S. Hua","Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China","IEEE Transactions on Visualization and Computer Graphics","30 Jun 2021","2021","27","8","3438","3450","There is an increasing demand for interior design and decorating. The main challenges are where to put the objects and how to put them plausibly in the given domain. In this article, we propose an automatic method for decorating the planes in a given image. We call it Decoration In (DecorIn for short). Given an image, we first extract planes as decorating candidates according to the estimated geometric features. Then we parameterize the planes with an orthogonal and semantically consistent grid. Finally, we compute the position for the decoration, i.e., a decoration box, on the plane by an example-based decorating method which can describe the partial image and compute the similarity between partial scenes. We have conducted comprehensive evaluations and demonstrate our method on a number of applications. Our method is more efficient both in time and economic than generating a layout from scratch.","1941-0506","","10.1109/TVCG.2020.2972897","Alibaba Group internship program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994048","Indoor decoration;scene parsing;plane extraction;plane parametrization;scene retrieval;plane layout","Layout;Image segmentation;Feature extraction;Three-dimensional displays;Two dimensional displays;Neural networks;Training data","architectural CAD;feature extraction;geometry;graph theory","plane-based;interior design;automatic method;DecorIn;estimated geometric features;orthogonal grid;semantically consistent grid;decoration box;partial image;example-based decorating method","","","","62","IEEE","11 Feb 2020","","","IEEE","IEEE Journals"
"Deep Exemplar-based Color Transfer for 3D Model","M. Zhang; J. Liao; J. Yu","Zhejiang university, CAD&CG Lab, Hangzhou, Zhejiang China (e-mail: zhangmohan@zju.edu.cn); Department of Computer Science, City University of Hong Kong, 53025 Kowloon, Hong Kong Hong Kong (e-mail: jingliao@cityu.edu.hk); State key lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang China (e-mail: jhyu@cad.zju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","Recoloring 3D models is a challenging task that often requires professional knowledge and tedious manual efforts. In this paper, we present the first deep-learning framework for exemplar-based 3D model recolor, which can automatically transfer the colors from a reference image to the 3D model texture. Our framework consists of two modules to solve two major challenges in the 3D color transfer. First, we propose a new feed-forward Color Transfer Network to achieve high-quality semantic-level color transfer by finding dense semantic correspondences between images. Second, considering 3D model constraints such as UV mapping, we design a novel 3D Texture Optimization Module which can generate a seamless and coherent texture by combining color transferred results rendered in multiple views. Experiments show that our method performs robustly and generalizes well to various kinds of models.","1941-0506","","10.1109/TVCG.2020.3041487","CityU of Hong Kong under APRC(grant numbers:9610488); Hong Kong ECS(grant numbers:21209119); National Natural Science Foundation of China(grant numbers:61772463); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275396","3D model texture;color transfer;deep learning","Image color analysis;Three-dimensional displays;Solid modeling;Semantics;Optimization;Task analysis;Histograms","","","","","","","IEEE","1 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Deep Line Art Video Colorization with a Few References","M. Shi; J. -Q. Zhang; S. -Y. Chen; L. Gao; Y. -K. Lai; F. Zhang","The School of Control & Computer Engineering, North China Electric Power University, 47840 Beijing, China, 102206 (e-mail: shimin01@ict.ac.cn); School of control and computer engineering, North China Electric Power University, 47840 Beijing, Beijing, China, 102206 (e-mail: zhangjiaqi0709@gmail.com); Adcanced Computer Research Center, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing, China, 100190 (e-mail: chenshuyu@ict.ac.cn); Advanced Computer Research Center, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing, China, (e-mail: gaolin@ict.ac.cn); School of Computer Science and Informatics, Cardiff University, 2112 Cardiff, South Glamorgan, United Kingdom of Great Britain and Northern Ireland, (e-mail: laiy4@cardiff.ac.uk); ECS, Victoria University of Wellington, 8491 Wellington, Wellington State, New Zealand, (e-mail: fanglue.zhang@ecs.vuw.ac.nz)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Coloring line art images based on the colors of reference images is an important stage in animation production, which is time-consuming and tedious. In this paper, we propose a deep architecture to automatically color line art videos with the same color style as the given reference images. Our framework consists of a color transform network and a temporal refinement network based on 3U-net. The color transform network takes the target line art images as well as the line art and color images of the reference images as input, and generates corresponding target color images. To cope with the large differences between each target line art image and the reference color images, we propose a distance attention layer that utilizes non-local similarity matching to determine the region correspondences between the target image and the reference images and transforms the local color information from the references to the target. To ensure global color style consistency, we further incorporate Adaptive Instance Normalization (AdaIN) with the transformation parameters obtained from a multiple-layer AdaIN that describes the global color style of the references, extracted by an embedder network. The temporal refinement network learns spatiotemporal features through 3D convolutions to ensure the temporal color consistency of the results. Our model can achieve even better coloring results by fine-tuning the parameters with only a small number of samples when dealing with an animation of a new style. To evaluate our method, we build a line art coloring dataset.","1941-0506","","10.1109/TVCG.2022.3146000","National Natural Science Foundation of China(grant numbers:No. 61972379, No. 62102403 and No. 61872440); Royal Society Newton Advanced Fellowship(grant numbers:No. NAF\R2\192151); Chinese Academy of Sciences(grant numbers:No. KFJ-STS-QYZD-2021-11-001); the Science and Technology Service Network Initiative; the Marsden Fund Council managed by Royal Society of New Zealand(grant numbers:No. MFP-20-VUW-180); Royal Society(grant numbers:No. IES\R1\180126); the Youth Innovation Pro- motion Association CAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693178","line art colorization;color transform;temporal coherence;few shot learning","Image color analysis;Art;Animation;Feature extraction;Three-dimensional displays;Transforms;Color","","","","","","","IEEE","25 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Deep Recursive Embedding for High-Dimensional Data","Z. Zhou; X. Zu; Y. Wang; B. P. F. Lelieveldt; Q. Tao","Department of Electronic Engineering, Fudan University, Shanghai, China; Faculty of Electrical Engineering, Mathematics and Computer Science (EEMCS), University of Twente, Enschede, NB, The Netherlands; Department of Electronic Engineering, Fudan University, Shanghai, China; Department of Radiology, Division of Image Processing, Leiden University Medical Center, Leiden, ZA, The Netherlands; Department of Imaging Physics, Delft University of Technology, Delft, CJ, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1237","1248","Embedding high-dimensional data onto a low-dimensional manifold is of both theoretical and practical value. In this article, we propose to combine deep neural networks (DNN) with mathematics-guided embedding rules for high-dimensional data embedding. We introduce a generic deep embedding network (DEN) framework, which is able to learn a parametric mapping from high-dimensional space to low-dimensional space, guided by well-established objectives such as Kullback-Leibler (KL) divergence minimization. We further propose a recursive strategy, called deep recursive embedding (DRE), to make use of the latent data representations for boosted embedding performance. We exemplify the flexibility of DRE by different architectures and loss functions, and benchmarked our method against the two most popular embedding methods, namely, t-distributed stochastic neighbor embedding (t-SNE) and uniform manifold approximation and projection (UMAP). The proposed DRE method can map out-of-sample data and scale to extremely large datasets. Experiments on a range of public datasets demonstrated improved embedding performance in terms of local and global structure preservation, compared with other state-of-the-art embedding methods. Code is available at <uri>https://github.com/tao-aimi/DeepRecursiveEmbedding</uri>.","1941-0506","","10.1109/TVCG.2021.3122388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585419","t-distributed stochastic neighbor embedding;uniform manifold approximation and projection;deep embedding network;deep recursive embedding;unsupervised learning","Data visualization;Feature extraction;Training;Manifolds;Unsupervised learning;Standards;Tools","data handling;data structures;deep learning (artificial intelligence);minimisation;stochastic processes","uniform manifold approximation and projection;t-distributed stochastic neighbor embedding;generic deep embedding network;deep recursive embedding;out-of-sample data;latent data representations;Kullback-Leibler divergence minimization;high-dimensional data embedding;mathematics-guided embedding rules;deep neural networks","","","","36","CCBY","26 Oct 2021","","","IEEE","IEEE Journals"
"Designing Visual Guides for Casual Listeners of Live Orchestral Music","C. Solis; F. Rajabiyazdi; F. Chevalier",University of Toronto; University of Toronto; University of Toronto,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","41","45","The experience of attending live orchestra performances is rich in cultural heritage and can be emotionally moving; however, for those unfamiliar with classical music, it can be intimidating. In this work, we explore the use of visual listening guides to supplement live performances with information that supports the casual listener's increased engagement. We employ human-centred design practices to evaluate a currently implemented guide with users, from which we extracted design requirements. We then identify dimensions of a music piece that may be visualized and created sample guide designs. Finally, we presented these designs to experts of visualization and music theory. Feedback from the two evaluations informs design implications to consider when creating visual guides of classical music for casual listeners.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933734","Music visualization;visual listening guides;orchestra.","Visualization;Music;Probes;Task analysis;Data mining","data visualisation;music;user centred design;user interfaces","casual listeners;live orchestral music;live orchestra performances;cultural heritage;classical music;visual listening guides;live performances;human-centred design practices;design requirements;music piece;sample guide designs;visualization;music theory","","","","15","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Designing for Ambiguity: Visual Analytics in Avalanche Forecasting","S. Nowak; L. Bartram; P. Haegeli",Simon Fraser University; Simon Fraser University; Simon Fraser University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","81","85","Ambiguity, an information state where multiple interpretations are plausible, is a common challenge in visual analytics (VA) systems. We discuss lessons learned from a case study designing VA tools for Canadian avalanche forecasters. Avalanche forecasting is a complex and collaborative risk-based decision-making and analysis domain, demanding experience and knowledge-based interpretation of human reported and uncertain data. Differences in reporting practices, organizational contexts, and the particularities of individual reports result in a variety of potential interpretations that have to be negotiated as part of the forecaster's sensemaking processes. We describe our preliminary research using glyphs to support sensemaking under ambiguity. Ambiguity is not unique to public avalanche forecasting. There are many other domains where the way data are measured and reported vary in ways not accounted explicitly in the data and require analysts to negotiate multiple potential meanings. We argue that ambiguity is under-served by visualization research and would benefit from more explicit VA support.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331311","Human-centered computing;Visualization;Visualization application domains;Visual analytics","Navigation;Visual analytics;Knowledge based systems;Data visualization;Collaboration;Tools;Forecasting","data analysis;data visualisation;decision making;knowledge based systems;risk management","VA tools;Canadian avalanche forecasters;complex risk-based decision-making;collaborative risk-based decision-making;knowledge-based interpretation;uncertain data;visualization research;visual analytics systems","","","","37","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Designing with Pictographs: Envision Topics without Sacrificing Understanding","A. Burns; C. Xiong; S. Franconeri; A. Cairo; N. Mahyar","College of Information and Computer Sciences, University of Massachusetts Amherst, 14707 Amherst, Massachusetts, United States, (e-mail: alyxanderbur@cs.umass.edu); Psychology, Northwestern University, 3270 Evanston, Illinois, United States, 60208-0001 (e-mail: cxiong@u.northwestern.edu); Psychology, Northwestern University, 3270 Evanston, Illinois, United States, (e-mail: franconeri@northwestern.edu); School of Communication, University of Miami, 5452 Coral Gables, Florida, United States, (e-mail: a.cairo@miami.edu); College of Information and Computer Sciences, University of Massachusetts Amherst, 14707 Amherst, Massachusetts, United States, (e-mail: nmahyar@cs.umass.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Past studies have shown that when a visualization uses pictographs to encode data, they have a positive effect on memory, engagement, and assessment of risk. However, little is known about how pictographs affect one's ability to understand a visualization, beyond memory for values and trends. We conducted two crowdsourced experiments to compare the effectiveness of using pictographs when showing part-to-whole relationships. In Experiment 1, we compared pictograph arrays to more traditional bar and pie charts. We tested participants' ability to generate high-level insights following Bloom's taxonomy of educational objectives via 6 free-response questions. We found that accuracy for extracting information and generating insights did not differ overall between the two versions. To explore the motivating differences between the designs, we conducted a second experiment where participants compared charts containing pictograph arrays to more traditional charts on 5 metrics and explained their reasoning. We found that some participants preferred the way that pictographs allowed them to envision the topic more easily, while others preferred traditional bar and pie charts because they seem less cluttered and faster to read. These results suggest that, at least in simple visualizations depicting part-to-whole relationships, the choice of using pictographs has little influence on sensemaking and insight extraction. When deciding whether to use pictograph arrays, designers should consider visual appeal, perceived comprehension time, ease of envisioning the topic, and clutteredness.","1941-0506","","10.1109/TVCG.2021.3092680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465643","Infographics;pictographs;design;graph comprehension;understanding;casual sensemaking","Data visualization;Visualization;Taxonomy;Graphics;Bars;Task analysis;COVID-19","","","","","","","IEEE","25 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Disentangled Representation of Data Distributions in Scatterplots","J. Jo; J. Seo","Seoul National University,Department of Computer Science and Engineering; Seoul National University,Department of Computer Science and Engineering","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","136","140","We present a data-driven approach to obtain a disentangled and interpretable representation that can characterize bivariate data distributions of scatterplots. We first collect tabular datasets from the Web and build a training corpus consisting of over one million scatterplot images. Then, we train a state-of-the-art disentangling model, β-variational autoencoder, to derive a disentangled representation of the scatterplot images. The main output of this work is a list of 32 representative features that can capture the underlying structures of bivariate data distributions. Through latent traversals, we seek for high-level semantics of the features and compare them to previous human-derived concepts such as scagnostics measures. Finally, using the 32 features as an input, we build a simple neural network to predict the perceptual distances between scatterplots that were previously scored by human annotators. We found Pearson's correlation coefficient between the predicted and perceptual distances was above 0.75, which indicates the effectiveness of our representation in the quantitative characterization of scatterplots.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933670","Human-centered computing;Visualization;Visualization theory;concepts and paradigms","Training;Neural networks;Visualization;Data visualization;Correlation;Machine learning;Generative adversarial networks","data visualisation;feature extraction;image representation;learning (artificial intelligence);neural nets","bivariate data distributions;scatterplots;tabular datasets;β-variational autoencoder;disentangled representation;disentangling model;data distribution representation;scatterplot image representation;neural network;Pearson correlation coefficient;visualization technique","","","","29","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Does the Layout Really Matter? A Study on Visual Model Accuracy Estimation","N. Grossmann; J. Bernard; M. Sedlmair; M. Waldner",TU Wien; University of Zurich; University of Stuttgart; TU Wien,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","61","65","In visual interactive labeling, users iteratively assign labels to data items until the machine model reaches an acceptable accuracy. A crucial step of this process is to inspect the model’s accuracy and decide whether it is necessary to label additional elements. In scenarios with no or very little labeled data, visual inspection of the predictions is required. Similarity-preserving scatterplots created through a dimensionality reduction algorithm are a common visualization that is used in these cases. Previous studies investigated the effects of layout and image complexity on tasks like labeling. However, model evaluation has not been studied systematically. We present the results of an experiment studying the influence of image complexity and visual grouping of images on model accuracy estimation. We found that users outperform traditional automated approaches when estimating a model’s accuracy. Furthermore, while the complexity of images impacts the overall performance, the layout of the items in the plot has little to no effect on estimations.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623326","Human-centered computing;Visualization;Empirical studies in visualization Human-centered computing;Visualization design and evaluation methods","Visualization;Layout;Estimation;Inspection;Predictive models;Prediction algorithms;Complexity theory","data visualisation;iterative methods;learning (artificial intelligence)","common visualization;image complexity;visual model accuracy estimation;visual interactive labeling;data items;machine model;additional elements;visual inspection;similarity-preserving scatterplots;dimensionality reduction algorithm","","","","22","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Dynamic Multi-projection Mapping Based on Parallel Intensity Control","T. Nomoto; W. Li; H. -L. Peng; Y. Watanabe","Tokyo Institute of Technology, Japan; Tokyo Institute of Technology, Japan; Tokyo Institute of Technology, Japan; Tokyo Institute of Technology, Japan","IEEE Transactions on Visualization and Computer Graphics","8 Apr 2022","2022","28","5","2125","2134","Projection mapping using multiple projectors is promising for spatial augmented reality; however, it is difficult to apply it to dynamic scenes. This is because the conventional method decides all pixel intensities of multiple images simultaneously based on the global optimization method, and it is hard to reduce the latency from motion to projection. To mitigate this, we propose a novel method of controlling the intensity based on a pixel-parallel calculation for each projector in real-time with low latency. This parallel calculation leverages the insight that the projected pixels from different projectors in overlapping areas can be approximated independently if the pixel is sufficiently small relative to the surface structure. Additionally, our pixel-parallel calculation method allows a distributed system configuration, such that the number of projectors can be increased to form a network for high scalability. We demonstrate a seamless mapping into dynamic scenes at 360 fps with a 9.5-ms latency using ten cameras and four projectors.","1941-0506","","10.1109/TVCG.2022.3150488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714121","Projection mapping;Multi-projector;Parallel computing methodologies","Rendering (computer graphics);Low latency communication;Shape;Image color analysis;Geometry;Surface structures;Real-time systems","","","","","","43","IEEE","15 Feb 2022","","","IEEE","IEEE Journals"
"EasyPZ.js: Interaction Binding for Pan and Zoom Visualizations","M. Schwab; J. Tompkin; J. Huang; M. A. Borkin","Northeastern University,Khoury College of Computer Sciences; Brown University; Brown University; Northeastern University,Khoury College of Computer Sciences","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","31","35","The creation of data visualizations has become easier as the skillbarrier to our tools has decreased. However, adding interactivity, such as gestures for pan and zoom, still requires significant coding expertise. We introduce an open-source library-EasyPZ.js-for the creation of multi-scale (pan and zoom) visualizations across desktop and mobile devices. EasyPZ is fully customizable and extendable with flexible options for interaction design. For example, it is easy to choose gestures which are compatible with selection interactions such as clicking. EasyPZ can be enabled on any SVG-based visualization on the web with one line of code, or by simply clicking a bookmark without requiring commitment to code changes. With this library, we contribute ways for the visualization community to more easily author interactive multi-scale visualizations.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933747","Human-computer interaction;SVG;visualization;interaction binding;pan;zoom;navigation;toolkit","Data visualization;Libraries;Mice;Visualization;Brushes;Encoding;Manuals","data visualisation;interactive systems","interaction binding;pan;zoom visualizations;data visualizations;open-source library;desktop devices;mobile devices;interaction design;selection interactions;SVG-based visualization;code changes;visualization community;interactive multiscale visualizations;coding expertise;EasyPZ","","","","19","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Edge-Path Bundling: A Less Ambiguous Edge Bundling Approach","M. Wallinger; D. Archambault; D. Auber; M. Nöllenburg; J. Peltonen","TU Wien, Austria; Swansea University, United Kingdom; University of Bordeaux, France; TU Wien, Austria; Tampere University, Finland","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","313","323","Edge bundling techniques cluster edges with similar attributes (i.e. similarity in direction and proximity) together to reduce the visual clutter. All edge bundling techniques to date implicitly or explicitly cluster groups of individual edges, or parts of them, together based on these attributes. These clusters can result in ambiguous connections that do not exist in the data. Confluent drawings of networks do not have these ambiguities, but require the layout to be computed as part of the bundling process. We devise a new bundling method, Edge-Path bundling, to simplify edge clutter while greatly reducing ambiguities compared to previous bundling techniques. Edge-Path bundling takes a layout as input and clusters each edge along a weighted, shortest path to limit its deviation from a straight line. Edge-Path bundling does not incur independent edge ambiguities typically seen in all edge bundling methods, and the level of bundling can be tuned through shortest path distances, Euclidean distances, and combinations of the two. Also, directed edge bundling naturally emerges from the model. Through metric evaluations, we demonstrate the advantages of Edge-Path bundling over other techniques.","1941-0506","","10.1109/TVCG.2021.3114795","Vienna Science and Technology Fund(grant numbers:ICT19-035); UK Research and Innovation(grant numbers:EP/V033670/1); Academy of Finland(grant numbers:327352); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552919","Graph/network and tree data;algorithms;edge bundling","Layout;Image edge detection;Clutter;Windings;Roads;Visualization;Lakes","computational geometry;data visualisation;edge detection;graph theory;pattern clustering","Edge-Path bundling;independent edge ambiguities;edge bundling methods;directed edge bundling;ambiguous Edge bundling approach;Edge bundling techniques;edge clutter;previous bundling techniques","","","","57","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"ElectroLens: Understanding Atomistic Simulations through Spatially-Resolved Visualization of High-Dimensional Features","X. Lei; F. Hohman; D. H. Polo Chau; A. J. Medford",NA; NA; NA; NA,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","196","200","In recent years, machine learning (ML) has gained significant popularity in the field of chemical informatics and electronic structure theory. These techniques often require researchers to engineer abstract ""features"" that encode chemical concepts into a mathematical form compatible with the input to machine-learning models. However, there is no existing tool to connect these abstract features back to the actual chemical system, making it difficult to diagnose failures and to build intuition about the meaning of the features. We present ElectroLens, a new visualization tool for high-dimensional spatially-resolved features to tackle this problem. The tool visualizes high-dimensional data sets for atomistic and electron environment features by a series of linked 3D views and 2D plots. The tool is able to connect different derived features and their corresponding regions in 3D via interactive selection. It is built to be scalable, and integrate with existing infrastructure.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933647","Molecular Visualization;Visual Design;Co-ordinated and Multiple Views;Interaction Design","Three-dimensional displays;Data visualization;Chemicals;Tools;Two dimensional displays;Image color analysis;Correlation","chemistry computing;data visualisation;learning (artificial intelligence)","high-dimensional data sets;atomistic environment features;electron environment features;ElectroLens;spatially-resolved visualization;high-dimensional features;machine learning;chemical informatics;electronic structure theory;mathematical form;machine-learning models;visualization tool;high-dimensional spatially-resolved features","","","","28","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Exact Analytical Parallel Vectors","H. Guo; T. Peterka","Argonne National Laboratory,Mathematics and Computer Science Division; Argonne National Laboratory,Mathematics and Computer Science Division","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","101","105","This paper demonstrates that parallel vector curves are piecewise cubic rational curves in 3D piecewise linear vector fields. Parallel vector curves—loci of points where two vector fields are parallel— have been widely used to extract features including ridges, valleys, and vortex core lines in scientific data. We define the term generalized and underdetermined eigensystem in the form of Ax + a = $\lambda$(Bx + b) in order to derive the piecewise rational representation of 3D parallel vector curves. We discuss how singularities of the rationals lead to different types of intersections with tetrahedral cells.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623310","Office of Science; U.S. Department of Energy; Advanced Scientific Computing Research; Laboratory Directed Research and Development; Office of Science; U.S. Department of Energy; Division of Information and Intelligent Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623310","","Three-dimensional displays;Conferences;Distributed databases;Data visualization;Reconstruction algorithms;Parallel processing;Filtering algorithms","computational geometry;curve fitting;data visualisation;feature extraction;piecewise linear techniques;vectors","exact analytical parallel;piecewise cubic rational curves;3D piecewise linear vector fields;piecewise rational representation","","","","15","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Explaining Semi-Supervised Text Alignment through Visualization","C. Meinecke; D. Wrisley; S. Janicke","Image and Signal Processing Group, Leipzig University, 9180 Leipzig, Saxony, Germany, 04109 (e-mail: cmeinecke@informatik.uni-leipzig.de); Arts & Humanities, New York University - Abu Dhabi, 167632 Abu Dhabi, Abu Dhabi, United Arab Emirates, (e-mail: djw12@nyu.edu); Department for Mathematics and Computer Science, University of Southern Denmark, 6174 Odense, Fyn, Denmark, 5230 (e-mail: stjaenicke@imada.sdu.dk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","The analysis of variance in complex text traditions is an arduous task when carried out manually. Text alignment algorithms provide domain experts with a robust alternative to such repetitive tasks. Existing white-box approaches allow the digital humanities to establish syntax-based metrics taking into account the spelling, morphology and order of words. However, they produce limited results, as semantic meanings are typically not taken into account. Our interdisciplinary collaboration between visualization and digital humanities combined a semi-supervised text alignment approach based on word embeddings that take not only syntactic but also semantic text features into account, thereby improving the overall quality of the alignment. In our collaboration, we developed different visual interfaces that communicate the word distribution in high-dimensional vector space generated by the underlying neural network for increased transparency, assessment of the tools reliability and overall improved hypothesis generation. We further offer visual means to enable the expert reader to feed domain knowledge into the system at multiple levels with the aim of improving both the product and the process of text alignment. This ultimately illustrates how visualization can engage with and augment complex modes of reading in the humanities.","1941-0506","","10.1109/TVCG.2021.3105899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516959","Text Alignment;Word Embeddings;Human-in-the-loop;Visualization in the Humanities;Professional Reading","Visualization;Semantics;Task analysis;Visual analytics;Pipelines;Data visualization;Collaboration","","","","","","","IEEE","18 Aug 2021","","","IEEE","IEEE Early Access Articles"
"Exploring How Personality Models Information Visualization Preferences","T. Alves; B. Ramalho; D. Gonçalves; S. Gama; J. Henriques-Calado","University of Lisbon,INESC-ID and Instituto Superior Técnico,Lisbon,Portugal; University of Lisbon,INESC-ID and Instituto Superior Técnico,Lisbon,Portugal; University of Lisbon,INESC-ID and Instituto Superior Técnico,Lisbon,Portugal; University of Lisbon,INESC-ID and Instituto Superior Técnico,Lisbon,Portugal; Universidade de Lisboa,CICPSI, Faculdade de Psicologia,Lisboa,Portugal","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","201","205","Recent research on information visualization has shown how individual differences act as a mediator on how users interact with visualization systems. We focus our exploratory study on whether personality has an effect on user preferences regarding idioms used for hierarchy, evolution over time, and comparison contexts. Specifically, we leverage all personality variables from the Five-Factor Model and the three dimensions from Locus of Control (LoC) with correlation and clustering approaches. The correlation-based method suggested that Neuroticism, Openness to Experience, Agreeableness, several facets from each trait, and the External dimensions from LoC mediate how much individuals prefer certain idioms. In addition, our results from the cluster-based analysis showed that Neuroticism, Extraversion, Conscientiousness, and all dimensions from LoC have an effect on preferences for idioms in hierarchy and evolution contexts. Our results support the incorporation of in-depth personality synergies with InfoVis into the design pipeline of visualization systems.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00047","Fundação para a Ciência e a Tecnologia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331318","Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies;Human-centered computing;Visualization;Visualization design and evaluation methods","Visualization;Correlation;Design methodology;Conferences;Computational modeling;Pipelines","data visualisation;human factors;pattern clustering","user preferences;personality variables;five-factor model;clustering approaches;correlation-based method;LoC;cluster-based analysis;evolution contexts;in-depth personality synergies;visualization systems;information visualization preference;neuroticism;correlation approach","","","","36","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Exploring the SenseMaking Process through Interactions and fNIRS in Immersive Visualization","A. Galati; R. Schoppa; A. Lu","University of North Carolina, Charlotte, United States; University of North Carolina, Charlotte, United States; University of North Carolina, Charlotte, United States","IEEE Transactions on Visualization and Computer Graphics","15 Apr 2021","2021","27","5","2714","2724","Theories of cognition inform our decisions when designing human-computer interfaces, and immersive systems enable us to examine these theories. This work explores the sensemaking process in an immersive environment through studying both internal and external user behaviors with a classical visualization problem: a visual comparison and clustering task. We developed an immersive system to perform a user study, collecting user behavior data from different channels: AR HMD for capturing external user interactions, functional near-infrared spectroscopy (fNIRS) for capturing internal neural sequences, and video for references. To examine sensemaking, we assessed how the layout of the interface (planar 2D vs. cylindrical 3D layout) and the challenge level of the task (low vs. high cognitive load) influenced the users' interactions, how these interactions changed over time, and how they influenced task performance. We also developed a visualization system to explore joint patterns among all the data channels. We found that increased interactions and cerebral hemodynamic responses were associated with more accurate performance, especially on cognitively demanding trials. The layout types did not reliably influence interactions or task performance. We discuss how these findings inform the design and evaluation of immersive systems, predict user performance and interaction, and offer theoretical insights about sensemaking from the perspective of embodied and distributed cognition.","1941-0506","","10.1109/TVCG.2021.3067693","NSF Awards(grant numbers:1564039,1629913,1661280,1840080,1937010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382916","Sensemaking;user behavior;immersive analytics;cognition load;mixed reality","Task analysis;Layout;Cognition;Data visualization;Three-dimensional displays;Tools;Two dimensional displays","brain;cognition;data visualisation;haemodynamics;helmet mounted displays;human computer interaction;infrared spectroscopy;neurophysiology;psychology;virtual reality","user performance;cognitively demanding trials;accurate performance;increased interactions;data channels;visualization system;task performance;users;high cognitive load;internal neural sequences;near-infrared spectroscopy;external user interactions;user behavior data;clustering task;visual comparison;classical visualization problem;internal user;immersive environment;immersive system;designing human-computer interfaces;immersive visualization;fNIRS;sensemaking process","Adult;Augmented Reality;Brain;Cerebrovascular Circulation;Cognition;Female;Humans;Male;Spectroscopy, Near-Infrared;Task Performance and Analysis;Young Adult","","","52","IEEE","22 Mar 2021","","","IEEE","IEEE Journals"
"FAVR - Accelerating Direct Volume Rendering for Virtual RealitySystems","A. Waschk; J. Krüger",University of Duisburg-Essen; University of Duisburg-Essen,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","106","110","In recent years, virtual reality (VR) has become readily available using robust and affordable head-mounted display (HMD) systems. Several VR-based scientific visualization solutions were proposed recently, but direct volume rendering (DVR) was considered only in a handful of VR-applications. We attribute this to the high computational demand of DVR and the limited rendering budget available for VR systems. For a heavily fragment-bound method such as DVR, it is challenging to achieve the very high update rates essential for VR. We propose an acceleration technique designed to take advantage of the specific characteristics of HMD systems. We utilize an adaptive rendering approach based on the lens distortion of HMDs and the visual perception of the human eye. Our implementation reduces the rendering cost of DVR while providing an experience indistinguishable to standard rendering techniques.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331288","Volume Rendering;Application Motivated Visualization;Algorithms;Scalar Field Data","Visualization;Head-mounted displays;Data visualization;Resists;Rendering (computer graphics);Acceleration;Visual perception","data visualisation;helmet mounted displays;rendering (computer graphics);virtual reality","FAVR;virtual reality systems;scientific visualization solutions;direct volume rendering;DVR;VR systems;HMD systems;visual perception;fragment-bound method;head-mounted display systems","","","","19","","1 Feb 2021","","","IEEE","IEEE Conferences"
"FacIt: Factorizing Tensors into Interpretable and Scrutinizable Patterns","X. Wen; K. Pelechrinis; Y. -R. Lin; X. Liu; Y. Ahn; N. Cao","University of Pittsburgh,School of Computing and Information; University of Pittsburgh,School of Computing and Information; University of Pittsburgh,School of Computing and Information; Texas A&M University,Program of Computer Engineering; University of Pittsburgh,School of Computing and Information; TongJi University,College of Design and Innovation","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Tensor Factorization has been widely used in many fields to discover latent patterns from multidimensional data. Interpreting or scrutinizing the tensor factorization results are, however, by no means easy. We introduce FacIt, a generic visual analytic system that directly factorizes tensor-formatted data into a visual representation of patterns to facilitate result interpretation, scrutinization, information query, as well as model selection. Our design consists of (i) a suite of model scrutinizing and inspection tools that allows efficient tensor model selection (commonly known as rank selection problem) and (ii) an interactive visualization design that empowers users with both characteristics- and content-driven pattern discovery. We demonstrate the effectiveness of our system through usage scenarios with policy adoption analysis.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933750","Human-centered computing;Visualization;Visualization application domains;Visual analytics","Analytical models;Task analysis;Measurement;Data visualization;Computational modeling;Inspection","data analysis;data visualisation;interactive systems;matrix decomposition;tensors","generic visual analytic system;tensor-formatted data;information query;inspection tools;rank selection problem;interactive visualization design;content-driven pattern discovery;FacIt;multidimensional data;tensor factorization results;factorizing tensors;scrutinizable patterns;tensor model selection;policy adoption analysis","","","","39","","19 Dec 2019","","","IEEE","IEEE Conferences"
"FairRankVis: A Visual Analytics Framework for Exploring Algorithmic Fairness in Graph Mining Models","T. Xie; Y. Ma; J. Kang; H. Tong; R. Maciejewski","Arizona State University, United States; Southern University of Science and Technology, China; University of Illinois at Urbana-Champaign, United States; University of Illinois at Urbana-Champaign, United States; Arizona State University, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","368","377","Graph mining is an essential component of recommender systems and search engines. Outputs of graph mining models typically provide a ranked list sorted by each item's relevance or utility. However, recent research has identified issues of algorithmic bias in such models, and new graph mining algorithms have been proposed to correct for bias. As such, algorithm developers need tools that can help them uncover potential biases in their models while also exploring the impacts of correcting for biases when employing fairness-aware algorithms. In this paper, we present FairRankVis, a visual analytics framework designed to enable the exploration of multi-class bias in graph mining algorithms. We support both group and individual fairness levels of comparison. Our framework is designed to enable model developers to compare multi-class fairness between algorithms (for example, comparing PageRank with a debiased PageRank algorithm) to assess the impacts of algorithmic debiasing with respect to group and individual fairness. We demonstrate our framework through two usage scenarios inspecting algorithmic fairness.","1941-0506","","10.1109/TVCG.2021.3114850","U.S. Department of Homeland Security(grant numbers:2017-ST-061-QA0001,17STQAC00001-03-03); National Science Foundation Program(grant numbers:1939725); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552229","Graph ranking;fairness;visual analytics","Analytical models;Visual analytics;Machine learning algorithms;Task analysis;Data mining;Data models;Machine learning","data analysis;data mining;data visualisation;graph theory;recommender systems;search engines","employing fairness-aware algorithms;FairRankVis;visual analytics framework;multiclass bias;graph mining algorithms;model developers;multiclass fairness;debiased PageRank algorithm;algorithmic debiasing;algorithmic fairness;graph mining models;algorithmic bias;potential biases","","","","37","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Fast & Accurate Gaussian Kernel Density Estimation","J. Heer",University of Washiington,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","11","15","Kernel density estimation (KDE) models a discrete sample of data as a continuous distribution, supporting the construction of visualizations such as violin plots, heatmaps, and contour plots. This paper draws on the statistics and image processing literature to survey efficient and scalable density estimation techniques for the common case of Gaussian kernel functions. We evaluate the accuracy and running time of these methods across multiple visualization contexts and find that the combination of linear binning and a recursive filter approximation by Deriche efficiently produces pixel-perfect estimates across a compelling range of kernel bandwidths.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623323","Kernel density estimation, Gaussian convolution, binning, approximation, performance, evaluation","Measurement;Maximum likelihood detection;Matched filters;Shape;Data visualization;Estimation;Nonlinear filters","data visualisation;Gaussian processes;image filtering;recursive filters","scalable density estimation techniques;Gaussian kernel functions;running time;multiple visualization contexts;pixel-perfect estimates;kernel bandwidths;Gaussian kernel density estimation;kernel density estimation models;continuous distribution;violin plots;contour plots;image processing literature;linear binning;recursive filter approximation","","","","27","","30 Nov 2021","","","IEEE","IEEE Conferences"
"Fast 3D Indoor Scene Synthesis by Learning Spatial Relation Priors of Objects","S. -H. Zhang; S. -K. Zhang; W. -Y. Xie; C. -Y. Luo; Y. Yang; H. Fu","Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, (e-mail: shz@tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University School of Information Science and Technology, 162653 Beijing, Beijing, China, 100084 (e-mail: zhangsk18@mails.tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: ervinxie@qq.com); Department of Mathematical Sciences, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: luocy16@mails.tsinghua.edu.cn); Department of Computer Science, University of Bath, 1555 Bath, Somerset, United Kingdom of Great Britain and Northern Ireland, (e-mail: y.yang@cs.bath.ac.uk); School of Creative Media, City University of Hong Kong, 53025 Kowloon, Hong Kong, Hong Kong, (e-mail: hongbofu@cityu.edu.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We present a framework for fast synthesizing indoor scenes, given a room geometry and a list of objects with learnt priors.Unlike existing data-driven solutions, which often learn priors by co-occurrence analysis and statistical model fitting, our methodmeasures the strengths of spatial relations by tests for complete spatial randomness (CSR), and learns discrete priors based onsamples with the ability to accurately represent exact layout patterns. With the learnt priors, our method achieves both acceleration andplausibility by partitioning the input objects into disjoint groups, followed by layout optimization using position-based dynamics (PBD)based on the Hausdorff metric. Experiments show that our framework is capable of measuring more reasonable relations amongobjects and simultaneously generating varied arrangements in seconds compared with the state-of-the-art works.","1941-0506","","10.1109/TVCG.2021.3050143","National Key Technology RD Program(grant numbers:2017YFB1002604); National Natural Science Foundation of China(grant numbers:61772298,61832016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321177","3D Indoor Scene Synthesis;Furniture Objects Arrangement;Complete Spatial Randomness","Layout;Three-dimensional displays;Computational modeling;Optimization;Mathematical model;Task analysis;Semantics","","","","","","","IEEE","12 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Fixation and Creativity in Data Visualization Design: Experiences and Perspectives of Practitioners","P. Parsons; P. Shukla; C. Park",Purdue University; Purdue University; Purdue University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","76","80","Data visualization design often requires creativity, and research is needed to understand its nature and means for promoting it. The current visualization literature on creativity is not well developed, especially with respect to the experiences of professional data visualization designers. We conducted semi-structured interviews with 15 data visualization practitioners, focusing on a specific aspect of creativity known as design fixation. Fixation occurs when designers adhere blindly or prematurely to a set of ideas that limit creative outcomes. We present practitioners’ experiences and perspectives from their own design practice, specifically focusing on their views of (i) the nature of fixation, (ii) factors encouraging fixation, and (iii) factors discouraging fixation. We identify opportunities for future research related to chart recommendations, inspiration, and perspective shifts in data visualization design.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623297","Human-centered computing;Visualization","Conferences;Data visualization;Focusing;Interviews;Creativity","data analysis;data visualisation;human factors","data visualization design;professional data visualization designers;data visualization practitioners;design fixation;creative outcomes;design practice","","","","53","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Fuzzy Spreadsheet: Understanding and Exploring Uncertainties in Tabular Calculations","V. Dhanoa; C. Walchshofer; A. Hinterreiter; E. Groeller; M. Streit","Visual Analytics, Pro2Future GmbH, Linz, Upper Austria, Austria, 4040 (e-mail: vaishali.dhanoa@pro2future.at); Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria, (e-mail: conny.walchshofer@jku.at); Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria, 4040 (e-mail: andreas.hinterreiter@jku.at); Institute of Computer Graphics and Algorithms, TU Wien, 27259 Wien, Wien, Austria, 1040 (e-mail: groeller@cg.tuwien.ac.at); Institute of Computer Graphics, Johannes Kepler University Linz, Linz, Upper Austria, Austria, 4040 (e-mail: marc.streit@jku.at)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Spreadsheet-based tools provide a simple yet effective way of calculating values, which makes them the number-one choice for building and formalizing simple models for budget planning and many other applications. A cell in a spreadsheet holds one specific value and gives a discrete, overprecise view of the underlying model. Therefore, spreadsheets are of limited use when investigating the inherent uncertainties of such models and answering what-if questions. Existing extensions typically require a complex modeling process that cannot easily be embedded in a tabular layout. In Fuzzy Spreadsheet, a cell can hold and display a distribution of values. This integrated uncertainty-handling immediately conveys sensitivity and robustness information. The fuzzification of the cells enables calculations not only with precise values but also with distributions, and probabilities. We conservatively added and carefully crafted visuals to maintain the look and feel of a traditional spreadsheet while facilitating what-if analyses. Given a user-specified reference cell, Fuzzy Spreadsheet automatically extracts and visualizes contextually relevant information, such as impact, uncertainty, and degree of neighborhood, for the selected and related cells. To evaluate its usability and the perceived mental effort required, we conducted a user study. The results show that our approach outperforms traditional spreadsheets in terms of answer correctness, response time, and perceived mental effort in almost all tasks tested.","1941-0506","","10.1109/TVCG.2021.3119212","State of Upper Austria(grant numbers:Human-Interpretable Machine Learning); sterreichische Forschungsfrderungsgesellschaft(grant numbers:FFG 854174,FFG 881844); LIT Linz Institute of Technology(grant numbers:LIT-2019-7-SEE-117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566799","Uncertainty visualization;tabular data;spreadsheet augmentation","Uncertainty;Costs;Automobiles;Tools;Visualization;Computational modeling;Maintenance engineering","","","","","","","IEEE","11 Oct 2021","","","IEEE","IEEE Early Access Articles"
"GDR-Net: A Geometric Detail Recovering Network for 3D Scanned Objects","W. Feng; J. Zhang; Y. Zhou; S. Xin","Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China, (e-mail: lcfwq@mail.ustc.edu.cn); Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China, (e-mail: juyong@ustc.edu.cn); School of Computer Science and Technology, Shandong University, Jinan, Shandong, China, 250101 (e-mail: yfzhou@sdu.edu.cn); School of Computer, Shandong University, 12589 Jinan, School of Computer Science and Technology, China, (e-mail: xinshiqing@sdu.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","This paper addresses the problem of mesh super-resolution such that the geometry details which are not well represented in the low-resolution models can be recovered and well represented in the generated high-quality models. The main challenges of this problem are the non-regularity of 3D mesh representation and the high complexity of 3D shapes. We propose a deep neural network called GDR-Net to solve this ill-posed problem, which resolves the two challenges simultaneously. First, to overcome the non-regularity, we regress a displacement in radial basis function parameter space instead of the vertex-wise coordinates in the Euclidean space. Second, to overcome the high complexity, we apply the detail recovery process to small surface patches extracted from the input surface and obtain the overall high-quality mesh by fusing the refined surface patches. To train the network, we constructed a dataset composed of both real-world and synthetic scanned models, including high/low-quality pairs. Our experimental results demonstrate that GDR-Net works well for general models and outperforms previous methods for recovering geometric details.","1941-0506","","10.1109/TVCG.2021.3110658","National Natural Science Foundation of China(grant numbers:62122071); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2018495); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9531524","Surface Representation;Geometric Detail Recovery;3D Scanning;Mesh Reconstruction","Three-dimensional displays;Shape;Surface reconstruction;Geometry;Computational modeling;Task analysis;Solid modeling","","","","","","","IEEE","8 Sep 2021","","","IEEE","IEEE Early Access Articles"
"GEViTRec: Data Reconnaissance Through Recommendation Using a Domain-Specific Visualization Prevalence Design Space","A. Crisan; S. E. Fisher; J. L. Gardy; T. Munzner","Tableau Research, Tableau Software Inc, 584918 Seattle, Washington, United States, (e-mail: acrisan@tableau.com); Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia, Canada, (e-mail: shannahelizabeth@gmail.com); Global Health: Malaria, Gates Foundation, 11037 Seattle, Washington, United States, (e-mail: jennifer.gardy@gatesfoundation.org); Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia, Canada, (e-mail: tmm@cs.ubc.ca)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Genomic Epidemiology (genEpi) is a branch of public health that uses many different data types including tabular, network, genomic, and geographic, to identify and contain outbreaks of deadly diseases. Due to the volume and variety of data, it is challenging for genEpi domain experts to conduct data reconnaissance; that is, have an overview of the data they have and make assessments toward its quality, completeness, and suitability. We present an algorithm for data reconnaissance through automatic visualization recommendation, GEViTRec. Our approach handles a broad variety of dataset types and automatically generates visually coherent combinations of charts, in contrast to existing systems that primarily focus on singleton visual encodings of tabular datasets. We automatically detect linkages across multiple input datasets by analyzing non-numeric attribute fields, creating a data source graph within which we analyze and rank paths. For each high-ranking path, we specify chart combinations with positional and color alignments between shared fields, using a gradual binding approach to transform initial partial specifications of singleton charts to complete specifications that are aligned and oriented consistently. A novel aspect of our approach is its combination of domain-agnostic elements with domain-specific information that is captured through a domain-specific visualization prevalence design space. Our implementation is applied to both synthetic data and real Ebola outbreak data. We compare GEViTRec's output to what previous visualization recommendation systems would generate, and to manually crafted visualizations used by practitioners. We conducted formative evaluations with ten genEpi experts to assess the relevance and interpretability of our results.","1941-0506","","10.1109/TVCG.2021.3107749","Natural Sciences and Engineering Research Council of Canada(grant numbers:USRA,Vanier Scholarship); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524484","Heterogeneous Data;Multiple Coordinated Views;Data Reconnaissance;Bioinformatics","Data visualization;Visualization;Encoding;Bioinformatics;Genomics;Image color analysis;Epidemiology","","","","","","","CCBY","27 Aug 2021","","","IEEE","IEEE Early Access Articles"
"GNN-Surrogate: A Hierarchical and Adaptive Graph Neural Network for Parameter Space Exploration of Unstructured-Mesh Ocean Simulations","N. Shi; J. Xu; S. W. Wurster; H. Guo; J. Woodring; L. P. Van Roekel; H. -W. Shen","Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, 43210, USA.; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, 43210, USA.; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, 43210, USA.; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL 60439, USA.; Applied Computer Science Group (CCS-7), Los Alamos National Laboratory, Los Alamos, NM 87544.; Fluid Dynamics and Solid Mechanics Group (T-3), Los Alamos National Laboratory, Los Alamos, NM 87544.; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, 43210, USA.","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","We propose GNN-Surrogate, a graph neural network-based surrogate model to explore the parameter space of ocean climate simulations. Parameter space exploration is important for domain scientists to understand the influence of input parameters (e.g., wind stress) on the simulation output (e.g., temperature). The exploration requires scientists to exhaust the complicated parameter space by running a batch of computationally expensive simulations. Our approach improves the efficiency of parameter space exploration with a surrogate model that predicts the simulation outputs accurately and efficiently. Specifically, GNN-Surrogate predicts the output field with given simulation parameters so scientists can explore the simulation parameter space with visualizations from user-specified visual mappings. Moreover, our graph-based techniques are designed for unstructured meshes, making the exploration of simulation outputs on irregular grids efficient. For efficient training, we generate hierarchical graphs and use adaptive resolutions. We give quantitative and qualitative evaluations on the MPAS-Ocean simulation to demonstrate the effectiveness and efficiency of GNN-Surrogate. Source code is publicly available at https://github.com/trainsn/GNN-Surrogate.","1941-0506","","10.1109/TVCG.2022.3165345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751203","Parameter Space Exploration;Ensemble Visualization;Unstructured Mesh;Surrogate Modeling;Graph Neural Network;Adaptive Resolution","Computational modeling;Adaptation models;Predictive models;Data models;Space exploration;Analytical models;Data visualization","","","","","","","IEEE","7 Apr 2022","","","IEEE","IEEE Early Access Articles"
"GNNLens: A Visual Analytics Approach for Prediction Error Diagnosis of Graph Neural Networks","Z. Jin; Y. Wang; Q. Wang; Y. Ming; T. Ma; H. Qu","Computer Science and Engineering, Hong Kong University of Science and Technology, 58207 Kowloon, Hong Kong, Hong Kong, 999077 (e-mail: zjinak@connect.ust.hk); School of Information Systems, Singapore Management University, 54756 Singapore, Singapore, Singapore, 178902 (e-mail: yongwang@smu.edu.sg); Bioinfomatics, Harvard University, 1812 Cambridge, Massachusetts, United States, 02138 (e-mail: qianwen_wang@hms.harvard.edu); Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, Hong Kong, Hong Kong, (e-mail: ymingaa@connect.ust.hk); AI, IBM, 3261 Armonk, New York, United States, (e-mail: tengfei.ma1@ibm.com); The Department of Computer Science and Engineering, he Hong Kong University of Science and Technology, Hong Kong, HK, Hong Kong, (e-mail: huamin@cse.ust.hk)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph data and have achieved significant progress in graph analysis tasks (e.g., node classification) in recent years. However, similar to other deep neural networks like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), GNNs behave like a black box with their details hidden from model developers and users. It is therefore difficult to diagnose possible errors of GNNs. Despite many visual analytics studies being done on CNNs and RNNs, little research has addressed the challenges for GNNs. This paper fills the research gap with an interactive visual analysis tool, GNNLens, to assist model developers and users in understanding and analyzing GNNs. Specifically, Parallel Sets View and Projection View enable users to quickly identify and validate error patterns in the set of wrong predictions; Graph View and Feature Matrix View offer a detailed analysis of individual nodes to assist users in forming hypotheses about the error patterns. Since GNNs jointly model the graph structure and the node features, we reveal the relative influences of the two types of information by comparing the predictions of three models: GNN, Multi-Layer Perceptron (MLP), and GNN Without Using Features (GNNWUF). Two case studies and interviews with domain experts demonstrate the effectiveness of GNNLens in facilitating the understanding of GNN models and their errors.","1941-0506","","10.1109/TVCG.2022.3148107","Hong Kong Theme-based Research Scheme(grant numbers:T41-709/17N); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9705076","Graph Neural Networks;Error Diagnosis;Visualization","Analytical models;Deep learning;Predictive models;Visual analytics;Data models;Convolutional neural networks;Task analysis","","","","","","","IEEE","4 Feb 2022","","","IEEE","IEEE Early Access Articles"
"GPU Optimization for High-Quality Kinetic Fluid Simulation","Y. Chen; W. Li; R. Fan; X. Liu","School of Information Science and Technology, ShanghaiTech University - Zhangjiang Campus, 387433 Shanghai, Shanghai, China, (e-mail: chenyixin1008@gmail.com); School of Information Science and Technology, ShanghaiTech University - Zhangjiang Campus, 387433 Shanghai, Shanghai, China, (e-mail: liwei@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University - Zhangjiang Campus, 387433 Shanghai, Shanghai, China, (e-mail: fanrui@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University - Zhangjiang Campus, 387433 Shanghai, Shanghai, China, (e-mail: aurorean.xp@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Fluid simulations are often performed using the incompressible Navier-Stokes equations (INSE), leading to sparse linear systems which are difficult to solve efficiently in parallel. Recently, kinetic methods based on the adaptive-central-moment multiple-relaxation-time (ACM-MRT) model have demonstrated impressive capabilities to simulate both laminar and turbulent flows, with quality matching or surpassing that of state-of-the-art INSE solvers. Furthermore, due to its local formulation, this method presents the opportunity for highly scalable implementations on parallel systems such as GPUs. However, an efficient ACM-MRT-based kinetic solver needs to overcome a number of computational challenges, especially when dealing with complex solids inside the fluid domain. In this paper, we present multiple novel GPU optimization techniques to efficiently implement high-quality ACM-MRT-based kinetic fluid simulations in domains containing complex solids. Our techniques include a new communication-efficient data layout, a load-balanced immersed-boundary method, a multi-kernel launch method using a simplified formulation of ACM-MRT calculations to enable greater parallelism, and the integration of these techniques into a parametric cost model to enable automated prameter search to achieve optimal execution performance. We also extended our method to multi-GPU systems to enable large-scale simulations. To demonstrate the state-of-the-art performance and high visual quality of our solver, we present extensive experimental results and comparisons to other solvers.","1941-0506","","10.1109/TVCG.2021.3059753","National Natural Science Foundation of China(grant numbers:61976138); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355005","GPU optimization;parallel computing;fluid simulation;lattice Boltzmann method;immersed boundary method","Kinetic theory;Mathematical model;Graphics processing units;Computational modeling;Solids;Optimization;Adaptation models","","","","","","","IEEE","16 Feb 2021","","","IEEE","IEEE Early Access Articles"
"GPU-based Raycasting of Hermite Spline Tubes","B. Russig; M. Salm; S. Gumhold",TU Dresden; TU Dresden; TU Dresden,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","26","30","Visualizing curve and trajectory data is a common task in many scientific fields including medicine and physics. Tubes are an effective visualization primitive for this sort of data, but they require highly specialized renderers to achieve high image quality at frame rates sufficient for interactive visualization. We present a rendering algorithm for Hermite spline tubes, i.e. tubes that result from Hermite splines interpolating the data, with support for varying-radii circular tube cross sections. Our approach employs raycasting and works directly on this continuous representation without the need for surface tessellation, made possible by an efficient ray-tube intersection routine suitable for execution on modern GPUs.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331319","Computing methodologies;Computer graphics;Rendering;Human-centered computing;Visualization;Visualization Application domains;Scientific visualization","Data visualization;Rendering (computer graphics);Electron tubes;Trajectory;Splines (mathematics);Task analysis;Physics","data visualisation;interpolation;production engineering computing;ray tracing;rendering (computer graphics);splines (mathematics)","varying-radii circular tube cross sections;efficient ray-tube intersection routine;GPU-based raycasting;Hermite spline tubes;trajectory data;effective visualization primitive;high image quality;interactive visualization;rendering algorithm;specialized renderers","","","","14","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Gaze-Driven Links for Magazine Style Narrative Visualizations","S. Lallé; T. Wu; C. Conati",The University of British Columbia; The University of British Columbia; The University of British Columbia,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","166","170","Magazine Style Narrative Visualizations (MSNV) can be challenging due to the need to integrate textual and visual information. This problem has prompted researchers to design dynamic guidance meant to ease the mapping of the information provided in the two modalities. We contribute to this line of work by evaluating gaze-driven adaptive guidance that dynamically links relevant sentences in the text to the corresponding datapoints in the visualizations (see Fig. 1). We conducted a user study that involved participants reading a series of MSNVs extracted from real-world sources. Results show that the adaptive links significantly improve the comprehension of the MSNVs as compared to receiving no guidance. This improvement comes at no expense of user reading time, and is consistent regardless of the MSNV complexity.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331313","Human-centered computing;Visualization;Visualization application domains;Information visualization;Empirical studies in visualization","Visualization;Adaptive systems;Navigation;Conferences;Complexity theory","data visualisation;text analysis","gaze-driven links;magazine style narrative visualizations;textual information;visual information;dynamic guidance;gaze-driven adaptive guidance;dynamically links relevant sentences;adaptive links;MSNV","","","","29","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Gemini<sup>2</sup>: Generating Keyframe-Oriented Animated Transitions Between Statistical Graphics","Y. Kim; J. Heer",University of Washington; University of Washington,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","201","205","Complex animated transitions may be easier to understand when divided into separate, consecutive stages. However, effective staging requires careful attention to both animation semantics and timing parameters. We present Gemini<sup>2</sup>, a system for creating staged animations from a sequence of chart keyframes. Given only a start state and an end state, Gemini<sup>2</sup> can automatically recommend intermediate keyframes for designers to consider. The Gemini<sup>2</sup> recommendation engine leverages Gemini, our prior work, and GraphScape to itemize the given complex change into semantic edit operations and to recombine operations into stages with a guided order for clearly conveying the semantics. To evaluate Gemini<sup>2</sup>’s recommendations, we conducted a human-subject study in which participants ranked recommended animations from both Gemini<sup>2</sup> and Gemini. We find that Gemini<sup>2</sup>’s animation recommendation ranking is well aligned with subjects’ preferences, and Gemini<sup>2</sup> can recommend favorable animations that Gemini cannot support.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623291","H.5.2 [User Interfaces]: User Interfaces;Graphical user interfaces (GUI);H.5.m [Information Interfaces and Presentation]: Miscellaneous","Visualization;Conferences;Semantics;User interfaces;Animation;Timing;Engines","computational geometry;computer animation;data visualisation;graph theory;network theory (graphs);pattern clustering","animation recommendation ranking;2 recommendation engine leverages Gemini;staged animations;animation semantics;consecutive stages;separate stages;generating keyframe-oriented animated transitions","","","","30","","30 Nov 2021","","","IEEE","IEEE Conferences"
"GeoDualCNN: Geometry-supporting Dual Convolutional Neural Network for Noisy Point Clouds","M. Wei; H. Chen; Y. Zhang; H. Xie; Y. Guo; J. Wang","Instrument Science and Opto-electronic Engineering, Hefei University of Technology, 12513 Hefei, Anhui, China, 230009 (e-mail: mingqiang.wei@gmail.com); College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, JiangSu, China, 210016 (e-mail: chenhonghuacn@gmail.com); Institute of Advanced Integration Technology, Shenzhen Institutes of Advanced Technology Chinese Academy of Sciences, 85411 Shenzhen, Guangdong, China, (e-mail: yk.zhang1@siat.ac.cn); Department of Computing and Decision Sciences, Lingnan University, 34743 Hongkong, Hongkong, Hong Kong, (e-mail: hrxie@ln.edu.hk); National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China, (e-mail: ywguo@nju.edu.cn); College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China, (e-mail: davis.wjun@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We propose a geometry-supporting dual convolutional neural network (GeoDualCNN) for both point cloud normal estimation and denoising. GeoDualCNN fuses the geometry domain knowledge that the underlying surface of a noisy point cloud is piecewisely smooth with the fact that a point normal is properly defined only when local surface smoothness is guaranteed. Centered around this insight, we define the homogeneous neighborhood (HoNe) which stays clear of surface discontinuities, and associate each HoNe with a point whose geometry and normal orientation is mostly consistent with that of HoNe. Thus, we not only obtain initial estimates of the point normals by performing PCA on HoNes, but also for the first time optimize these initial point normals by learning the mapping from two proposed geometric descriptors to the ground-truth point normals. GeoDualCNN consists of two parallel branches that remove noise using the first geometric descriptor (a homogeneous height map, which encodes the point-position information), while preserving surface features using the second geometric descriptor (a homogeneous normal map, which encodes the point-normal information). Such geometry-supporting network architectures enable our model to leverage previous geometry expertise and to benefit from training data. Experiments with noisy point clouds show that GeoDualCNN outperforms the state-of-the-art methods in terms of both noise-robustness and feature preservation.","1941-0506","","10.1109/TVCG.2021.3113463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543583","GeoDualCNN;normal estimation;point cloud denoising;geometry domain knowledge;neural network","Three-dimensional displays;Geometry;Noise reduction;Estimation;Noise measurement;Convolutional neural networks;Principal component analysis","","","","","","","IEEE","21 Sep 2021","","","IEEE","IEEE Early Access Articles"
"GeoSneakPique: Visual Autocompletion for Geospatial Queries","V. Setlur; S. Battersby; T. Wong",Tableau Software; Tableau Software; Tableau Software,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","166","170","How many crimes occurred in the city center? And exactly which part of town is the “city center”? While location is at the heart of many data questions, geographic location can be difficult to specify in natural language (NL) queries. This is especially true when working with fuzzy cognitive regions or regions that may be defined based on data distributions instead of absolute administrative location (e.g., state, country). GeoSneakPique presents a novel method for using a mapping widget to support the NL query process, allowing users to specify location via direct manipulation with data-driven guidance on spatial distributions to help select the area of interest. Users receive feedback to help them evaluate and refine their spatial selection interactively and can save spatial definitions for re-use in subsequent queries. We conduct a qualitative evaluation of the GeoSneakPique that indicates the usefulness of the interface as well as opportunities for better supporting geospatial workflows in visual analysis tasks employing cognitive regions.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623324","Data-driven scaffolds;cognitive region;Human-centered computing;Visualization","Measurement;Heart;Visualization;Graphical models;Image color analysis;Query processing;Urban areas","cognition;data visualisation;geographic information systems;query processing","GeoSneakPique;visual autocompletion;geospatial queries;data questions;geographic location;natural language;fuzzy cognitive regions;data distributions;absolute administrative location;mapping widget;NL query process;direct manipulation;data-driven guidance;spatial distributions;spatial selection;spatial definitions;subsequent queries;geospatial workflows;visual analysis tasks","","","","46","CCBY","30 Nov 2021","","","IEEE","IEEE Conferences"
"Geodesic Tracks: Computing Discrete Geodesics with Track-based Steiner Point Propagation","W. Meng; S. Xin; C. Tu; S. -M. Chen; Y. He; W. Wang","School of Computer Science and Technology, Shandong University, 12589 Qindao, Shandong, China, (e-mail: longwuya@163.com); School of Computer Science and Technology, Shandong University, 12589 Qindao, Shandong, China, (e-mail: xinshiqing@sdu.edu.cn); School of Computer Science and Technology, Shandong University, 12589 Qindao, Shandong, China, (e-mail: chtu@sdu.edu.cn); School of Information and Technology, Qingdao University of Science and Technology, 66280 Qingdao, Shandong, China, (e-mail: csmqq@163.com); School of Computer Engineering, Nanyang Technological University, 54761 Singapore, Singapore, Singapore, (e-mail: yhe@ntu.edu.sg); Dept. of Computer Science, Hong Kong University, 25809 Hong Kong, Hong Kong, Hong Kong, (e-mail: Wenping@cs.hku.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","This paper presents a simple yet effective method for computing geodesic distances on triangle meshes. Unlike the popular window propagation methods that partition mesh edges into intervals of varying lengths, our method places evenly-spaced, source-independent Steiner points on edges. Given a source vertex, our method constructs a Steiner-point graph that partitions the surface into mutually exclusive tracks, called geodesic tracks. Inside each triangle, the tracks form sub-regions in which the change of distance field is approximately linear. Our method does not require any pre-computation, and can effectively balance speed and accuracy. Experimental results show that with 5 Steiner points on each edge, the mean relative error is less than 0.3%. Thanks to a set of effective filtering rules, our method can eliminate lots of useless broadcast events. For a 1000K-face model, our method runs 10 times faster than the conventional Steiner point method that examines a complete graph of Steiner points in each triangle. We also observe that using more Steiner points increases the accuracy at only a small extra computational cost. Our method works well for meshes with poor triangulation and non-manifold configuration, which often poses challenges to the existing PDE methods. We show that geodesic tracks, as a new data structure that encodes rich information of discrete geodesics, support accurate geodesic path and isoline tracing, and efficient distance query. Our method can be easily extended to meshes with non-constant density functions and/or anisotropic metrics.","1941-0506","","10.1109/TVCG.2021.3109042","Singapore Ministry of Education Grants(grant numbers:RG20/20,T2EP20220-0014); National Natural Science Foundation of China(grant numbers:61772016,61772318,62002190,62072284); the Key Program of Shandong Provincial Natural Science Foundation(grant numbers:2020ZLYS01); NSF of Shandong Province China(grant numbers:ZR2020MF036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527080","Discrete geodesics;shortest paths;geodesic tracks;Steiner points;ridge points","Steiner trees;Approximation algorithms;Partitioning algorithms;Faces;Measurement;Data structures;Computer science","","","","","","","IEEE","1 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Geometry-Aware Planar Embedding of Treelike Structures","P. Hu; S. Boorboor; J. Marino; A. E. Kaufman","Computer Science, Stony Brook University, 12301 Stony Brook, New York, United States, 11794; Computer Science, Stony Brook University, Stony Brook, New York, United States; Computer Science, Stony Brook University, Port Jefferson Station, New York, United States; Computer Science, Stony Brook University, Stony Brook, New York, United States","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","The growing complexity of spatial and structural information in 3D data makes data inspection and visualization a challenging task. We describe a method to create a planar embedding of 3D treelike structures using their skeleton representations. Our method maintains the original geometry, without overlaps, to the best extent possible, allowing exploration of the topology within a single view. We present a novel camera view generation method which maximizes the visible geometric attributes (segment shape and relative placement between segments). Camera views are created for individual segments and are used to determine local bending angles at each node by projecting them to 2D. The final embedding is generated by minimizing an energy function (the weights of which are user adjustable) based on branch length and the 2D angles, while avoiding intersections. The user can also interactively modify segment placement within the 2D embedding, and the overall embedding will update accordingly. A global to local interactive exploration is provided using hierarchical camera views that are created for subtrees within the structure. We evaluate our method both qualitatively and quantitatively and demonstrate our results by constructing planar visualizations of line data (traced neurons) and volume data (CT vascular and bronchial data).","1941-0506","","10.1109/TVCG.2022.3153871","Office of Advanced Cyberinfrastructure(grant numbers:1919752); Division of Computer and Network Systems(grant numbers:1650499); Integrative and Collaborative Education and Research(grant numbers:1940302); Division of Information and Intelligent Systems(grant numbers:2107224); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721643","Geometry-based techniques;camera view generation;planar embedding;biomedical visualization","Three-dimensional displays;Data visualization;Topology;Shape;Skeleton;Cameras;Morphology","","","","","","","IEEE","25 Feb 2022","","","IEEE","IEEE Early Access Articles"
"Geometry-guided Dense Perspective Network for Speech-Driven Facial Animation","J. Liu; B. Hui; K. Li; Y. Liu; Y. -K. Lai; Y. Zhang; Y. Liu; J. Yang","College of Intelligence and Computing, Tianjin University, Tianjin, Tianjin, China, (e-mail: 981132775@qq.com); College of Intelligence and Computing, Tianjin University, Tianjin, Tianjin, China, (e-mail: huybery@gmail.com); College of Intelligence and Computing, Tianjin University, Tianjin, Tianjin, China, (e-mail: lik@tju.edu.cn); College of Intelligence and Computing, Tianjin University, Tianjin, Tianjin, China, (e-mail: 787782917@qq.com); Computer Science and Informatics, Cardiff University, Cardiff, Wales, United Kingdom of Great Britain and Northern Ireland, CF24 3AA (e-mail: Yukun.Lai@cs.cardiff.ac.uk); Department of Automation, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: yx-z19@mails.tsinghua.edu.cn); Automation, Tsinghua University, 12442 Beijing, Beijing, China, 100084 (e-mail: liuyebin@mail.tsinghua.edu.cn); School of Electronic Information Engineering, Tianjin University, Tianjin, Tianjin, China, 300072 (e-mail: yjy@tju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Realistic speech-driven 3D facial animation is a challenging problem due to the complex relationship between speech and face. In this paper, we propose a deep architecture, called Geometry-guided Dense Perspective Network (GDPnet), to achieve speaker-independent realistic 3D facial animation. The encoder is designed with dense connections to strengthen feature propagation and encourage the re-use of audio features, and the decoder is integrated with an attention mechanism to adaptively recalibrate point-wise feature responses by explicitly modeling interdependencies between different neuron units. We also introduce a non-linear face reconstruction representation as a guidance of latent space to obtain more accurate deformation, which helps solve the geometry-related deformation and is good for generalization across subjects. Huber and HSIC (Hilbert-Schmidt Independence Criterion) constraints are adopted to promote the robustness of our model and to better exploit the non-linear and high-order correlations. Experimental results on the public dataset and real scanned dataset validate the superiority of our proposed GDPnet compared with state-of-the-art model. We will make the code available for research purposes.","1941-0506","","10.1109/TVCG.2021.3107669","National Natural Science Foundation of China(grant numbers:62171317, 62122058, 61771339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524465","Speech-driven;3D Facial Animation;Geometry-guided;Speaker-independent","Three-dimensional displays;Facial animation;Solid modeling;Faces;Geometry;Correlation;Decoding","","","","","","","IEEE","27 Aug 2021","","","IEEE","IEEE Early Access Articles"
"Global Beautification of 2D and 3D Layouts With Interactive Ambiguity Resolution","P. Xu; G. Yan; H. Fu; T. Igarashi; C. -L. Tai; H. Huang","Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Visual Computing Research Center (VCC), Shenzhen University, Shenzhen, Guangdong, China; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Visual Computing Research Center (VCC), Shenzhen University, Shenzhen, Guangdong, China; City University of Hong Kong, Kowloon, Hong Kong; University of Tokyo, Bunkyo City, Tokyo, Japan; Hong Kong University of Science & Technology, Kowloon, Hong Kong; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Visual Computing Research Center (VCC), Shenzhen University, Shenzhen, Guangdong, China","IEEE Transactions on Visualization and Computer Graphics","26 Feb 2021","2021","27","4","2355","2368","Specifying precise relationships among graphic elements is often a time-consuming process with traditional alignment tools. Automatic beautification of roughly designed layouts can provide a more efficient solution but often lead to undesired results due to ambiguity problems. To facilitate ambiguity resolution in layout beautification, we present a novel user interface for visualizing and editing inferred relationships through an automatic global layout beautification process. First, our interface provides a preview of the beautified layout with inferred constraints without directly modifying an input layout. In this way, the user can easily keep refining beautification results by interactively repositioning and/or resizing elements in the input layout. Second, we present a gestural interface for editing automatically inferred constraints by directly interacting with the visualized constraints via simple gestures. Our technique is applicable to both 2D and 3D global layout beautification, supported by efficient system implementation that provides instant user feedback. Our user study validates that our tool is capable of creating, editing, and refining layouts of graphic elements, and is significantly faster than the standard snap-dragging or command-based alignment tools for both 2D and 3D layout tasks.","1941-0506","","10.1109/TVCG.2019.2954321","National Natural Science Foundation of China(grant numbers:61602310,61761146002,61861130365); GD Higher Education Innovation Key Program(grant numbers:2018KZDXM058); GD Science and Technology Program(grant numbers:2015A030312015); Shenzhen Innovation Program(grant numbers:JCYJ20170302154106666); LHTD(grant numbers:20170003); Research Grants Council of HKSAR(grant numbers:HKUST16210718); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906136","Global beautification;layout editing;snapping;alignment;ambiguity resolution;gestural interface","Layout;Tools;Three-dimensional displays;Two dimensional displays;User interfaces;Visualization","data visualisation;gesture recognition;user interfaces","global beautification;interactive ambiguity resolution;graphic elements;automatic beautification;ambiguity problems;user interface;inferred relationships;automatic global layout beautification process;beautified layout;resizing elements;gestural interface;visualized constraints;3D global layout beautification;instant user feedback;user study validates;3D layout tasks;interactive repositioning;automatically inferred constraints;2D global layout beautification","","","","38","IEEE","19 Nov 2019","","","IEEE","IEEE Journals"
"Graph-Based Information Block Detection in Infographic with Gestalt Organization Principles","J. Lin; Y. Cai; X. Wu; J. Lu","School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: se_jielin@mail.scut.edu.cn); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: ycai@scut.edu.cn); School of Software Engineering, South China University of Technology, 26467 GuangZhou, Guangdong, China, (e-mail: sexinwu@mail.scut.edu.cn); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: 202021046039@mail.scut.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","An infographic is a type of visualization chart that displays pieces of information through information blocks. Existing information block detection work utilizes spatial proximity to group elements into several information blocks. However, prior studies ignore the chromatic and structural features of the infographic, resulting in incorrect omissions when detecting information blocks. To alleviate this kind of error, we use a scene graph to represent an infographic and propose a graph-based information block detection model to group elements based on Gestalt Organization Principles (spatial proximity, chromatic similarity, and structural similarity principle). We also construct a new dataset for information block detection. Quantitative and qualitative experiments show that our model can detect the information blocks in the infographic more effectively compared with the spatial proximity-based method.","1941-0506","","10.1109/TVCG.2021.3130071","Natural Science Foundation of Guangdong Province(grant numbers:2019A1515012152); National Natural Science Foundation of China(grant numbers:61802130,62076100); the Fundamental Research Funds for the Central Universities SCUT(grant numbers:D2201300,D2210010); the Science and Technology Programs of Guangzhou(grant numbers:201902010046); the Science and Technology Planning Project of Guangdong Province(grant numbers:2020B0101100002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625765","Infographic;Deep Learning;Graph-Based Approach;Information Block Detection","Feature extraction;Visualization;Data visualization;Semantics;Organizations;Layout;Task analysis","","","","","","","IEEE","23 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Graphical Enhancements for Effective Exemplar Identification in Contextual Data Visualizations","X. Zhang; S. Cheng; K. Mueller","Computer Science, Stony Brook University College of Engineering and Applied Sciences, 189653 Stony Brook, New York, United States, 11794-2200; School of Engineering, Westlake University, 557712 Hangzhou, Hangzhou, China; Computer Science, State University of New York at Stony Brook, Stony Brook, New York, United States, 11794-4400","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","An exemplar is an entity that represents a desirable instance in a multi-attribute configuration space. It offers certain strengths in some of its attributes without unduly compromising the strengths in other attributes. Exemplars are frequently sought after in real life applications, such as systems engineering, investment banking, drug advisory, product marketing and many others. We study a specific method for the visualization of multi-attribute configuration spaces, the Data Context Map (DCM), for its capacity in enabling users to identify proper exemplars. The DCM produces a 2D embedding where users can view the data objects in the context of the data attributes. We ask whether certain graphical enhancements can aid users to gain a better understanding of the attribute-wise tradeoffs and so select better exemplar sets. We conducted several user studies for three different graphical designs, namely iso-contour, value-shaded topographic rendering and terrain topographic rendering, and compare these with a baseline DCM display. As a benchmark we use an exemplar set generated via Pareto optimization which has similar goals but unlike humans can operate in the native high-dimensional data space. Our study finds that the two topographic maps are statistically superior to both the iso-contour and the DCM baseline display.","1941-0506","","10.1109/TVCG.2022.3170531","National Science Foundation(grant numbers:IIS 1527200,IIS 1941613); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9765327","High-dimensional data;multivariate data;contextual displays;exemplar generation;decision support;configuration space","Data visualization;Task analysis;Visualization;Optimization;Layout;Location awareness;Pareto optimization","","","","","","","IEEE","28 Apr 2022","","","IEEE","IEEE Early Access Articles"
"GridSet: Visualizing Individual Elements and Attributes for Analysis of Set-Typed Data","H. Chung; S. Nandhakumar; S. Yang","Computer Science, University of Alabama in Huntsville, 14843 Huntsville, Alabama, United States, (e-mail: hc0021@uah.edu); Computer Science, University of Alabama in Huntsville, 14843 Huntsville, Alabama, United States, (e-mail: sn0026@uah.edu); Information Science, Louisiana State University, 5779 Baton Rouge, Louisiana, United States, (e-mail: seungwonyang@lsu.edu)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","We present GridSet, a novel set visualization for exploring elements, their attributes, intersections, as well as entire sets. In this set visualization, each set representation is composed of glyphs, which represent individual elements and their attributes utilizing different visual encodings. In each set, elements are organized within a grid treemap layout that can provide space-efficient overviews of the elements structured by set intersections across multiple sets. These intersecting elements can be connected among sets through visual links. These visual representations for the individual set, elements, and intersection in GridSet facilitate novel interaction approaches for undertaking analysis tasks by utilizing both macroscopic views of sets, as well as microscopic views of elements and attribute details. In order to perform multiple set operations, GridSet supports a simple and straightforward process for set operations through dragging and dropping set objects. Our use cases involving two large set-typed datasets demonstrate that GridSet facilitates the exploration and identification of meaningful patterns and distributions of elements with respect to attributes and set intersections for solving complex analysis problems in set-typed data.","1941-0506","","10.1109/TVCG.2020.3047111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307276","","Data visualization;Visualization;Layout;Motion pictures;Image color analysis;Complexity theory;Aggregates","","","","","","","IEEE","24 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Guest Editor's Introduction: Special Section on Virtual Reality","A. Steed; W. Sherman; M. C. Lin","University College London, London, UK; Desert Research Institute, 2215 Raggio Parkway, Reno, NV; University of North Carolina, Computer Science Department, Sitterson Hall, CB#3175, Chapel Hill, NC 27599-3175","IEEE Transactions on Visualization and Computer Graphics","21 Mar 2008","2008","14","3","485","486","The four papers in this special section focus on the field of virtual reality. The papers are summarized here.","1941-0506","","10.1109/TVCG.2008.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4472705","","Virtual reality;Usability;Design engineering;Three dimensional displays;Two dimensional displays;Layout;Computer displays;Head;Switches;Augmented reality","","","Algorithms;Computer Graphics;Data Display;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Numerical Analysis, Computer-Assisted;Signal Processing, Computer-Assisted;User-Computer Interface","","","","","21 Mar 2008","","","IEEE","IEEE Journals"
"H-Matrix: Hierarchical Matrix for Visual Analysis of Cross-Linguistic Features in Large Learner Corpora","M. Shimabukuro; J. Zipf; M. El-Assady; C. Collins","Ontario Tech University; University of Konstanz; Ontario Tech University,University of Konstanz; Ontario Tech University","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","61","65","This paper presents a visualization technique for cross-linguistic error analysis in large learner corpora. H-Matrix combines a matrix, which is commonly used by linguists to investigate cross-linguistic patterns, with a tree diagram to aggregate and interactively re-weight the importance of matrix rows to create custom investigative views. Our technique can help experts to perform data operations, such as, feature aggregation, filtering, ordering and language comparison interactively without having to reprocess the data. H-Matrix dynamically links the high-level multi-language overview to the extracted textual examples, and a reading view where linguists can see the detected features in context, confirm and generate hypotheses.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933537","Linguistic visualization;learner corpora;matrix","Feature extraction;Linguistics;Data visualization;Visualization;Task analysis;Heating systems;Tools","computational linguistics;data visualisation;error analysis;feature extraction;matrix algebra;trees (mathematics)","cross-linguistic patterns;tree diagram;feature aggregation;h-Matrix;high-level multilanguage overview;hierarchical matrix;visual analysis;cross-linguistic features;visualization technique;cross-linguistic error analysis","","","","17","","19 Dec 2019","","","IEEE","IEEE Conferences"
"High-quality real-time raycasting and raytracing of streamtubes with sparse voxel octrees","T. McGraw",Purdue University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","21","25","Voxel-based rendering and signed distance function (SDF) raycasting have been active areas of graphics research recently because they simplify high-quality graphical effects like ambient occlusion and shadowing as compared to rasterization. Much work has centered around converting triangle meshes to sparse voxel octrees (SVOs) and developing memory efficient storage schemes but little exploration of the implications to scientific visualization has taken place. In this work we explore techniques for high-performance rendering of tubes, such as streamtubes used for visualizing vector fields and fiber tracts from diffusion tensor MRI. We first present our method for generating a voxelization of the tubes, and then describe several methods for rendering: raytracing a SVO storing straight tube segments in the leaves, and hybrid raytracing/raycasting a SVO storing curved tube segments. We discuss the tradeoffs inherent in these different representations and compare the rendering techniques and results. Compared to standard graphics pipeline approaches, like using the geometry shader, we achieve joining, capping, and smooth circular cross-sections with minimal additional effort.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331287","Human-centered computing;Visualization;Visualization application domains;Scientific visualization","Visualization;Tensors;Octrees;Rendering (computer graphics);Electron tubes;Standards;Shadow mapping","biomedical MRI;data visualisation;mesh generation;octrees;ray tracing","SVO storing straight tube segments;SVO storing curved tube segments;standard graphics pipeline approaches;high-quality real-time raycasting;sparse voxel octrees;voxel-based rendering;graphics research;high-quality graphical effects;ambient occlusion;triangle meshes;high-performance rendering;diffusion tensor MRI","","","","26","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Histogram binning revisited with a focus on human perception","R. Sahann; T. Müller; J. Schmidt","University of Vienna,Faculty of Computer Science,Austria; Data Science @ Uni Vienna, University of Vienna,Faculty of Computer Science,Austria; VRVis Zentrum für Virtual Reality und Visualisierung Forschungs-GmbH,Austria","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","66","70","This paper presents a quantitative user study to evaluate how well users can visually perceive the underlying data distribution from a histogram representation. We used different sample and bin sizes and four different distributions (uniform, normal, bimodal, and gamma). The study results confirm that, in general, more bins correlate with fewer errors by the viewers. However, upon a certain number of bins, the error rate cannot be improved by adding more bins. By comparing our study results with the outcomes of existing mathematical models for histogram binning (e.g., Sturges’ formula, Scott’s normal reference rule, the Rice Rule, or Freedman–Diaconis’ choice), we can see that most of them overestimate the number of bins necessary to make the distribution visible to a human viewer.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623301","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623301","empirical studies in visualization;histogram binning","Histograms;Error analysis;Conferences;Mathematical models","bin packing;data visualisation;image representation;statistical distributions","histogram binning;human perception;quantitative user study;data distribution;histogram representation;different sample;bin sizes;normal gamma;error rate;human viewer;bimodal gamma;uniform gamma","","","","26","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"How Immersion and Self-Avatars in VR Affect Learning Programming and Computational Thinking in Middle School Education","D. Parmar; L. Lin; N. Dsouza; S. Joerg; A. E. Leonard; S. B. Daily; S. Babu","Khoury College of Computer Sciences, Northeastern University, 1848 Boston, Massachusetts, United States, 02115-5005; School of Computing, Clemson University, 2545 Clemson, South Carolina, United States; Office of the Vice Provost for Diversity and Inclusion, Indiana University Bloomington, 1771 Bloomington, Indiana, United States; School of Computing, Clemson University, Clemson, South Carolina, United States; Eugene T. Moore School of Education, Clemson University, 2545 Clemson, South Carolina, United States; Department of Electrical & Computer Engineering and Computer Science, Duke University, 3065 Durham, North Carolina, United States; Human Centered Computing, Clemson University, Clemson, South Carolina, United States, 29534","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","We present an empirical evaluation of immersion and self-avatars as compared to desktop viewing in Virtual Reality (VR) for learning computer programming and computational thinking in middle school education using an educational VR simulation. Students were asked to programmatically choreograph dance performances for virtual characters within an educational desktop application we built earlier called Virtual Environment Interactions (VEnvI). As part of a middle school science class, 90 students from the 6th and 7th grades participated in our study. All students first visually programmed dance choreography for a virtual character they created in VEnvI on a laptop. Then, they viewed and interacted with the resulting dance performance in a between-subjects design in one of the three conditions. We compared and contrasted the benefits of embodied immersive virtual reality (EVR) viewing utilizing a head-mounted display with a body-scaled and gender-matched self-avatar, immersive virtual reality only (IVR) viewing, and desktop VR (NVR) viewing with VEnvI on pedagogical outcomes, programming performance, presence, and attitudes towards STEM and computational thinking. Results from a cognition questionnaire showed that, in the learning dimensions of Knowledge and Understanding (Bloom's taxonomy) as well as Multistructural (SOLO taxonomy), participants in EVR and IVR scored significantly higher than NVR. Also, participants in EVR scored significantly higher than IVR. We also discovered similar results in objective programming performance and presence scores in VEnvI. Furthermore, students' attitudes towards computer science, programming confidence, and impressions significantly improved to be the highest in EVR and then IVR as compared to NVR condition.","1941-0506","","10.1109/TVCG.2022.3169426","Division of Computer and Network Systems(grant numbers:1344228); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762800","Virtual reality;computer science education;embodied cognition;self-avatars;immersion;VR in middle school education","Programming profession;Cognition;Training;Task analysis;STEM;Solid modeling;Virtual environments","","","","","","","IEEE","25 Apr 2022","","","IEEE","IEEE Early Access Articles"
"How Learners Sketch Data Stories","R. Bhargava; D. Williams; C. D’Ignazio",Northeastern University; Northeastern University; MIT,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","196","200","Learning data storytelling involves a complex web of skills. Professional and academic educational offerings typically focus on the computational literacies required, but professionals in the field employ many non-technical methods; sketching by hand on paper is a common practice. This paper introduces and classifies a corpus of 101 data sketches produced by participants as part of a guided learning activity in informal and formal settings. We manually code each sketch against 12 metrics related to visual encodings, representations, and story structure. We find evidence for preferential use of positional and shape-based encodings, frequent use of symbolic and textual representations, and a high prevalence of stories comparing subsets of data. These findings contribute to our understanding of how learners sketch with data. This case study can inform tool design for learners, and help create educational programs that introduce novices to sketching practices used by experts.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623299","Human-centered computing Visualization design and evaluation methods;Social and professional topics Informal education","Measurement;Human computer interaction;Visualization;Educational programs;Codes;Design methodology;Conferences","computer aided instruction;computer literacy","story structure;shape-based encodings;symbolic representations;textual representations;educational programs;data stories;learning data storytelling;academic educational offerings;computational literacies;nontechnical methods;data sketches;guided learning activity;informal settings;visual encodings;professional offerings","","","","32","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Human-in-the-loop Extraction of Interpretable Concepts in Deep Learning Models","Z. Zhao; P. Xu; C. Scheidegger; L. Ren","University of Arizona, United States; Amazon AWS AI, United States; University of Arizona, United States; Bosch Research North America, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","780","790","The interpretation of deep neural networks (DNNs) has become a key topic as more and more people apply them to solve various problems and making critical decisions. Concept-based explanations have recently become a popular approach for post-hoc interpretation of DNNs. However, identifying human-understandable visual concepts that affect model decisions is a challenging task that is not easily addressed with automatic approaches. We present a novel human-in-the-Ioop approach to generate user-defined concepts for model interpretation and diagnostics. Central to our proposal is the use of active learning, where human knowledge and feedback are combined to train a concept extractor with very little human labeling effort. We integrate this process into an interactive system, ConceptExtract. Through two case studies, we show how our approach helps analyze model behavior and extract human-friendly concepts for different machine learning tasks and datasets and how to use these concepts to understand the predictions, compare model performance and make suggestions for model refinement. Quantitative experiments show that our active learning approach can accurately extract meaningful visual concepts. More importantly, by identifying visual concepts that negatively affect model performance, we develop the corresponding data augmentation strategy that consistently improves model performance.","1941-0506","","10.1109/TVCG.2021.3114837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552218","Visual Data Exploration;Deep Neural Network;Model Interpretation;Explainable AI","Visualization;Data models;Analytical models;Predictive models;Computational modeling;Deep learning;Task analysis","data visualisation;decision making;deep learning (artificial intelligence);explanation;human computer interaction;interactive systems","interpretable concepts;deep learning models;deep neural networks;DNN;critical decision making;concept-based explanations;post-hoc interpretation;human-understandable visual concepts;user-defined concepts;model interpretation;concept extractor;model behavior analysis;machine learning;active learning;human-in-the-loop extraction;human-friendly concept extraction;model diagnostics","Computer Graphics;Deep Learning;Humans;Machine Learning;Neural Networks, Computer","","","55","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Hybrid Grids for Sparse Volume Rendering","S. Zellmann; D. Meurer; U. Lang",University of Cologne; University of Cologne; University of Cologne,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","Shallow k-d trees are an efficient empty space skipping data structure for sparse volume rendering and can be constructed in real-time for moderately sized data sets. Larger volume data sets however require deeper k-d trees that sufficiently cull empty space but take longer to construct. In contrast to k-d trees, uniform grids have inferior culling properties but can be constructed in real-time. We propose a hybrid data structure that employs hierarchical subdivision at the root level and a uniform grid at the leaf level to balance construction and rendering times for sparse volume rendering. We provide a thorough evaluation of this spatial index and compare it to state of the art space skipping data structures.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933631","Computing methodologies;Visualization;Visualization application domains;Scientific visualization; Computing methodologies;Computer Graphics;Rendering;Ray tracing","Rendering (computer graphics);Data structures;Transfer functions;Graphics processing units;Vegetation;Real-time systems;Spatial indexes","data structures;grid computing;rendering (computer graphics);trees (mathematics)","hybrid grids;sparse volume rendering;uniform grid;inferior culling properties;hybrid data structure;rendering times;shallow k-d trees;empty space culling;empty space skipping data structure","","","","17","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Implicit Ray Casting of the Parallel Vectors Operator","R. Witschi; T. Günther","ETH,Department of Computer Science,Zurich,Switzerland; ETH,Department of Computer Science,Zurich,Switzerland","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","31","35","Feature extraction is an essential aspect of scientific data analysis, as it allows for a data reduction onto relevant structures. The extraction of such features from scalar and vector fields, however, can be computationally expensive and numerically challenging. In this paper, we concentrate on 3D line features in vector fields that are defined by the parallel vectors operator. Common examples are vortex corelines and hyperbolic trajectories, i.e., lines around which particles are rotating, or from which particles are repelled and attracted locally the strongest. In our work, we use a GPU volume rendering framework to calculate the lines on-the-fly via a parallel vectors implementation in the volume rendering kernels. We achieve real-time performance for the feature curve extraction, which enables interactive filtering and parameter adjustment.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00013","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331290","Scientific visualization;vortex extraction;parallel vectors","Visualization;Three-dimensional displays;Tensors;Feature extraction;Rendering (computer graphics);Trajectory;Acceleration","data analysis;data visualisation;feature extraction;graphics processing units;parallel processing;rendering (computer graphics);vectors","3D line features;vector fields;parallel vectors operator;feature curve extraction;implicit ray casting;scientific data analysis;data reduction;GPU volume rendering framework;interactive filtering;volume rendering kernels;parameter adjustment","","","","36","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Improving Engagement of Animated Visualization with Visual Foreshadowing","W. Li; Y. Wang; H. Zhang; H. Qu",The Hong Kong University of Science and Technology; Microsoft Research Asia; Microsoft Research Asia; The Hong Kong University of Science and Technology,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","141","145","Animated visualization is becoming increasingly popular as a compelling way to illustrate changes in time series data. However, maintaining the viewer's focus throughout the entire animation is difficult because of its time-consuming nature. Viewers are likely to become bored and distracted during the ever-changing animated visualization. Informed by the role of foreshadowing that builds the expectation in film and literature, we introduce visual foreshadowing to improve the engagement of animated visualizations. In specific, we propose designs of visual foreshadowing that engage the audience while watching the animation. To demonstrate our approach, we built a proof-of-concept animated visualization authoring tool that incorporates visual foreshadowing techniques with various styles. Our user study indicates the effectiveness of our foreshadowing techniques on improving engagement for animated visualization.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331276","Human-centered computing—Visualization— Visualization design and evaluation methods;Computing methodologies—Computer graphics—Animation","Visualization;Design methodology;Time series analysis;Data visualization;Animation;Timing;Pattern recognition","authoring systems;computer animation;data visualisation;time series","time-consuming nature;visual foreshadowing techniques;proof-of-concept animated visualization authoring tool;entire animation","","","","32","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Inspecting the Process of Bank Credit Rating via Visual Analytics","Q. Liu; Q. Li; Z. Zhu; T. Ye; X. Ma","ShanghaiTech University,China; ShanghaiTech University,China; Tencent,China; Tencent,China; The Hong Kong University of Science and Technology,Hong Kong,China","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","136","140","Bank credit rating classifies banks into different levels based on publicly disclosed and internal information, serving as an important input in financial risk management. However, domain experts have a vague idea of exploring and comparing different bank credit rating schemes. A loose connection between subjective and quantitative analysis and difficulties in determining appropriate indicator weights obscure understanding of bank credit ratings. Furthermore, existing models fail to consider bank types by just applying a unified indicator weight set to all banks. We propose RatingVis to assist experts in exploring and comparing different bank credit rating schemes. It supports interactively inferring indicator weights for banks by involving domain knowledge and considers bank types in the analysis loop. We conduct a case study with real-world bank data to verify the efficacy of RatingVis. Expert feedback suggests that our approach helps them better understand different rating schemes.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623312","Human-centered computing;Visualization","Statistical analysis;Visual analytics;Conferences;Data visualization;Risk management","bank data processing;banking;data analysis;data visualisation;decision making;financial management;fuzzy set theory;risk management","different bank credit rating schemes;appropriate indicator weights obscure understanding;bank types;real-world bank data;different rating schemes","","","","32","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Interactive Data Comics","Z. Wang; H. Romat; F. Chevalier; N. H. Riche; D. Murray-Rust; B. Bach","University of Edinburgh, Scotland; ETH Zurich, Switzerland; University of Toronto, Canada; Microsoft Research, United States; TU Delft, Netherlands; University of Edinburgh, Scotland","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","944","954","This paper investigates how to make data comics interactive. Data comics are an effective and versatile means for visual communication, leveraging the power of sequential narration and combined textual and visual content, while providing an overview of the storyline through panels assembled in expressive layouts. While a powerful static storytelling medium that works well on paper support, adding interactivity to data comics can enable non-linear storytelling, personalization, levels of details, explanations, and potentially enriched user experiences. This paper introduces a set of operations tailored to support data comics narrative goals that go beyond the traditional linear, immutable storyline curated by a story author. The goals and operations include adding and removing panels into pre-defined layouts to support branching, change of perspective, or access to detail-on-demand, as well as providing and modifying data, and interacting with data representation, to support personalization and reader-defined data focus. We propose a lightweight specification language, COMICSCRIPT, for designers to add such interactivity to static comics. To assess the viability of our authoring process, we recruited six professional illustrators, designers and data comics enthusiasts and asked them to craft an interactive comic, allowing us to understand authoring workflow and potential of our approach. We present examples of interactive comics in a gallery. This initial step towards understanding the design space of interactive comics can inform the design of creation tools and experiences for interactive storytelling.","1941-0506","","10.1109/TVCG.2021.3114849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552591","Data comics;Non-linear narrative;interactive storytelling","Data visualization;Tools;Layout;Visualization;Media;Space exploration;Navigation","authoring systems;computer games;data visualisation;formal specification;interactive systems;specification languages","interactive data comics;textual content;visual content;powerful static storytelling medium;paper support;nonlinear storytelling;data comics narrative goals;data representation;reader-defined data focus;static comics;data comics enthusiasts;interactive comics;interactive storytelling","","","","108","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Interactive Deep Colorization and its Application for Image Compression","Y. Xiao; J. Wu; J. Zhang; P. Zhou; Y. Zheng; C. -S. Leung; L. Kavan","Hunan University, Changsha, Hunan, China; Hunan University, Changsha, Hunan, China; Hunan University, Changsha, Hunan, China; Hunan University, Changsha, Hunan, China; Hunan University, Changsha, Hunan, China; City University of Hong Kong, Kowloon Tong, Hong Kong; University of Utah, Salt Lake City, UT, USA","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2022","2022","28","3","1557","1572","Recent methods based on deep learning have shown promise in converting grayscale images to colored ones. However, most of them only allow limited user inputs (no inputs, only global inputs, or only local inputs), to control the output colorful images. The possible difficulty lies in how to differentiate the influences of different inputs. To solve this problem, we propose a two-stage deep colorization method allowing users to control the results by flexibly setting global inputs and local inputs. The key steps include enabling color themes as global inputs by extracting <inline-formula><tex-math notation=""LaTeX"">$K$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href=""xiao-ieq1-3021510.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> mean colors and generating <inline-formula><tex-math notation=""LaTeX"">$K$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href=""xiao-ieq2-3021510.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-color maps to define a global theme loss, and designing a loss function to differentiate the influences of different inputs without causing artifacts. We also propose a color theme recommendation method to help users choose color themes. Based on the colorization model, we further propose an image compression scheme, which supports variable compression ratios in a single network. Experiments on colorization show that our method can flexibly control the colorized results with only a few inputs and generate state-of-the-art results. Experiments on compression show that our method achieves much higher image quality at the same compression ratio when compared to the state-of-the-art methods.","1941-0506","","10.1109/TVCG.2020.3021510","National Key Research and Development Program of China(grant numbers:2018YFB0203904); National Natural Science Foundation of China(grant numbers:61872137,61803150); Natural Science Foundation of Hunan Province(grant numbers:2020JJ4009,2018JJ3067); China Scholarship Council(grant numbers:201806135087); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186041","Deep convolutional neural network;interactive;residual learning;image colorization;image compression","Image color analysis;Image coding;Gray-scale;Color;Histograms;Loss measurement;Image quality","data compression;deep learning (artificial intelligence);image coding;image colour analysis","colorization model;image compression scheme;image quality;interactive deep colorization;deep learning;grayscale images;user inputs;global inputs;local inputs;output colorful images;deep colorization method;color themes;KK mean colors;global theme loss;color theme recommendation method;compression ratio","","","","69","IEEE","3 Sep 2020","","","IEEE","IEEE Journals"
"Interactive Visual Pattern Search on Graph Data via Graph Representation Learning","H. Song; Z. Dai; P. Xu; L. Ren","Robert Bosch Research and Technology Center, USA; ByteDance Inc., China; Amazon AWS AI, United States; Robert Bosch Research and Technology Center, USA","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","335","345","Graphs are a ubiquitous data structure to model processes and relations in a wide range of domains. Examples include control-flow graphs in programs and semantic scene graphs in images. Identifying subgraph patterns in graphs is an important approach to understand their structural properties. We propose a visual analytics system GraphQ to support human-in-the-loop, example-based, subgraph pattern search in a database containing many individual graphs. To support fast, interactive queries, we use graph neural networks (GNNs) to encode a graph as fixed-length latent vector representation, and perform subgraph matching in the latent space. Due to the complexity of the problem, it is still difficult to obtain accurate one-to-one node correspondences in the matching results that are crucial for visualization and interpretation. We, therefore, propose a novel GNN for node-alignment called NeuroAlign, to facilitate easy validation and interpretation of the query results. GraphQ provides a visual query interface with a query editor and a multi-scale visualization of the results, as well as a user feedback mechanism for refining the results with additional constraints. We demonstrate GraphQ through two example usage scenarios: analyzing reusable subroutines in program workflows and semantic scene graph search in images. Quantitative experiments show that NeuroAlign achieves 19%-29% improvement in node-alignment accuracy compared to baseline GNN and provides up to 100× speedup compared to combinatorial algorithms. Our qualitative study with domain experts confirms the effectiveness for both usage scenarios.","1941-0506","","10.1109/TVCG.2021.3114857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552902","Graph;Graph Neural Network;Representation Learning;Visual Query Interface","Task analysis;Semantics;Visual analytics;Graph neural networks;Computational modeling;Visual databases;Pattern matching","data structures;data visualisation;graph theory;learning (artificial intelligence);neural nets;query processing;vectors","interactive visual pattern search;graph data;graph representation learning;ubiquitous data structure;control-flow graphs;semantic scene graphs;structural properties;visual analytics system GraphQ;subgraph pattern search;interactive queries;graph neural networks;fixed-length latent vector representation;subgraph matching;latent space;node correspondences;node-alignment;visual query interface;query editor;multiscale visualization;semantic scene graph search;NeuroAlign","","","","83","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Intercept Graph: An Interactive Radial Visualization for Comparison of State Changes","S. Ruan; Y. Wang; Q. Guan",Kent State University; Singapore Management University; Kent State University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","111","115","State change comparison of multiple data items is often necessary in multiple application domains, such as medical science, financial engineering, sociology, biological science, etc. Slope graphs and grouped bar charts have been widely used to show a “before-and-after” story of different data states and indicate their changes. However, they visualize state changes as either slope or difference of bars, which has been proved less effective for quantitative comparison. Also, both visual designs suffer from visual clutter issues with an increasing number of data items. In this paper, we propose Intercept Graph, a novel visual design to facilitate effective interactive comparison of state changes. Specifically, a radial design is proposed to visualize the starting and ending states of each data item and the line segment length explicitly encodes the “state change By interactively adjusting the radius of the inner circular axis, Intercept Graph can smoothly filter the large state changes and magnify the difference between similar state changes, mitigating the visual clutter issues and enhancing the effective comparison of state changes. We conducted a case study through comparing Intercept Graph with slope graphs and grouped bar charts on real datasets to demonstrate the effectiveness of Intercept Graph.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623307","Ministry of Education; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623307","Visual representation design;Interaction;State change comparison;Radial visualization","Visualization;Conferences;Sociology;Data visualization;Focusing;Tools;Clutter","data visualisation;graph theory","interactive radial visualization;state change comparison;multiple data items;slope graphs;grouped bar charts;data states;visual clutter issues;starting ending states;intercept graph","","","","23","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"JPEG Robust Invertible Grayscale","K. Liu; D. Chen; J. Liao; W. Zhang; H. Zhou; J. Zhang; W. Zhou; N. Yu","School of cyber science and engineering, University of Science and Technology of China, 12652 Hefei, Anhui, China, 230026 (e-mail: lkl6949@mail.ustc.edu.cn); Microsoft Research, Microsoft Research, 214606 Redmond, Washington, United States, (e-mail: cddlyf@gmail.com); CSE, cityu of Hong Kong, Hong Kong, Kowloon, Hong Kong, (e-mail: jingliao@cityu.edu.hk); Information Security, University of Science and Technology, Hefei, Anhui, China, (e-mail: zhangwm@ustc.edu.cn); Information Security, University of Science and Technology, Hefei, Anhui, China, (e-mail: zh2991@mail.ustc.edu.cn); the Department of Electronic Engineering and Information Science, University of Science and Technology of China, 12652 Hefei, Anhui, China, (e-mail: zjzac@mail.ustc.edu.cn); the Department of Electronic Engineering and Information Science, University of Science and Technology of China, 12652 Hefei, Anhui, China, (e-mail: welbeckz@mail.ustc.edu.cn); Elec. Engi. & Infor. Sci., Univ. of Sci. & Tech. of China, Information Processing Center, Hefei, Anhui, China, (e-mail: ynh@ustc.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Invertible grayscale is a special kind of grayscale from which the original color can be recovered. Given an input color image, this seminal work tries to hide the color information into its grayscale counterpart while making it hard to recognize any anomalies. This powerful functionality is enabled by training a hiding sub-network and restoring sub-network in an end-to-end way. Despite its expressive results, two key limitations exist: 1) The restored color image often suffers from some noticeable visual artifacts in the smooth regions. 2) It is very sensitive to JPEG compression, i.e., the original color information cannot be well recovered once the intermediate grayscale image is compressed by JPEG. To overcome these two limitations, this paper introduces adversarial training and JPEG simulator respectively. Specifically, two auxiliary adversarial networks are incorporated to make the intermediate grayscale images and final restored color images indistinguishable from normal grayscale and color images. And the JPEG simulator is utilized to simulate real JPEG compression during the online training so that the hiding and restoring sub-networks can automatically learn to be JPEG robust. Extensive experiments demonstrate that the proposed method is superior to the original invertible grayscale work both qualitatively and quantitatively while ensuring the JPEG robustness. We further show that the proposed framework can be applied under different types of grayscale constraints and achieve excellent results.","1941-0506","","10.1109/TVCG.2021.3088531","Anhui Science Foundation of China(grant numbers:2008085QF296); Anhui Initiative in Quantum Information Technologies(grant numbers:AHY15040); National Natural Science Foundation of China(grant numbers:62002334,62072421,U20B2047); Central University Basic Research Fund of China(grant numbers:WK2100000018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453114","Invertible Grayscale;Adversarial Training;JPEG Robust","Gray-scale;Transform coding;Image color analysis;Image restoration;Color;Training;Image coding","","","","","","","IEEE","11 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Joint <italic>t</italic>-SNE for Comparable Projections of Multiple High-Dimensional Datasets","Y. Wang; L. Chen; J. Jo; Y. Wang","Shandong University, CN, China; Shandong University, CN, China; Sungkyunkwan University, KR, South Korea; Shandong University, CN, China","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","623","632","We present Joint t-Stochastic Neighbor Embedding (Joint t-SNE), a technique to generate comparable projections of multiple high-dimensional datasets. Although t-SNE has been widely employed to visualize high-dimensional datasets from various domains, it is limited to projecting a single dataset. When a series of high-dimensional datasets, such as datasets changing over time, is projected independently using t-SNE, misaligned layouts are obtained. Even items with identical features across datasets are projected to different locations, making the technique unsuitable for comparison tasks. To tackle this problem, we introduce edge similarity, which captures the similarities between two adjacent time frames based on the Graphlet Frequency Distribution (GFD). We then integrate a novel loss term into the t-SNE loss function, which we call vector constraints, to preserve the vectors between projected points across the projections, allowing these points to serve as visual landmarks for direct comparisons between projections. Using synthetic datasets whose ground-truth structures are known, we show that Joint t-SNE outperforms existing techniques, including Dynamic t-SNE, in terms of local coherence error, Kullback-Leibler divergence, and neighborhood preservation. We also showcase a real-world use case to visualize and compare the activation of different layers of a neural network.","1941-0506","","10.1109/TVCG.2021.3114765","NSFC(grant numbers:61772315,61861136012); Open Project Program of State Key Laboratory of Virtual Reality Technology and Systems, Beihang University(grant numbers:VRLAB2020C08); CAS(grant numbers:GJHZ1862); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552433","High-dimensional data;projection;embedding;t-stochastic neighbor embedding","Visualization;Task analysis;Optimization;Time measurement;Position measurement;Gain measurement;Distortion","data visualisation;feature extraction;network theory (graphs);stochastic processes;vectors","comparable projections;multiple high-dimensional datasets;single dataset;t-SNE loss function;projected points;synthetic datasets;dynamic t-SNE;joint t-stochastic neighbor embedding;joint t-SNE;misaligned layouts;graphlet frequency distribution;GFD;Kullback-Leibler divergence;neighborhood preservation;neural network","","","","44","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Just TYPEical: Visualizing Common Function Type Signatures in R","C. Moy; J. Belyakova; A. Turcotte; S. D. Bartolomeo; C. Dunne",Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","121","125","Data-driven approaches to programming language design are uncommon. Despite the availability of large code repositories, distilling semantically-rich information from programs remains difficult. Important dimensions, like run-time type data, are inscrutable without the appropriate tools. We contribute a task abstraction and interactive visualization, TYPEICAL, for programming language designers who are exploring and analyzing type information from execution traces. Our approach aids user understanding of function type signatures across many executions. Insights derived from our visualization are aimed at informing language design decisions - specifically of a new gradual type system being developed for the R programming language. A copy of this paper, along with all the supplemental material, is available at osf.io/mc6zt.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331268","Human-centered computing;Visualization","Computer languages;Conferences;Ecosystems;Data visualization;Tools;Task analysis","data visualisation;digital signatures;functional languages;program diagnostics;programming languages;R language;source code (software)","code repositories;task abstraction;interactive visualization;TYPEICAL;R programming language;programming language design;common function type signature visualization","","","","20","","1 Feb 2021","","","IEEE","IEEE Conferences"
"<italic>KG4Vis:</italic> A Knowledge Graph-Based Approach for Visualization Recommendation","H. Li; Y. Wang; S. Zhang; Y. Song; H. Qu","Hong Kong University of Science and Technology and Singapore Management University, Hong Kong; Singapore Management University, Singapore; Singapore Management University, Singapore; Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","195","205","Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data columns and visualization design choices) and the relations between them, to model the mapping rules between data and effective visualizations. A TransE-based embedding technique is employed to learn the embeddings of both entities and relations of the knowledge graph from existing dataset-visualization pairs. Such embeddings intrinsically model the desirable visualization rules. Then, given a new dataset, effective visualizations can be inferred from the knowledge graph with semantically meaningful rules. We conducted extensive evaluations to assess the proposed approach, including quantitative comparisons, case studies and expert interviews. The results demonstrate the effectiveness of our approach.","1941-0506","","10.1109/TVCG.2021.3114863","Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1(grant numbers:20-C220-SMU-011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552844","Data visualization;Visualization recommendation;Knowledge graph","Data visualization;Feature extraction;Tools;Manuals;Data models;Visualization;Interviews","data visualisation;graph theory;learning (artificial intelligence)","automatic visualization generation;effective data visualizations;existing rule-based approaches;tedious manual specifications;visualization experts;machine learning-based approaches;specific visualization;knowledge graph-based approach;visualization recommendation;visualization design choices;effective visualizations;TransE-based;dataset-visualization pairs;desirable visualization rules","","","","60","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Learning Physical Parameters and Detail Enhancement for Gaseous Scene Design Based on Data Guidance","C. Li; S. Qiu; C. Wang; H. Qin","East China Normal University, Shanghai, China; East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China; Department of Computer Science, Stony Brook University, Brook, NY, USA","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2021","2021","27","10","3867","3880","This article articulates a novel learning framework for both parameter estimation and detail enhancement for Eulerian gas based on data guidance. The key motivation of this article is to devise a new hybrid, grid-based simulation that could inherit modeling and simulation advantages from both physically-correct simulation methods and powerful data-driven methods, while combating existing difficulties exhibited in both approaches. We first employ a convolutional neural network (CNN) to estimate the physical parameters of gaseous phenomena in Eulerian settings, then we can use the just-learnt parameters to re-simulate (with or without artists' guidance) for specific scenes with flexible coupling effects. Next, a second CNN is adopted to reconstruct the high-resolution velocity field to guide a fast re-simulation on the finer grid, achieving richer and more realistic details with little extra computational expense. From the perspective of physics-based simulation, our trained networks respect temporal coherence and physical constraints. From the perspective of the data-driven machine-learning approaches, our network design aims at extracting a meaningful parameters and reconstructing visually realistic details. Additionally, our implementation based on parallel acceleration could significantly enhance the computational performance of every involved module. Our comprehensive experiments confirm the controllability, effectiveness, and accuracy of our novel approach when producing various gaseous scenes with rich details for widespread graphics applications.","1941-0506","","10.1109/TVCG.2020.2991217","National Natural Science Foundation of China(grant numbers:61532002,61672237); National Science Foundation(grant numbers:IIS-1715985,IIS-1812606); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082171","Computer graphics;physics-based modeling and simulation;neural networks for learning physical parameters and detail enhancement;gaseous scene design","Computational modeling;Data models;Numerical models;Parameter estimation;Couplings;Graphics;Deep learning","convolutional neural nets;image enhancement;image reconstruction;learning (artificial intelligence);realistic images","physical constraints;data-driven machine-learning approaches;network design;physical parameters;gaseous scene design;data guidance;learning framework;parameter estimation;Eulerian gas;grid-based simulation;physically-correct simulation methods;data-driven methods;convolutional neural network;CNN;just-learnt parameters;flexible coupling effects;high-resolution velocity field;physics-based simulation;temporal coherence","","","","57","IEEE","29 Apr 2020","","","IEEE","IEEE Journals"
"Learning from Deep Stereoscopic Attention for Simulator Sickness Prediction","M. Du; H. Cui; Y. Wang; H. Duh","Department of Computer Science and Information Technology, La Trobe University, 2080 Melbourne, Victoria, Australia, (e-mail: 19617849@students.latrobe.edu.au); Department of Computer Science and Information Technology, La Trobe University, 2080 Melbourne, Victoria, Australia, (e-mail: L.Cui@latrobe.edu.au); Department of Computer Science and Information Technology, La Trobe University, 2080 Melbourne, Victoria, Australia, (e-mail: yuan.wang@latrobe.edu.au); Department of Computer Science and Information Technology, La Trobe University, 2080 Melbourne, Victoria, Australia, (e-mail: b.duh@latrobe.edu.au)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Simulator sickness induced by 360 stereoscopic video contents is a prolonged challenging issue in Virtual Reality (VR) system. Current machine learning models for simulator sickness prediction ignore the underlying interdependencies and correlations across multiple visual features which may lead to simulator sickness. We propose a model for sickness prediction by automatic learning and adaptive integrating multi-level mappings from stereoscopic video features to simulator sickness scores. Firstly, saliency, optical flow and disparity features are extracted from videos to reflect the factors causing simulator sickness, including human attention area, motion velocity and depth information. Then, these features are embedded and fed into a 3-dimensional convolutional neural network (3D CNN) to extract the underlying multi-level knowledge which includes low-level and higher-order visual concepts, and global image descriptor. Finally, an attentional mechanism is exploited to adaptively fuse multi-level information with attentional weights for sickness score estimation. The proposed model is trained by an end-to-end approach and validated over a public dataset. Comparison results with state-of-the-art models and ablation studies demonstrated improved performance in terms of Root Mean Square Error (RMSE) and Pearson Linear Correlation Coefficient.","1941-0506","","10.1109/TVCG.2021.3115901","China Scholarship Council(grant numbers:201806030241); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551731","Stereoscopic video;simulator sickness;virtual reality;attention mechanism;3D CNN I49 [Image Processing and Computer Vision]: Applications; H51 [Information Interfaces and Presentation]: Multimedia Information Systems","Feature extraction;Stereo image processing;Visualization;Predictive models;Optical flow;Solid modeling;Three-dimensional displays","","","","","","","IEEE","28 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Lightweight Bilateral Convolutional Neural Networks for Interactive Single-Bounce Diffuse Indirect Illumination","H. Xin; S. Zheng; K. Xu; L. -Q. Yan","Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; Department of Computer Science, UC Santa Barbara, Santa Barbara, CA, USA","IEEE Transactions on Visualization and Computer Graphics","25 Feb 2022","2022","28","4","1824","1834","Physically correct, noise-free global illumination is crucial in physically-based rendering, but often takes a long time to compute. Recent approaches have exploited sparse sampling and filtering to accelerate this process but still cannot achieve interactive performance. It is partly due to the time-consuming ray sampling even at 1 sample per pixel, and partly because of the complexity of deep neural networks. To address this problem, we propose a novel method to generate plausible single-bounce indirect illumination for dynamic scenes in interactive framerates. In our method, we first compute direct illumination and then use a lightweight neural network to predict screen space indirect illumination. Our neural network is designed explicitly with bilateral convolution layers and takes only essential information as input (direct illumination, surface normals, and 3D positions). Also, our network maintains the coherence between adjacent image frames efficiently without heavy recurrent connections. Compared to state-of-the-art works, our method produces single-bounce indirect illumination of dynamic scenes with higher quality and better temporal coherence and runs at interactive framerates.","1941-0506","","10.1109/TVCG.2020.3023129","National Natural Science Foundation of China(grant numbers:61822204,61932003,61521002); Beijing Higher Institution Engineering Research Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194085","Real-time rendering;global illumination","Lighting;Neural networks;Rendering (computer graphics);Three-dimensional displays;Coherence;Monte Carlo methods;Lattices","","","Algorithms;Computer Graphics;Lighting;Neural Networks, Computer","","","49","IEEE","10 Sep 2020","","","IEEE","IEEE Journals"
"Local Latent Representation based on Geometric Convolution for Particle Data Feature Exploration.","H. Li; H. -W. Shen","Computer Science and Engineering, The Ohio State University, 2647 Columbus, Ohio, United States, 43210; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, United States","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Feature related particle data analysis plays an important role in many scientific applications such as fluid simulations, cosmology simulations and molecular dynamics. Compared to conventional methods that use hand-crafted feature descriptors, some recent studies focus on transforming the data into a new latent space, where features are easier to be identified, compared and extracted. However, it is challenging to transform particle data into latent representations, since the convolution neural networks used in prior studies require the data presented in regular grids. In this paper, we adopt Geometric Convolution, a neural network building block designed for 3D point clouds, to create latent representations for scientific particle data. These latent representations capture both the particle positions and their physical attributes in the local neighborhood so that features can be extracted by clustering in the latent space, and tracked by applying tracking algorithms such as mean-shift. We validate the extracted features and tracking results from our approach using datasets from three applications and show that they are comparable to the methods that define hand-crafted features for each specific dataset.","1941-0506","","10.1109/TVCG.2022.3159114","National Science Foundation Office of Advanced Cyberinfrastructure(grant numbers:2112606); Los Alamos National Laboratory(grant numbers:47145); National Science Foundation Division of Information and Intelligent Systems(grant numbers:1955764); UT-Battelle(grant numbers:4000159447); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9735308","Data transformation;Particle data;Feature extraction and tracking;Deep learning","Feature extraction;Neural networks;Point cloud compression;Data visualization;Convolution;Three-dimensional displays;Kernel","","","","","","","IEEE","15 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Localization and Completion for 3D Object Interactions","X. Zhao; R. Hu; H. Liu; T. Komura; X. Yang","School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong, China; School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi, China; School of informatics, Edinburgh University, Edinburgh, United Kingdom; School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi, China","IEEE Transactions on Visualization and Computer Graphics","30 Jun 2020","2020","26","8","2634","2644","Finding where and what objects to put into an existing scene is a common task for scene synthesis and robot/character motion planning. Existing frameworks require development of hand-crafted features suitable for the task, or full volumetric analysis that could be memory intensive and imprecise. In this paper, we propose a data-driven framework to discover a suitable location and then place the appropriate objects in a scene. Our approach is inspired by computer vision techniques for localizing objects in images: using an all directional depth image (ADD-image) that encodes the 360-degree field of view from samples in the scene, our system regresses the images to the positions where the new object can be located. Given several candidate areas around the host object in the scene, our system predicts the partner object whose geometry fits well to the host object. Our approach is highly parallel and memory efficient, and is especially suitable for handling interactions between large and small objects. We show examples where the system can hang bags on hooks, fit chairs in front of desks, put objects into shelves, insert flowers into vases, and put hangers onto laundry rack.","1941-0506","","10.1109/TVCG.2019.2892454","National Natural Science Foundation of China(grant numbers:61602366); China Postdoctoral Science Foundation(grant numbers:2015M582664); National Natural Science Foundation of China(grant numbers:61602311,61872250); Shenzhen Innovation Program(grant numbers:JCYJ20170302153208613); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611181","Scene synthesis;ADD-image;localization;interaction completion","Three-dimensional displays;Geometry;Shape;Convolution;Predictive models;Layout;Planning","control engineering computing;feature extraction;mobile robots;path planning;robot vision;solid modelling","computer vision techniques;object localization;directional depth image;ADD-image;host object;partner object;scene synthesis;hand-crafted features;volumetric analysis;data-driven framework;3D object interactions;robot character motion planning","","","","25","IEEE","13 Jan 2019","","","IEEE","IEEE Journals"
"Loch Prospector: Metadata Visualization for Lakes of Open Data","N. Makhija; M. Jain; N. Tziavelis; L. Di Rocco; S. Di Bartolomeo; C. Dunne",Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University; Northeastern University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","126","130","Data lakes are an emerging storage paradigm that promotes data availability over integration. A prime example are repositories of Open Data which show great promise for transparent data science. Due to the lack of proper integration, Data Lakes may not have a common consistent schema and traditional data management techniques fall short with these repositories. Much recent research has tried to address the new challenges associated with these data lakes. Researchers in this area are mainly interested in the structural proper-ties of the data for developing new algorithms, yet typical Open Data portals offer limited functionality in that respect and instead focus on data semantics. We propose Loch Prospector, a visualization to assist data management researchers in exploring and understanding the most crucial structural aspects of Open Data - in particular, metadata attributes - and the associated task abstraction for their work. Our visualization enables researchers to navigate the contents of data lakes effectively and easily accomplish what were previously laborious tasks. A copy of this paper with all supplemental material is available at osf.io/zkxv9.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331286","Human-centered computing;Visualization","Visualization;Data visualization;Lakes;Metadata;Task analysis;Usability;Open data","data visualisation;meta data;portals","data management researchers;data lakes;data availability;transparent data science;traditional data management techniques;Open Data portals;data semantics;loch prospector","","","","36","","1 Feb 2021","","","IEEE","IEEE Conferences"
"MV<sup>2</sup>Net: Multi-Variate Multi-View Brain Network Comparison over Uncertain Data","L. Shi; J. Hu; Z. Tan; J. Tao; J. Ding; Y. Jin; Y. Wu; P. Thompson","Computer Science and Engineering, Beihang University, 12633 Beijing, Beijing, China, (e-mail: shijim@gmail.com); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong, China, (e-mail: hujn3@mail2.sysu.edu.cn); Institute of Software, Chinese Academy of Sciences, Beijing, Beijing, China, (e-mail: zhihtan18@gmail.com); School of Data and Computer Science, Sun Yat-Sen University, 26469 Guangzhou, Guangdong, China, (e-mail: taoj23@mail.sysu.edu.cn); College of Design and Innovation, Tongji University, Shanghai, Shanghai, China, (e-mail: dingjy@tongji.edu.cn); Department of Radiation Oncology, The University of Texas MD Anderson Cancer Center, Houston, Texas, United States, (e-mail: yjinz@ucla.edu); Institute of Software Chinese Academy of Sciences, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, (e-mail: yanjun@iscas.ac.cn); Mark and Mary Stevens Institute for Neuroimaging and Informatics, University of Southern California, LA, California, United States, (e-mail: lynnpaul@earthlink.net)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Visually identifying effective bio-markers from human brain networks poses non-trivial challenges to the field of data visualization and analysis. Existing methods in the literature and neuroscience practice are generally limited to the study of individual connectivity features in the brain (e.g., the strength of neural connection among brain regions). Pairwise comparisons between contrasting subject groups (e.g., the diseased and the healthy controls) are normally performed. The underlying neuroimaging and brain network construction process is assumed to have 100% fidelity. Yet, real-world user requirements on brain network visual comparison lean against these assumptions. In this work, we present MV^2Net, a visual analytics system that tightly integrates multi-variate multi-view visualization for brain network comparison with an interactive wrangling mechanism to deal with data uncertainty. On the analysis side, the system integrates multiple extraction methods on diffusion and geometric connectivity features of brain networks, an anomaly detection algorithm for data quality assessment, single- and multi-connection feature selection methods for bio-marker detection. On the visualization side, novel designs are introduced which optimize network comparisons among contrasting subject groups and related connectivity features. Our design provides level-of-detail comparisons, from juxtaposed and explicit-coding views for subject group comparisons, to high-order composite view for correlation of network comparisons, and to fiber tract detail view for voxel-level comparisons. The proposed techniques are inspired and evaluated in expert studies, as well as through case analyses on diffusion and geometric bio-markers of certain neurology diseases. Results in these experiments demonstrate the effectiveness and superiority of MV^2Net over state-of-the-art approaches.","1941-0506","","10.1109/TVCG.2021.3098123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9492002","Brain network;visual comparison;multivariate analysis","Data visualization;Feature extraction;Diseases;Neuroimaging;Three-dimensional displays;Neuroscience;Heuristic algorithms","","","","","","","IEEE","20 Jul 2021","","","IEEE","IEEE Early Access Articles"
"Mapping the Global South: Equal-Area Projections for Choropleth Maps","G. M. León; M. Lischka; A. Breiter",University of Bremen; University of Bremen; University of Bremen,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","91","95","Choropleth maps are among the most common visualization techniques used to present geographical data. These maps require an equal-area projection but there are no clear criteria for selecting one. We collaborated with 20 social scientists researching on the Global South, interested in using choropleth maps, to investigate their design choices according to their research tasks. We asked them to design world choropleth maps through a survey, and analyzed their answers both qualitatively and quantitatively. The results suggest that the design choices of map projection, center, scale, and color scheme, were influenced by their personal research goals and the tasks. The projection was considered the most important choice and the Equal Earth projection was the most common projection used. Our study takes the first substantial step in investigating projection choices for world choropleth maps in applied visualization research.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00025","Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331278","Choropleth maps;equal-area projections;social sciences;Human-centered computing;Visualization;Visualization application domains;Visualization techniques","Earth;Image color analysis;Conferences;Data visualization;Task analysis","cartography;data visualisation;geographic information systems","equal-area projections;choropleth maps;equal-area projection;geographical data visualization;global south mapping;equal earth projection","","","","34","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Mesh Convolutional Networks with Face and Vertex Feature Operators","D. Perez; Y. Shen; J. Li","Computational Modeling and Simulation Engineering, Old Dominion University, 6042 Norfolk, Virginia, United States, 23529 (e-mail: dpere013@odu.edu); Virginia Modeling, Analysis, and Simulation Center, Old Dominion University, Norfolk, Virginia, United States, 23517 (e-mail: yshen@odu.edu); ECE, Old Dominion University, 6042 Norfolk, Virginia, United States, (e-mail: jli@odu.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Deep learning techniques have proven effective in many applications, but these implementations mostly apply to data in one or two dimensions. Handling 3D data is more challenging due to its irregularity and complexity, and there is a growing interest in adapting deep learning techniques to the 3D domain. A recent successful approach called MeshCNN consists of a set of convolutional and pooling operators applied to the edges of triangular meshes. While this approach produced superb results in classification and segmentation of 3D shapes, it can only be applied to edges of a mesh, which can constitute a disadvantage for applications where the focuses are other primitives of the mesh. In this study, we propose face-based and vertex-based operators for mesh convolutional networks. We design two novel architectures based on the MeshCNN network that can operate on faces and vertices of a mesh, respectively. We demonstrate that the proposed face-based architecture outperforms the original MeshCNN implementation in mesh classification and mesh segmentation, setting the new state of the art on benchmark datasets. In addition, we extend the vertex-based operator to fit in the Point2Mesh model for mesh reconstruction from clean, noisy, and incomplete point clouds. While no statistically significant performance improvements are observed, the model training and inference time are reduced by the proposed approach by 91% and 20%, respectively, as compared with the original Point2Mesh model.","1941-0506","","10.1109/TVCG.2021.3129156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619951","Class;IEEEtran;L A T E X;paper;style;template;typesetting","Conferences;Portable document format;Indexes;Typesetting;Loading;Web sites;Warranties","","","","","","","IEEE","18 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Molecumentary: Adaptable Narrated Documentaries Using Molecular Visualization","D. Kouril; O. Strnad; P. Mindek; S. Halladjian; T. Isenberg; E. Groeller; I. Viola","Faculty of Informatics, Masaryk University, 37748 Brno, Jihomoravsk, Czech Republic, (e-mail: dvdkouril@cg.tuwien.ac.at); Visual Computing Center, King Abdullah University of Science and Technology, 127355 Thuwal, Makkah, Saudi Arabia, (e-mail: ondrej.strnad@kaust.edu.sa); Institute of Visual Computing & Human-Centered Technology, TU Wien, 27259 Wien, Wien, Austria, 1040 (e-mail: mindek@cg.tuwien.ac.at); AVIZ, INRIA, Saclay, Ile-de-France, France, (e-mail: sarkis.halladjian@inria.fr); AVIZ, INRIA, Saclay, Ile-de-France, France, (e-mail: tobias.isenberg@inria.fr); Institute of Computer Graphics and Algorithms, Vienna University of Technology, A-1040 Vienna, Austria, Austria, A-1040 (e-mail: groeller@cg.tuwien.ac.at); Visual Computing Center, King Abdullah University of Science and Technology, 127355 Thuwal, Makkah, Saudi Arabia, 23955-6900 (e-mail: ivan.viola@kaust.edu.sa)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We present a method for producing documentary-style content using real-time scientific visualization. We introduce molecumentaries, i.e., molecular documentaries featuring structural models from molecular biology, created through adaptable methods instead of the rigid traditional production pipeline. Our work is motivated by the rapid evolution of scientific visualization and it potential in science dissemination. Without some form of explanation or guidance, however, novices and lay-persons often find it difficult to gain insights from the visualization itself. We integrate such knowledge using the verbal channel and provide it along an engaging visual presentation. To realize the synthesis of a molecumentary, we provide technical solutions along two major production steps: (1) preparing a story structure and (2) turning the story into a concrete narrative. In the first step, we compile information about the model from heterogeneous sources into a story graph. We combine local knowledge with external sources to complete the story graph and enrich the final result. In the second step, we synthesize a narrative, i.e., story elements presented in sequence, using the story graph. We then traverse the story graph and generate a virtual tour, using automated camera and visualization transitions. We turn texts written by domain experts into verbal representations using text-to-speech functionality and provide them as a commentary. Using the described framework, we synthesize fly-throughs with descriptions: automatic ones that mimic a manually authored documentary or semi-automatic ones which guide the documentary narrative solely through curated textual input.","1941-0506","","10.1109/TVCG.2021.3130670","King Abdullah University of Science and Technology(grant numbers:BAS/1/1680-01-01); Vienna Science and Technology Fund(grant numbers:VRG11-010); Agence Nationale de la Recherche(grant numbers:ANR-16-CE91-0011-01); Austrian Science Fund(grant numbers:I 2953-N31); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627526","Virtual tour;audio;biological data;storytelling;illustrative visualization","Data visualization;Visualization;Cameras;Three-dimensional displays;Animation;Real-time systems;Solid modeling","","","","","","","CCBY","25 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Multi-level Area Balancing of Clustered Graphs","H. -Y. Wu; M. Nollenburg; I. Viola","Institute of Visual Computing & Human-Centered Technology, TU Wien, 27259 Vienna, Vienna Austria (e-mail: hsiang.yun.wu@acm.org); Faculty of Informatics, TU Wien, Vienna, Vienna Austria (e-mail: noellenburg@ac.tuwien.ac.at); Visual Computing Center, King Abdullah University of Science and Technology, 127355 Thuwal, Makkah Saudi Arabia 23955-6900 (e-mail: ivan.viola@kaust.edu.sa)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","We present a multi-level area balancing technique for laying out clustered graphs to facilitate a comprehensive understanding of the complex relationships that exist in various fields, such as life sciences and sociology. Clustered graphs are often used to model relationships that are accompanied by attribute-based grouping information. Such information is essential for robust data analysis, such as for the study of biological taxonomies or educational backgrounds. Hence, the ability to smartly arrange textual labels and packing graphs within a certain screen space is therefore desired to successfully convey the attribute data . Here we propose to hierarchically partition the input screen space using Voronoi tessellations in multiple levels of detail. In our method, the position of textual labels is guided by the blending of constrained forces and the forces derived from centroidal Voronoi cells. The proposed algorithm considers three main factors: (1) area balancing, (2) schematized space partitioning, and (3) hairball management. We primarily focus on area balancing, which aims to allocate a uniform area for each textual label in the diagram. We achieve this by first untangling a general graph to a clustered graph through textual label duplication, and then coupling with spanning-tree-like visual integration. We illustrate the feasibility of our approach with examples and then evaluate our method by comparing it with well-known conventional approaches and collecting feedback from domain experts.","1941-0506","","10.1109/TVCG.2020.3038154","Vienna Science and Technology Fund(grant numbers:VRG11-010); King Abdullah University of Science and Technology(grant numbers:BAS/1/1680-01-01); H2020 Marie Sklodowska-Curie Actions(grant numbers:747985); Austrian Science Fund(grant numbers:P31119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262073","Graph drawing;Voronoi tessellation;multi-level;spatially-efficient layout","Layout;Visualization;Clustering algorithms;Data visualization;Shape;Partitioning algorithms;Chemical elements","","","","","","","CCBY","17 Nov 2020","","","IEEE","IEEE Early Access Articles"
"MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation","A. Wu; Y. Wang; M. Zhou; X. He; H. Zhang; H. Qu; D. Zhang","Hong Kong University of Science and Technology, Hong Kong; Microsoft Research Area, United States; Microsoft Research Area, United States; Microsoft Research Area, United States; Microsoft Research Area, United States; Hong Kong University of Science and Technology, Hong Kong; Microsoft Research Area, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","162","172","We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model, in turn, learns from provenance data of authoring logs in an offline manner. We compare our deep learning model with existing methods for visualization recommendation and conduct a user study to evaluate the usefulness of the system.","1941-0506","","10.1109/TVCG.2021.3114826","MSRA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552449","Visualization Recommendation;Deep Learning;Multiple-View;Dashboard;Mixed-Initiative;Visualization Provenance","Data visualization;Visualization;Encoding;Deep learning;Tools;Measurement;Layout","data visualisation;interactive systems;learning (artificial intelligence);recommender systems","creating charts;multiple-view visualizations;manually crafted design rules;deep learning approach;data columns;recommending multiple charts;deep learning model;optional user-input selections;provenance data;visualization recommendation;designing analytical dashboards;based recommendation;data table;data workers;tedious time-consuming process","","","","73","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Multicriteria Optimization for Dynamic Demers Cartograms","S. Nickel; M. Sondag; W. Meulemans; S. G. Kobourov; J. Peltonen; M. Nollenburg","Faculty of Informatics, TU Wien, Vienna, Vienna, Austria,; Computer Science and Engineering, Swansea University College of Science, 151376 Swansea, Swansea, United Kingdom of Great Britain and Northern Ireland,; Mathematics & Computer Science, TU Eindhoven, Eindhoven, Noord-Brabant, Netherlands,; Department of Computer Science, University of Arizona, Tucson, Arizona, United States, 85721; Faculty of Information Technology and Communication Sciences, Tampere University, 7840 Tampere, Pirkanmaa, Finland, 33100; Faculty of Informatics, TU Wien, Vienna, Vienna, Austria,","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Cartograms are popular for visualizing numerical data for administrative regions in thematic maps. When there are multiple data values per region (over time or from different datasets) shown as animated or juxtaposed cartograms, preserving the viewer's mental map in terms of stability between multiple cartograms is another important criterion alongside traditional cartogram criteria such as maintaining adjacencies. We present a method to compute stable stable Demers cartograms, where each region is shown as a square scaled proportionally to the given numerical data and similar data yield similar cartograms. We enforce orthogonal separation constraints using linear programming, and measure quality in terms of keeping adjacent regions close (cartogram quality) and using similar positions for a region between the different data values (stability). Our method guarantees the ability to connect most lost adjacencies with minimal-length planar orthogonal polylines. Experiments show that our method yields good quality and stability on multiple quality criteria.","1941-0506","","10.1109/TVCG.2022.3151227","Academy of Finland(grant numbers:327352); Nederlandse Organisatie voor Wetenschappelijk Onderzoek(grant numbers:639.023.20); National Science Foundation(grant numbers:CCF-1712119,DMS-1839274,CCF-1740858); Austrian Science Fund(grant numbers:P 31119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9713709","Time-varying data;Cartograms;Mental map preservation","Layout;Strain;Stability criteria;Visualization;Data visualization;Task analysis;Shape","","","","","","","CCBY","14 Feb 2022","","","IEEE","IEEE Early Access Articles"
"Multicriteria Scalable Graph Drawing via Stochastic Gradient Descent, (SGD)^2","R. Ahmed; F. De Luca; S. Devkota; S. G. Kobourov; M. Li","Computer science, The University of Arizona Department of Computer Science, 369108 Tucson, Arizona, United States, 85721-0077; Computer Science, The University of Arizona Department of Computer Science, 369108 Tucson, Arizona, United States; Computer Science, University of Arizona, 8041 Tucson, Arizona, United States, 85721-0001; Department of Computer Science, The University of Arizona Department of Computer Science, 369108 Tucson, Arizona, United States; Computer Science, University of Arizona Department of Computer Science, 369108 Tucson, Arizona, United States, 85721-0077","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Readability criteria, such as distance or neighborhood preservation, are often used to optimize node-link representations of graphs to enable the comprehension of the underlying data. With few exceptions, graph drawing algorithms typically optimize one such criterion, usually at the expense of others. We propose a layout approach, Multicriteria Scalable Graph Drawing via Stochastic Gradient Descent, (SGD)^2, that can handle multiple readability criteria. (SGD)^2 can optimize any criterion that can be described by a differentiable function. Our approach is flexible and can be used to optimize several criteria that have already been considered earlier (e.g., obtaining ideal edge lengths, stress, neighborhood preservation) as well as other criteria which have not yet been explicitly optimized in such fashion (e.g., node resolution, angular resolution, aspect ratio). The approach is scalable and can handle large graphs. A variation of the underlying approach can also be used to optimize many desirable properties in planar graphs, while maintaining planarity. Finally, we provide quantitative and qualitative evidence of the effectiveness of (SGD)^2: we analyze the interactions between criteria, measure the quality of layouts generated from (SGD)^2 as well as the runtime behavior, and analyze the impact of sample sizes. The source code is available on github and we also provide an interactive demo for small graphs.","1941-0506","","10.1109/TVCG.2022.3155564","National Science Foundation(grant numbers:CCF-1712119,CCF-1740858,DMS-1839274); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723546","Graph drawing;gradient descent;quality metrics","Layout;Stress;Optimization;Graph drawing;Minimization;Linear programming;Standards","","","","","","","IEEE","1 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Narrative Sensemaking: Strategies for Narrative Maps Construction","B. F. K. Norambuena; T. Mitra; C. North",Virginia Tech Universidad Católica del Norte; University of Washington; Virginia Tech,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","181","185","Narrative sensemaking is a fundamental process to understand sequential information. Narrative maps are a visual representation framework that can aid analysts in this process. They allow analysts to understand the big picture of a narrative, uncover new relationships between events, and model connections between storylines. As a sensemaking tool, narrative maps have applications in intelligence analysis, misinformation modeling, and computational journalism. In this work, we seek to understand how analysts construct narrative maps in order to improve narrative map representation and extraction methods. We perform an experiment with a data set of news articles. Our main contribution is an analysis of how analysts construct narrative maps. The insights extracted from our study can be used to design narrative map visualizations, extraction algorithms, and visual analytics tools to support the sensemaking process.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623296","Human-centered computing;Visualization;Empirical studies in visualization;Human-centered Visualization;Visualization techniques;Graph drawings","Training;Analytical models;Design methodology;Computational modeling;Visual analytics;Layout;Data visualization","data analysis;data visualisation;multimedia computing","narrative sensemaking;narrative maps construction;narrative map representation;extraction methods;narrative map visualizations;visual analytics tools;intelligence analysis;misinformation modeling;computational journalism;storylines","","","","34","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"NeuRegenerate: A Framework for Visualizing Neurodegeneration","S. Boorboor; S. Mathew; M. Ananth; D. Talmage; L. W. Role; A. E. Kaufman","Computer Science, Stony Brook University, Stony Brook, New York, United States, (e-mail: sboorboor@cs.stonybrook.edu); Computer Science, Stony Brook University, Stony Brook, New York, United States, (e-mail: shawmathew@cs.stonybrook.edu); National Institute of Neurological Disorders and Stroke, National Institutes of Health, 2511 Bethesda, Maryland, United States, (e-mail: mala.ananth@nih.gov); National Institute of Mental Health, National Institutes of Health, 2511 Bethesda, Maryland, United States, (e-mail: david.talmage@nih.gov); National Institute of Neurological Disorders and Stroke, National Institutes of Health, 2511 Bethesda, Maryland, United States, (e-mail: lorna.role@nih.gov); Computer Science, Stony Brook University, Stony Brook, New York, United States, (e-mail: ari@cs.stonybrook.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Recent advances in high-resolution microscopy have allowed scientists to better understand the underlying brain connectivity. However, due to the limitation that biological specimens can only be imaged at a single timepoint, studying changes to neural projections over time is limited to observations gathered using population analysis. In this paper, we introduce NeuRegenerate, a novel end-to-end framework for the prediction and visualization of changes in neural fiber morphology within a subject across specified age-timepoints. To predict projections, we present neuReGANerator, a deep-learning network based on cycle-consistent generative adversarial network that translates features of neuronal structures across age-timepoints for large brain microscopy volumes. We improve the reconstruction quality of the predicted neuronal structures by implementing a density multiplier and a new loss function, called the hallucination loss. Moreover, to alleviate artifacts that occur due to tiling of large input volumes, we introduce a spatial-consistency module in the training pipeline of neuReGANerator. Finally, to visualize the change in projections, predicted using neuReGANerator, NeuRegenerate offers two modes: (i) neuroCompare to simultaneously visualize the difference in the structures of the neuronal projections, from two age domains (using structural view and bounded view), and (ii) neuroMorph, a vesselness-based morphing technique to interactively visualize the transformation of the structures from one age-timepoint to the other. Our framework is designed specifically for volumes acquired using wide-field microscopy. We demonstrate our framework by visualizing the structural changes within the cholinergic system of the mouse brain between a young and old specimen.","1941-0506","","10.1109/TVCG.2021.3127132","Division of Information and Intelligent Systems(grant numbers:IIS2107224); Office of Advanced Cyberinfrastructure National Science Foundation(grant numbers:OAC1919752); Integrative Computing Education and Research(grant numbers:ICER1940302); Division of Computer and Network Systems(grant numbers:CNS1650499); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9610985","","Microscopy;Data visualization;Image reconstruction;Visualization;Neurites;Training;Three-dimensional displays","","","","","","","IEEE","10 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Neural Photometry-guided Visual Attribute Transfer","C. Rodriguez-Pardo; E. Garces","Computer Science and Engineering, Universidad Carlos III de Madrid, 16726 Madrid, Madrid, Spain, (e-mail: carlos.rodriguezpardo.jimenez@gmail.com); Computer Science and Engineering, Universidad Rey Juan Carlos, 16776 Madrid, Madrid, Spain, (e-mail: elenagarces@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We present a deep learning-based method for propagating spatially-varying visual material attributes (e.g. texture maps or image stylizations) to larger samples of the same or similar materials. For training, we leverage images of the material taken under multiple illuminations and a dedicated data augmentation policy, making the transfer robust to novel illumination conditions and affine deformations. Our model relies on a supervised image-to-image translation framework and is agnostic to the transferred domain; we showcase a semantic segmentation, a normal map, and a stylization. Following an image analogies approach, the method only requires the training data to contain the same visual structures as the input guidance. Our approach works at interactive rates, making it suitable for material edit applications. We thoroughly evaluate our learning methodology in a controlled setup providing quantitative measures of performance. Last, we demonstrate that training the model on a single material is enough to generalize to materials of the same type without the need for massive datasets.","1941-0506","","10.1109/TVCG.2021.3133081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9640557","Artificial intelligence;Artificial neural network;Machine vision;Image texture;Graphics;Computational photography","Visualization;Lighting;Training;Semantics;Image segmentation;Image color analysis;Geometry","","","","","","","IEEE","7 Dec 2021","","","IEEE","IEEE Early Access Articles"
"Neural Reflectance Capture in the View-Illumination Domain","K. Kang; M. Gu; C. Xie; X. Yang; H. Wu; K. Zhou","State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: cocoa_kang@zju.edu.cn); State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: 3140104738@zju.edu.cn); State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: 752936985@qq.com); State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: xuandayang@gmail.com); State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, 310058 (e-mail: hongzhi.wu@gmail.com); State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: kunzhou@acm.org)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We propose a novel framework to efficiently capture the unknown reflectance on a non-planar 3D object, by learning to probe the 4D view-lighting domain with a high-performance illumination multiplexing setup. The core of our framework is a deep neural network, specifically tailored to exploit the multi-view coherence for efficiency. It takes as input the photometric measurements of a surface point under learned lighting patterns at different views, automatically aggregates the information and reconstructs the anisotropic reflectance. We also evaluate the impact of different sampling parameters over our network. The effectiveness of our framework is demonstrated on high-quality reconstructions of a variety of physical objects, with an acquisition efficiency outperforming state-of-the-art techniques.","1941-0506","","10.1109/TVCG.2021.3117370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557800","multi-view illumination multiplexing;neural acquisition","Reflectivity;Lighting;Image reconstruction;Cameras;Light emitting diodes;Multiplexing;Light sources","","","","","","","IEEE","4 Oct 2021","","","IEEE","IEEE Early Access Articles"
"NeuroCartography: Scalable Automatic Visual Summarization of Concepts in Deep Neural Networks","H. Park; N. Das; R. Duggal; A. P. Wright; O. Shaikh; F. Hohman; D. H. Polo Chau","Georgia Institute of Technology, United States; Georgia Institute of Technology, United States; Georgia Institute of Technology, United States; Georgia Institute of Technology, United States; Georgia Institute of Technology, United States; Apple, United States; Georgia Institute of Technology, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","813","823","Existing research on making sense of deep neural networks often focuses on neuron-level interpretation, which may not adequately capture the bigger picture of how concepts are collectively encoded by multiple neurons. We present Neurocartography, an interactive system that scalably summarizes and visualizes concepts learned by neural networks. It automatically discovers and groups neurons that detect the same concepts, and describes how such neuron groups interact to form higher-level concepts and the subsequent predictions. Neurocartography introduces two scalable summarization techniques: (1) neuron clustering groups neurons based on the semantic similarity of the concepts detected by neurons (e.g., neurons detecting “dog faces” of different breeds are grouped); and (2) neuron embedding encodes the associations between related concepts based on how often they co-occur (e.g., neurons detecting “dog face” and “dog tail” are placed closer in the embedding space). Key to our scalable techniques is the ability to efficiently compute all neuron pairs' relationships, in time linear to the number of neurons instead of quadratic time. Neurocartography scales to large data, such as the ImageNet dataset with 1.2M images. The system's tightly coordinated views integrate the scalable techniques to visualize the concepts and their relationships, projecting the concept associations to a 2D space in Neuron Projection View, and summarizing neuron clusters and their relationships in Graph View. Through a large-scale human evaluation, we demonstrate that our technique discovers neuron groups that represent coherent, human-meaningful concepts. And through usage scenarios, we describe how our approaches enable interesting and surprising discoveries, such as concept cascades of related and isolated concepts. The Neurocartography visualization runs in modern browsers and is open-sourced.","1941-0506","","10.1109/TVCG.2021.3114858","DARPA(grant numbers:HR00112030001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552879","Deep learning interpretability;visual analytics;scalable summarization;neuron clustering;neuron embedding","Neurons;Dogs;Feature extraction;Visualization;Faces;Deep learning;Semantics","data visualisation;deep learning (artificial intelligence);graph theory;interactive systems;pattern clustering;public domain software","neuron-level interpretation;multiple neurons;higher-level concepts;dog face;dog tail;neuron pairs;concept associations;Neuron Projection View;human-meaningful concepts;concept cascades;scalable automatic visual summarization;deep neural networks;neurocartography visualization;neuron cluster summarization;interactive system;concept learning;concept semantic similarity;ImageNet dataset;graph view;neuron group discovery","Animals;Cluster Analysis;Computer Graphics;Dogs;Neural Networks, Computer;Neurons;Semantics","","","60","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"On the Potential of Zines as a Medium for Visualization","A. McNutt",University of Chicago,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","176","180","Zines are a form of small-circulation self-produced publication often akin to a magazine. This free-form medium has a long history and has been used as means for personal or intimate expression, as a way for marginalized people to describe issues that are important to them, and as a venue for graphical experimentation. It would seem then that zines would make an ideal vehicle for the recent interest in applying feminist or humanist ideas to visualization. Yet, there has been little work combining visualization and zines. In this paper we explore the potential of this intersection by analyzing examples of zines that use data graphics and by describing the pedagogical value that they can have in a visualization classroom. In doing so, we argue that there are plentiful opportunities for visualization research and practice in this rich intersectional-medium.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623294","Human-centered computing;Visualization;Visualization application domains","Graphics;Conferences;Data visualization;History;Gender issues","computer aided instruction;data visualisation","zines;free-form medium;personal expression;visualization classroom;rich intersectional-medium;data graphics","","","","58","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Online Projector Deblurring Using a Convolutional Neural Network","Y. Kageyama; D. Iwai; K. Sato","Graduate School of Engineering Science, Osaka University, Japan; PRESTO, Japan Science and Technology Agency, Japan; Graduate School of Engineering Science, Osaka University, Japan","IEEE Transactions on Visualization and Computer Graphics","8 Apr 2022","2022","28","5","2223","2233","Projector deblurring is an important technology for dynamic projection mapping (PM), where the distance between a projector and a projection surface changes in time. However, conventional projector deblurring techniques do not support dynamic PM because they need to project calibration patterns to estimate the amount of defocus blur each time the surface moves. We present a deep neural network that can compensate for defocus blur in dynamic PM. The primary contribution of this paper is a unique network structure that consists of an extractor and a generator. The extractor explicitly estimates a defocus blur map and a luminance attenuation map. These maps are then injected into the middle layers of the generator network that computes the compensation image. We also propose a pseudo-projection technique for synthesizing physically plausible training data, considering the geometric misregistration that potentially happens in actual PM systems. We conducted simulation and actual PM experiments and confirmed that: (1) the proposed network structure is more suitable than a simple, more general structure for projector deblurring; (2) the network trained with the proposed pseudo-projection technique can compensate projection images for defocus blur artifacts in dynamic PM; and (3) the network supports the translation speed of the surface movement within a certain range that covers normal human motions.","1941-0506","","10.1109/TVCG.2022.3150465","JSPS KAKENHI(grant numbers:JP20H05958); JST; PRESTO(grant numbers:JPMJPR19J2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714047","Projector deblurring;dynamic projection mapping;deep neural network","Generators;Attenuation;Cameras;Deep learning;Calibration;Neural networks;Estimation","","","Algorithms;Artifacts;Computer Graphics;Computer Simulation;Humans;Neural Networks, Computer","","","52","CCBY","15 Feb 2022","","","IEEE","IEEE Journals"
"PRAGMA: Interactively Constructing Functional Brain Parcellations","R. G. Bayrak; N. Hoang; C. B. Hansen; C. Chang; M. Berger",Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","46","50","A prominent goal of neuroimaging studies is mapping the human brain, in order to identify and delineate functionally-meaningful regions and elucidate their roles in cognitive behaviors. These brain regions are typically represented by atlases that capture general trends over large populations. Despite being indispensable to neuroimaging experts, population-level atlases do not capture individual differences in functional organization. In this work, we present an interactive visualization method, PRAGMA, that allows domain experts to derive scan-specific parcellations from established atlases. PRAGMA features a user-driven, hierarchical clustering scheme for defining temporally correlated parcels in varying granularity. The visualization design supports the user in making decisions on how to perform clustering, namely when to expand, collapse, or merge parcels. This is accomplished through a set of linked and coordinated views for understanding the user's current hierarchy, assessing intra-cluster variation, and relating parcellations to an established atlas. We assess the effectiveness of PRAGMA through a user study with four neuroimaging domain experts, where our results show that PRAGMA shows the potential to enable exploration of individualized and state-specific brain parcellations and to offer interesting insights into functional brain networks.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331292","Human-centered modeling;neuroimage analysis;functional parcellation;brain mapping","Neuroimaging;Visualization;Conferences;Sociology;Organizations;Market research;Statistics","biomedical MRI;brain;cognition;data visualisation;medical image processing;neurophysiology;pattern clustering","neuroimaging domain experts;PRAGMA;functional brain networks;functional brain parcellations;human brain;functionally-meaningful regions;cognitive behaviors;brain regions;interactive visualization method;scan-specific parcellations;hierarchical clustering scheme;visualization design","","","","36","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Point Movement in a DSL for Higher-Order FEM Visualization","T. Collin; C. Chiw; L. R. Scott; J. Reppy; G. Kindlmann","University of Chicago,Department of Computer Science; Galois, Inc.; University of Chicago,Department of Computer Science; University of Chicago,Department of Computer Science; University of Chicago,Department of Computer Science","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","281","285","Scientific visualization tools tend to be flexible in some ways (e.g., for exploring isovalues) while restricted in other ways, such as working only on regular grids, or only on unstructured meshes (as used in the finite element method, FEM). Our work seeks to expose the common structure of visualization methods, apart from the specifics of how the fields being visualized are formed. Recognizing that previous approaches to FEM visualization depend on efficiently updating computed positions within a mesh, we took an existing visualization domain-specific language, and added a mesh position type and associated arithmetic operators. These are orthogonal to the visualization method itself, so existing programs for visualizing regular grid data work, with minimal changes, on higher-order FEM data. We reproduce the efficiency gains of an earlier guided search method of mesh position update for computing streamlines, and we demonstrate a novel ability to uniformly sample ridge surfaces of higher-order FEM solutions defined on curved meshes.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933623","Software and its engineering;Software notations and tools;Context specific languages;DSLs","Finite element analysis;Data visualization;DSL;Tools;Rendering (computer graphics);Visualization;Geometry","data visualisation;finite element analysis","point movement;scientific visualization tools;regular grids;unstructured meshes;finite element method;common structure;FEM visualization;mesh position type;regular grid data work;FEM data;mesh position update;FEM solutions;curved meshes;guided search method;visualization domain-specific language","","","","41","","19 Dec 2019","","","IEEE","IEEE Conferences"
"PowerNet: Learning-based Real-time Power-budget Rendering","Y. Zhang; R. Wang; Y. Huo; W. Hua; H. Bao","State Key Laboratory of CAD & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: zhangyunjin@zju.edu.cn); State Key Laboratory of CAD & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: rwang@cad.zju.edu.cn); State Key Laboratory of CAD & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: huo.yuchi.sc@gmail.com); State Key Laboratory of CAD & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: huawei@cad.zju.edu.cn); State Key Laboratory of CAD & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: bao@cad.zju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","With the prevalence of embedded GPUs on mobile devices, power-efficient rendering has become a widespread concern for graphics applications. Reducing the power consumption of rendering applications is critical for extending battery life. In this paper, we present a new real-time power-budget rendering system to meet this need by selecting the optimal rendering settings that maximize visual quality for each frame under a given power budget. Our method utilizes two independent neural networks trained entirely by synthesized datasets to predict power consumption and image quality under various workloads. This approach spares time-consuming precomputation or runtime periodic refitting and additional error computation. We evaluate the performance of the proposed framework on different platforms, two desktop PCs and two smartphones. Results show that compared to the previous state of the art, our system has less overhead and better flexibility. Existing rendering engines can integrate our system with negligible costs.","1941-0506","","10.1109/TVCG.2021.3064367","National Key Research and Development Program of China(grant numbers:2017YFB1002605); Zhejiang Provincial NSFC(grant numbers:LR18F020002); National Natural Science Foundation of China(grant numbers:61872319); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372829","Power-budget rendering;rendering system;neural network","Rendering (computer graphics);Power demand;Real-time systems;Predictive models;Neural networks;Integrated circuit modeling;Computational modeling","","","","","","","IEEE","8 Mar 2021","","","IEEE","IEEE Early Access Articles"
"ProtoViewer: Visual Interpretation and Diagnostics of Deep Neural Networks with Factorized Prototypes","J. Zhao; Z. Dai; P. Xu; L. Ren",Purdue University; Bosch Research North America; Bosch Research North America; Bosch Research North America,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","286","290","In recent years deep neural networks (DNNs) are increasingly used in a variety of application domains for their state-of-the-art performance in many challenging machine learning tasks. However their lack of interpretability could cause trustability and fairness issues and also makes model diagnostics a difficult task. In this paper we present a novel visual analytics framework to interpret and diagnose DNNs. Our approach utilizes ProtoFac to factorize the latent representations in DNNs into weighted combinations of prototypes, which are exemplar cases (e.g., representative image patches) from the original data. The visual interface uses the factorized prototypes to summarize and explain the model behaviour as well as support comparisons across subsets of data such that the users can form a hypothesis about the model's failure on certain subsets. The method is model-agnostic and provides global explanation of the model behaviour. Furthermore, the system selects prototypes and weights that faithfully represents the model under analysis by mimicking its latent representation and predictions. Example usage scenarios on two DNN architectures and two datasets illustrates the effectiveness and general applicability of the proposed approach.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331285","Machine Learning Techniques, Machine Learning, Statistics, Modeling, and Simulation Applications, Data Analysis, Reasoning, Problem Solving, and Decision Making","Visual analytics;Neural networks;Prototypes;Machine learning;Predictive models;Data models;Task analysis","data analysis;data visualisation;deep learning (artificial intelligence);set theory","subsets;visual interface;representative image patches;latent representations;visual analytics framework;model diagnostics;trustability;machine learning;DNN;deep neural networks;factorized prototypes;ProtoViewer;latent representation;model behaviour","","","","31","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Provectories: Embedding-based Analysis of Interaction Provenance Data","C. Walchshofer; A. Hinterreiter; K. Xu; H. Stitz; M. Streit","Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria, (e-mail: conny.walchshofer@jku.at); Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria, 4040 (e-mail: andreas.hinterreiter@jku.at); Computer Science, Middlesex University, London, London, United Kingdom of Great Britain and Northern Ireland, NW4 4BT (e-mail: K.Xu@mdx.ac.uk); Institute of Computer Graphics, Johannes Kepler University Linz, Linz, Upper Austria, Austria, 4040 (e-mail: holger.stitz@datavisyn.io); Institute of Computer Graphics, Johannes Kepler University Linz, Linz, Upper Austria, Austria, 4040 (e-mail: marc.streit@jku.at)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Understanding user behavior patterns and visual analysis strategies is a long-standing challenge. Existing approaches rely largely on time-consuming manual processes such as interviews and the analysis of observational data. While it is technically possible to capture a history of user interactions and application states, it remains difficult to extract and describe analysis strategies based on interaction provenance. In this paper, we propose a novel visual approach to the meta-analysis of interaction provenance. We capture single and multiple user sessions as graphs of high-dimensional application states. Our meta-analysis is based on two different types of two-dimensional embeddings of these high-dimensional states: layouts based on (i) topology and (ii) attribute similarity. We applied these visualization approaches to synthetic and real user provenance data captured in two user studies. From our visualizations, we were able to extract patterns for data types and analytical reasoning strategies.","1941-0506","","10.1109/TVCG.2021.3135697","sterreichische Forschungsfrderungsgesellschaft(grant numbers:881844); Bundesministerium fr Bildung Wissenschaft und Forschung(grant numbers:LIT-2019-7-SEE-117); State of Upper Austria(grant numbers:Human-Interpretable Machine Learning); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652041","Visualization techniques;Information visualization;Visual analytics;Interaction Provenance;Sensemaking","Data visualization;Layout;Cognition;Visual analytics;Time series analysis;Task analysis;Collaboration","","","","","","","CCBY","15 Dec 2021","","","IEEE","IEEE Early Access Articles"
"Quantifiable Fine-Grain Occlusion Removal Assistance for Efficient VR Exploration","J. Wu; L. Wang; H. Zhang; V. Popescu","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 Beijing, Beijing, China, 100083 (e-mail: lanayawj@buaa.edu.cn); State Key Laboratory of Virtual Reality Technology and Systems,School of Computer Science and Engineering, Beihang University, 12633 Beijing, Beijing, China, (e-mail: wanglily@buaa.edu.cn); State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 Beijing, Beijing, China, (e-mail: zh_1520@163.com); Computer Science, Purdue University, 311308 West Lafayette, Indiana, United States, (e-mail: popescu@purdue.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","This paper presents an occlusion management approach that handles fine-grain occlusions, and that quantifies and localizes occlusions as a user explores a virtual environment (VE). Fine-grain occlusions are handled by finding the VE region where they occur, and by constructing a multiperspective visualization that lets the user explore the region from the current location, with intuitive head motions, without first having to walk to the region. VE geometry close to the user is rendered conventionally, from the user's viewpoint, to anchor the user, avoiding disorientation and simulator sickness. Given a viewpoint, residual occlusions are quantified and localized as VE voxels that cannot be seen from the given viewpoint but that can be seen from nearby viewpoints. This residual occlusion quantification and localization helps the user ascertain that a VE region has been explored exhaustively. The occlusion management approach was tested in three controlled studies, which confirmed the exploration efficiency benefit of the approach, and in perceptual experiments, which confirmed that exploration efficiency does not come at the cost of reducing spatial awareness and sense of presence, or of increasing simulator sickness.","1941-0506","","10.1109/TVCG.2021.3053287","National Key RD plan(grant numbers:2019YFC1521102); funding of Shenzhen Research Institute of Big Data; National Natural Science Foundation of China(grant numbers:61772051,61932003); Natural Science Foundation of Beijing Municipality(grant numbers:L182016); Beijing Program for International ST Cooperation Project(grant numbers:Z191100001619003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332290","VR exploration;fine grain disocclusion;multiperspective visualization;graph camera;occlusion quantification","Visualization;Legged locomotion;Geometry;Teleportation;Cameras;Navigation;Virtual environments","","","","","","","IEEE","21 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Rapid Labels: Point-Feature Labeling on GPU","V. Pavlovec; L. Cmolik","Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","604","613","Labels, short textual annotations are an important component of data visualizations, illustrations, infographics, and geographical maps. In interactive applications, the labeling method responsible for positioning the labels should not take the resources from the application itself. In other words, the labeling method should provide the result as fast as possible. In this work, we propose a greedy point-feature labeling method running on GPU. In contrast to existing methods that position the labels sequentially, the proposed method positions several labels in parallel. Yet, we guarantee that the positioned labels will not overlap, nor will they overlap important visual features. When the proposed method is searching for the label position of a point-feature, the available label candidates are evaluated with respect to overlaps with important visual features, conflicts with label candidates of other point-features, and their ambiguity. The evaluation of each label candidate is done in constant time independently from the number of point-features, the number of important visual features, and the resolution of the created image. Our measurements indicate that the proposed method is able to position more labels than existing greedy methods that do not evaluate conflicts between the label candidates. At the same time, the proposed method achieves a significant increase in performance. The increase in performance is mainly due to the parallelization and the efficient evaluation of label candidates.","1941-0506","","10.1109/TVCG.2021.3114854","MEYS of Czechia OP VVV(grant numbers:CZ.02.1.01/0.0/0.0/16_019/0000765); Research Center for Informatics, Czech Technical University in Prague; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552249","Label placement;Point-feature labeling;GPU","Labeling;Visualization;Layout;Data visualization;Graphics processing units;Annotations;Optimization","data visualisation;graphics processing units;image resolution","visual features;label candidate;rapid labels;greedy point-feature labeling;GPU;short textual annotations;data visualizations;illustrations;infographics;geographical maps;interactive applications;label positioning;image resolution;parallelization","","","","33","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Ray-traced Shell Traversal of Tetrahedral Meshes for Direct Volume Visualization","A. Şahıstan; S. Demirci; N. Morrical; S. Zellmann; A. Aman; I. Wald; U. Güdükbay",Bilkent University; Bilkent University; University of Utah; University of Cologne; Bilkent University; NVIDIA Corporation; Bilkent University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","91","95","A well-known method for rendering unstructured volumetric data is tetrahedral marching (tet marching), where rays are marched through a series of tetrahedral elements. Rowever, existing tet marching techniques do not easily generalize to rays with arbitrary origin and direction required for advanced shading effects or non-convex meshes. Additionally, the memory footprint of these methods may exceed GPU memory limits. Interactive performance and high image quality are opposing goals. Our approach significantly lowers the burden to render unstructured datasets with high image fidelity while maintaining real-time and interactive performance even for large datasets. To this end, we leverage hardware-accelerated ray tracing to find entry and exit faces for a given ray into a volume and utilize a compact mesh representation to enable the efficient marching of arbitrary rays, thus allowing for advanced shading effects that ultimately yields more convincing and grounded images. Our approach is also robust, supporting both convex and non-convex unstructured meshes. We show that our method achieves interactive rates even with moderately-sized datasets while secondary effects are applied.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623298","University of Utah; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623298","Human-centered computing;Visualization;Visualization application domains;Scientific visualization;Computing methodologies;Computer Graphics;Rendering;Ray Tracing","Image quality;Conferences;Graphics processing units;Ray tracing;Rendering (computer graphics);Real-time systems;Faces","computational geometry;data visualisation;graphics processing units;image representation;mesh generation;ray tracing;rendering (computer graphics)","tet marching techniques;memory footprint;GPU memory limits;interactive performance;high image quality;high image fidelity;compact mesh representation;arbitrary rays;ray-traced shell traversal;tetrahedral meshes;direct volume visualization;unstructured volumetric data;tetrahedral marching;hardware-accelerated ray tracing;render unstructured datasets;nonconvex unstructured meshes;convex unstructured meshes","","","","24","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Real-Time Globally Consistent 3D Reconstruction with Semantic Priors","S. -S. Huang; H. Chen; J. Huang; H. Fu; S. -M. Hu","the School of Artificial Intelligence, Beijing Normal University, 47836 Beijing, Beijing, China, (e-mail: shishenghuang.net@gmail.com); Department Of Computer Science, Tsinghua University, 12442 Beijing, Beijing, China, 100084 (e-mail: chx20@mails.tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: huang-jh18@mails.tsinghua.edu.cn); School of Creative Media, City University of Hong Kong, Hong Kong, Hong Kong, China, (e-mail: fuplus@gmail.com); Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, 100084 (e-mail: shimin@tsinghua.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Maintaining global consistency continues to be critical for online 3D indoor scene reconstruction. However, it is still challenging to generate satisfactory 3D reconstruction in terms of global consistency for previous approaches using purely geometric analysis, even with bundle adjustment or loop closure techniques. In this paper, we propose a novel real-time 3D reconstruction approach which effectively integrates both semantic and geometric cues. The key challenge is how to map this indicative information, i.e. semantic priors, into a metric space as measurable information, thus enabling more accurate semantic fusion leveraging both the geometric and semantic cues. To this end, we introduce a semantic space with a continuous metric function measuring the distance between discrete semantic observations. Within the semantic space, we present an accurate frame-to-model semantic tracker for camera pose estimation, and semantic pose graph equipped with semantic links between submaps for globally consistent 3D scene reconstruction. With extensive evaluation on public synthetic and real-world 3D indoor scene RGB-D datasets, we show that our approach outperforms the previous approaches for 3D scene reconstruction both quantitatively and qualitatively, especially in terms of global consistency.","1941-0506","","10.1109/TVCG.2021.3137912","National Natural Science Foundation of China(grant numbers:61521002,61902210); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662197","3D Reconstruction;Semantic Fusion;Semantic Tracker;Semantic Pose Graph","Three-dimensional displays;Semantics;Cameras;Pose estimation;Real-time systems;Geometry;Simultaneous localization and mapping","","","","","","","IEEE","23 Dec 2021","","","IEEE","IEEE Early Access Articles"
"Real-Time Lighting Estimation for Augmented Reality via Differentiable Screen-Space Rendering","C. Liu; L. Wang; Z. Li; S. Quan; Y. Xu","Augmented Reality, OPPO US Research Center, Palo Alto, California, United States, (e-mail: liucl.2007@tsinghua.org.cn); Augmented Reality, OPPO US Research Center, Palo Alto, California, United States, (e-mail: lingyu.wang@oppo.com); Augmented Reality, OPPO US Research Center, Palo Alto, California, United States, (e-mail: zhong.li@oppo.com); Augmented Reality, OPPO US Research Center, Palo Alto, California, United States, (e-mail: shuxue.quan@oppo.com); Augmented Reality, OPPO US Research Center, Palo Alto, California, United States, (e-mail: yi.xu@oppo.com)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Augmented Reality (AR) applications aim to provide realistic blending between the real-world and virtual objects. One of the important factors for realistic AR is the correct lighting estimation. In this paper, we present a method that estimates the real-world lighting condition from a single image in real-time, using information from an optional support plane provided by advanced AR frameworks (e.g. ARCore, ARKit, etc.). By analyzing the visual appearance of the real scene, our algorithm could predict the lighting condition from the input RGB photo. In the first stage, we use a deep neural network to decompose the scene into several components: lighting, normal, and BRDF. Then we introduce differentiable screen-space rendering, a novel approach to providing the supervisory signal for regressing lighting, normal, and BRDF jointly. We recover the most plausible real-world lighting condition using Spherical Harmonics and the main directional lighting. Through a variety of experimental results, we demonstrate that our method could provide improved results than prior works quantitatively and qualitatively, and it could enhance the real-time AR experiences.","1941-0506","","10.1109/TVCG.2022.3141943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678000","Mixed/augmented reality;rendering;scene understanding;light estimation;real time","Lighting;Rendering (computer graphics);Real-time systems;Estimation;Probes;Image reconstruction;Geometry","","","","","","","IEEE","11 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Real-time Shadow Detection from Live Outdoor Videos for Augmented Reality","Y. Liu; X. Zou; S. Xu; G. Xing; H. Wei; Y. Zhang","College of Computer Science, Sichuan University, 12530 Chengdu, Sichuan, China, (e-mail: yanliliu@scu.edu.cn); College of Computer Science, Sichuan University, 12530 Chengdu, Sichuan, China, (e-mail: zzxxmm414@outlook.com); Computer Science, University of South Carolina, 2629 Columbia, South Carolina, United States, (e-mail: xus1@cec.sc.edu); College of Computer Science, Sichuan University, 12530 Chengdu, Sichuan, China, (e-mail: xingguanyu@scu.edu.cn); College of Computer Science, Sichuan University, 12530 Chengdu, Sichuan, China, (e-mail: willson.wei.hou@qq.com); College of Computer Science, Sichuan University, 12530 Chengdu, Sichuan, China, (e-mail: yczhang@scu.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","Simulating shadow interactions between real and virtual objects is important for augmented reality (AR), in which accurately and efficiently detecting real shadows from live videos is a crucial step. Most of the existing methods are capable of processing only scenes captured under a fixed viewpoint. In contrast, this paper proposes a new framework for shadow detection in live outdoor videos captured under moving viewpoints. The framework splits each frame into a tracked region, which is the region tracked from the previous video frame through optical flow analysis, and an emerging region, which is newly introduced into the scene due to the moving viewpoint. The framework subsequently extracts features based on the intensity profiles surrounding the boundaries of candidate shadow regions. These features are then utilized to both correct erroneous shadow boundaries for the tracked region and to detect shadow boundaries for the emerging region by a Bayesian learning module. To remove spurious shadows, spatial layout constraints are further considered for emerging regions. The experimental results demonstrate that the proposed framework outperforms the state-of-the-art shadow tracking and detection algorithms on a variety of challenging cases in real time, including shadows on backgrounds with complex textures, nonplanar shadows, fast-moving shadows with changing typologies, and shadows cast by nonrigid objects. The quantitative experiments show that our method outperforms the best existing method, achieving a 33.3% increase in the average F_{measure}. Coupled with an image-based shadow-casting method, the proposed framework generates realistic shadow interaction results. This capability will be particularly beneficial for supporting AR","1941-0506","","10.1109/TVCG.2020.3041100","National Natural Science Foundation of China(grant numbers:61572333,61972271); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272883","Shadow boundary detection under moving viewpoints;optical tracking;shadow interaction for augmented reality","Videos;Feature extraction;Image edge detection;Erbium;Geometry;Real-time systems;Lighting","","","","","","","IEEE","27 Nov 2020","","","IEEE","IEEE Early Access Articles"
"Reconstruction of Dexterous 3D Motion Data from a Flexible Magnetic Sensor with Deep Learning and Structure-Aware Filtering","J. Huang; R. Sugawara; K. Chu; T. Komura; Y. Kitamura","Research Institute of Electrical Communication, Tohoku University, 13101 Sendai, Miyagi Japan 980-8577 (e-mail: swfly@riec.tohoku.ac.jp); Research Institute of Electronical Communications, Tohoku University, 13101 Sendai, Miyagi Japan (e-mail: rsugawara@riec.tohoku.ac.jp); Research Institute of Electronical Communications, Tohoku University, 13101 Sendai, Miyagi Japan (e-mail: kennychu@riec.tohoku.ac.jp); Department of Computer Science, University of Hong Kong, 25809 Hong Kong, Hong Kong Hong Kong (e-mail: tkomura@ed.ac.uk); Research Institute of Electronical Communications, Tohoku University, 13101 Sendai, Miyagi Japan (e-mail: kitamura@riec.tohoku.ac.jp)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","We propose a novel approach to reconstructing 3D motion data from a flexible magnetic flux sensor array using deep learning and a structure-aware temporal bilateral filter. Computing the 3D configuration of markers (inductor-capacitor (LC) coils) from flux sensor data is difficult because the existing numerical approaches suffer from system noise, dead angles, the need for initialization, and limitations in the sensor array's layout. We solve these issues with deep neural networks to learn the regression from the simulation flux values to the LC coils' 3D configuration, which can be applied to the actual LC coils at any location and orientation within the capture volume. To cope with the influence of system noise and the dead-angle limitation caused by the characteristics of the hardware and sensing principle, we propose a structure-aware temporal bilateral filter for reconstructing motion sequences. Our method can track various movements, including fingers that manipulate objects, beetles that move inside a vivarium with leaves and soil, and the flow of opaque fluid. Since no power supply is needed for the lightweight wireless markers, our method can robustly track movements for a very long time, making it suitable for various types of observations whose tracking is difficult with existing motion-tracking systems. Furthermore, the flexibility of the flux sensor layout allows users to reconfigure it based on their own applications, thus making our approach suitable for a variety of virtual reality applications.","1941-0506","","10.1109/TVCG.2020.3031632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226608","3D user interface;3D interaction;Motion capture;Input devices;Filtering;Deep learning","Tracking;Three-dimensional displays;Coils;Layout;Deep learning;Optical sensors;Noise measurement","","","","","","","CCBY","16 Oct 2020","","","IEEE","IEEE Early Access Articles"
"Relationship-aware Multivariate Sampling Strategy for Scientific Simulation Data","S. Hazarika; A. Biswas; P. J. Wolfram; E. Lawrence; N. Urban","Los Alamos National Laboratory,New Mexico,USA; Los Alamos National Laboratory,New Mexico,USA; Los Alamos National Laboratory,New Mexico,USA; Los Alamos National Laboratory,New Mexico,USA; Los Alamos National Laboratory,New Mexico,USA","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","41","45","With the increasing computational power of current supercomputers, the size of data produced by scientific simulations is rapidly growing. To reduce the storage footprint and facilitate scalable post-hoc analyses of such scientific data sets, various data reduction/summarization methods have been proposed over the years. Different flavors of sampling algorithms exist to sample the high-resolution scientific data, while preserving important data properties required for subsequent analyses. However, most of these sampling algorithms are designed for univariate data and cater to post-hoc analyses of single variables. In this work, we propose a multivariate sampling strategy which preserves the original variable relationships and enables different multivariate analyses directly on the sampled data. Our proposed strategy utilizes principal component analysis to capture the variance of multivariate data and can be built on top of any existing state-of-the-art sampling algorithms for single variables. In addition, we also propose variants of different data partitioning schemes (regular and irregular) to efficiently model the local multivariate relationships. Using two real-world multivariate data sets, we demonstrate the efficacy of our proposed multivariate sampling strategy with respect to its data reduction capabilities as well as the ease of performing efficient post-hoc multivariate analyses.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00015","Research and Development; U.S. Department of Energy; Office of Science; Biological and Environmental Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331314","","Conferences;Computational modeling;Data visualization;Data models;Supercomputers;Partitioning algorithms;Principal component analysis","data analysis;data reduction;principal component analysis;sampling methods","high-resolution scientific data;data properties;subsequent analyses;univariate data;sampled data;sampling algorithms;data partitioning schemes;real-world multivariate data sets;data reduction capabilities;relationship-aware multivariate sampling strategy;scientific simulation data;data reduction method;data summarization method;principal component analysis","","","","27","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Relationship-based Point Cloud Completion","X. Zhao; B. Zhang; J. Wu; R. Hu; T. Komura","The School of Electronic and Information Engineering, Xi'an jiaotong University, Xi'an, Shaanxi, China, (e-mail: xiaoppx_zx@126.com); The School of Electronic and Information Engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi, China, (e-mail: zbw1682123@stu.xjtu.edu.cn); The School of Electronic and Information Engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi, China, (e-mail: walf568@stu.xjtu.edu.can); College of Computer Science & Software Engineering, Shenzhen University, 47890 Shenzhen, Guangdong, China, 518060 (e-mail: ruizhen.hu@gmail.com); Informatics, University of Edinburgh, Edinburgh, Scotland, United Kingdom of Great Britain and Northern Ireland, (e-mail: tkomura@ed.ac.uk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We propose a partial point cloud completion approach for scenes that are composed of multiple objects. We focus on pairwise scenes where two objects are in close proximity and are contextually related to each other, such as a chair tucked in a desk, a fruit in a basket, a hat on a hook and a flower in a vase. Different from existing point cloud completion methods, which mainly focus on single objects, we design a network that encodes not only the geometry of the individual shapes, but also the spatial relations between different objects. More specifically, we complete the missing parts of the objects in a conditional manner, where the partial or completed point cloud of the other object is used as an additional input to help predict the missing parts. Based on the idea of conditional completion, we further propose a two-path network, which is guided by a consistency loss between different sequences of completion. Our method can handle difficult cases where the objects heavily occlude each other. Also, it only requires a small set of training data to reconstruct the interaction area compared to existing completion approaches. We evaluate our method qualitatively and quantitatively via ablation studies and in comparison to the state-of-the-art point cloud completion methods.","1941-0506","","10.1109/TVCG.2021.3109392","Fundamental Research Funds for the Central Universities(grant numbers:xzy012019048); China Postdoctoral Science Foundation(grant numbers:2020M673407); Natural Science Foundation of Guangdong Province(grant numbers:2021B1515020085); National Natural Science Foundation of China(grant numbers:61872250,62072366); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528986","point cloud completion;spatial relationships","Three-dimensional displays;Task analysis;Shape;Geometry;Training data;Semantics;Robot vision systems","","","","","","","IEEE","3 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Rethinking the Ranks of Visual Channels","C. M. McColeman; F. Yang; T. F. Brady; S. Franconeri","Northwestern University, USA; Brown University, USA; University of San Diego, USA; Northwestern University, USA","IEEE Transactions on Visualization and Computer Graphics","29 Dec 2021","2022","28","1","707","717","Data can be visually represented using visual channels like position, length or luminance. An existing ranking of these visual channels is based on how accurately participants could report the ratio between two depicted values. There is an assumption that this ranking should hold for different tasks and for different numbers of marks. However, there is surprisingly little existing work that tests this assumption, especially given that visually computing ratios is relatively unimportant in real-world visualizations, compared to seeing, remembering, and comparing trends and motifs, across displays that almost universally depict more than two values. To simulate the information extracted from a glance at a visualization, we instead asked participants to immediately reproduce a set of values from memory after they were shown the visualization. These values could be shown in a bar graph (position (bar)), line graph (position (line)), heat map (luminance), bubble chart (area), misaligned bar graph (length), or ‘wind map’ (angle). With a Bayesian multilevel modeling approach, we show how the rank positions of visual channels shift across different numbers of marks (2, 4 or 8) and for bias, precision, and error measures. The ranking did not hold, even for reproductions of only 2 marks, and the new probabilistic ranking was highly inconsistent for reproductions of different numbers of marks. Other factors besides channel choice had an order of magnitude more influence on performance, such as the number of values in the series (e.g., more marks led to larger errors), or the value of each mark (e.g., small values were systematically overestimated). Every visual channel was worse for displays with 8 marks than 4, consistent with established limits on visual memory. These results point to the need for a body of empirical studies that move beyond two-value ratio judgments as a baseline for reliably ranking the quality of a visual channel, including testing new tasks (detection of trends or motifs), timescales (immediate computation, or later comparison), and the number of values (from a handful, to thousands).","1941-0506","","10.1109/TVCG.2021.3114684","National Science Foundation(grant numbers:BCS-1653457,IIS-1901485); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557878","DataType Agnostic;Human-Subjects Quantitative Studies;Perception & Cognition;Charts, Diagrams, and Plots","Task analysis;Visualization;Bars;Data visualization;Memory management;Measurement uncertainty;Correlation","Bayes methods;data visualisation;graph theory;probability;statistical analysis","real-world visualizations;rank positions;visual channels;visual memory;wind map;misaligned bar graph;channel choice;Bayesian multilevel modeling approach","","","","87","IEEE","4 Oct 2021","","","IEEE","IEEE Journals"
"RuleVis: Constructing Patterns and Rules for Rule-Based Models","D. Abramov; J. Otto; M. Dubey; C. Artanegara; P. Boutillier; W. Fontana; A. G. Forbes","University of California,Department of Computational Media,Santa Cruz; University of California,Department of Computational Media,Santa Cruz; University of California,Department of Computational Media,Santa Cruz; University of California,Department of Computational Media,Santa Cruz; Harvard Medical School,Department of Systems Biology; Harvard Medical School,Department of Systems Biology; University of California,Department of Computational Media,Santa Cruz","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","191","195","We introduce RuleVis, a web-based application for defining and editing ""correct-by-construction"" executable rules that model biochemical functionality, which can be used to simulate the behavior of protein-protein interaction networks and other complex systems. Rule-based models involve emergent effects based on the interactions between rules, which can vary considerably with regard to the scale of a model, requiring the user to inspect and edit individual rules. RuleVis bridges the graph rewriting and systems biology research communities by providing an external visual representation of salient patterns that experts can use to determine the appropriate level of detail for a particular modeling context. We describe the visualization and interaction features available in RuleVis and provide a detailed example demonstrating how RuleVis can be used to reason about intracellular interactions.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933596","Rule-based modeling;biological data visualization","Visualization;Biological system modeling;Data visualization;Computational modeling;Layout;Systems biology","biology computing;data visualisation;Internet;knowledge based systems;proteins;rewriting systems","protein-protein interaction networks;rule-based models;RuleVis bridges;graph rewriting;systems biology research communities;visualization;interaction features;web-based application;correct-by-construction;biochemical functionality;intracellular interactions","","","","33","","19 Dec 2019","","","IEEE","IEEE Conferences"
"S4: Self-Supervised learning of Spatiotemporal Similarity","G. Tkachev; S. Frey; T. Ertl","VISUS, Universitat Stuttgart, 9149 Stuttgart, Baden-Wrttemberg, Germany, 70569 (e-mail: gleb.tkachev@visus.uni-stuttgart.de); Bernoulli Institute of Mathematics, Computer Science and Artificial Intelligence, University of Groningen, 3647 Groningen, Groningen, Netherlands, 9700 AB (e-mail: s.d.frey@rug.nl); Institut fuer Visualisierung und Interaktive Systeme, Universitaet Stuttgart, Stuttgart, BW, Germany, 70569 (e-mail: Thomas.Ertl@vis.uni-stuttgart.de)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","We introduce an ML-driven approach that enables interactive example-based queries for similar behavior in ensembles of spatiotemporal scientific data. This addresses an important use case in the visual exploration of simulation and experimental data, where data is often large, unlabeled and has no meaningful similarity measures available. We exploit the fact that nearby locations often exhibit similar behavior and train a Siamese Neural Network in a self-supervised fashion, learning an expressive latent space for spatiotemporal behavior. This space can be used to find similar behavior with just a few user-provided examples. We evaluate this approach on several ensemble datasets and compare with multiple existing methods, showing both qualitative and quantitative results.","1941-0506","","10.1109/TVCG.2021.3101418","Deutsche Forschungsgemeinschaft(grant numbers:EXC-2075 (SimTech) 390740016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503317","Spatiotemporal Data;Machine Learning;Ensemble Visualization;Visual Exploration","Measurement;Task analysis;Data visualization;Data models;Spatiotemporal phenomena;Computational modeling;Visualization","","","","","","","IEEE","2 Aug 2021","","","IEEE","IEEE Early Access Articles"
"SAniHead: Sketching Animal-like 3D Character Heads Using a View-surface Collaborative Mesh Generative Network","D. Du; X. Han; H. Fu; F. Wu; Y. Yu; S. Cui; L. Liu","School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui China 230026 (e-mail: dongdu@mail.ustc.edu.cn); Department of Computer Science, The University of Hong Kong, Hong Kong, Hong Kong China (e-mail: hanxiaoguang@cuhk.edu.cn); School of Creative Media, City University of Hong Kong, Hong Kong, Hong Kong China (e-mail: fuplus@gmail.com); School of Science and Engineering, The Chinese University of Hong Kong - Shenzhen, 407605 Shenzhen, Guangdong China 518100 (e-mail: feiyangwu@link.cuhk.edu.cn); Department of Computer Science, The University of Hong Kong, Pokfulam, Hong Kong Hong Kong (e-mail: yizhouy@acm.org); Shenzhen Research Institute of Big Data and Future Network of Intelligence Institute (FNii), The Chinese University of Hong Kong - Shenzhen, 407605 Shenzhen, Guangdong China (e-mail: shuguangcui@cuhk.edu.cn); Department of Mathematics, Zhejiang University, Hangzhou, Zhejiang China 310027 (e-mail: lgliu@ustc.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","In the game and film industries, modeling 3D heads plays a very important role in designing characters. Although human head modeling has been researched for a long time, few works have focused on animal-like heads, which are of more diverse shapes and richer geometric details. In this work, we present SAniHead, an interactive system for creating animal-like heads with a mesh representation from dual-view sketches. Our core technical contribution is a view-surface collaborative mesh generative network. Initially, a Graph Convolutional Neural Network(GCNN) is trained to learn the deformation of a template mesh to fit the shape of sketches, giving rise to a coarse model. It is then projected into vertex maps where image-to-image translation networks are performed for detail inference. After back-projecting the inferred details onto the meshed surface, a new GCNN is trained for further detail refinement. The modules of view-based detail inference and surface-based detail refinement are conducted in an alternating cascaded fashion, collaboratively improving the model. A refinement sketching interface is also implemented to support direct mesh manipulation. Experimental results show the superiority of our approach and the usability of our interactive system. Our work also contributes a 3D animal head dataset with corresponding line drawings.","1941-0506","","10.1109/TVCG.2020.3030330","Guangdong Research Project(grant numbers:2017ZT07X152); National Key R and D Program of China(grant numbers:2018YFB1800800); Research Grants Council of the Hong Kong Special Administrative Region China(grant numbers:CityU 11212119); National Natural Science Foundation of China(grant numbers:61629101,61672482,61902334); Zhejiang Lab(grant numbers:2019NB0AB03); Key Area R and D Program of Guangdong Province(grant numbers:2018B030338001); City University of Hong Kong(grant numbers:7005176); Hong Kong Research Grants Council under General Research Funds(grant numbers:HKU17206218); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222121","Sketch-based 3D Modeling;Graph Convolutional Neural Network;Animal-like Character Heads","Three-dimensional displays;Shape;Solid modeling;Head;Computational modeling;Collaboration;Strain","","","","","","","IEEE","13 Oct 2020","","","IEEE","IEEE Early Access Articles"
"SEAR: Scaling Experiences in Multi-user Augmented Reality","W. Zhang; B. Han; P. Hui","Hong Kong University of Science and Technology, Hong Kong; George Mason University, USA; Hong Kong University of Science and Technology, Hong Kong","IEEE Transactions on Visualization and Computer Graphics","8 Apr 2022","2022","28","5","1982","1992","In this paper, we present the design, implementation, and evaluation of SEAR, a collaborative framework for Scaling Experiences in multi-user Augmented Reality (AR). Most AR systems benefit from computer vision (CV) algorithms to detect, classify, or recognize physical objects for augmentation. A widely used acceleration method for mobile AR is to offload the compute-intensive tasks (<italic>e.g.</italic>, CV algorithms) to the network edge. However, we show that the end-to-end latency, an important metric of mobile AR, may dramatically increase when offloading AR tasks from a large number of concurrent users to the edge. SEAR tackles this scalability issue through the innovation of a lightweight collaborative local caching scheme. Our key observation is that nearby AR users may share some common interests, and may even have overlapped views to augment (<italic>e.g.</italic>, when playing a multi-user AR game). Thus, SEAR opportunistically exchanges the results of offloaded AR tasks among users when feasible and leverages compute resources on mobile devices to relieve, if necessary, the edge workload by intelligently reusing these results. We build a prototype of SEAR to demonstrate its efficacy in scaling AR experiences. We conduct extensive evaluations through both real-world experiments and trace-driven simulations. We observe that SEAR not only reduces the end-to-end latency, by up to 130×, compared to the state-of-the-art adaptive edge offloading scheme, but also achieves high object-recognition accuracy for mobile AR.","1941-0506","","10.1109/TVCG.2022.3150467","Research Grants Council of Hong Kong(grant numbers:26211515,16214817,318927); Academy of Finland(grant numbers:325570); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714049","Augmented Reality (AR);Multi-user AR;Edge-assisted AR;Scalability;User Experience;Latency","Scalability;Task analysis;Collaboration;Servers;Image edge detection;Mobile handsets;Annotations","","","","","","72","IEEE","15 Feb 2022","","","IEEE","IEEE Journals"
"SG-GAN: Adversarial Self-Attention GCN for Point Cloud Topological Parts Generation","Y. Li; G. Baciu","Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csysli@comp.polyu.edu.hk); Computing, The Hong Kong Polytechnic University, Kowloon, Kowloon, Hong Kong, (e-mail: csgeorge@polyu.edu.hk)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Point clouds are fundamental in the representation of 3D objects. However, they can also be highly unstructured and irregular. This makes it difficult to directly extend 2D generative models to three-dimensional space. In this paper, we cast the problem of point cloud generation as a topological representation learning problem. To infer the representative information of 3D shapes in the latent space, we propose a hierarchical mixture model that integrates self-attention with an inference tree structure for constructing a point cloud generator. Based on this, we design a novel Generative Adversarial Network (GAN) architecture that is capable to generate realistic point clouds in an unsupervised manner. The proposed adversarial framework (SG-GAN) relies on self-attention mechanism and Graph Convolution Network (GCN) to hierarchically infer the latent topology of 3D shapes. Embedding and transferring the global topology information in a tree framework allows our model to capture and enhance the structural connectivity. Furthermore, the proposed architecture endows our model with partially generating 3D structures. Finally, we propose two gradient penalty methods to stabilize the training of SG-GAN and overcome the possible mode collapse of GAN networks. To demonstrate the performance of our model, we present both quantitative and qualitative evaluations and show that SG-GAN is more efficient in training and it exceeds the state-of-the-art in 3D point cloud generation.","1941-0506","","10.1109/TVCG.2021.3069195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387601","Generative Adversarial Network;Graph Convolution Network;binary tree;self-attention;3D shape generation;point cloud learning;gradient penalty","Three-dimensional displays;Gallium nitride;Training;Shape;Generative adversarial networks;Solid modeling;Convolution","","","","","","","IEEE","26 Mar 2021","","","IEEE","IEEE Early Access Articles"
"<sc>SP</sc>E<sc>ULER</sc>: Semantics-preserving Euler Diagrams","R. Kehlbeck; J. Görtler; Y. Wang; O. Deussen","University of Konstanz, Germany; University of Konstanz, Germany; Shandong University, China; University of Konstanz, Germany","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","433","442","Creating comprehensible visualizations of highly overlapping set-typed data is a challenging task due to its complexity. To facilitate insights into set connectivity and to leverage semantic relations between intersections, we propose a fast two-step layout technique for Euler diagrams that are both well-matched and well-formed. Our method conforms to established form guidelines for Euler diagrams regarding semantics, aesthetics, and readability. First, we establish an initial ordering of the data, which we then use to incrementally create a planar, connected, and monotone dual graph representation. In the next step, the graph is transformed into a circular layout that maintains the semantics and yields simple Euler diagrams with smooth curves. When the data cannot be represented by simple diagrams, our algorithm always falls back to a solution that is not well-formed but still well-matched, whereas previous methods often fail to produce expected results. We show the usefulness of our method for visualizing set-typed data using examples from text analysis and infographics. Furthermore, we discuss the characteristics of our approach and evaluate our method against state-of-the-art methods.","1941-0506","","10.1109/TVCG.2021.3114834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552459","Euler diagrams;Venn diagrams;set visualization;layout algorithm","Data visualization;Task analysis;Faces;Semantics;Layout;Guidelines;Visualization","data visualisation;graph theory;text analysis","circular layout;yields simple Euler diagrams;simple diagrams;semantics-preserving Euler diagrams;comprehensible visualizations;set connectivity;leverage semantic relations;two-step layout technique;established form guidelines;monotone dual graph representation","","","","49","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"STD-Net: Structure-preserving and Topology-adaptive Deformation Network for Single-View 3D Reconstruction","A. Mao; C. Dai; Q. Liu; J. Yang; L. Gao; Y. He; Y. -J. Liu","School of Computer Science & Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, 510640 (e-mail: ahmao@scut.edu.cn); School of Computer Science and Engineering, South China University of Technology, Guangzhou, Guangdong, China, (e-mail: 201821033708@scut.edu.cn); School of Software Engineering, South China University of Technology Guangzhou College, 441317 Guangzhou, Guangdong, China, (e-mail: 202021045838@mail.scut.edu.cn); computer science, Institute of Computing Technology Chinese Academy of Sciences, 53035 beijing, Beijing, China, 100190 (e-mail: yangjie01@ict.ac.cn); Advanced Computer Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, Beijing, China, (e-mail: gaolin@ict.ac.cn); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore, Singapore, 639798 (e-mail: yhe@ntu.edu.sg); Computer Science and Technology, Tsinghua University, Beijing, Beijing, China, 100084 (e-mail: liuyongjin@tsinghua.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","3D reconstruction from single-view images is a long-standing research problem. To date, there are various methods based on point clouds and volumetric representations. In spite of success in 3D models generation, it is quite challenge for these approaches to deal with models with complex topology and fine geometric details. Thanks to the recent advance of deep shape representations,learning the structure and detail representation using deep neural networks is a promising direction. In this paper, we propose a novel approach named STD-Net to reconstruct 3D models utilizing mesh representation that is well suited for characterizing complex structures and geometry details. Our method consists of (1) an auto-encoder network for recovering the structure of an object with bounding box representation from a single-view image; (2) a topology-adaptive GCN for updating vertex position for meshes of complex topology; and (3) a unified mesh deformation block that deforms the structural boxes into structure-aware meshes. Evaluation on ShapeNet shows that STD-Net has better performance than state-of-the-art methods in reconstructing complex structures and fine geometric details.","1941-0506","","10.1109/TVCG.2021.3131712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632437","Single-View Reconstruction;Deformation Driven Method;Structure Preservation;Topology Adaptivity","Three-dimensional displays;Shape;Image reconstruction;Solid modeling;Topology;Periodic structures;Deep learning","","","","","","","IEEE","1 Dec 2021","","","IEEE","IEEE Early Access Articles"
"STNet: An End-to-End Generative Framework for Synthesizing Spatiotemporal Super-Resolution Volumes","J. Han; H. Zheng; D. Z. Chen; C. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","270","280","We present STNet, an end-to-end generative framework that synthesizes spatiotemporal super-resolution volumes with high fidelity for time-varying data. STNet includes two modules: a generator and a spatiotemporal discriminator. The input to the generator is two low-resolution volumes at both ends, and the output is the intermediate and the two-ending spatiotemporal super-resolution volumes. The spatiotemporal discriminator, leveraging convolutional long short-term memory, accepts a spatiotemporal super-resolution sequence as input and predicts a conditional score for each volume based on its spatial (the volume itself) and temporal (the previous volumes) information. We propose an unsupervised pre-training stage using cycle loss to improve the generalization of STNet. Once trained, STNet can generate spatiotemporal super-resolution volumes from low-resolution ones, offering scientists an option to save data storage (i.e., sparsely sampling the simulation output in both spatial and temporal dimensions). We compare STNet with the baseline bicubic+linear interpolation, two deep learning solutions (<inline-formula><tex-math notation=""LaTeX"">$\mathsf{SSR}+\mathsf{TSF}$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-han-3114815-eqinline-1-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, STD), and a state-of-the-art tensor compression solution (TTHRESH) to show the effectiveness of STNet.","1941-0506","","10.1109/TVCG.2021.3114815","National Science Foundation(grant numbers:IIS-1455886,CCF-1617735,CNS-1629914,DUE-1833129,IIS-1955395,IIS-2101696,OAC-2104158); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552857","Time-varying data;generative adversarial network;spatiotemporal super-resolution","Spatiotemporal phenomena;Superresolution;Interpolation;Training;Task analysis;Deep learning;Feature extraction","image reconstruction;image resolution;interpolation;learning (artificial intelligence);medical image processing;tensors","STNet;end-to-end generative framework;spatiotemporal super-resolution volumes;spatiotemporal discriminator;low-resolution volumes;spatiotemporal super-resolution sequence","","","","65","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"STRATISFIMAL LAYOUT: A modular optimization model for laying out layered node-link network visualizations","S. di Bartolomeo; M. Riedewald; W. Gatterbauer; C. Dunne","Northeastern University, USA; Northeastern University, USA; Northeastern University, USA; Northeastern University, USA","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","324","334","Node-link visualizations are a familiar and powerful tool for displaying the relationships in a network. The readability of these visualizations highly depends on the spatial layout used for the nodes. In this paper, we focus on computing <italic>layered</italic> layouts, in which nodes are aligned on a set of parallel axes to better expose hierarchical or sequential relationships. Heuristic-based layouts are widely used as they scale well to larger networks and usually create readable, albeit sub-optimal, visualizations. We instead use a <italic>layout optimization model</italic> that prioritizes <italic>optimality</italic> - as compared to <italic>scalability</italic> - because an optimal solution not only represents the best attainable result, but can also serve as a baseline to evaluate the effectiveness of layout heuristics. We take an important step towards powerful and flexible network visualization by proposing S<sc>tratisfimal</sc> L<sc>ayout</sc>, a <italic>modular integer-linear-programming formulation</italic> that can consider several important readability criteria <italic>simultaneously</italic> — crossing reduction, edge bendiness, and nested and multi-layer groups. The layout can be adapted to diverse use cases through its modularity. Individual features can be enabled and customized depending on the application. We provide open-source and documented implementations of the layout, both for web-based and desktop visualizations. As a proof-of-concept, we apply it to the problem of visualizing complicated SQL queries, which have features that we believe cannot be addressed by existing layout optimization models. We also include a benchmark network generator and the results of an empirical evaluation to assess the performance trade-offs of our design choices. A full version of this paper with all appendices, data, and source code is available at osf.io/qdyt9 with live examples at <uri>https://visdunneright.github.io/stratisfimal/</uri>.","1941-0506","","10.1109/TVCG.2021.3114756","National Science Foundation(grant numbers:IIS-1762268,IIS-1956096); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556579","Layered node-link visualization;integer linear programming;crossing reduction;bendiness reduction;nested groups","Layout;Structured Query Language;Visualization;Optimization;Scalability;Integer linear programming;Computational modeling","data visualisation;integer programming;Internet;linear programming;metaheuristics;network theory (graphs);query processing;SQL","modular optimization model;layered node-link network visualizations;heuristic-based layouts;layout optimization model;Stratisfimal Layout;modular integer-linear-programming formulation;benchmark network generator;crossing reduction;edge bendiness;multilayer group;nested group;Web-based visualization;desktop visualization;SQL queries","","","","81","IEEE","1 Oct 2021","","","IEEE","IEEE Journals"
"SafetyLens: Visual Data Analysis of Functional Safety of Vehicles","A. Narechania; A. Qamar; A. Endert",Georgia Institute of Technology; Ford Motor Company; Georgia Institute of Technology,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","1688","1697","Modern automobiles have evolved from just being mechanical machines to having full-fledged electronics systems that enhance vehicle dynamics and driver experience. However, these complex hardware and software systems, if not properly designed, can experience failures that can compromise the safety of the vehicle, its occupants, and the surrounding environment. For example, a system to activate the brakes to avoid a collision saves lives when it functions properly, but could lead to tragic outcomes if the brakes were applied in a way that's inconsistent with the design. Broadly speaking, the analysis performed to minimize such risks falls into a systems engineering domain called Functional Safety. In this paper, we present SafetyLens, a visual data analysis tool to assist engineers and analysts in analyzing automotive Functional Safety datasets. SafetyLens combines techniques including network exploration and visual comparison to help analysts perform domain-specific tasks. This paper presents the design study with domain experts that resulted in the design guidelines, the tool, and user feedback.","1941-0506","","10.1109/TVCG.2020.3030382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222266","Visual data analysis;Design study;Network visualization;Functional safety;Automotive engineering","Hazards;Acceleration;Visualization;Automotive engineering;Brakes;Tools","automobile industry;automobiles;automotive electronics;automotive engineering;data analysis;data visualisation;failure analysis;mechanical engineering computing;road safety;safety-critical software;systems engineering;vehicle dynamics","visual data analysis tool;visual comparison;design guidelines;modern automobiles;mechanical machines;full-fledged electronics systems;vehicle dynamics;driver experience;complex hardware;software systems;brakes;tragic outcomes;broadly speaking;systems engineering domain;SafetyLens;automotive functional safety datasets","","","","57","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Same Stats, Different Graphs: Exploring the Space of Graphs in Terms of Graph Properties","H. Chen; U. Soni; Y. Lu; V. Huroyan; R. Maciejewski; S. Kobourov","Department of Computer Science, The University of Arizona, Tucson, AZ, USA; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Phoenix, AZ, USA; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Phoenix, AZ, USA; Department of Computer Science, The University of Arizona, Tucson, AZ, USA; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Phoenix, AZ, USA; Department of Computer Science, The University of Arizona, Tucson, AZ, USA","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","3","2056","2072","Data analysts commonly utilize statistics to summarize large datasets. While it is often sufficient to explore only the summary statistics of a dataset (e.g., min/mean/max), Anscombe's Quartet demonstrates how such statistics can be misleading. We consider a similar problem in the context of graph mining. To study the relationships between different graph properties, we examine low-order non-isomorphic graphs and provide a simple visual analytics system to explore correlations across multiple graph properties. However, for larger graphs, studying the entire space quickly becomes intractable. We use different random graph generation methods to further look into the distribution of graph properties for higher order graphs and investigate the impact of various sampling methodologies. We also describe a method for generating many graphs that are identical over a number of graph properties and statistics yet are clearly different and identifiably distinct.","1941-0506","","10.1109/TVCG.2019.2946558","National Science Foundation(grant numbers:CCF-1740858,DMS-1839274); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863985","Graph mining;graph properties;graph generators","Generators;Correlation;Data mining;Space exploration;Visual analytics;Tools","data analysis;data mining;data visualisation;graph theory;random processes","low-order nonisomorphic graphs;graph properties;random graph generation;graph mining;data analysts;visual analytics system","","","","61","IEEE","11 Oct 2019","","","IEEE","IEEE Journals"
"Scalable Comparative Visualization of Ensembles of Call Graphs","S. Kesavan; H. Bhatia; A. Bhatele; S. Brink; O. Pearce; T. Gamblin; P. -T. Bremer; K. -L. Ma","Computer Science, UC Davis, 8789 Davis, California, United States, (e-mail: spkesavan@ucdavis.edu); Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, 4578 Livermore, California, United States, 94550 (e-mail: hbhatia@llnl.gov); Computer Science, University of Maryland at College Park, 1068 College Park, Maryland, United States, (e-mail: bhatele@cs.umd.edu); Center for Applied Scientific Computing, LLNL, 4578 Livermore, California, United States, (e-mail: brink2@llnl.gov); Center for Applied Scientific Computing, LLNL, 4578 Livermore, California, United States, (e-mail: pearce8@llnl.gov); Center for Applied Scientific Computing, LLNL, 4578 Livermore, California, United States, (e-mail: tgamblin@llnl.gov); Center for Applied Scientific Computing, LLNL, 4578 Livermore, California, United States, (e-mail: bremer5@llnl.gov); Computer Science, UC Davis, 8789 Davis, California, United States, (e-mail: ma@cs.ucdavis.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Optimizing the performance of large-scale parallel codes is critical for efficient utilization of computing resources. Code developers often explore various execution parameters, such as hardware configurations, system software choices, and application parameters, and are interested in detecting and understanding bottlenecks in different executions. They often collect hierarchical performance profiles represented as call graphs, which combine performance metrics with their execution contexts. The crucial task of exploring multiple call graphs together is tedious and challenging because of the many structural differences in the execution contexts and significant variability in the collected performance metrics (e.g., execution runtime). In this paper, we present EnsembleCallFlow to support the exploration of ensembles of call graphs using new types of visualizations, analysis, graph operations, and features. We introduce ensemble-Sankey, a new visual design that combines the strengths of resource-flow (Sankey) and box-plot visualization techniques. Whereas the resource-flow visualization can easily and intuitively describe the graphical nature of the call graph, the box plots overlaid on the nodes of Sankey convey the performance variability within the ensemble. Our interactive visual interface provides linked views to help explore ensembles of call graphs, e.g., by facilitating the analysis of structural differences, and identifying similar or distinct call graphs. We demonstrate the effectiveness and usefulness of our design through case studies on large-scale parallel codes.","1941-0506","","10.1109/TVCG.2021.3129414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622132","Performance analysis;software visualization;visual analytics;hierarchical data;coordinated and multiple views","Codes;Measurement;Tools;Runtime;Libraries;Task analysis;Data visualization","","","","","","","IEEE","19 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Scalable Scalable Vector Graphics: Automatic Translation of Interactive SVGs to a Multithread VDOM for Fast Rendering","M. Schwab; D. Saffo; N. Bond; S. Sinha; C. Dunne; J. Huang; J. Tompkin; M. Borkin","College of Computer and Information Science, Northeastern University, Boston, Massachusetts, United States, (e-mail: me@michailschwab.com); College of Computer and Information Science, Northeastern University, Boston, Massachusetts, United States, (e-mail: saffo.d@northeastern.edu); College of Computer and Information Science, Northeastern University, Boston, Massachusetts, United States, (e-mail: Nicholaskbond@gmail.com); Department of Computer Science, Brown University, Providence, Rhode Island, United States, (e-mail: shash678@gmail.com); Khoury College of Computer Sciences, Northeastern University, 1848 Boston, Massachusetts, United States, (e-mail: c.dunne@northeastern.edu); Computer Science, Brown Universtiy, Providence, Rhode Island, United States, (e-mail: jeff_huang@brown.edu); Computer Science, Brown University, Providence, Rhode Island, United States, (e-mail: james_tompkin@brown.edu); Khoury College of Computer Sciences, Northeastern University, 1848 Boston, Massachusetts, United States, 02115-5005 (e-mail: m.borkin@northeastern.edu)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","The dominant markup language for Web visualizations---Scalable Vector Graphics (SVG)---is comparatively easy to learn, and is open, accessible, customizable via CSS, and searchable via the DOM, with easy interaction handling and debugging. Because these attributes allow visualization creators to focus on design on implementation details, tools built on top of SVG, such as D3.js, are essential to the visualization community. However, slow SVG rendering can limit designs by effectively capping the number of on-screen data points, and this can force visualization creators to switch to Canvas or WebGL. These are less flexible (e.g., no search or styling via CSS), and harder to learn. We introduce Scalable Scalable Vector Graphics (SSVG) to reduce these limitations and allow complex and smooth visualizations to be created with SVG. SSVG automatically translates interactive SVG visualizations into a dynamic virtual DOM (VDOM) to bypass the browser's slow ‘to specification’ rendering by intercepting JavaScript function calls. De-coupling the SVG visualization specification from SVG rendering, and obtaining a dynamic VDOM, creates flexibility and opportunity for visualization system research. SSVG uses this flexibility to free up the main thread for more interactivity and renders the visualization with Canvas or WebGL on a web worker. Together, these concepts create a drop-in JavaScript library which can improve rendering performance by 3-9X with only one line of code added. To demonstrate applicability, we describe the use of SSVG on many example visualizations including published visualization research. A free copy of this paper, collected data, and source code are available at osf.io/ge8wp.","1941-0506","","10.1109/TVCG.2021.3059294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354592","Visualization Systems;SVG;Performance;Virtual DOM;Rendering;D3js","Data visualization;Rendering (computer graphics);Browsers;Cascading style sheets;Layout;Tools;Instruction sets","","","","","","","IEEE","15 Feb 2021","","","IEEE","IEEE Early Access Articles"
"ScanGAN360: A Generative Model of Realistic Scanpaths for 360° Images","D. Martin; A. Serrano; A. W. Bergman; G. Wetzstein; B. Masia","Universidad de Zaragoza, I3A, Spain; Universidad de Zaragoza, I3A, Spain; Stanford University, United States; Stanford University, United States; Universidad de Zaragoza, I3A, Spain","IEEE Transactions on Visualization and Computer Graphics","8 Apr 2022","2022","28","5","2003","2013","Understanding and modeling the dynamics of human gaze behavior in 360° environments is crucial for creating, improving, and developing emerging virtual reality applications. However, recruiting human observers and acquiring enough data to analyze their behavior when exploring virtual environments requires complex hardware and software setups, and can be time-consuming. Being able to generate <italic>virtual observers</italic> can help overcome this limitation, and thus stands as an open problem in this medium. Particularly, generative adversarial approaches could alleviate this challenge by generating a large number of scanpaths that reproduce human behavior when observing new scenes, essentially mimicking virtual observers. However, existing methods for scanpath generation do not adequately predict realistic scanpaths for 360° images. We present ScanGAN360, a new generative adversarial approach to address this problem. We propose a novel loss function based on dynamic time warping and tailor our network to the specifics of 360° images. The quality of our generated scanpaths outperforms competing approaches by a large margin, and is almost on par with the human baseline. ScanGAN360 allows fast simulation of large numbers of virtual observers, whose behavior mimics real users, enabling a better understanding of gaze behavior, facilitating experimentation, and aiding novel applications in virtual reality and beyond.","1941-0506","","10.1109/TVCG.2022.3150502","European Research Council (ERC)(grant numbers:682080); NSF(grant numbers:1839974); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714046","Scanpath generation;360° images;virtual reality;generative adversarial models;saliency;human behavior","Observers;Predictive models;Solid modeling;Virtual environments;Visualization;MIMICs;Task analysis","","","Computer Graphics;Computer Simulation;Humans;Software","","","70","IEEE","15 Feb 2022","","","IEEE","IEEE Journals"
"SeamlessGAN: Self-Supervised Synthesis of Tileable Texture Maps","C. Rodriguez - Pardo; E. Garces","Research, Seddi, Madrid, Madrid, Spain, 28007 (e-mail: carlos.rodriguezpardo.jimenez@gmail.com); Research, SEDDI, Madrid, Madrid, Spain, 28007 (e-mail: elenagarces@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Real-time graphics applications require high-quality textured materials to convey realism in virtual environments. Generating these textures is challenging as they need to be visually realistic, seamlessly tileable, and have a small impact on the memory consumption of the application. For this reason, they are often created manually by skilled artists. In this work, we present SeamlessGAN,a method capable of automatically generating tileable texture maps from a single input exemplar. In contrast to most existing methods, focused solely on solving the synthesis problem, our work tackles both problems, synthesis and tileability, simultaneously. Our key idea isto realize that tiling a latent space within a generative network trained using adversarial expansion techniques produces outputs with continuity at the seam intersection that can be then be turned into tileable images by cropping the central area. Since not every value of the latent space is valid to produce high-quality outputs, we leverage the discriminator as a perceptual error metric capable of identifying artifact-free textures during a sampling process. Further, in contrast to previous work on deep texture synthesis, our model is designed and optimized to work with multi-layered texture representations, enabling textures composed of multiple maps such as albedo, normals, etc. We extensively test our design choices for the network architecture, loss function, and sampling parameters. We show qualitatively and quantitatively that our approach outperforms previous methods and works for textures of different types.","1941-0506","","10.1109/TVCG.2022.3143615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684694","Artificial intelligence;Artificial neural network;Machine vision;Image texture;Graphics;Computational photography","Measurement;Crops;Training;Semantics;Generative adversarial networks;Estimation;Virtual environments","","","","","","","IEEE","18 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Segmentation Driven Peeling for Visual Analysis of Electronic Transitions","M. Sharma; T. B. Masood; S. S. Thygesen; M. Linares; I. Hotz; V. Natarajan","Indian Institute of Science,Bangalore,India; Linköping University,Department of Science and Technology (ITN),Norrköping,Sweden; Linköping University,Department of Science and Technology (ITN),Norrköping,Sweden; Linköping University,Department of Science and Technology (ITN),Norrköping,Sweden; Linköping University,Department of Science and Technology (ITN),Norrköping,Sweden; Indian Institute of Science,Bangalore,India","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","96","100","Electronic transitions in molecules due to absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of those electronic transitions, i.e. which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this paper, we present a novel approach towards the study of electronic transitions based on the visual analysis of a bivariate field, namely the electron density in the hole and particle Natural Transition Orbital (NTO). The visual analysis focuses on the continuous scatter plots (CSPs) of the bivariate field linked to their spatial domain. The method supports selections in the CSP visualized as fiber surfaces in the spatial domain, the grouping of atoms, and segmentation of the density fields to peel the CSP. This peeling operator is central to the visual analysis process and helps identify donors and acceptors. We study different molecular systems, identifying local excitation and charge transfer excitations to demonstrate the utility of the method.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623300","Human-centered computing;Visualization;Visualization application domains;Scientific visualization","Visualization;Data analysis;Absorption;Conferences;Data visualization;Quantum mechanics;Orbits","charge exchange;charge transfer states;data visualisation;density functional theory;electron density;excited states;impurity states;localised modes;molecular configurations;molecular electronic states;organic compounds;physics computing;quantum theory","electronic transitions;electron density;visual analysis process;particle natural transition orbital;NTO;continuous scatter plots;CSP;quantum mechanical process","","","","22","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Semantic Explanation of Interactive Dimensionality Reduction","Y. Bian; C. North; E. Krokos; S. Joseph",Virginia Tech; Virginia Tech; Department of Defense; Department of Defense,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","26","30","Interactive dimensionality reduction helps analysts explore the high-dimensional data based on their personal needs and domain-specific problems. Recently, expressive nonlinear models are employed to support these tasks. However, the interpretation of these human-steered nonlinear models during human-in-the-loop analysis has not been explored. To address this problem, we present a new visual explanation design called semantic explanation. Semantic explanation visualizes model behaviors in a manner that is similar to users’ direct projection manipulations. This design conforms to the spatial analytic process and enables analysts better understand the updated model in response to their interactions. We propose a pipeline to empower interactive dimensionality reduction with semantic explanation using counterfactuals. Based on the pipeline, we implement a visual text analytics system with nonlinear dimensionality reduction powered by deep learning via the BERT model. We demonstrate the efficacy of semantic explanation with two case studies of academic article exploration and intelligence analysis.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623322","Interactive Dimensionality Reduction;Projection Explanation;Counterfactual Explanation;Human-in-the-loop Analysis","Dimensionality reduction;Deep learning;Analytical models;Visualization;Conferences;Semantics;Pipelines","data analysis;data mining;data visualisation;learning (artificial intelligence);text analysis","semantic explanation;interactive dimensionality reduction;high-dimensional data;domain-specific problems;expressive nonlinear models;visual explanation design;model behaviors;updated model;nonlinear dimensionality reduction","","","","34","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Semantic Resizing of Charts Through Generalization: A Case Study with Line Charts","V. Setlur; H. Chung",Tableau Research; University of Alabama in Huntsville,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","1","5","Inspired by cartographic generalization principles, we present a generalization technique for rendering line charts at different sizes, preserving the important semantics of the data at that display size. The algorithm automatically determines the generalization operators to be applied at that size based on spatial density, distance, and the semantic importance of the various visualization elements in the line chart. A qualitative evaluation of the prototype that implemented the algorithm indicates that the generalized line charts preserved the general data shape, while minimizing visual clutter. We identify future opportunities where generalization can be extended and applied to other chart types and visual analysis authoring tools.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623306","Responsive charts;visual clutter;spatial metrics;Human-centered computing;Visualization","Measurement;Visualization;Shape;Conferences;Semantics;Prototypes;Data visualization","cartography;data visualisation;rendering (computer graphics)","cartographic generalization principles;display size;generalized line charts;general data shape;chart types;chart semantic resizing;visual clutter;visual analysis authoring tools;line chart rendering","","","","47","","30 Nov 2021","","","IEEE","IEEE Conferences"
"Semantic Snapping for Guided Multi-View Visualization Design","Y. S. Kristiansen; L. Garrison; S. Bruckner","Department of Informatics, University of Bergen, Norway; Department of Informatics, University of Bergen, Norway; Department of Informatics, University of Bergen, Norway","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","43","53","Visual information displays are typically composed of multiple visualizations that are used to facilitate an understanding of the underlying data. A common example are dashboards, which are frequently used in domains such as finance, process monitoring and business intelligence. However, users may not be aware of existing guidelines and lack expert design knowledge when composing such multi-view visualizations. In this paper, we present semantic snapping, an approach to help non-expert users design effective multi-view visualizations from sets of pre-existing views. When a particular view is placed on a canvas, it is “aligned” with the remaining views-not with respect to its geometric layout, but based on aspects of the visual encoding itself, such as how data dimensions are mapped to channels. Our method uses an on-the-fly procedure to detect and suggest resolutions for conflicting, misleading, or ambiguous designs, as well as to provide suggestions for alternative presentations. With this approach, users can be guided to avoid common pitfalls encountered when composing visualizations. Our provided examples and case studies demonstrate the usefulness and validity of our approach.","1941-0506","","10.1109/TVCG.2021.3114860","MetaVis project(grant numbers:250133); Research Council of Norway(grant numbers:813558); Trond Mohn Foundation in Bergen, Norway; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555491","Tabular data;guidelines;mixed initiative human-machine analysis;coordinated and multiple views","Data visualization;Semantics;Task analysis;Guidelines;Visualization;Tools;Image color analysis","competitive intelligence;data visualisation;process monitoring","semantic snapping;guided multiview visualization design;visual information displays;process monitoring;business intelligence;expert design knowledge;nonexpert users;effective multiview visualizations;particular view;visual encoding;data dimensions;ambiguous designs;composing visualizations;preexisting views","","","","50","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"Shape-Driven Coordinate Ordering for Star Glyph Sets via Reinforcement Learning","R. Hu; B. Chen; J. Xu; O. van Kaick; O. Deussen; H. Huang","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; School of Computer Science, Carleton University, Ottawa, ON, Canada; Department of Computer and Information Science, University of Konstanz, Konstanz, Germany; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Visualization and Computer Graphics","13 May 2021","2021","27","6","3034","3047","We present a neural optimization model trained with reinforcement learning to solve the coordinate ordering problem for sets of star glyphs. Given a set of star glyphs associated to multiple class labels, we propose to use shape context descriptors to measure the perceptual distance between pairs of glyphs, and use the derived silhouette coefficient to measure the perception of class separability within the entire set. To find the optimal coordinate order for the given set, we train a neural network using reinforcement learning to reward orderings with high silhouette coefficients. The network consists of an encoder and a decoder with an attention mechanism. The encoder employs a recurrent neural network (RNN) to encode input shape and class information, while the decoder together with the attention mechanism employs another RNN to output a sequence with the new coordinate order. In addition, we introduce a neural network to efficiently estimate the similarity between shape context descriptors, which allows to speed up the computation of silhouette coefficients and thus the training of the axis ordering network. Two user studies demonstrate that the orders provided by our method are preferred by users for perceiving class separation. We tested our model on different settings to show its robustness and generalization abilities and demonstrate that it allows to order input sets with unseen data size, data dimension, or number of classes. We also demonstrate that our model can be adapted to coordinate ordering of other types of plots such as RadViz by replacing the proposed shape-aware silhouette coefficient with the corresponding quality metric to guide network training.","1941-0506","","10.1109/TVCG.2021.3052167","National Natural Science Foundation of China(grant numbers:61872250,U2001206,61902254); GD Talent Program(grant numbers:2019JC05X328); GD Science and Technology Program(grant numbers:2020A0505100064,2015A030312015); DEGP Key Project(grant numbers:2018KZDXM058); Shenzhen Innovation Program(grant numbers:JCYJ20180305125709986); Natural Sciences and Engineering Research Council of Canada(grant numbers:2015-05407); DFG(grant numbers:422037984); National Engineering Laboratory for Big Data System Computing Technology; Guangdong Laboratory of Artificial Intelligence and Digital Economy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328215","Star glyph set;coordinate ordering;reinforcement learning;shape context","Shape;Shape measurement;Task analysis;Coordinate measuring machines;Reinforcement learning;Recurrent neural networks;Optimization","data visualisation;learning (artificial intelligence);neural nets;recurrent neural nets","derived silhouette coefficient;class separability;reinforcement learning;high silhouette coefficients;encoder;decoder;attention mechanism;recurrent neural network;input shape;class information;coordinate order;shape context descriptors;axis ordering network;class separation;order input sets;shape-aware silhouette coefficient;network training;shape-driven coordinate ordering;star glyph sets;neural optimization model;coordinate ordering problem;star glyphs;multiple class labels;perceptual distance","","","","28","IEEE","18 Jan 2021","","","IEEE","IEEE Journals"
"SightBi: Exploring Cross-View Data Relationships with Biclusters","M. Sun; A. R. Shaikh; H. Alhoori; J. Zhao","Northern Illinois University, United States; Northern Illinois University, United States; Northern Illinois University, United States; University of Waterloo, Canada","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","54","64","Multiple-view visualization (MV) has been heavily used in visual analysis tools for sensemaking of data in various domains (e.g., bioinformatics, cybersecurity and text analytics). One common task of visual analysis with multiple views is to relate data across different views. For example, to identify threats, an intelligence analyst needs to link people from a social network graph with locations on a crime-map, and then search for and read relevant documents. Currently, exploring cross-view data relationships heavily relies on view-coordination techniques (e.g., brushing and linking), which may require significant user effort on many trial-and-error attempts, such as repetitiously selecting elements in one view, and then observing and following elements highlighted in other views. To address this, we present SightBi, a visual analytics approach for supporting cross-view data relationship explorations. We discuss the design rationale of SightBi in detail, with identified user tasks regarding the use of cross-view data relationships. SightBi formalizes cross-view data relationships as biclusters, computes them from a dataset, and uses a bi-context design that highlights creating stand-alone relationship-views. This helps preserve existing views and offers an overview of cross-view data relationships to guide user exploration. Moreover, SightBi allows users to interactively manage the layout of multiple views by using newly created relationship-views. With a usage scenario, we demonstrate the usefulness of SightBi for sensemaking of cross-view data relationships.","1941-0506","","10.1109/TVCG.2021.3114801","NSF(grant numbers:IIS-2002082,SMA-2022443); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555226","Cross-view data relationship;multi-view visualization;bicluster;visual analytics","Visualization;Data visualization;Tools;Task analysis;Layout;Sun;Bioinformatics","data analysis;data visualisation;pattern clustering","multiple-view visualization;cross-view data relationship explorations;SightBi;biclusters;visual analysis tools;data sensemaking;visual analytics;bi-context design;relationship views","Computer Graphics;Humans","","","74","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"Simultaneous Matrix Orderings for Graph Collections","N. van Beusekom; W. Meulemans; B. Speckmann","TU Eindhoven, the Netherlands; TU Eindhoven, the Netherlands; TU Eindhoven, the Netherlands","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","1","10","Undirected graphs are frequently used to model phenomena that deal with interacting objects, such as social networks, brain activity and communication networks. The topology of an undirected graph <inline-formula><tex-math notation=""LaTeX"">$G$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-1-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> can be captured by an adjacency matrix; this matrix in turn can be visualized directly to give insight into the graph structure. Which visual patterns appear in such a matrix visualization crucially depends on the <italic>ordering</italic> of its rows and columns. Formally defining the quality of an ordering and then automatically computing a high-quality ordering are both challenging problems; however, effective heuristics exist and are used in practice. <p>Often, graphs do not exist in isolation but as part of a collection of graphs on the same set of vertices, for example, brain scans over time or of different people. To visualize such graph collections, we need a <italic>single</italic> ordering that works well for all matrices <italic>simultaneously</italic>. The current state-of-the-art solves this problem by taking a (weighted) union over all graphs and applying existing heuristics. However, this union leads to a loss of information, specifically in those parts of the graphs which are different. We propose a <italic>collection-aware</italic> approach to avoid this loss of information and apply it to two popular heuristic methods: leaf order and barycenter.</p> <p>The de-facto standard computational quality metrics for matrix ordering capture only block-diagonal patterns (cliques). Instead, we propose to use <italic>Moran's</italic> <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-2-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, a spatial auto-correlation metric, which captures the full range of established patterns. Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-3-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> refines previously proposed stress measures. Furthermore, the popular leaf order method heuristically optimizes a similar measure which further supports the use of Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-4-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> in this context. An ordering that maximizes Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-5-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> can be computed via solutions to the Traveling Salesperson Problem (TSP); orderings that approximate the optimal ordering can be computed more efficiently, using any of the approximation algorithms for metric TSP.</p> <p>We evaluated our methods for simultaneous orderings on real-world datasets using Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-6-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> as the quality metric. Our results show that our collection-aware approach matches or improves performance compared to the union approach, depending on the similarity of the graphs in the collection. Specifically, our Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-7-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-based collection-aware leaf order implementation consistently outperforms other implementations. Our collection-aware implementations carry no significant additional computational costs.</p>","1941-0506","","10.1109/TVCG.2021.3114773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552242","Matrix ordering;graph visualization;algorithms;quality measures","Visualization;Measurement;Tools;Symmetric matrices;Current measurement;Standards;Social networking (online)","approximation theory;data visualisation;directed graphs;mathematics computing;matrix algebra;metaheuristics;travelling salesman problems","simultaneous matrix orderings;graph collections;undirected graphs;matrix visualization;high-quality ordering;heuristic methods;barycenter method;de-facto standard computational quality metrics;leaf order method;Moran I-based collection-aware leaf order implementation;traveling salesperson problem;TSP;approximation algorithms","","","","34","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"TeethGNN: Semantic 3D Teeth Segmentation with Graph Neural Networks","Y. Zheng; B. Chen; Y. Shen; K. Shen","Computer Science, Zhejiang University College of Computer Science and Technology, 366095 Hangzhou, Zhejiang, China, 310027; The State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, 310058; State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, 310058; AI Lab, Hangzhou Zoho Information Technology Co. Ltd., Hangzhou, Zhejiang, China","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","In this paper, we present TeethGNN, a novel 3D tooth segmentation method based on graph neural networks (GNNs). Given a mesh-represented 3D dental model in non-Euclidean domain, our method outputs accurate and fine-grained separation of each individual tooth robust to scanning noise, foreign matters (e.g., bubbles, dental accessories, etc.), and even severe malocclusion. Unlike previous CNN-based methods that bypass handling non-Euclidean mesh data by reshaping hand-crafted geometric features into regular grids, we explore the non-uniform and irregular structure of mesh itself in its dual space and exploit graph neural networks for effective geometric feature learning. To address the crowded teeth issues and incomplete segmentation that commonly exist in previous methods, we design a two-branch network, one of which predicts a segmentation label for each facet while the other regresses each facet an offset away from its tooth centroid. Clustering are later conducted on offset-shifted locations, enabling both the separation of adjoining teeth and the adjustment of incompletely segmented teeth. Exploiting GNN for directly processing mesh data frees us from extracting hand-crafted feature, and largely speeds up the inference procedure. Extensive experiments have shown that our method achieves the new state-of-the-art results for teeth segmentation and outperforms previous methods both quantitatively and qualitatively.","1941-0506","","10.1109/TVCG.2022.3153501","National Key Research Development Program of China(grant numbers:2018YFE0100900); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9720214","3D Teeth segmentation;graph neural network;geometric deep learning;clustering","Teeth;Feature extraction;Three-dimensional displays;Semantics;Image segmentation;Deep learning;Representation learning","","","","","","","IEEE","23 Feb 2022","","","IEEE","IEEE Early Access Articles"
"Text Visualization and Close Reading for Journalism with Storifier","N. Sultanum; A. Bezerianos; F. Chevalier","University of Toronto; Univ. Paris-Sud, CNRS, INRIA, Université Paris-Saclay; University of Toronto","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","186","190","Journalistic inquiry often requires analysis and close study of large text collections around a particular topic. We argue that this practice could benefit from a more text- and reading-centered approach to journalistic text analysis, one that allows for a fluid transition between overview of entities of interest, the context of these entities in the text, down to the detailed documents they are extracted from. In this context, we present the design and development of Storifier, a text visualization tool created in close collaboration with a large francophone news office. We also discuss a case study on how our tool was used to analyze a text collection and helped publish a story.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623264","","Visualization;Fluids;Text analysis;Conferences;Collaboration;Tools;Journalism","data visualisation;publishing;text analysis","Storifier;journalistic inquiry;text collection;journalistic text analysis;text visualization tool;francophone news office","","","","38","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"The Effect of Exploration Mode and Frame of Reference in Immersive Analytics","J. Wagner; W. Stuerzlinger; L. Nedel","Institute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil, 91501-970 (e-mail: jorgewafi@gmail.com); School of Interactive Arts + Technology, Simon Fraser University, Vancouver, British Columbia, Canada, V3T 0A3 (e-mail: w.s@sfu.ca); Instituto de Informtica, UFRGS, Porto Alegre, Rio Grande do Sul, Brazil, 91501-470 (e-mail: nedel@inf.ufrgs.br)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","The design space for user interfaces for Immersive Analytics applications is vast. Designers can combine navigation and manipulation to enable data exploration with ego- or exocentric views, have the user operate at different scales, or use different forms of navigation with varying levels of physical movement. This freedom results in a multitude of different viable approaches. Yet, there is no clear understanding of the advantages and disadvantages of each choice. Our goal is to investigate the affordances of several major design choices, to enable both application designers and users to make better decisions. In this work, we assess two main factors, exploration mode and frame of reference, consequently also varying visualization scale and physical movement demand. To isolate each factor, we implemented nine different conditions in a Space-Time Cube visualization use case and asked 36 participants to perform multiple tasks. We analyzed the results in terms of performance and qualitative measures and correlated them with participants' spatial abilities. While egocentric room-scale exploration significantly reduced mental workload, exocentric exploration improved performance in some tasks. Combining navigation and manipulation made tasks easier by reducing workload, temporal demand, and physical effort.","1941-0506","","10.1109/TVCG.2021.3060666","Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico; Coordenao de Aperfeioamento de Pessoal de Nvel Superior; Canadian Network for Research and Innovation in Machining Technology Natural Sciences and Engineering Research Council of Canada; Global Affairs Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359481","Navigation techniques;Frame of reference;Immersive analytics;Space-time cube","Navigation;Task analysis;Data visualization;Legged locomotion;Three-dimensional displays;Inspection;Affordances","","","","","","","IEEE","19 Feb 2021","","","IEEE","IEEE Early Access Articles"
"The Importance of Phase to Texture Discrimination and Similarity","X. Dong; Y. Gao; J. Dong; M. J. Chantler","Department of Computer Science, Ocean University of China, Qingdao, Shandong, China; Department of Computer Science, Ocean University of China, Qingdao, Shandong, China; Department of Computer Science, Ocean University of China, Qingdao, Shandong, China; Texture Lab, School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, U.K","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2021","2021","27","9","3755","3768","In this article, we investigate the importance of phase for texture discrimination and similarity estimation tasks. We first use two psychophysical experiments to investigate the relative importance of phase and magnitude spectra for human texture discrimination and similarity estimation. The results show that phase is more important to humans for both tasks. We further examine the ability of 51 computational feature sets to perform these two tasks. In contrast with the psychophysical experiments, it is observed that the magnitude data is more important to these computational feature sets than the phase data. We hypothesise that this inconsistency is due to the difference between the abilities of humans and the computational feature sets to utilise phase data. This motivates us to investigate the application of the 51 feature sets to phase-only images in addition to their use on the original data set. This investigation is extended to exploit Convolutional Neural Network (CNN) features. The results show that our feature fusion scheme improves the average performance of those feature sets for estimating humans' perceptual texture similarity. The superior performance should be attributed to the importance of phase to texture similarity.","1941-0506","","10.1109/TVCG.2020.2981063","Young Taishan Scholars Program; National Natural Science Foundation of China(grant numbers:61271405,41576011); Ministry of Education of the People's Republic of China(grant numbers:20120132110018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9040272","Fourier phase;Fourier magnitude;texture features;texture discrimination;texture similarity","Task analysis;Observers;Feature extraction;Visualization;Convolutional neural networks;Computer science","feature extraction;image classification;image texture;neural nets","psychophysical experiments;magnitude spectra;human texture discrimination;51 computational feature;magnitude data;computational feature sets;phase data;phase-only images;Convolutional Neural Network features;humans;texture similarity;similarity estimation tasks","","","","61","IEEE","18 Mar 2020","","","IEEE","IEEE Journals"
"The Sprawlter Graph Readability Metric: Combining Sprawl and Area-Aware Clutter","Z. Liu; T. Itoh; J. Q. Dawson; T. Munzner",University of British Columbia; Ochanomizu University; University of British Columbia; University of British Columbia,"IEEE Transactions on Visualization and Computer Graphics","30 Apr 2020","2020","26","6","2180","2191","Graph drawing readability metrics are routinely used to assess and create node-link layouts of network data. Existing readability metrics fall short in three ways. The many count-based metrics such as edge-edge or node-edge crossings simply provide integer counts, missing the opportunity to quantify the amount of overlap between items, which may vary in size, at a more fine-grained level. Current metrics focus solely on single-level topological structure, ignoring the possibility of multi-level structure such as large and thus highly salient metanodes. Most current metrics focus on the measurement of clutter in the form of crossings and overlaps, and do not take into account the trade-off between the clutter and the information sparsity of the drawing, which we refer to as sprawl. We propose an area-aware approach to clutter metrics that tracks the extent of geometric overlaps between node-node, node-edge, and edge-edge pairs in detail. It handles variable-size nodes and explicitly treats metanodes and leaf nodes uniformly. We call the combination of a sprawl metric and an area-aware clutter metric a sprawlter metric. We present an instantiation of the sprawlter metrics featuring a formal and thorough discussion of the crucial component, the penalty mapping function. We implement and validate our proposed metrics with extensive computational analysis of graph layouts, considering four layout algorithms and 56 layouts encompassing both real-world data and synthetic examples illustrating specific configurations of interest.","1941-0506","","10.1109/TVCG.2020.2970523","Natural Sciences and Engineering Research Council of Canada(grant numbers:#RGPIN-2014-06309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977505","Graph drawing;graph drawing metrics;readability metrics;aesthetic criteria","Measurement;Layout;Clutter;Readability metrics;Compounds;Visualization;Periodic structures","data visualisation;graph theory;telecommunication network topology","node-link layouts;count-based metrics;node-edge crossings;integer counts;fine-grained level;current metrics focus;single-level topological structure;multilevel structure;clutter metrics;geometric overlaps;edge-edge pairs;variable-size nodes;leaf nodes;sprawl metric;sprawlter metrics;graph layouts;sprawlter graph readability metric;graph drawing readability metrics;area-aware clutter metric;salient metanodes","","","","51","IEEE","31 Jan 2020","","","IEEE","IEEE Journals"
"Time-Varying Fuzzy Contour Trees","A. -P. Lohfink; F. Gartzky; F. Wetzels; L. Vollmer; C. Garth","Technische Universität Kaiserslautern,Germany; Technische Universität Kaiserslautern,Germany; Technische Universität Kaiserslautern,Germany; Technische Universität Kaiserslautern,Germany; Technische Universität Kaiserslautern,Germany","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","86","90","We present a holistic, topology-based visualization technique for spatial time series data based on an adaptation of Fuzzy Contour Trees. Common analysis approaches for time dependent scalar fields identify and track specific features. To give a more general overview of the data, we extend Fuzzy Contour Trees, from the visualization and simultaneous analysis of the topology of multiple scalar fields, to time dependent scalar fields. The resulting time-varying Fuzzy Contour Trees allow the comparison of multiple time steps that are not required to be consecutive. We provide specific interaction and navigation possibilities that allow the exploration of individual time steps and time windows in addition to the behavior of the contour trees over all time steps. To achieve this, we reduce an existing alignment to multiple sub-alignments and adapt the Fuzzy Contour Tree-layout to continuously reflect changes and similarities in the sub-alignments. We apply time-varying Fuzzy Contour Trees to different real-world data sets and demonstrate their usefulness.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623286","Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods","Navigation;Design methodology;Conferences;Time series analysis;Data visualization;Spatial databases;Topology","data visualisation;time series;time-varying systems;trees (mathematics)","resulting time-varying Fuzzy Contour Trees;multiple time steps;individual time steps;time windows;Fuzzy Contour Tree-layout;holistic topology-based visualization technique;spatial time series data;time dependent scalar fields identify;multiple scalar fields","","","","15","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"TimeElide: Visual Analysis of Non-Contiguous Time Series Slices","M. Oppermann; L. Liu; T. Munzner",University of British Columbia; University of British Columbia; University of British Columbia,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","41","45","We introduce the design and implementation of TimeElide, a visual analysis tool for the novel data abstraction of non-contiguous time series slices, namely time intervals that contain a sequence of time-value pairs but are not adjacent to each other. This abstraction is relevant for analysis tasks where time periods of interest are known in advance or inferred from the data, rather than discovered through open-ended visual exploration. We present a visual encoding design space as an underpinning of TimeElide, and the new sparkbox technique for visualizing fine and coarse grained temporal structures within one view. Datasets from different domains and with varying characteristics guided the development and their analysis provides preliminary evidence of TimeElide’s utility. We provide open-source code and demo at https://github.com/UBC-InfoVis/time-elide and supplemental materials at https://osf.io/yqvmf/.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623320","Human-centered computing;Visualization;Visualization systems and tools","Visualization;Codes;Conferences;Time series analysis;Data visualization;Tools;Encoding","data analysis;data visualisation;time series","visual encoding design space;noncontiguous time series slices;visual analysis tool;data abstraction;time intervals;time-value pairs;open-ended visual exploration;TimeElide;sparkbox technique","","","","26","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Topological Simplifications of Hypergraphs","Y. Zhou; A. Rathore; E. Purvine; B. Wang","Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, Utah, United States; Computer Science, The University of Utah School of Computing, 415825 Salt Lake City, Utah, United States, 84108; Information Modeling & Analysis, Pacific Northwest National Laboratory, Seattle, Washington, United States, 98109; Scientific Computing and Imaging Institute, University of Utah, SALT LAKE CITY, Utah, United States, 84112","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","We study hypergraph visualization via its topological simplification. We explore both vertex simplification and hyperedge simplification of hypergraphs using tools from topological data analysis. In particular, we transform a hypergraph into its graph representations known as the line graph and clique expansion. A topological simplification of such a graph representation induces a simplification of the hypergraph. In simplifying a hypergraph, we allow vertices to be combined if they belong to almost the same set of hyperedges, and hyperedges to be merged if they share almost the same set of vertices. Our proposed approaches are general, mathematically justifiable, and put vertex simplification and hyperedge simplification in a unifying framework.","1941-0506","","10.1109/TVCG.2022.3153895","DOE(grant numbers:DE-SC0021015); NSF(grant numbers:IIS 1513616); Battelle(grant numbers:DE-ACO6-76RL01830); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721603","Hypergraph simplification;hypergraph visualization;graph simplification;topological data analysis","Visualization;Data visualization;Encoding;Bipartite graph;Data analysis;Clutter;Pipelines","","","","","","","IEEE","25 Feb 2022","","","IEEE","IEEE Early Access Articles"
"Topology Constrained Shape Correspondence","X. Li; C. Wen; L. Wang; Y. Fang","NYU Multimedia and Visual Computing Lab, NYU Abu Dhabi, NYU Tandon, Abu Dhabi; NYU Tandon School of Engineering, USA; NYU Multimedia and Visual Computing Lab, NYU Abu Dhabi, NYU Tandon, Abu Dhabi; NYU Multimedia and Visual Computing Lab, NYU Abu Dhabi, NYU Tandon, Abu Dhabi","IEEE Transactions on Visualization and Computer Graphics","1 Sep 2021","2021","27","10","3926","3937","To better address the deformation and structural variation challenges inherently present in 3D shapes, researchers have shifted their focus from designing handcrafted point descriptors to learning point descriptors and their correspondences in a data-driven manner. Recent studies have developed deep neural networks for robust point descriptor and shape correspondence learning in consideration of local structural information. In this article, we developed a novel shape correspondence learning network, called TC-NET, which further enhances performance by encouraging the topological consistency between the embedding feature space and the input shape space. Specifically, in this article, we first calculate the topology-associated edge weights to represent the topological structure of each point. Then, in order to preserve this topological structure in high-dimensional feature space, a structural regularization term is defined to minimize the topology-consistent feature reconstruction loss (Topo-Loss) during the correspondence learning process. Our proposed method achieved state-of-the-art performance on three shape correspondence benchmark datasets. In addition, the proposed topology preservation concept can be easily generalized to other learning-based shape analysis tasks to regularize the topological structure of high-dimensional feature spaces.","1941-0506","","10.1109/TVCG.2020.2994013","NYU Abu Dhabi Institute(grant numbers:AD131); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091324","Topology preservation;shape correspondence;locally linear embedding;graph convolution","Shape;Topology;Heating systems;Manifolds;Image reconstruction;Kernel;Strain","feature extraction;graph theory;image matching;image representation;learning (artificial intelligence);neural nets;topology","topology constrained shape correspondence;deformation;structural variation;handcrafted point descriptors;data-driven manner;deep neural networks;robust point descriptor;local structural information;shape correspondence learning network;called TC-NET;topological consistency;embedding feature space;input shape space;topology-associated edge weights;topological structure;high-dimensional feature space;structural regularization term;topology-consistent feature reconstruction loss;correspondence learning process;shape correspondence benchmark datasets;topology preservation concept;learning-based shape analysis tasks","","","","53","IEEE","11 May 2020","","","IEEE","IEEE Journals"
"Towards Automatic Skeleton Extraction With Skeleton Grafting","C. Yang; B. Indurkhya; J. See; M. Grzegorzek","Institute for Vision and Graphics, University of Siegen, Siegen, Germany; Computer Science and Cognitive Science Departments, Jagiellonian University, Cracow, Poland; Faculty of Computing and Informatics, Multimedia University, Cyberjaya, Selangor, Malaysia; Institute of Medical Informatics, University of Lübeck, Lübeck, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2021","2021","27","12","4520","4532","This article introduces a novel approach to generate visually promising skeletons automatically without any manual tuning. In practice, it is challenging to extract promising skeletons directly using existing approaches. This is because they either cannot fully preserve shape features, or require manual intervention, such as boundary smoothing and skeleton pruning, to justify the eye-level view assumption. We propose an approach here that generates backbone and dense skeletons by shape input, and then extends the backbone branches via skeleton grafting from the dense skeleton to ensure a well-integrated output. Based on our evaluation, the generated skeletons best depict the shapes at levels that are similar to human perception. To evaluate and fully express the properties of the extracted skeletons, we introduce two potential functions within the high-order matching protocol to improve the accuracy of skeleton-based matching. These two functions fuse the similarities between skeleton graphs and geometrical relations characterized by multiple skeleton endpoints. Experiments on three high-order matching protocols show that the proposed potential functions can effectively reduce the number of incorrect matches.","1941-0506","","10.1109/TVCG.2020.3003994","Deutsche Forschungsgemeinschaft(grant numbers:GRK 1564); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122436","Skeleton extraction;skeleton matching;shape matching;skeleton grafting;high-order matching","Skeleton;Solid modeling;Bayes methods;Tuning;Feature extraction","feature extraction;graph theory;image matching","skeleton graphs;multiple skeleton endpoints;potential functions;skeleton grafting;visually promising skeletons;manual tuning;shape features;boundary smoothing;skeleton pruning;eye-level view assumption;dense skeleton;generated skeletons;extracted skeletons;automatic skeleton extraction;high-order matching protocol","Algorithms;Computer Graphics;Humans;Skeleton","","","71","IEEE","22 Jun 2020","","","IEEE","IEEE Journals"
"Towards Understanding Sensory Substitution for Accessible Visualization: An Interview Study","P. Chundury; B. Patnaik; Y. Reyazuddin; C. Tang; J. Lazar; N. Elmqvist","University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; National Federation of the Blind, MD, USA; Poolesville High School, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","1084","1094","For all its potential in supporting data analysis, particularly in exploratory situations, visualization also creates barriers: accessibility for blind and visually impaired individuals. Regardless of how effective a visualization is, providing equal access for blind users requires a paradigm shift for the visualization research community. To enact such a shift, it is not sufficient to treat visualization accessibility as merely another technical problem to overcome. Instead, supporting the millions of blind and visually impaired users around the world who have equally valid needs for data analysis as sighted individuals requires a respectful, equitable, and holistic approach that includes all users from the onset. In this paper, we draw on accessibility research methodologies to make inroads towards such an approach. We first identify the people who have specific insight into how blind people perceive the world: orientation and mobility (O&M) experts, who are instructors that teach blind individuals how to navigate the physical world using non-visual senses. We interview 10 O&M experts—all of them blind—to understand how best to use sensory substitution other than the visual sense for conveying spatial layouts. Finally, we investigate our qualitative findings using thematic analysis. While blind people in general tend to use both sound and touch to understand their surroundings, we focused on auditory affordances and how they can be used to make data visualizations accessible—using sonification and auralization. However, our experts recommended supporting a combination of senses—sound and touch—to make charts accessible as blind individuals may be more familiar with exploring tactile charts. We report results on both sound and touch affordances, and conclude by discussing implications for accessible visualization for blind individuals.","1941-0506","","10.1109/TVCG.2021.3114829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552177","Accessibility;blind users;sonification;visualization;spatial layouts;sound perception","Data visualization;Visualization;Interviews;Blindness;Training;Navigation;Layout","data analysis;data visualisation;handicapped aids","data visualizations;sensory substitution;data analysis;visualization accessibility;blind impaired users;visually impaired users;orientation and mobility experts;O&M experts","Blindness;Computer Graphics;Humans;Touch;Vision, Ocular;Visually Impaired Persons","","","84","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Towards a Survey on Static and Dynamic Hypergraph Visualizations","M. T. Fischer; A. Frings; D. A. Keim; D. Seebacher","University of Konstanz,Germany; University of Konstanz,Germany; University of Konstanz,Germany; University of Konstanz,Germany","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","81","85","Leveraging hypergraph structures to model advanced processes has gained much attention over the last few years in many areas, ranging from protein-interaction in computational biology to image retrieval using machine learning. Hypergraph models can provide a more accurate representation of the underlying processes while reducing the overall number of links compared to regular representations. However, interactive visualization methods for hypergraphs and hypergraph-based models have rarely been explored or systematically analyzed. This paper reviews the existing research landscape for hypergraph and hypergraph model visualizations and assesses the currently employed techniques. We provide an overview and a categorization of proposed approaches, focusing on performance, scalability, interaction support, successful evaluation, and the ability to represent different underlying data structures, including a recent demand for a temporal representation of interaction networks and their improvements beyond graph-based methods. Lastly, we discuss the strengths and weaknesses of the approaches and give an insight into the future challenges arising in this emerging research field.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623305","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623305","Hypergraphs;hypergraph model;temporal;visualization;visual analytics;survey","Proteins;Analytical models;Visualization;Computational modeling;Biological system modeling;Scalability;Image retrieval","data mining;data structures;data visualisation;graph theory;image retrieval;learning (artificial intelligence);network theory (graphs);proteins","static hypergraph visualizations;dynamic hypergraph visualizations;leveraging hypergraph structures;advanced processes;protein-interaction;computational biology;image retrieval;machine learning;hypergraph models;regular representations;interactive visualization methods;hypergraphs;hypergraph-based models;existing research landscape;hypergraph model visualizations;interaction support;different underlying data structures;temporal representation;interaction networks;graph-based methods","","","","45","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Towards replacing physical testing of granular materials with a Topology-based Model","A. Venkat; A. Gyulassy; G. Kosiba; A. Maiti; H. Reinstein; R. Gee; P. -T. Bremer; V. Pascucci","SCI Institute, University of Utah, United States; SCI Institute, University of Utah, United States; Lawrence Livermore National Laboratory, United States; Lawrence Livermore National Laboratory, United States; Lawrence Livermore National Laboratory, United States; Lawrence Livermore National Laboratory, United States; Lawrence Livermore National Laboratory, United States; SCI Institute, University of Utah, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","76","85","In the study of packed granular materials, the performance of a sample (e.g., the detonation of a high-energy explosive) often correlates to measurements of a fluid flowing through it. The “effective surface area,” the surface area accessible to the airflow, is typically measured using a permeametry apparatus that relates the flow conductance to the permeable surface area via the Carman-Kozeny equation. This equation allows calculating the flow rate of a fluid flowing through the granules packed in the sample for a given pressure drop. However, Carman-Kozeny makes inherent assumptions about tunnel shapes and flow paths that may not accurately hold in situations where the particles possess a wide distribution in shapes, sizes, and aspect ratios, as is true with many powdered systems of technological and commercial interest. To address this challenge, we replicate these measurements virtually on micro-CT images of the powdered material, introducing a new Pore Network Model based on the skeleton of the Morse-Smale complex. Pores are identified as basins of the complex, their incidence encodes adjacency, and the conductivity of the capillary between them is computed from the cross-section at their interface. We build and solve a resistive network to compute an approximate laminar fluid flow through the pore structure. We provide two means of estimating flow-permeable surface area: (i) by direct computation of conductivity, and (ii) by identifying dead-ends in the flow coupled with isosurface extraction and the application of the Carman-Kozeny equation, with the aim of establishing consistency over a range of particle shapes, sizes, porosity levels, and void distribution patterns.","1941-0506","","10.1109/TVCG.2021.3114819","Department of Energy(grant numbers:DE-FE0031880); Exascale Computing Project(grant numbers:17-SC-20-SC); U.S. Department of Energy Office of Science and the National Nuclear Security Administration; NSF OAC(grant numbers:1842042,1941085); NSF CMMI(grant numbers:1629660); U.S. Department of Energy by Lawrence Livermore National Laboratory(grant numbers:DE-AC52-07NA27344); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9645370","Physical and Environmental Sciences;Computational Topology-based Techniques;Data Abstractions and Types;Scalar Field Data;Pore Network Model;Morse-Smale Complex","Shape;Mathematical models;Surface treatment;Powders;Computational modeling;Area measurement;Particle measurements","computerised tomography;flow simulation;flow through porous media;geophysical fluid dynamics;granular materials;laminar flow;permeability;porosity;porous materials;voids (solid)","physical testing;Topology-based Model;packed granular materials;effective surface area;permeametry apparatus;flow conductance;Carman-Kozeny equation;flow rate;given pressure drop;inherent assumptions;tunnel shapes;flow paths;wide distribution;aspect ratios;powdered systems;technological interest;commercial interest;microCT images;powdered material;Pore Network Model;Morse-Smale complex;approximate laminar fluid flow;pore structure;flow-permeable surface area;particle shapes","","","","46","IEEE","9 Dec 2021","","","IEEE","IEEE Journals"
"Umbra: A Visual Analysis Approach for Defense Construction Against Inference Attacks on Sensitive Information","X. Wang; C. J. Bryan; Y. Li; R. Pan; Y. Liu; W. Chen; K. -L. Ma","State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: wangxumeng@zju.edu.cn); Computer Science, Arizona State University, 7864 Phoenix, Arizona United States (e-mail: cbryan16@asu.edu); Department of Computer Science, University of California Davis, 8789 Davis, California United States (e-mail: ranli@ucdavis.edu); State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: panrusheng@zju.edu.cn); Computer Science, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: 3150104312@zju.edu.cn); Zhejiang University, State Key Lab of CAD&CG, Hangzhou, Zhejiang China (e-mail: chenwei@cad.zju.edu.cn); Computer Science, University of California at Davis, Davis, California United States 95616-8562 (e-mail: ma@cs.ucdavis.edu)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","Collecting and analyzing anonymous personal information is required as a part of data analysis processes, such as medical diagnosis and restaurant recommendation. Such data should ostensibly be stored so that specific individual information cannot be disclosed. Unfortunately, inference attacks---integrating background knowledge and intelligent models---hinder classic sanitization techniques like syntactic anonymity and differential privacy from exhaustively protecting sensitive information. As a solution, we introduce a three-stage approach empowered within a visual interface, which depicts underlying inferences behaviors via Bayesian Network and supports customized defense against inference attacks from unknown adversaries. In particular, our approach visually explains the process details of the underlying privacy preserving models, allowing users to verify if the results sufficiently satisfy the requirements of privacy preservation. We demonstrate the effectiveness of our approach through two case studies and expert reviews.","1941-0506","","10.1109/TVCG.2020.3037670","National Natural Science Foundation of China(grant numbers:61761136020,61772456); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9258413","Privacy;inference attack;bayesian network;visual analytics","Data privacy;Privacy;Bayes methods;Visualization;Task analysis;Data visualization;Data models","","","","","","","IEEE","12 Nov 2020","","","IEEE","IEEE Early Access Articles"
"Uncertain Transport in Unsteady Flows","T. Rapp; C. Dachsbacher","Karlsruhe Institute of Technology,Institute for Visualization and Data Analysis; Karlsruhe Institute of Technology,Institute for Visualization and Data Analysis","2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","16","20","We study uncertainty in the dynamics of time-dependent flows by identifying barriers and enhancers to stochastic transport. This topological segmentation is closely related to the theory of Lagrangian coherent structures and is based on a recently introduced quantity, the diffusion barrier strength (DBS). The DBS is defined similar to the finite-time Lyapunov exponent (FTLE), but incorporates diffusion during flow integration. Height ridges of the DBS indicate stochastic transport barriers and enhancers, i.e. material surfaces that are minimally or maximally diffusive. To apply these concepts to real-world data, we represent uncertainty in a flow by a stochastic differential equation that consists of a deterministic and a stochastic component modeled by a Gaussian. With this formulation we identify barriers and enhancers to stochastic transport, without performing expensive Monte Carlo simulation and with a computational complexity comparable to FTLE. In addition, we propose a complementary visualization to convey the absolute scale of uncertainties in the Lagrangian frame of reference. This enables us to study uncertainty in real-world datasets, for example due to small deviations, data reduction, or estimated from multiple ensemble runs.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331300","Human-centered computing;Visualization;Visualization application domains;Scientific visualization","Uncertainty;Monte Carlo methods;Satellite broadcasting;Measurement uncertainty;Stochastic processes;Data visualization;Probabilistic logic","computational complexity;computational fluid dynamics;data visualisation;differential equations;flow;Gaussian processes;Lyapunov methods;stochastic processes;topology","DBS;stochastic transport barriers;material surfaces;stochastic differential equation;stochastic component;FTLE;uncertain transport;unsteady flows;time-dependent flow dynamics;topological segmentation;Lagrangian coherent structures;diffusion barrier strength;finite-time Lyapunov exponent;flow integration;complementary visualization","","","","24","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Uncertainty Visualization of the Marching Squares and Marching Cubes Topology Cases","T. M. Athawale; S. Sane; C. R. Johnson","Scientific Computing & Imaging (SCI) Institute, University of Utah; Scientific Computing & Imaging (SCI) Institute, University of Utah; Scientific Computing & Imaging (SCI) Institute, University of Utah","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","106","110","Marching squares (MS) and marching cubes (MC) are widely used algorithms for level-set visualization of scientific data. In this paper, we address the challenge of uncertainty visualization of the topology cases of the MS and MC algorithms for uncertain scalar field data sampled on a uniform grid. The visualization of the MS and MC topology cases for uncertain data is challenging due to their exponential nature and the possibility of multiple topology cases per cell of a grid. We propose the topology case count and entropy-based techniques for quantifying uncertainty in the topology cases of the MS and MC algorithms when noise in data is modeled with probability distributions. We demonstrate the applicability of our techniques for independent and correlated uncertainty assumptions. We visualize the quantified topological uncertainty via color mapping proportional to uncertainty, as well as with interactive probability queries in the MS case and entropy isosurfaces in the MC case. We demonstrate the utility of our uncertainty quantification framework in identifying the isovalues exhibiting relatively high topological uncertainty. We illustrate the effectiveness of our techniques via results on synthetic, simulation, and hixel datasets.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623267","Human-centered computing;Visualization;Visualization application domains;Scientific visualization","Uncertainty;Image color analysis;Conferences;Computational modeling;Probability distribution;Entropy;Data models","computational geometry;data visualisation;entropy;probability;topology","uncertainty visualization;marching squares;marching cubes topology cases;level-set visualization;scientific data;uncertain scalar field data;uniform grid;uncertain data;multiple topology cases;topology case count;entropy-based techniques;independent uncertainty assumptions;correlated uncertainty assumptions;quantified topological uncertainty;MS case;MC case;uncertainty quantification framework;relatively high topological uncertainty","","","","27","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Understanding the Effects of Visualizing Missing Values on Visual Data Exploration","H. Song; Y. Fu; B. Saket; J. Stasko",Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","161","165","When performing data analysis, people often confront data sets containing missing values. We conducted an empirical study to understand the effect of visualizing those missing values on participants’ decision-making processes while performing a visual data exploration task. More specifically, our study participants purchased a hypothetical portfolio of stocks based on a data set where some stocks had missing values for attributes such as PE ratio, beta, and EPS. The experiment used scatterplots to communicate the stock data. For one group of participants, stocks with missing values simply were not shown, while the second group saw such stocks depicted with estimated values as points with error bars. We measured participants’ cognitive load involved in decision-making with data with missing values. Our results indicate that their decision-making workflow was different across two conditions.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623328","Human-centered computing;Visualization;Empiriacal evaluation;Missing data","Visualization;Data analysis;Atmospheric measurements;Conferences;Decision making;Data visualization;Particle measurements","cognition;data analysis;data visualisation;decision making","performing data analysis;data set;visual data exploration task;stock data","","","","38","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Unsupervised Category-Specific Partial Point Set Registration via Joint Shape Completion and Registration","X. Li; L. Wang; Y. Fang","Tandon School of Engineering, New York University, 5894 New York, New York, United States; Electrical Engineering, New York University - Abu Dhabi Campus, 167632 Abu Dhabi, Abu Dhabi, United Arab Emirates; Electrical and Computer Engineering, New York University Tandon School of Engineering, 34242 Brooklyn, New York, United States, 11201","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","We propose a self-supervised method for partial point set registration. Although recently proposed learning-based methods demonstrate impressive registration performance on full shape observations, these methods often suffer from performance degradation when dealing with partial shapes. To bridge the performance gap between partial and full point set registration, we propose to incorporate a shape completion network to benefit the registration process. To achieve this, we introduce a learnable latent code for each pair of shapes, which can be regarded as the geometric encoding of the target shape. By doing so, our model does not require an explicit feature embedding network to learn the feature encodings. More importantly, both our shape completion and point set registration networks take the shared latent codes as input, which are optimized simultaneously with the parameters of two decoder networks in the training process. Therefore, the point set registration process can benefit from the joint optimization process of latent codes, which are enforced to represent the information of full shapes instead of partial ones. In the inference stage, we fix the network parameters and optimize the latent codes to obtain the optimal shape completion and registration results. Our proposed method is purely unsupervised and does not require ground truth supervision. Experiments on the ModelNet40 dataset demonstrate the effectiveness of our model for partial point set registration.","1941-0506","","10.1109/TVCG.2022.3157061","NYU Abu Dhabi Institute(grant numbers:AD131); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729524","Point Set Registration;Partial Registration;Unsupervised learning;Shape Completion","Shape;Three-dimensional displays;Codes;Optimization;Task analysis;Point cloud compression;Training","","","","","","","IEEE","7 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Using Foliation Leaves To Extract Reeb Graphs On Surfaces","S. Wang; W. Wang; H. Zhao","State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, (e-mail: wangsd@ios.ac.cn); State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, (e-mail: whn@ios.ac.cn); State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, (e-mail: huizhao@ios.ac.cn)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","For Reeb graph extraction on surfaces, existing methods always use the isolines of a function defined on the surface to detect the surface components and the neighboring relationships between them. Since such detection is unstable, it is still a challenge for the extracted Reeb graphs to stably and concisely encode the topological information of the surface. In this paper, we address this challenge by using foliation leaves to extract Reeb graphs. In particular, we employ a method for generating measured harmonic foliations by defining loops for foliation initialization and diffusing leaves from loops over the surface. We demonstrate that when the loops are determined, the neighboring relationships between the leaves from different loops are fixed. Thus, we can use loops to represent surface components for robustly detecting the interrelationships between surface components. As a result, we are able to extract stable and concise Reeb graphs. We developed novel measures for loop determination and improved foliation generation, and our method allows the user to manually prescribe loops for generating Reeb graphs with desired structures. Therefore, the potential of Reeb graphs for representing surfaces is enhanced, including conveniently representing the symmetries of the surface and ignoring topological noise. This is verified by our experimental results which indicate that our Reeb graphs are compact and expressive, promoting shape analysis.","1941-0506","","10.1109/TVCG.2022.3141764","National Natural Science Foundation of China(grant numbers:62072446); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9677901","Reeb graph;topology;foliation","Harmonic analysis;Surface treatment;Shape;Level set;Task analysis;Skeleton;Manifolds","","","","","","","IEEE","11 Jan 2022","","","IEEE","IEEE Early Access Articles"
"VAC-CNN: A Visual Analytics System for Comparative Studies of Deep Convolutional Neural Networks","X. Xuan; X. Zhang; O. -H. Kwon; K. -L. Ma","University of California, Davis; University of California, Davis; University of California, Davis; University of California, Davis","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","The rapid development of Convolutional Neural Networks (CNNs) in recent years has triggered significant breakthroughs in many machine learning (ML) applications. The ability to understand and compare various CNN models available is thus essential. The conventional approach with visualizing each model&#x0027;s quantitative features, such as classification accuracy and computational complexity, is not sufficient for a deeper understanding and comparison of the behaviors of different models. Moreover, most of the existing tools for assessing CNN behaviors only support comparison between two models and lack the flexibility of customizing the analysis tasks according to user needs. This paper presents a visual analytics system, VAC-CNN (Visual Analytics for Comparing CNNs), that supports the in-depth inspection of a single CNN model as well as comparative studies of two or more models. The ability to compare a larger number of (e.g., tens of) models especially distinguishes our system from previous ones. With a carefully designed model visualization and explaining support, VAC-CNN facilitates a highly interactive workflow that promptly presents both quantitative and qualitative information at each analysis stage. We demonstrate VAC-CNN&#x0027;s effectiveness for assisting novice ML practitioners in evaluating and comparing multiple CNN models through two use cases and one preliminary evaluation study using the image classification tasks on the ImageNet dataset.","1941-0506","","10.1109/TVCG.2022.3165347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751204","Visual analytics;machine learning;convolutional neural network;model comparison;visual explanation","Analytical models;Visual analytics;Predictive models;Convolutional neural networks;Task analysis;Computational modeling;Numerical models","","","","","","","IEEE","7 Apr 2022","","","IEEE","IEEE Early Access Articles"
"VAINE: Visualization and AI for Natural Experiments","G. Guo; M. Glenski; Z. Shaw; E. Saldanha; A. Endert; S. Volkova; D. Arendt",Georgia Institute of Technology; Pacific Northwest National Laboratories; Pacific Northwest National Laboratories; Pacific Northwest National Laboratories; Georgia Institute of Technology; Pacific Northwest National Laboratories; Pacific Northwest National Laboratories,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","21","25","Natural experiments are observational studies where the assignment of treatment conditions to different populations occurs by chance“in the wild”. Researchers from fields such as economics, healthcare, and the social sciences leverage natural experiments to conduct hypothesis testing and causal effect estimation for treatment and outcome variables that would otherwise be costly, infeasible, or unethical. In this paper, we introduce VAINE (Visualization and AI for Natural Experiments), a visual analytics tool for identifying and understanding natural experiments from observational data. We then demonstrate how VAINE can be used to validate causal relationships, estimate average treatment effects, and identify statistical phenomena such as Simpson’s paradox through two usage scenarios.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623285","Human-centered computing;Visualization;Visualization systems and tools;Visualization application domains;Visual analytics","Economics;Visual analytics;Sociology;Data visualization;Estimation;Medical services;Tools","data analysis;data visualisation;natural sciences computing;statistical analysis","VAINE;treatment conditions;causal effect estimation;visual analytics tool;visualization and AI for natural experiments;natural experiments;Simpson paradox;hypothesis testing","","","","21","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"VERTIGo: A Visual Platform for Querying and Exploring Large Multilayer Networks","E. Cuenca; A. Sallaberry; D. Ienco; P. Poncelet","Yachay Tech University, Urcuquí, Ecuador; LIRMM, AMIS Research Group of the Paul Valéry University of Montpellier, University of Montpellier, Montpellier, France; INRAE, Villeurbanne, France; LIRMM, University of Montpellier, Montpellier, France","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2022","2022","28","3","1634","1647","Many real world data can be modeled by a graph with a set of nodes interconnected to each other by multiple relationships. Such a rich graph is called multilayer graph or network. Providing useful visualization tools to support the query process for such graphs is challenging. Although many approaches have addressed the visual query construction, few efforts have been done to provide a contextualized exploration of query results and suggestion strategies to refine the original query. This is due to several issues such as i) the size of the graphs ii) the large number of retrieved results and iii) the way they can be organized to facilitate their exploration. In this article, we present <italic>VERTIGo</italic>, a novel visual platform to query, explore and support the analysis of large multilayer graphs. <italic>VERTIGo</italic> provides coordinated views to navigate and explore the large set of retrieved results at different granularity levels. In addition, the proposed system supports the refinement of the query by visual suggestions to guide the user through the exploration process. Two examples and a user study demonstrate how <italic>VERTIGo</italic> can be used to perform visual analysis (query, exploration, and suggestion) on real world multilayer networks.","1941-0506","","10.1109/TVCG.2021.3067820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382912","Visual querying system;visual pattern suggestion;multilayer networks","Visualization;Nonhomogeneous media;Task analysis;Social networking (online);Query processing;Databases;Standards","data visualisation;graph theory;query processing","VERTIGo;multiple relationships;rich graph;multilayer graph;providing useful visualization tools;query process;visual query construction;contextualized exploration;original query;graphs ii;retrieved results;novel visual platform;visual suggestions;exploration process;visual analysis;world multilayer networks","Computer Graphics;Humans;Vertigo","","","43","IEEE","22 Mar 2021","","","IEEE","IEEE Journals"
"Vectorizing Quantum Turbulence Vortex-Core Lines for Real-Time Visualization","D. Liu; C. Xiong; X. Liu","School of Information Science and Technology (Shanghai Engineering Research Center of Intelligent Vision and Imaging), ShanghaiTech University, Pudong, China; Institute of Advanced Studies and School of Physical and Mathematical Sciences, Nanyang Technological University, Singapore; School of Information Science and Technology (Shanghai Engineering Research Center of Intelligent Vision and Imaging), ShanghaiTech University, Pudong, China","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2021","2021","27","9","3794","3807","Vectorizing vortex-core lines is crucial for high-quality visualization and analysis of turbulence. While several techniques exist in the literature, they can only be applied to classical fluids. As quantum fluids with turbulence are gaining attention in physics, extracting and visualizing vortex-core lines for quantum fluids is increasingly desirable. In this article, we develop an efficient vortex-core line vectorization method for quantum fluids enabling real-time visualization of high-resolution quantum turbulence structure. From a dataset obtained through simulation, our technique first identifies vortex nodes based on the circulation field. To vectorize the vortex-core lines interpolating these vortex nodes, we propose a novel graph-based data structure, with iterative graph reduction and density-guided local optimization, to locate sub-grid-scale vortex-core line samples more precisely, which are then vectorized by continuous curves. This vortex-core representation naturally captures complex topology, such as branching during reconnection. Our vectorization approach reduces memory consumption by orders of magnitude, enabling real-time visualization performance. Different types of interactive visualizations are demonstrated to show the effectiveness of our technique, which could help further research on quantum turbulence.","1941-0506","","10.1109/TVCG.2020.2981460","ShanghaiTech University; National Natural Science Foundation of China(grant numbers:61502305); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039696","Quantum turbulence;vortex-core line vectorization;real-time visualization;graph representation","Mathematical model;Visualization;Real-time systems;Data visualization;Quantum mechanics;Quantum computing","data structures;data visualisation;flow visualisation;graph theory;interpolation;turbulence;vectors;vortices","interactive visualizations;quantum turbulence vortex-core lines;vectorizing vortex-core lines;high-quality visualization;classical fluids;quantum fluids;vortex-core line vectorization method;high-resolution quantum turbulence structure;vortex nodes;novel graph-based data structure;iterative graph reduction;density-guided local optimization;sub-grid-scale vortex-core line samples;vortex-core representation;vectorization approach;real-time visualization performance","","","","62","IEEE","17 Mar 2020","","","IEEE","IEEE Journals"
"Visilant: Visual Support for the Exploration and Analytical Process Tracking in Criminal Investigations","K. Zákopčanová; M. Řeháček; J. Bátrna; D. Plakinger; S. Stoppel; B. Kozlíková",Masaryk University; Masaryk University; Masaryk University; Masaryk University; University of Bergen and Rainfall AS Bergen; Masaryk University,"IEEE Transactions on Visualization and Computer Graphics","28 Jan 2021","2021","27","2","881","890","The daily routine of criminal investigators consists of a thorough analysis of highly complex and heterogeneous data of crime cases. Such data can consist of case descriptions, testimonies, criminal networks, spatial and temporal information, and virtually any other data that is relevant for the case. Criminal investigators work under heavy time pressure to analyze the data for relationships, propose and verify several hypotheses, and derive conclusions, while the data can be incomplete or inconsistent and is changed and updated throughout the investigation, as new findings are added to the case. Based on a four-year intense collaboration with criminalists, we present a conceptual design for a visual tool supporting the investigation workflow and Visilant, a web-based tool for the exploration and analysis of criminal data guided by the proposed design. Visilant aims to support namely the exploratory part of the investigation pipeline, from case overview, through exploration and hypothesis generation, to the case presentation. Visilant tracks the reasoning process and as the data is changing, it informs investigators which hypotheses are affected by the data change and should be revised. The tool was evaluated by senior criminology experts within two sessions and their feedback is summarized in the paper. Additional supplementary material contains the technical details and exemplary case study.","1941-0506","","10.1109/TVCG.2020.3030356","Ministry of Interior of the Czech Republic(grant numbers:VI20172020096); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222116","Criminal investigation;visualization;network;exploration;interaction;tracking;diagram","Visualization;Tools;Collaboration;Data visualization;Databases;Cognition;Computer crime","criminal law;data visualisation;Internet;police data processing","Visilant;visual support;criminal investigations;heterogeneous data;crime cases;case descriptions;criminal networks;spatial information;temporal information;visual tool;investigation workflow;Web-based tool;criminal data;investigation pipeline;data change","","","","43","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Visual Exploration of Relationships and Structure in Low-Dimensional Embeddings","K. Eckelt; A. Hinterreiter; P. Adelberger; C. Walchshofer; V. Dhanoa; C. Humer; M. Heckmann; C. Steinparz; M. Streit","Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria, 4040; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria, 4040; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria; Institute of Computer Graphics, Johannes Kepler University Linz, 27266 Linz, Upper Austria, Austria","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","In this work, we propose an interactive visual approach for the exploration and formation of structural relationships in embeddings of high-dimensional data. These structural relationships, such as item sequences, associations of items with groups, and hierarchies between groups of items, are defining properties of many real-world datasets. Nevertheless, most existing methods for the visual exploration of embeddings treat these structures as second-class citizens or do not take them into account at all. In our proposed analysis workflow, users explore enriched scatterplots of the embedding, in which relationships between items and/or groups are visually highlighted. The original high-dimensional data for single items, groups of items, or differences between connected items and groups is accessible through additional summary visualizations. We carefully tailored these summary and difference visualizations to the various data types and semantic contexts. During their exploratory analysis, users can externalize their insights by setting up additional groups and relationships between items and/or groups. We demonstrate the utility and potential impact of our approach by means of two use cases and multiple examples from various domains.","1941-0506","","10.1109/TVCG.2022.3156760","Austrian Science Fund(grant numbers:DFH 23-N); Boehringer Ingelheim Regional Center Vienna; LIT - Linz Institute of Technology(grant numbers:LIT-2019-7-SEE-117); sterreichische Forschungsfrderungsgesellschaft(grant numbers:881844); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729550","Dimensionality reduction;projection;visual analytics;layout enrichment;aggregation;comparison","Visualization;Task analysis;Layout;Data visualization;Space exploration;Visual analytics;Trajectory","","","","","","","CCBY","7 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Visual Inspection of DBS Efficacy","B. E. Hollister; G. Duffley; C. Butson; C. Johnson; P. Rosen","California State University Dominguez Hills; Scientific Computing and Imaging Institute,University of Utah; Scientific Computing and Imaging Institute,University of Utah; Scientific Computing and Imaging Institute,University of Utah; University of South Florida","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","1","5","At present, approximately ten million people worldwide are afflicted by Parkinson's Disease (PD). One of the most promising therapies for PD is Deep Brain Stimulation (DBS). DBS works via stimulation of targeted central brain regions (nuclei), whose dysfunction is implicated in PD. A key problem with DBS is determining optimal parameters for clinical outcome. While multiple parameters may influence outcomes in DBS, we explore spatial correlation of volume of tissue activated (VTA) to Unified Parkinson's Disease Rating Scale (UPDRS) scores. Using the Neurostimulation Uncertainty Viewer (nuView), we investigate a number of cooperative visualizations for DBS inspection. Surface-to-surface Euclidean distance between VTA and selected brain nuclei are used in a linked 3D and parallel coordinates view of patient outcome. We then present a semivariogram-based approach to measure spatial correlation of patient outcomes with VTA. As a third component, nuView provides a unique visualization of an ensemble of electrode placements to reduce clutter and emphasize electrodes with spatially similar VTA. These methods corroborate a spatial aspect to DBS efficacy.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933720","Human-centered computing;Visualization;Visualization design and evaluation methods","Satellite broadcasting;Electrodes;Computational modeling;Uncertainty;Brain modeling;Magnetic resonance imaging;Data visualization","biomedical electrodes;biomedical MRI;brain;data visualisation;diseases;image registration;medical disorders;medical image processing;medical signal processing;neurophysiology;vision","deep brain stimulation;targeted central brain regions;spatial correlation;unified Parkinson disease rating scale;DBS inspection;surface-to-surface Euclidean distance;brain nuclei;VTA;DBS efficacy;visual inspection;tissue activated volume;neurostimulation uncertainty viewer;semivariogram-based approach","","","","37","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Visual Reasoning for Uncertainty in Spatio-temporal Events of Historical Figures","W. Zhang; S. Tan; S. Chen; L. Meng; T. Zhang; R. Zhu; W. Chen","Computer Scienece, Zhejiang University, 12377 Hangzhou, Zhejiang, China, 310058 (e-mail: vis-public@cad.zju.edu.cn); Computer Science, Zhejiang University, 12377 Hangzhou, Zhejiang, China, 310058 (e-mail: siweitan@zju.edu.cn); School of Data Science, Fudan University, 12478 Shanghai, Shanghai, China, 200433 (e-mail: simingchen3@gmail.com); Department of Mathematics and Computer Science, University of Technology Eindhoven Department of Mathematics and Computer Science, 215692 Eindhoven, North Brabant, Netherlands, (e-mail: alice.menglh@gmail.com); the state key lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, 310058 (e-mail: zhangtianye1026@zju.edu.cn); School of Software Technology, Zhejiang University, 12377 Hangzhou, Zhejiang, China, 310058 (e-mail: 22051105@zju.edu.cn); Zhejiang University, State Key Lab of CAD&CG, Hangzhou, Zhejiang, China, 310058 (e-mail: chenwei@cad.zju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","The development of digitized humanity information provides a new perspective on data-oriented studies of history. Many previous studies have ignored uncertainty in the exploration of historical figures and events, which has limited the capability of researchers to capture complex processes associated with historical phenomena. We propose a visual reasoning system to support visual reasoning of uncertainty associated with spatio-temporal events of historical figures based on data from the China Biographical Database Project. We build a knowledge graph of entities extracted from a historical database to capture uncertainty generated by missing data and error. The proposed system uses an overview of chronology, a map view, and an interpersonal relation matrix to describe and analyse heterogeneous information of events. The system also includes uncertainty visualization to identify uncertain events with missing or imprecise spatio-temporal information. Results from case studies and expert evaluations suggest that the visual reasoning system is able to quantify and reduce uncertainty generated by the data.","1941-0506","","10.1109/TVCG.2022.3146508","National Natural Science Foundation of China(grant numbers:61772456,61972122); Fundamental Research Funds for the Central Universities(grant numbers:2-2050205-21-688); Science and Technology Commission of Shanghai Municipality(grant numbers:21YF1402900,21ZR1403300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695348","History;Uncertainty;Spatio-temporal Events;Visual Reasoning","Uncertainty;Visualization;Cognition;Data visualization;Biographies;Task analysis;Data mining","","","","","","","IEEE","27 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Visualizing Graph Neural Networks with CorGIE: Corresponding a Graph to Its Embedding","Z. Liu; Y. Wang; J. Bernard; T. Munzner","Software, Beihang University, 12633 Beijing, Beijing, China, (e-mail: zipeng@buaa.edu.cn); Instagram, Facebook Inc, 342996 Menlo Park, California, United States, (e-mail: gnavvy@gmail.com); Computer Science, University of Zurich, 27217 Zurich, ZH, Switzerland, (e-mail: bernard@ifi.uzh.ch); Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia, Canada, (e-mail: tmm@cs.ubc.ca)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Graph neural networks (GNNs) are a class of powerful machine learning tools that model node relations for making predictions of nodes or links. GNN developers rely on quantitative metrics of the predictions to evaluate a GNN, but similar to many other neural networks, it is difficult for them to understand if the GNN truly learns characteristics of a graph as expected. We propose an approach to corresponding an input graph to its node embedding (aka latent space), a common component of GNNs that is later used for prediction. We abstract the data and tasks, and develop an interactive multi-view interface called CorGIE to instantiate the abstraction. As the key function in CorGIE, we propose the K-hop graph layout to show topological neighbors in hops and their clustering structure. To evaluate the functionality and usability of CorGIE, we present how to use CorGIE in two usage scenarios, and conduct a case study with five GNN experts.","1941-0506","","10.1109/TVCG.2022.3148197","Uber Technologies; Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2014- 06309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9705082","Visualization for machine learning;graph neural network;graph layout","Training;Motion pictures;Task analysis;Computational modeling;Aggregates;Pipelines;Layout","","","","","","","IEEE","4 Feb 2022","","","IEEE","IEEE Early Access Articles"
"Visualizing Movement Control Optimization Landscapes","P. Hämäläinen; J. Toikka; A. Babadi; C. K. Liu","Department of Computer Science, Aalto University, Espoo, Finland; Department of Computer Science, Aalto University, Espoo, Finland; Department of Computer Science, Aalto University, Espoo, Finland; Department of Computer Science, Stanford University, Stanford, CA, USA","IEEE Transactions on Visualization and Computer Graphics","28 Jan 2022","2022","28","3","1648","1660","A large body of animation research focuses on optimization of movement control, either as action sequences or policy parameters. However, as closed-form expressions of the objective functions are often not available, our understanding of the optimization problems is limited. Building on recent work on analyzing neural network training, we contribute novel visualizations of high-dimensional control optimization landscapes; this yields insights into why control optimization is hard and why common practices like early termination and spline-based action parameterizations make optimization easier. For example, our experiments show how trajectory optimization can become increasingly ill-conditioned with longer trajectories, but parameterizing control as partial target states—e.g., target angles converted to torques using a PD-controller—can act as an efficient preconditioner. Both our visualizations and quantitative empirical data also indicate that neural network policy optimization scales better than trajectory optimization for long planning horizons. Our work advances the understanding of movement optimization and our visualizations should also provide value in educational use.","1941-0506","","10.1109/TVCG.2020.3018187","Academy of Finland(grant numbers:299358); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172089","Visualization;animation;movement synthesis;trajectory optimization;policy optimization;control optimization","Visualization;Linear programming;Animation;Trajectory optimization;Two dimensional displays","computer animation;control engineering computing;learning (artificial intelligence);learning systems;motion control;neurocontrollers;optimal control;optimisation;PD control;splines (mathematics);trajectory control","animation;action sequences;policy parameters;objective functions;neural network training;trajectory optimization;parameterizing control;PD-controller;spline-based action parameterization;high-dimensional control optimization landscape;movement control optimization landscape visualization;neural network policy optimization;early termination;planning horizon","","","","51","CCBY","20 Aug 2020","","","IEEE","IEEE Journals"
"Visualizing Uncertainty in Probabilistic Graphs with Network Hypothetical Outcome Plots (NetHOPs)","D. Zhang; E. Adar; J. Hullman","Northwestern University, United States; University of Michigan, United States; Northwestern University, United States","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","443","453","Probabilistic graphs are challenging to visualize using the traditional node-link diagram. Encoding edge probability using visual variables like width or fuzziness makes it difficult for users of static network visualizations to estimate network statistics like densities, isolates, path lengths, or clustering under uncertainty. We introduce Network Hypothetical Outcome Plots (NetHOPs), a visualization technique that animates a sequence of network realizations sampled from a network distribution defined by probabilistic edges. NetHOPs employ an aggregation and anchoring algorithm used in dynamic and longitudinal graph drawing to parameterize layout stability for uncertainty estimation. We present a community matching algorithm to enable visualizing the uncertainty of cluster membership and community occurrence. We describe the results of a study in which 51 network experts used NetHOPs to complete a set of common visual analysis tasks and reported how they perceived network structures and properties subject to uncertainty. Participants' estimates fell, on average, within 11% of the ground truth statistics, suggesting NetHOPs can be a reasonable approach for enabling network analysts to reason about multiple properties under uncertainty. Participants appeared to articulate the distribution of network statistics slightly more accurately when they could manipulate the layout anchoring and the animation speed. Based on these findings, we synthesize design recommendations for developing and using animated visualizations for probabilistic networks.","1941-0506","","10.1109/TVCG.2021.3114679","NSF(grant numbers:IIS-1907941,IIS-1815760); Microsoft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552465","Network;Uncertainty;Application","Probabilistic logic;Visualization;Uncertainty;Layout;Task analysis;Stability analysis;Encoding","computer animation;data visualisation;graph theory;image representation;probability","probabilistic graphs;Network Hypothetical Outcome Plots;NetHOPs;traditional node-link diagram;encoding edge probability;visual variables;static network visualizations;network statistics;visualization technique;network realizations;network distribution;probabilistic edges;aggregation;anchoring algorithm;dynamic graph;longitudinal graph;uncertainty estimation;51 network experts;common visual analysis tasks;network structures;network analysts;animated visualizations;probabilistic networks","","","","93","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Visualizing the Scripts of Data Wrangling with SOMNUS","K. Xiong; S. Fu; G. Ding; Z. Luo; R. Yu; W. Chen; H. Bao; Y. Wu","State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: kaixiong@zju.edu.cn); Artificial Intelligence Research Institute, Zhejiang Lab, 559075 Hangzhou, Zhejiang, China, (e-mail: fusiwei339@gmail.com); State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: dinggm@zju.edu.cn); College of Computer Science and Technology, Zhejiang University of Technology, 12624 Hangzhou, Zhejiang, China, (e-mail: rickyluozs@gmail.com); Artificial Intelligence Research Institute, Zhejiang Lab, 559075 Hangzhou, Zhejiang, China, (e-mail: 1721298964@qq.com); State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: chenvis@zju.edu.cn); State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: bao@cad.zju.edu.cn); State Key Lab of CAD&CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: ycwu@zju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Data workers use various scripting languages for data transformation, such as SAS, R, and Python. However, understanding intricate code pieces requires advanced programming skills, which hinders data workers from grasping the idea of data transformation at ease. Program visualization is beneficial for debugging and education and has the potential to illustrate transformations intuitively and interactively. In this paper, we explore visualization design for demonstrating the semantics of code pieces in the context of data transformation. First, to depict individual data transformations, we structure a design space by two primary dimensions, i.e., key parameters to encode and possible visual channels to be mapped. Then, we derive a collection of 23 glyphs that visualize the semantics of transformations. Next, we design a pipeline, named Somnus, that provides an overview of the creation and evolution of data tables using a provenance graph. At the same time, it allows detailed investigation of individual transformations. User feedback on Somnus is positive. Our study participants achieved better accuracy with less time using Somnus, and preferred it over carefully-crafted textual description. Further, we provide two example applications to demonstrate the utility and versatility of Somnus.","1941-0506","","10.1109/TVCG.2022.3144975","National Natural Science Foundation of China(grant numbers:62002331,62072400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693232","Program understanding;data transformation;visualization design","Data visualization;Codes;Semantics;Visualization;Debugging;Python;Task analysis","","","","","","","IEEE","25 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Visually Analyzing Contextualized Embeddings","M. Berger",Vanderbilt University,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","276","280","In this paper we introduce a method for visually analyzing contextualized embeddings produced by deep neural network-based language models. Our approach is inspired by linguistic probes for natural language processing, where tasks are designed to probe language models for linguistic structure, such as parts-of-speech and named entities. These approaches are largely confirmatory, however, only enabling a user to test for information known a priori. In this work, we eschew supervised probing tasks, and advocate for unsupervised probes, coupled with visual exploration techniques, to assess what is learned by language models. Specifically, we cluster contextualized embeddings produced from a large text corpus, and introduce a visualization design based on this clustering and textual structure - cluster co-occurrences, cluster spans, and cluster-word membership- to help elicit the functionality of, and relationship between, individual clusters. User feedback highlights the benefits of our design in discovering different types of linguistic structures.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331271","Machine Learning;visual analytics;Natural Language Processing","Visualization;Analytical models;Linguistics;Natural language processing;Probes;Task analysis;Context modeling","data visualisation;deep learning (artificial intelligence);interactive systems;natural language processing;pattern clustering;text analysis","cluster spans;cluster-word membership;linguistic structure;analyzing contextualized embeddings;deep neural network-based language models;linguistic probes;natural language processing;parts-of-speech;supervised probing tasks;unsupervised probes;visual exploration techniques;visualization design;cluster cooccurrences","","","","37","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Visually Connecting Historical Figures Through Event Knowledge Graphs","S. Latif; S. Agarwal; S. Gottschalk; C. Chrosch; F. Feit; J. Jahn; T. Braun; Y. C. Tchenko; E. Demidova; F. Beck","University of Duisburg-Essen,paluno; University of Duisburg-Essen,paluno; Leibniz University of Hannover,L3S Research Center; University of Duisburg-Essen; University of Duisburg-Essen; University of Duisburg-Essen; University of Duisburg-Essen; University of Duisburg-Essen; University of Bonn,Data Science & Intelligent Systems (DSIS); University of Duisburg-Essen,paluno","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","156","160","Knowledge graphs store information about historical figures and their relationships indirectly through shared events. We developed a visualization system, VisKonnect, for analyzing the intertwined lives of historical figures based on the events they participated in. A user’s query is parsed for identifying named entities, and related data is retrieved from an event knowledge graph. While a short textual answer to the query is generated using the GPT-3 language model, various linked visualizations provide context, display additional information related to the query, and allow exploration.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623313","Deutsche Forschungsgemeinschaft; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623313","Knowledge graphs;general public;question answering;visualization;natural language generation","Conferences;Natural languages;Data visualization;Context modeling","data mining;data visualisation;graph theory;natural language processing;natural languages;query processing;text analysis","linked visualizations;historical figures;event knowledge graph;knowledge graphs;shared events;visualization system","","","","25","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"VividGraph: Learning to Extract and Redesign Network Graphs from Visualization Images","S. Song; C. Li; Y. Sun; C. Wang","School of Computer Science and Technology, East China Normal University, 12655 Shanghai, Shanghai, China; School of Computer Science and Technology, East China Normal University, 12655 Shanghai, Shanghai, China; School of Computer Science and Technology, East China Normal University, 12655 Shanghai, Shanghai, China; School of Computer Science and Technology, East China Normal University, 12655 Shanghai, Shanghai, China","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Network graphs are common visualization charts. They often appear in the form of bitmaps in papers, web pages, magazine prints, and designer sketches. People often want to modify network graphs because of their poor design, but it is difficult to obtain their underlying data. In this paper, we present VividGraph, a pipeline for automatically extracting and redesigning network graphs from static images. We propose using convolutional neural networks to solve the problem of network graph data extraction. Our method is robust to hand-drawn graphs, blurred graph images, and large graph images. We also present a network graph classification module to make it effective for directed graphs. We propose two evaluation methods to demonstrate the effectiveness of our approach. It can be used to quickly transform designer sketches, extract underlying data from existing network graphs, and interactively redesign poorly designed network graphs.","1941-0506","","10.1109/TVCG.2022.3153514","National Natural Science Foundation of China(grant numbers:61802128,62072183); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9720180","Information visualization;Network graph;Data extraction;Chart recognition;Semantic segmentation;Redesign","Data mining;Semantics;Image color analysis;Image segmentation;Data visualization;Pipelines;Image edge detection","","","","","","","IEEE","23 Feb 2022","","","IEEE","IEEE Early Access Articles"
"VizSnippets: Compressing Visualization Bundles Into Representative Previews for Browsing Visualization Collections","M. Oppermann; T. Munzner","University of British Columbia, Canada; University of British Columbia, Canada","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","747","757","Visualization collections, accessed by platforms such as Tableau Online or Power Bl, are used by millions of people to share and access diverse analytical knowledge in the form of interactive visualization bundles. Result snippets, compact previews of these bundles, are presented to users to help them identify relevant content when browsing collections. Our engagement with Tableau product teams and review of existing snippet designs on five platforms showed us that current practices fail to help people judge the relevance of bundles because they include only the title and one image. Users frequently need to undertake the time-consuming endeavour of opening a bundle within its visualization system to examine its many views and dashboards. In response, we contribute the first systematic approach to visualization snippet design. We propose a framework for snippet design that addresses eight key challenges that we identify. We present a computational pipeline to compress the visual and textual content of bundles into representative previews that is adaptive to a provided pixel budget and provides high information density with multiple images and carefully chosen keywords. We also reflect on the method of visual inspection through random sampling to gain confidence in model and parameter choices.","1941-0506","","10.1109/TVCG.2021.3114841","Madison Elliot, Steve Kasica, Zipeng Liu, Ben Shneiderman, and Mara Solen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555620","visualization collections;visualization bundles;result snippets;visual inspection","Data visualization;Visualization;Tools;Pipelines;Layout;Inspection;Image coding","data visualisation;information retrieval;Internet;query processing;search engines;text analysis;user interfaces","representative previews;visualization collections;Tableau Online;Power Bl;diverse analytical knowledge;interactive visualization bundles;result snippets;compact previews;relevant content;browsing collections;visualization system;visualization snippet design;visual content;textual content;visual inspection","","","","72","IEEE","1 Oct 2021","","","IEEE","IEEE Journals"
"WYSIWYG Design of Hypnotic Line Art","C. -K. Yeh; Z. Liu; I. -H. Lin; E. Zhang; T. -Y. Lee","Computer Science and Software, Zhaoqing University, 117974 Zhaoqing, Guangdong, China, (e-mail: simpson.ycg@gmail.com); Computer Science, Kentucky State University, Frankfort, Kentucky, United States, 40601 (e-mail: zhanpingliu@hotmail.com); Computer Science and Information Engineering, National Cheng-Kung University, Tainan, 701, Taiwan, (e-mail: sherrygottalent@hotmail.com); Computer Science, Oregon State University, Corvallis, Oregon, United States, 97331 (e-mail: zhange@eecs.oregonstate.edu); Dept. of Computer Science and Information Engineering, National Cheng-Kung University, Tainan, Taiwan, Taiwan, 7001 (e-mail: tonylee@mail.ncku.edu.tw)","IEEE Transactions on Visualization and Computer Graphics","","2020","PP","99","1","1","Hypnotic line art is a modern form in which white narrow curved ribbons, with the width and direction varying along each path over a black background, provide a keen sense of 3D objects regarding surface shapes and topological contours. However, the procedure of manually creating such line art work can be quite tedious and time-consuming. In this paper, we present an interactive system that offers a What-You-See-Is-What-You-Get (WYSIWYG) scheme for producing hypnotic line art images by integrating and placing evenly-spaced streamlines in tensor fields. With an input picture segmented, the user just needs to sketch a few illustrative strokes to guide the construction of a tensor field for each part of the objects therein. Specifically, we propose a new method which controls, with great precision, the aesthetic layout and artistic drawing of an array of streamlines in each tensor field to emulate the style of hypnotic line art. Given several parameters for streamlines such as density, thickness, and sharpness, our system is capable of generating professional-level hypnotic line art work. With great ease of use, it allows art designers to explore a wide variety of possibilities to obtain hypnotic line art results of their own preferences.","1941-0506","","10.1109/TVCG.2020.3032734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234714","Non-photorealistic rendering (NPR);hypnotic line art;tensor field design;streamline placement;vector field visualization","Art;Tensors;Three-dimensional displays;Streaming media;Shape;Rendering (computer graphics);Layout","","","","","","","IEEE","21 Oct 2020","","","IEEE","IEEE Early Access Articles"
"When Red Means Good, Bad, or Canada: Exploring People’s Reasoning for Choosing Color Palettes","J. Ahmad; E. Huynh; F. Chevalier",University of Toronto; University of Toronto; University of Toronto,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","56","60","Color palette selection is an essential aspect of visualization design, influencing data interpretation and evoking emotions in the viewer. Rules of thumb grounded in perceptual science and visual arts generally form the basis of recommendation tools to support color assignment, but palette design is more nuanced than optimizing for perceptual tasks. In this work, we investigate how the general public reconciles the varied facets of color design in visualization. Does their decision-making align with established rules of thumb? What factors do they take into consideration? Through a crowd-sourced study with 63 participants, we find that the majority of palette choices are perceptually motivated, but other factors such as semantic associations and bias also play a role. We identify some flaws in participant reasoning, highlight clashes in opinions, and present some implications for future work in this space.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623314","Color;General Public;Human Subjects Qualitative Studies","Fault diagnosis;Visualization;Image color analysis;Conferences;Decision making;Semantics;Data visualization","data visualisation;image colour analysis","visualization design;data interpretation;evoking emotions;perceptual science;visual arts;recommendation tools;color palette design;decision-making;crowd-sourced study;palette choices;Canada;people;color palette selection","","","","37","","30 Nov 2021","","","IEEE","IEEE Conferences"
"<italic>Where Can We Help</italic>? A Visual Analytics Approach to Diagnosing and Improving Semantic Segmentation of Movable Objects","W. He; L. Zou; A. K. Shekar; L. Gou; L. Ren","Robert Bosch Research and Technology Center, USA; Robert Bosch Research and Technology Center, USA; Robert Bosch GmbH, Germany; Robert Bosch Research and Technology Center, USA; Robert Bosch Research and Technology Center, USA","IEEE Transactions on Visualization and Computer Graphics","24 Dec 2021","2022","28","1","1040","1050","Semantic segmentation is a critical component in autonomous driving and has to be thoroughly evaluated due to safety concerns. Deep neural network (DNN) based semantic segmentation models are widely used in autonomous driving. However, it is challenging to evaluate DNN-based models due to their black-box-like nature, and it is even more difficult to assess model performance for crucial objects, such as lost cargos and pedestrians, in autonomous driving applications. In this work, we propose <italic>VASS</italic>, a <italic><underline>V</underline></italic>isual <italic><underline>A</underline></italic>nalytics approach to diagnosing and improving the accuracy and robustness of <italic><underline>S</underline></italic>emantic <italic><underline>S</underline></italic>egmentation models, especially for critical objects moving in various driving scenes. The key component of our approach is a context-aware spatial representation learning that extracts important spatial information of objects, such as position, size, and aspect ratio, with respect to given scene contexts. Based on this spatial representation, we first use it to create visual summarization to analyze models' performance. We then use it to guide the generation of adversarial examples to evaluate models' spatial robustness and obtain actionable insights. We demonstrate the effectiveness of <italic>VASS</italic> via two case studies of lost cargo detection and pedestrian detection in autonomous driving. For both cases, we show quantitative evaluation on the improvement of models' performance with actionable insights obtained from <italic>VASS</italic>.","1941-0506","","10.1109/TVCG.2021.3114855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552909","Model diagnosis;semantic segmentation;spatial representation learning;adversarial learning;autonomous driving","Semantics;Image segmentation;Autonomous vehicles;Analytical models;Robustness;Visual analytics;Data models","convolutional neural nets;data analysis;data visualisation;deep learning (artificial intelligence);image segmentation;object detection;traffic engineering computing","visual analytics approach;movable objects;deep neural network;semantic segmentation models;DNN-based models;pedestrians;autonomous driving applications;VASS;driving scenes;context-aware spatial representation;scene contexts;visual summarization;lost cargo detection;pedestrian detection;quantitative evaluation;semantic segmentation","Automobile Driving;Computer Graphics;Humans;Neural Networks, Computer;Pedestrians;Semantics","","","52","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Where and Why is My Bot Failing? A Visual Analytics Approach for Investigating Failures in Chatbot Conversation Flows","A. Yaeli; S. Zeltyn","IBM Research,Haifa; IBM Research,Haifa","2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","141","145","The ongoing coronavirus pandemic has accelerated the adoption of AI-powered task-oriented chatbots by businesses and healthcare organizations. Despite advancements in chatbot platforms, implementing a successful and effective bot is still challenging and requires a lot of manual work. There is a strong need for tools to help conversation analysts quickly identify problem areas and, consequently, introduce changes to chatbot design. We present a visual analytics approach and tool for conversation analysts to identify and assess common patterns of failure in conversation flows. We focus on two key capabilities: path flow analysis and root cause analysis. Interim evaluation results from applying our tool in real-world customer production projects are presented.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623295","visual analytics;conversation analytics;visualization systems and tools;chatbots;dialogue systems;root cause analysis","Root cause analysis;Pandemics;Visual analytics;Production;Organizations;Medical services;Manuals","artificial intelligence;chatbots;data visualisation;health care;interactive systems","visual analytics;chatbot conversation flows;coronavirus pandemic;AI-powered task-oriented chatbots;healthcare organizations;chatbot platforms;conversation analysts;problem areas;path flow analysis;root cause analysis","","","","18","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"fCoSE: a fast compound graph layout algorithm with constraint support","H. Balci; U. Dogrusoz","Department of Computer Engineering, Bilkent University, Ankara, Bilkent, Turkey, (e-mail: hasan.balci@bilkent.edu.tr); Computer Engineering, Bilkent University, Ankara, -, Turkey, 06800 (e-mail: ugur@cs.bilkent.edu.tr)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Visual analysis of relational information is vital in most real-life analytics applications. Automatic layout is a key requirement for effective visual display of such information. This paper introduces a new layout algorithm named fCoSE for compound graphs showing varying levels of groupings or abstractions with support for user-specified placement constraints. fCoSE builds on a previous compound spring embedder layout algorithm and makes use of the spectral graph drawing technique for producing a quick draft layout, followed by phases where constraints are enforced and compound structures are properly shown while polishing the layout with respect to commonly accepted graph layout criteria. Experimental evaluation verifies that fCoSE produces quality layouts and is fast enough for interactive applications with small to medium-sized graphs by combining the speed of spectral graph drawing technique with the quality of force-directed layout algorithms while satisfying specified constraints and properly displaying compound structures. An implementation of fCoSE along with documentation and a demo page is freely available on GitHub.","1941-0506","","10.1109/TVCG.2021.3095303","The Scientific and Technological Research Council of Turkey(grant numbers:118E131,5180088); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477202","Information visualization;graph layout;visual analytics;compound graphs;constrained layout;spectral graph drawing","Layout;Compounds;Stress;Data visualization;Time complexity;Springs;Heuristic algorithms","","","","","","","IEEE","7 Jul 2021","","","IEEE","IEEE Early Access Articles"
"“Why did my AI agent lose?”: Visual Analytics for Scaling Up After-Action Review","D. Tabatabai; A. Ruangrotsakun; J. Irvine; J. Dodge; Z. Shureih; K. -H. Lam; M. Burnett; A. Fern; M. Kahng",Oregon State University; Oregon State University; Oregon State University; Oregon State University; Oregon State University; Oregon State University; Oregon State University; Oregon State University; Oregon State University,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","16","20","How can we help domain-knowledgeable users who do not have expertise in AI analyze why an AI agent failed? Our research team previously developed a new structured process for such users to assess AI, called After-Action Review for AI (AAR/AI), consisting of a series of steps a human takes to assess an AI agent and formalize their understanding. In this paper, we investigate how the AAR/AI process can scale up to support reinforcement learning (RL) agents that operate in complex environments. We augment the AAR/AI process to be performed at three levels—episode-level, decision-level, and explanation-level—and integrate it into our redesigned visual analytics interface. We illustrate our approach through a usage scenario of analyzing why a RL agent lost in a complex real-time strategy game built with the StarCraft 2 engine. We believe integrating structured processes like AAR/AI into visualization tools can help visualization play a more critical role in AI interpretability.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623268","","Visual analytics;Conferences;Reinforcement learning;Games;Tools;Real-time systems;Artificial intelligence","computer games;data visualisation;reinforcement learning","structured processes;AI interpretability;AI agent;domain-knowledgeable users;after-action review;reinforcement learning agents;visual analytics interface;RL agent;AAR-AI process;decision-level;explanation-level;episode-level;StarCraft 2 engine;visualization tools;complex real-time strategy game","","","","31","","30 Nov 2021","","","IEEE","IEEE Conferences"
"Guest Editorial: Special Section on Visual Analytics","D. A. Keim; G. G. Robertson; J. J. Thomas; J. J. van Wijk",NA; NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","18 Sep 2006","2006","12","6","1361","1362","","1941-0506","","10.1109/TVCG.2006.93","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703358","","Visual analytics;Multidimensional systems;Communication networks;Data analysis;Social network services;Tree graphs;Research and development;Information analysis;Turning;Visualization","","","","6","","","","18 Sep 2006","","","IEEE","IEEE Journals"
"Errata to “Guidelines for Effective Usage of Text Highlighting Techniques” [1]","H. Strobelt; D. Oelke; B. C. Kwon; T. Schreck; H. Pfister","Harvard University, MA, Cambridge; German Institute for International Educational Research, Frankfurt, Germany; University of Konstanz, Konstanz, Germany; Graz University of Technology, Graz, Austria; Harvard University, MA, Cambridge","IEEE Transactions on Visualization and Computer Graphics","24 Mar 2016","2016","22","5","1637","1637","Presents corrections for the paper, “Guidelines for effective usage of text highlighting techniques,” (Strobelt, H., et al), IEEE Trans. Vis. Comput.Graph., vol. 22, no. 1, pp. 489–498, Jan. 2016. ","1941-0506","","10.1109/TVCG.2016.2532240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7440927","","Text mining;Statistical analysis","","","","1","","1","IEEE","24 Mar 2016","","","IEEE","IEEE Journals"
"Errata to “RingText: Dwell-Free and Hands-Free Text Entry for Mobile Head-Mounted Displays Using Head Motions” [May 19 1991-2001]","W. Xu; H. -N. Liang; Y. Zhao; T. Zhang; D. Yu; D. Monteiro","Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China; Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China; Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China; Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China; Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China; Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China","IEEE Transactions on Visualization and Computer Graphics","27 May 2019","2019","25","7","2513","2513","Presents corrections to author information for the paper, “RingText: Dwell-Free and Hands-Free Text Entry for Mobile Head-Mounted Displays Using Head Motions,” (Xu, W., et al), IEEE Trans. Vis. Comput. Graph., vol. 25, no. 5, pp. 1991–2001, May 2019.","1941-0506","","10.1109/TVCG.2019.2913518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723303","","Head-mounted displays;Mobile computing;Virtual reality;Text analysis;Keyboards","","","","","","1","IEEE","27 May 2019","","","IEEE","IEEE Journals"
"Errata to “Robust Non-Rigid Motion Tracking and Surface Reconstruction Using L<sub>0 </sub> Regularization”","K. Guo; F. Xu; Y. Wang; Y. Liu; Q. Dai",NA; NA; NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","25 May 2018","2018","24","7","2268","2268","Presents corrections to grant number information from the paper, “Robust non-rigid motion tracking and surface reconstruction using L0 regularization,” (Guo, K., et al), IEEE Trans. Vis. Comput. Graph., vol. 24, no. 5, pp. 1770–1783, May 2018. ","1941-0506","","10.1109/TVCG.2018.2826859","National key foundation(grant numbers:2013YQ140517); The open funding project of state key laboratory of virtual reality technology and systems of Beihang University(grant numbers:BUAA-VR-14KF-08); NSFC(grant numbers:61671268,61522111,61531014,61727808); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8365924","","Surface reconstruction;Motion tracking","","","","","","1","IEEE","25 May 2018","","","IEEE","IEEE Journals"
"Guest Editor's Introduction: Special Section on EuroVis","K. Museth; A. Ynnerman; T. Möller",NA; NA; NA,"IEEE Transactions on Visualization and Computer Graphics","23 May 2008","2008","14","4","725","726","The three papers in this special section are extended versions of three papers from the Ninth Eurographics/IEEE VGTC Symposium on Visualization (EuroVis '07), held in Norrkoping, Sweden, May 23-25, 2007. The papers are summarized here.","1941-0506","","10.1109/TVCG.2008.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4530418","","Animation;Electroencephalography;Data visualization;Electrodes;Quantum computing;Sections;Pattern analysis;Layout;Graphics;Hardware","","","","","","","IEEE","23 May 2008","","","IEEE","IEEE Journals"
"Guest Editor's Introduction: Special Section on VRST","W. Purgathofer",NA,"IEEE Transactions on Visualization and Computer Graphics","17 Nov 2008","2009","15","1","4","5","The three papers in this special section are extended versions of papers originally presented at the ACM Symposium on Virtual Reality Software and Technology (VRST) 2007.","1941-0506","","10.1109/TVCG.2009.7","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4675193","","Three dimensional displays;Virtual reality;Rendering (computer graphics);Design for disassembly;Aerodynamics;Navigation;Virtual environment;Application software;Robustness;Layout","","","","","","","","17 Nov 2008","","","IEEE","IEEE Journals"
"Guest Editors' Introduction: Special Section on ACM VRST","R. W. H. Lau; H. -. Seidel","Department of Computer Science, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong; Max-Planck-Institut Informatik, Stuhlsatzenhausweg 85, 66123 Saarbruecken, Germany","IEEE Transactions on Visualization and Computer Graphics","23 Jan 2006","2006","12","2","129","130","","1941-0506","","10.1109/TVCG.2006.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580447","","Layout;Virtual reality;Animation;Liquid crystal displays;Graphics;Hair;Electrostatics;Deformable models;Lattices;Context modeling","","","","","","","","23 Jan 2006","","","IEEE","IEEE Journals"
"Message from the VIS 2020 Short Paper Co-chairs","",,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","11","11","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331293","","","","","","","","","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Message from the VIS 2021 General Chairs","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","10","10","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623292","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"VIS 2019 Committees","",,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","i","ii","Provides a listing of current committee members and society officers.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933601","","","","","","","","","","19 Dec 2019","","","IEEE","IEEE Conferences"
"VIS 2020 Short Paper Committees","",,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","12","12","Provides a listing of current committee members and society officers.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331262","","","","","","","","","","1 Feb 2021","","","IEEE","IEEE Conferences"
"VIS 2021 Area Curation Committee","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","16","16","Provides a listing of current committee members and society officers.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623281","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"VIS 2021 Conference Committee","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","11","13","Provides a listing of current committee members and society officers.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623283","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"VIS 2021 Executive Committee","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","15","15","Provides a listing of current committee members and society officers.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623276","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"VIS 2021 Program Committee","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","17","20","Provides a listing of current committee members and society officers.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623277","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"VIS 2021 Steering Committee","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","14","14","Provides a listing of current committee members and society officers.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623279","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"VIS conference committee","",,"2015 IEEE Scientific Visualization Conference (SciVis)","10 Mar 2016","2015","","","1","1","Provides a listing of current committee members and society officers.","","978-1-4673-9785-8","10.1109/SciVis.2015.7429479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429479","","","","","","","","","","10 Mar 2016","","","IEEE","IEEE Conferences"
"Author Index","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","207","209","Presents an index of the authors whose articles are published in the conference proceedings record.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623311","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"Author Index","",,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","297","299","Presents an index of the authors whose articles are published in the conference proceedings record.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331266","","","","","","","","","","1 Feb 2021","","","IEEE","IEEE Conferences"
"Guest editor's introduction: special section on visualization","D. S. Ebert",University of Maryland Baltimore,"IEEE Transactions on Visualization and Computer Graphics","6 Aug 2002","2000","6","2","97","97","","1941-0506","","10.1109/TVCG.2000.856991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=856991","","Data visualization;Rendering (computer graphics);Biomedical imaging;Isosurfaces;Data mining;Time factors;Layout;Computer science;Computer graphics;Animation","","","","","","","","6 Aug 2002","","","IEEE","IEEE Journals"
"Table of Contents","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","5","9","Presents the table of contents/splash page of the proceedings record.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623304","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"Table of contents","",,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","i","iv","Presents the table of contents/splash page of the proceedings record.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933667","","","","","","","","","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Table of contents","",,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","4","10","Presents the table of contents/splash page of the proceedings record.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331298","","","","","","","","","","1 Feb 2021","","","IEEE","IEEE Conferences"
"VIS capstone address: Architectures physical and digital","M. W. Steenson",Carnegie Mellon,"2015 IEEE Scientific Visualization Conference (SciVis)","10 Mar 2016","2015","","","1","1","How do computer architectures and physical architectures inform each other? This talk will explore the interconnection of data and visualization through an architectural and computational lens over the last 50 years, including the work of Steven Coons, Christopher Alexander, Richard Saul Wurman and others.","","978-1-4673-9785-8","10.1109/SciVis.2015.7429483","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429483","","","computer architecture;data visualisation","VIS;computer architectures;physical architectures;visualization","","","","","","10 Mar 2016","","","IEEE","IEEE Conferences"
"VIS keynote address: An evolving visual language","D. J. Cox","University of Illinois, Chicago","2015 IEEE Scientific Visualization Conference (SciVis)","10 Mar 2016","2015","","","1","1","Visualization of all types of data is a highly effective tool used by researchers to gain insight into natural phenomena and to communicate their findings. It is also an increasingly popular means of presenting large scientific datasets to the general public in informal educational settings such as museums and planetaria. Visualization has appeared in many forms and in many cultures throughout digital history and contributes to the evolving visual language of science. Dr. Donna Cox and the Advanced Visualization Laboratory team at the National Center for Supercomputing Applications, University of Illinois, collaborate with science teams, writers, producers, educators, and media distribution professionals on content designed to engage a wide range of audiences. In the past 8 years alone, her collaborative educational and outreach projects have produced science narratives featuring data visualizations that have been viewed by more than 45 million people worldwide. Cox leads an NSF-funded project to create scientific visualizations and then test audiences' understanding of the phenomenon that is being presented. Large-scale computational data present unique visualization challenges for producers of high-resolution, production-quality 3D IMAX movies; feature films; and museum fulldomes. In this keynote, Cox will provide a visual feast of major projects, including new digital fulldome museum shows and award-winning IMAX films.","","978-1-4673-9785-8","10.1109/SciVis.2015.7429482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429482","","","computer aided instruction;data visualisation","data visualization;visual language;informal educational settings;Advanced Visualization Laboratory team;National Center for Supercomputing Applications;University of Illinois;production-quality 3D IMAX movies;feature films;museum fulldomes","","","","","","10 Mar 2016","","","IEEE","IEEE Conferences"
"[Copyright notice]","",,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","i","i","Presents the copyright information for the conference. May include reprint permission information.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933690","","","","","","","","","","19 Dec 2019","","","IEEE","IEEE Conferences"
"[Copyright notice]","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","4","4","Presents the copyright information for the conference. May include reprint permission information.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623290","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"[Copyright notice]","",,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","3","3","Presents the copyright information for the conference. May include reprint permission information.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331316","","","","","","","","","","1 Feb 2021","","","IEEE","IEEE Conferences"
"[Title page i]","",,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","1","1","Presents the title page of the proceedings record.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331284","","","","","","","","","","1 Feb 2021","","","IEEE","IEEE Conferences"
"[Title page i]","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","1","1","Presents the title page of the proceedings record.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623309","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
"[Title page iii]","",,"2020 IEEE Visualization Conference (VIS)","1 Feb 2021","2020","","","2","2","Presents the title page of the proceedings record.","","978-1-7281-8014-4","10.1109/VIS47514.2020.00002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331304","","","","","","","","","","1 Feb 2021","","","IEEE","IEEE Conferences"
"[Title page iii]","",,"2021 IEEE Visualization Conference (VIS)","30 Nov 2021","2021","","","3","3","Presents the title page of the proceedings record.","","978-1-6654-3335-8","10.1109/VIS49827.2021.9623325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623325","","","","","","","","","","30 Nov 2021","","","IEEE","IEEE Conferences"
